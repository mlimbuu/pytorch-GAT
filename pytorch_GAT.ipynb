{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyN1zbI6qpSHOTuGnrcnBD1t",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/mlimbuu/pytorch-GAT/blob/main/pytorch_GAT.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# SetUp Environment"
      ],
      "metadata": {
        "id": "fNbrVSkcyBPa"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# !pip install torch==2.3.0\n",
        "# !pip install networkx==3.3\n",
        "# !pip install scipy==1.13.0\n",
        "# !pip install numpy==1.26.4\n",
        "# !pip install jupyter==1.0.0"
      ],
      "metadata": {
        "id": "cGA5MPE71LTp"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Import Libraries"
      ],
      "metadata": {
        "id": "5ATgMuLA1IS3"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "import torch.optim as optim\n",
        "from torch.autograd import Variable\n",
        "\n",
        "\n",
        "import os\n",
        "import glob\n",
        "import time\n",
        "import random\n",
        "import argparse\n",
        "import numpy as np\n",
        "import scipy.sparse as sp\n",
        "\n",
        "import matplotlib.pyplot as plt\n",
        "from sklearn.manifold import TSNE"
      ],
      "metadata": {
        "id": "89h4HHBa0y-L"
      },
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Data Loading & Preprocessing"
      ],
      "metadata": {
        "id": "WjUMgR3g0s_h"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import zipfile\n",
        "with zipfile.ZipFile(\"data.zip\",\"r\") as zip_ref:\n",
        "    zip_ref.extractall(\"data\")"
      ],
      "metadata": {
        "id": "rjQmj4DZ6Me3"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def encode_onehot(labels):\n",
        "    # The classes must be sorted before encoding to enable static class encoding.\n",
        "    # In other words, make sure the first class always maps to index 0.\n",
        "    classes = sorted(list(set(labels)))\n",
        "    classes_dict = {c: np.identity(len(classes))[i, :] for i, c in enumerate(classes)}\n",
        "    labels_onehot = np.array(list(map(classes_dict.get, labels)), dtype=np.int32)\n",
        "    return labels_onehot\n",
        "\n",
        "def normalize_adj(mx):\n",
        "    \"\"\"Row-normalize sparse matrix\"\"\"\n",
        "    rowsum = np.array(mx.sum(1))\n",
        "    r_inv_sqrt = np.power(rowsum, -0.5).flatten()\n",
        "    r_inv_sqrt[np.isinf(r_inv_sqrt)] = 0.\n",
        "    r_mat_inv_sqrt = sp.diags(r_inv_sqrt)\n",
        "    return mx.dot(r_mat_inv_sqrt).transpose().dot(r_mat_inv_sqrt)\n",
        "\n",
        "def normalize_features(mx):\n",
        "    \"\"\"Row-normalize sparse matrix\"\"\"\n",
        "    rowsum = np.array(mx.sum(1))\n",
        "    r_inv = np.power(rowsum, -1).flatten()\n",
        "    r_inv[np.isinf(r_inv)] = 0.\n",
        "    r_mat_inv = sp.diags(r_inv)\n",
        "    mx = r_mat_inv.dot(mx)\n",
        "    return mx\n",
        "\n",
        "def load_data(path=\"./data/data/cora/\", dataset=\"cora\"):\n",
        "    \"\"\"Load citation network dataset (cora only for now)\"\"\"\n",
        "    print('Loading {} dataset...'.format(dataset))\n",
        "\n",
        "    idx_features_labels = np.genfromtxt(\"{}{}.content\".format(path, dataset), dtype=np.dtype(str))\n",
        "    features = sp.csr_matrix(idx_features_labels[:, 1:-1], dtype=np.float32)\n",
        "    labels = encode_onehot(idx_features_labels[:, -1])\n",
        "\n",
        "    # build graph\n",
        "    idx = np.array(idx_features_labels[:, 0], dtype=np.int32)\n",
        "    idx_map = {j: i for i, j in enumerate(idx)}\n",
        "    edges_unordered = np.genfromtxt(\"{}{}.cites\".format(path, dataset), dtype=np.int32)\n",
        "    edges = np.array(list(map(idx_map.get, edges_unordered.flatten())), dtype=np.int32).reshape(edges_unordered.shape)\n",
        "    adj = sp.coo_matrix((np.ones(edges.shape[0]), (edges[:, 0], edges[:, 1])), shape=(labels.shape[0], labels.shape[0]), dtype=np.float32)\n",
        "\n",
        "    # build symmetric adjacency matrix\n",
        "    adj = adj + adj.T.multiply(adj.T > adj) - adj.multiply(adj.T > adj)\n",
        "\n",
        "    # normalize features and adjacency matrix\n",
        "    features = normalize_features(features)\n",
        "    adj = normalize_adj(adj + sp.eye(adj.shape[0]))\n",
        "\n",
        "    idx_train = range(140)\n",
        "    idx_val = range(200, 500)\n",
        "    idx_test = range(500, 1500)\n",
        "\n",
        "    adj = torch.FloatTensor(np.array(adj.todense()))\n",
        "    features = torch.FloatTensor(np.array(features.todense()))\n",
        "    labels = torch.LongTensor(np.where(labels)[1])\n",
        "\n",
        "    idx_train = torch.LongTensor(idx_train)\n",
        "    idx_val = torch.LongTensor(idx_val)\n",
        "    idx_test = torch.LongTensor(idx_test)\n",
        "\n",
        "    return adj, features, labels, idx_train, idx_val, idx_test\n"
      ],
      "metadata": {
        "id": "pv-6omVU0sV8"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Load data\n",
        "adj, features, labels, idx_train, idx_val, idx_test = load_data()\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "eDxRlMm8yCHs",
        "outputId": "e15d4eb1-bb1a-417b-9208-b6f76d896224"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Loading cora dataset...\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# GAT Layers"
      ],
      "metadata": {
        "id": "E3OYlYTS0BdH"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "class GraphAttentionLayer(nn.Module):\n",
        "    \"\"\"\n",
        "    Simple GAT layer, similar to https://arxiv.org/abs/1710.10903\n",
        "    \"\"\"\n",
        "    def __init__(self, in_features, out_features, dropout, alpha, concat=True):\n",
        "        super(GraphAttentionLayer, self).__init__()\n",
        "        self.dropout = dropout\n",
        "        self.in_features = in_features\n",
        "        self.out_features = out_features\n",
        "        self.alpha = alpha\n",
        "        self.concat = concat\n",
        "\n",
        "        self.W = nn.Parameter(torch.empty(size=(in_features, out_features)))\n",
        "        nn.init.xavier_uniform_(self.W.data, gain=1.414)\n",
        "        self.a = nn.Parameter(torch.empty(size=(2*out_features, 1)))\n",
        "        nn.init.xavier_uniform_(self.a.data, gain=1.414)\n",
        "\n",
        "        self.leakyrelu = nn.LeakyReLU(self.alpha)\n",
        "\n",
        "    def forward(self, h, adj):\n",
        "        Wh = torch.mm(h, self.W) # h.shape: (N, in_features), Wh.shape: (N, out_features)\n",
        "        e = self._prepare_attentional_mechanism_input(Wh)\n",
        "\n",
        "        zero_vec = -9e15*torch.ones_like(e)\n",
        "        attention = torch.where(adj > 0, e, zero_vec)\n",
        "        attention = F.softmax(attention, dim=1)\n",
        "        attention = F.dropout(attention, self.dropout, training=self.training)\n",
        "        h_prime = torch.matmul(attention, Wh)\n",
        "\n",
        "        if self.concat:\n",
        "            return F.elu(h_prime)\n",
        "        else:\n",
        "            return h_prime\n",
        "\n",
        "    def _prepare_attentional_mechanism_input(self, Wh):\n",
        "        # Wh.shape (N, out_feature)\n",
        "        # self.a.shape (2 * out_feature, 1)\n",
        "        # Wh1&2.shape (N, 1)\n",
        "        # e.shape (N, N)\n",
        "        Wh1 = torch.matmul(Wh, self.a[:self.out_features, :])\n",
        "        Wh2 = torch.matmul(Wh, self.a[self.out_features:, :])\n",
        "        # broadcast add\n",
        "        e = Wh1 + Wh2.T\n",
        "        return self.leakyrelu(e)\n",
        "\n",
        "    def __repr__(self):\n",
        "        return self.__class__.__name__ + ' (' + str(self.in_features) + ' -> ' + str(self.out_features) + ')'\n"
      ],
      "metadata": {
        "id": "95fJp5vm0N5H"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# GAT Model"
      ],
      "metadata": {
        "id": "e3qdm_y_0Omp"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "class GAT(nn.Module):\n",
        "    def __init__(self, nfeat, nhid, nclass, dropout, alpha, nheads):\n",
        "        \"\"\"Dense version of GAT.\"\"\"\n",
        "        super(GAT, self).__init__()\n",
        "        self.dropout = dropout\n",
        "\n",
        "        self.attentions = [GraphAttentionLayer(nfeat, nhid, dropout=dropout, alpha=alpha, concat=True) for _ in range(nheads)]\n",
        "        for i, attention in enumerate(self.attentions):\n",
        "            self.add_module('attention_{}'.format(i), attention)\n",
        "\n",
        "        self.out_att = GraphAttentionLayer(nhid * nheads, nclass, dropout=dropout, alpha=alpha, concat=False)\n",
        "\n",
        "    def forward(self, x, adj):\n",
        "        x = F.dropout(x, self.dropout, training=self.training)\n",
        "        x = torch.cat([att(x, adj) for att in self.attentions], dim=1)\n",
        "        x = F.dropout(x, self.dropout, training=self.training)\n",
        "        x = F.elu(self.out_att(x, adj))\n",
        "        return F.log_softmax(x, dim=1)"
      ],
      "metadata": {
        "id": "q6Y7QNdi0Q3r"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Model Traning"
      ],
      "metadata": {
        "id": "9ntq3C6G0hMq"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Parameters\n",
        "seed = 72\n",
        "epochs = 1000\n",
        "lr = 0.005\n",
        "weight_decay = 5e-4\n",
        "hidden = 8\n",
        "nb_heads = 8\n",
        "dropout = 0.6\n",
        "alpha = 0.2\n",
        "patience = 100"
      ],
      "metadata": {
        "id": "5WBP5T8YEqWN"
      },
      "execution_count": 54,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Initialize model\n",
        "model = GAT(nfeat=features.shape[1], nhid=hidden, nclass=int(labels.max()) + 1, dropout=dropout, nheads=nb_heads, alpha=alpha)\n",
        "optimizer = optim.Adam(model.parameters(), lr=lr, weight_decay=weight_decay)\n"
      ],
      "metadata": {
        "id": "ucKc9hlF0qWS"
      },
      "execution_count": 55,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Training & Test\n",
        "\n",
        "def accuracy(output, labels):\n",
        "    preds = output.max(1)[1].type_as(labels)\n",
        "    correct = preds.eq(labels).double()\n",
        "    correct = correct.sum()\n",
        "    return correct / len(labels)\n",
        "\n",
        "def train(epoch):\n",
        "    t = time.time()\n",
        "    model.train()\n",
        "    optimizer.zero_grad()\n",
        "    output = model(features, adj)\n",
        "    loss_train = F.nll_loss(output[idx_train], labels[idx_train])\n",
        "    acc_train = accuracy(output[idx_train], labels[idx_train])\n",
        "    loss_train.backward()\n",
        "    optimizer.step()\n",
        "\n",
        "    loss_val = F.nll_loss(output[idx_val], labels[idx_val])\n",
        "    acc_val = accuracy(output[idx_val], labels[idx_val])\n",
        "    print('Epoch: {:04d}'.format(epoch+1),\n",
        "          'loss_train: {:.4f}'.format(loss_train.data.item()),\n",
        "          'acc_train: {:.4f}'.format(acc_train.data.item()),\n",
        "          'loss_val: {:.4f}'.format(loss_val.data.item()),\n",
        "          'acc_val: {:.4f}'.format(acc_val.data.item()),\n",
        "          'time: {:.4f}s'.format(time.time() - t))\n",
        "\n",
        "    return loss_val, acc_val, output\n",
        "\n",
        "def test():\n",
        "    model.eval()\n",
        "    output = model(features, adj)\n",
        "    loss_test = F.nll_loss(output[idx_test], labels[idx_test])\n",
        "    acc_test = accuracy(output[idx_test], labels[idx_test])\n",
        "    print(\"Test set results:\",\n",
        "          \"loss= {:.4f}\".format(loss_test.data.item()),\n",
        "          \"accuracy= {:.4f}\".format(acc_test.data.item()))\n"
      ],
      "metadata": {
        "id": "P1sD4LsOFvh-"
      },
      "execution_count": 56,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "val_acc_list = []\n",
        "val_loss_list = []\n",
        "\n",
        "# Training model\n",
        "for epoch in range(epochs):\n",
        "    print(f\"Training: {epoch}\")\n",
        "    val_loss, val_acc, out_features = train(epoch)\n",
        "    print(f\"loss_val:{val_loss}, val_acc:{val_acc}, out_features:{out_features}\")\n",
        "    # val_acc_list.append(val_acc.item())\n",
        "    # val_loss_list.append(loss_val.item())\n",
        "    val_loss_list.append(val_loss.item())\n",
        "    val_acc_list.append(val_acc.item())\n",
        "\n",
        "\n",
        "# Testing model\n",
        "test()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cKSfkg69lLz3",
        "outputId": "c7500675-0079-48e8-8d83-8bdbcd677135"
      },
      "execution_count": 57,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1;30;43mStreaming output truncated to the last 5000 lines.\u001b[0m\n",
            "        [-7.9953e+00, -8.2567e+00, -7.5007e+00,  ..., -1.6302e-03,\n",
            "         -8.7006e+00, -8.6908e+00],\n",
            "        ...,\n",
            "        [-4.5631e+00, -7.4365e-02, -5.0968e+00,  ..., -4.7995e+00,\n",
            "         -3.6298e+00, -4.2223e+00],\n",
            "        [-1.7941e-01, -4.2953e+00, -4.1590e+00,  ..., -2.9588e+00,\n",
            "         -2.8283e+00, -4.3833e+00],\n",
            "        [-4.7095e+00, -4.1338e+00, -5.4685e-02,  ..., -4.6098e+00,\n",
            "         -4.9341e+00, -5.1261e+00]], grad_fn=<LogSoftmaxBackward0>)\n",
            "Training: 609\n",
            "Epoch: 0610 loss_train: 0.6513 acc_train: 0.7929 loss_val: 1.0761 acc_val: 0.6533 time: 4.2092s\n",
            "loss_val:1.0760871171951294, val_acc:0.6533333333333333, out_features:tensor([[-7.8207e+00, -6.1204e+00, -5.3733e-03,  ..., -7.3589e+00,\n",
            "         -7.6849e+00, -7.6438e+00],\n",
            "        [-1.9459e+00, -1.9459e+00, -1.9459e+00,  ..., -1.9459e+00,\n",
            "         -1.9459e+00, -1.9459e+00],\n",
            "        [-6.6661e+00, -6.3673e+00, -6.7148e+00,  ..., -8.5098e-03,\n",
            "         -6.1217e+00, -6.6813e+00],\n",
            "        ...,\n",
            "        [-1.9979e+00, -1.4629e+00, -2.0570e+00,  ..., -2.5043e+00,\n",
            "         -2.3100e+00, -1.3856e+00],\n",
            "        [-8.8473e-01, -2.6819e+00, -2.5177e+00,  ..., -2.1690e+00,\n",
            "         -1.9276e+00, -2.4207e+00],\n",
            "        [-3.5551e+00, -4.1936e+00, -1.8468e-01,  ..., -3.8657e+00,\n",
            "         -3.2859e+00, -3.2361e+00]], grad_fn=<LogSoftmaxBackward0>)\n",
            "Training: 610\n",
            "Epoch: 0611 loss_train: 0.6108 acc_train: 0.8143 loss_val: 1.1232 acc_val: 0.6500 time: 4.3275s\n",
            "loss_val:1.1231878995895386, val_acc:0.65, out_features:tensor([[-3.3053, -3.3124, -0.2702,  ..., -3.3514, -3.0254, -3.1014],\n",
            "        [-1.9459, -1.9459, -1.9459,  ..., -1.9459, -1.9459, -1.9459],\n",
            "        [-1.6492, -2.3314, -2.8021,  ..., -0.9519, -2.0811, -2.5701],\n",
            "        ...,\n",
            "        [-1.9459, -1.9459, -1.9459,  ..., -1.9459, -1.9459, -1.9459],\n",
            "        [-1.9459, -1.9459, -1.9459,  ..., -1.9459, -1.9459, -1.9459],\n",
            "        [-4.3281, -4.7158, -0.1484,  ..., -4.7969, -4.0567, -4.7488]],\n",
            "       grad_fn=<LogSoftmaxBackward0>)\n",
            "Training: 611\n",
            "Epoch: 0612 loss_train: 0.6727 acc_train: 0.7929 loss_val: 0.9396 acc_val: 0.6900 time: 4.2030s\n",
            "loss_val:0.9396474957466125, val_acc:0.69, out_features:tensor([[-5.0398e+00, -4.9861e+00, -1.1349e-01,  ..., -4.4960e+00,\n",
            "         -4.9003e+00, -2.6866e+00],\n",
            "        [-2.5953e+00, -3.0948e+00, -2.4252e+00,  ..., -1.9455e+00,\n",
            "         -1.1322e+00, -1.2372e+00],\n",
            "        [-7.3328e+00, -6.3246e+00, -7.9694e+00,  ..., -5.1946e-03,\n",
            "         -6.5150e+00, -7.4826e+00],\n",
            "        ...,\n",
            "        [-5.7574e+00, -2.1506e-02, -6.1913e+00,  ..., -5.0979e+00,\n",
            "         -5.2323e+00, -5.9085e+00],\n",
            "        [-7.2111e-01, -2.0814e+00, -3.2155e+00,  ..., -2.5797e+00,\n",
            "         -1.8618e+00, -2.7311e+00],\n",
            "        [-3.8308e+00, -4.4010e+00, -1.1514e-01,  ..., -3.1688e+00,\n",
            "         -4.6018e+00, -4.2023e+00]], grad_fn=<LogSoftmaxBackward0>)\n",
            "Training: 612\n",
            "Epoch: 0613 loss_train: 0.5896 acc_train: 0.7857 loss_val: 1.0740 acc_val: 0.6567 time: 4.3560s\n",
            "loss_val:1.0739617347717285, val_acc:0.6566666666666666, out_features:tensor([[-8.1485e+00, -7.7585e+00, -3.5545e-03,  ..., -6.3370e+00,\n",
            "         -8.1650e+00, -8.1015e+00],\n",
            "        [-1.6350e+00, -5.2408e+00, -5.0843e+00,  ..., -1.3565e+00,\n",
            "         -8.2795e-01, -2.3642e+00],\n",
            "        [-2.4608e+00, -2.3724e+00, -2.0966e+00,  ..., -7.4540e-01,\n",
            "         -2.5624e+00, -2.4404e+00],\n",
            "        ...,\n",
            "        [-5.6821e+00, -2.6591e-02, -5.5620e+00,  ..., -5.7027e+00,\n",
            "         -5.7481e+00, -4.6528e+00],\n",
            "        [-5.2551e-01, -3.2172e+00, -3.5336e+00,  ..., -2.0140e+00,\n",
            "         -2.1236e+00, -3.0268e+00],\n",
            "        [-5.6263e+00, -5.7918e+00, -3.1049e-02,  ..., -5.1691e+00,\n",
            "         -5.5745e+00, -5.9644e+00]], grad_fn=<LogSoftmaxBackward0>)\n",
            "Training: 613\n",
            "Epoch: 0614 loss_train: 0.6395 acc_train: 0.7929 loss_val: 1.0281 acc_val: 0.6400 time: 4.3642s\n",
            "loss_val:1.0280563831329346, val_acc:0.64, out_features:tensor([[-9.1764e+00, -8.9436e+00, -3.5929e-03,  ..., -9.0196e+00,\n",
            "         -9.1672e+00, -8.2530e+00],\n",
            "        [-1.9459e+00, -1.9459e+00, -1.9459e+00,  ..., -1.9459e+00,\n",
            "         -1.9459e+00, -1.9459e+00],\n",
            "        [-8.2513e+00, -7.2660e+00, -8.1305e+00,  ..., -2.1668e-03,\n",
            "         -8.4029e+00, -7.6466e+00],\n",
            "        ...,\n",
            "        [-2.6007e+00, -6.2578e-01, -2.9219e+00,  ..., -2.3027e+00,\n",
            "         -2.4090e+00, -2.6497e+00],\n",
            "        [-7.3305e-01, -2.0994e+00, -3.0511e+00,  ..., -2.4556e+00,\n",
            "         -2.4515e+00, -2.3698e+00],\n",
            "        [-1.9459e+00, -1.9459e+00, -1.9459e+00,  ..., -1.9459e+00,\n",
            "         -1.9459e+00, -1.9459e+00]], grad_fn=<LogSoftmaxBackward0>)\n",
            "Training: 614\n",
            "Epoch: 0615 loss_train: 0.5914 acc_train: 0.8500 loss_val: 1.0970 acc_val: 0.6633 time: 4.1073s\n",
            "loss_val:1.096968173980713, val_acc:0.6633333333333333, out_features:tensor([[-4.9934, -4.8117, -0.0733,  ..., -4.4141, -5.1237, -4.2562],\n",
            "        [-4.7895, -6.2139, -6.5852,  ..., -1.2080, -0.9368, -1.2164],\n",
            "        [-5.6120, -6.6108, -6.5999,  ..., -0.0119, -6.2036, -6.0255],\n",
            "        ...,\n",
            "        [-4.5620, -0.0701, -5.1299,  ..., -3.4816, -4.7203, -5.0744],\n",
            "        [-0.2322, -3.8813, -3.1948,  ..., -3.2916, -3.2693, -3.4503],\n",
            "        [-1.9459, -1.9459, -1.9459,  ..., -1.9459, -1.9459, -1.9459]],\n",
            "       grad_fn=<LogSoftmaxBackward0>)\n",
            "Training: 615\n",
            "Epoch: 0616 loss_train: 0.5854 acc_train: 0.8643 loss_val: 1.0103 acc_val: 0.6967 time: 4.2184s\n",
            "loss_val:1.0103005170822144, val_acc:0.6966666666666667, out_features:tensor([[-1.0082e+01, -9.0359e+00, -4.7684e-04,  ..., -9.2729e+00,\n",
            "         -1.0074e+01, -9.6401e+00],\n",
            "        [-1.7775e+00, -2.7029e+00, -1.8504e+00,  ..., -2.4342e+00,\n",
            "         -1.2419e+00, -1.8347e+00],\n",
            "        [-3.9614e+00, -3.2282e+00, -3.5832e+00,  ..., -1.7593e-01,\n",
            "         -3.5650e+00, -3.4343e+00],\n",
            "        ...,\n",
            "        [-3.9352e+00, -3.0094e-01, -4.2906e+00,  ..., -2.7310e+00,\n",
            "         -2.1397e+00, -3.7710e+00],\n",
            "        [-7.4745e-01, -2.4749e+00, -3.0078e+00,  ..., -2.2052e+00,\n",
            "         -2.3436e+00, -2.6828e+00],\n",
            "        [-5.7716e+00, -6.4670e+00, -1.4378e-02,  ..., -6.9031e+00,\n",
            "         -5.1158e+00, -6.8592e+00]], grad_fn=<LogSoftmaxBackward0>)\n",
            "Training: 616\n",
            "Epoch: 0617 loss_train: 0.6309 acc_train: 0.8357 loss_val: 1.0290 acc_val: 0.6467 time: 4.4559s\n",
            "loss_val:1.0289738178253174, val_acc:0.6466666666666666, out_features:tensor([[-2.7454, -2.2983, -0.8209,  ..., -2.1486, -2.5354, -2.5312],\n",
            "        [-5.7554, -5.3351, -6.2808,  ..., -4.5065, -0.0341, -4.5254],\n",
            "        [-3.8125, -3.4036, -3.8227,  ..., -0.1631, -3.3583, -3.8171],\n",
            "        ...,\n",
            "        [-2.6261, -0.6362, -2.7148,  ..., -2.3042, -2.0677, -2.9913],\n",
            "        [-1.1978, -2.5899, -2.6419,  ..., -1.6461, -1.7602, -2.0726],\n",
            "        [-1.9459, -1.9459, -1.9459,  ..., -1.9459, -1.9459, -1.9459]],\n",
            "       grad_fn=<LogSoftmaxBackward0>)\n",
            "Training: 617\n",
            "Epoch: 0618 loss_train: 0.6440 acc_train: 0.8286 loss_val: 1.1699 acc_val: 0.6567 time: 4.1341s\n",
            "loss_val:1.1699011325836182, val_acc:0.6566666666666666, out_features:tensor([[-9.1337e+00, -9.1400e+00, -8.3995e-04,  ..., -8.8424e+00,\n",
            "         -9.3042e+00, -9.2647e+00],\n",
            "        [-5.8991e+00, -5.6384e+00, -6.0149e+00,  ..., -5.9617e+00,\n",
            "         -3.0510e-01, -1.4486e+00],\n",
            "        [-3.5060e+00, -2.9943e+00, -2.4918e+00,  ..., -3.1350e-01,\n",
            "         -3.5530e+00, -3.3203e+00],\n",
            "        ...,\n",
            "        [-2.4015e+00, -1.4045e+00, -1.8876e+00,  ..., -2.5023e+00,\n",
            "         -1.5798e+00, -2.0066e+00],\n",
            "        [-3.6740e-01, -2.9725e+00, -3.6341e+00,  ..., -3.4440e+00,\n",
            "         -2.5903e+00, -2.9891e+00],\n",
            "        [-8.9110e+00, -7.5646e+00, -1.2926e-03,  ..., -8.7379e+00,\n",
            "         -8.4448e+00, -8.8978e+00]], grad_fn=<LogSoftmaxBackward0>)\n",
            "Training: 618\n",
            "Epoch: 0619 loss_train: 0.7302 acc_train: 0.7571 loss_val: 1.0360 acc_val: 0.6600 time: 4.4457s\n",
            "loss_val:1.0359750986099243, val_acc:0.66, out_features:tensor([[-3.9145, -3.7161, -0.1940,  ..., -2.9924, -3.7106, -3.8490],\n",
            "        [-4.8453, -7.9138, -7.9253,  ..., -1.1883, -0.4482, -3.0454],\n",
            "        [-4.0647, -3.8723, -3.7434,  ..., -0.1140, -3.9073, -4.4714],\n",
            "        ...,\n",
            "        [-1.9459, -1.9459, -1.9459,  ..., -1.9459, -1.9459, -1.9459],\n",
            "        [-0.6559, -3.2820, -3.5712,  ..., -2.3126, -2.3096, -1.8724],\n",
            "        [-5.0525, -5.1288, -0.0673,  ..., -4.7949, -5.1093, -4.9793]],\n",
            "       grad_fn=<LogSoftmaxBackward0>)\n",
            "Training: 619\n",
            "Epoch: 0620 loss_train: 0.6510 acc_train: 0.8286 loss_val: 1.0176 acc_val: 0.6667 time: 4.2998s\n",
            "loss_val:1.0176458358764648, val_acc:0.6666666666666666, out_features:tensor([[-3.0106, -2.4669, -0.5050,  ..., -3.0948, -2.6103, -2.9260],\n",
            "        [-2.1527, -3.4691, -2.4135,  ..., -2.0639, -0.8636, -1.6873],\n",
            "        [-2.0013, -2.8536, -2.8242,  ..., -0.8002, -1.9399, -2.4353],\n",
            "        ...,\n",
            "        [-2.6706, -0.6735, -2.1743,  ..., -2.2896, -2.3422, -2.7899],\n",
            "        [-0.0233, -6.6477, -6.3900,  ..., -4.2334, -6.1857, -6.1596],\n",
            "        [-5.0259, -5.3254, -0.0334,  ..., -5.4855, -4.9171, -5.0269]],\n",
            "       grad_fn=<LogSoftmaxBackward0>)\n",
            "Training: 620\n",
            "Epoch: 0621 loss_train: 0.6229 acc_train: 0.8214 loss_val: 1.0307 acc_val: 0.6833 time: 4.1694s\n",
            "loss_val:1.0306732654571533, val_acc:0.6833333333333333, out_features:tensor([[-1.2643e+01, -1.2440e+01, -2.8371e-05,  ..., -1.2434e+01,\n",
            "         -1.2416e+01, -1.1998e+01],\n",
            "        [-2.8748e+00, -3.0671e+00, -3.2379e+00,  ..., -2.9607e+00,\n",
            "         -1.0602e+00, -8.4268e-01],\n",
            "        [-1.0899e+01, -1.0365e+01, -1.1243e+01,  ..., -1.2910e-04,\n",
            "         -1.0851e+01, -1.0285e+01],\n",
            "        ...,\n",
            "        [-3.9056e+00, -3.5607e-01, -2.0939e+00,  ..., -2.4261e+00,\n",
            "         -3.1882e+00, -4.2284e+00],\n",
            "        [-3.6958e-03, -7.2067e+00, -8.2353e+00,  ..., -7.2206e+00,\n",
            "         -6.5947e+00, -8.1244e+00],\n",
            "        [-5.6616e+00, -5.1733e+00, -2.8155e-02,  ..., -5.1988e+00,\n",
            "         -5.7790e+00, -5.4827e+00]], grad_fn=<LogSoftmaxBackward0>)\n",
            "Training: 621\n",
            "Epoch: 0622 loss_train: 0.6753 acc_train: 0.8071 loss_val: 0.9997 acc_val: 0.6933 time: 4.4662s\n",
            "loss_val:0.99965900182724, val_acc:0.6933333333333334, out_features:tensor([[-3.9884, -3.8712, -0.2181,  ..., -3.7687, -3.8253, -2.6996],\n",
            "        [-4.9658, -4.8899, -2.2377,  ..., -4.8650, -0.5844, -1.1787],\n",
            "        [-2.6120, -2.9661, -2.4154,  ..., -0.5218, -2.7850, -2.5290],\n",
            "        ...,\n",
            "        [-5.3389, -0.0458, -4.2853,  ..., -4.4535, -5.1128, -5.5281],\n",
            "        [-1.2963, -2.2123, -2.4793,  ..., -2.2269, -1.6610, -1.9912],\n",
            "        [-1.9459, -1.9459, -1.9459,  ..., -1.9459, -1.9459, -1.9459]],\n",
            "       grad_fn=<LogSoftmaxBackward0>)\n",
            "Training: 622\n",
            "Epoch: 0623 loss_train: 0.5837 acc_train: 0.8429 loss_val: 1.0222 acc_val: 0.6767 time: 4.1994s\n",
            "loss_val:1.0221803188323975, val_acc:0.6766666666666666, out_features:tensor([[-5.2772e+00, -5.4925e+00, -5.2220e-02,  ..., -5.0221e+00,\n",
            "         -5.6880e+00, -3.9041e+00],\n",
            "        [-4.0451e+00, -8.6021e+00, -8.7218e+00,  ..., -8.6059e+00,\n",
            "         -1.8538e-02, -8.4642e+00],\n",
            "        [-3.6340e+00, -2.2782e+00, -4.0558e+00,  ..., -2.5243e-01,\n",
            "         -3.4918e+00, -3.5817e+00],\n",
            "        ...,\n",
            "        [-5.8618e+00, -1.8421e-02, -6.4012e+00,  ..., -4.8946e+00,\n",
            "         -5.9804e+00, -6.1050e+00],\n",
            "        [-1.4327e-02, -5.9096e+00, -6.6698e+00,  ..., -5.8172e+00,\n",
            "         -5.3657e+00, -6.5429e+00],\n",
            "        [-7.9378e+00, -8.0674e+00, -2.9740e-03,  ..., -7.7788e+00,\n",
            "         -6.8478e+00, -7.6257e+00]], grad_fn=<LogSoftmaxBackward0>)\n",
            "Training: 623\n",
            "Epoch: 0624 loss_train: 0.6235 acc_train: 0.7857 loss_val: 1.0981 acc_val: 0.6600 time: 4.1266s\n",
            "loss_val:1.0980761051177979, val_acc:0.66, out_features:tensor([[-1.9459, -1.9459, -1.9459,  ..., -1.9459, -1.9459, -1.9459],\n",
            "        [-4.5690, -4.3502, -5.2446,  ..., -4.7385, -0.0622, -4.1095],\n",
            "        [-3.6527, -4.3569, -4.0449,  ..., -0.0983, -3.9964, -4.5441],\n",
            "        ...,\n",
            "        [-6.0358, -0.0212, -6.4224,  ..., -5.2095, -4.8387, -6.2401],\n",
            "        [-2.1304, -2.5279, -2.1709,  ..., -2.5351, -1.8247, -1.6757],\n",
            "        [-6.2341, -7.0280, -0.0083,  ..., -7.2165, -5.8803, -7.1703]],\n",
            "       grad_fn=<LogSoftmaxBackward0>)\n",
            "Training: 624\n",
            "Epoch: 0625 loss_train: 0.7329 acc_train: 0.7857 loss_val: 1.0206 acc_val: 0.6700 time: 4.3397s\n",
            "loss_val:1.0206387042999268, val_acc:0.67, out_features:tensor([[-4.7123e+00, -4.7164e+00, -9.4394e-02,  ..., -3.9919e+00,\n",
            "         -4.4835e+00, -4.0599e+00],\n",
            "        [-1.0601e+01, -1.3004e+01, -1.3076e+01,  ..., -1.2997e+01,\n",
            "         -7.7721e-05, -1.3069e+01],\n",
            "        [-1.9459e+00, -1.9459e+00, -1.9459e+00,  ..., -1.9459e+00,\n",
            "         -1.9459e+00, -1.9459e+00],\n",
            "        ...,\n",
            "        [-2.1909e+00, -1.4057e+00, -2.2426e+00,  ..., -2.3410e+00,\n",
            "         -1.6036e+00, -1.7763e+00],\n",
            "        [-2.9705e-01, -2.3557e+00, -4.0380e+00,  ..., -2.7247e+00,\n",
            "         -3.4220e+00, -3.5328e+00],\n",
            "        [-3.1754e+00, -3.4497e+00, -2.2257e-01,  ..., -3.8575e+00,\n",
            "         -3.1001e+00, -4.0412e+00]], grad_fn=<LogSoftmaxBackward0>)\n",
            "Training: 625\n",
            "Epoch: 0626 loss_train: 0.5664 acc_train: 0.8429 loss_val: 1.0760 acc_val: 0.6467 time: 4.1029s\n",
            "loss_val:1.0760468244552612, val_acc:0.6466666666666666, out_features:tensor([[-6.2992, -6.4609, -0.0100,  ..., -6.0608, -6.5337, -6.6252],\n",
            "        [-5.4706, -5.6232, -6.0806,  ..., -6.0108, -0.2311, -4.3437],\n",
            "        [-2.5225, -2.2296, -2.6139,  ..., -0.8284, -2.3965, -1.9664],\n",
            "        ...,\n",
            "        [-3.2744, -0.1947, -4.3940,  ..., -3.7601, -3.0125, -3.1905],\n",
            "        [-0.5063, -3.4533, -3.7962,  ..., -1.8671, -2.3904, -3.4908],\n",
            "        [-1.9459, -1.9459, -1.9459,  ..., -1.9459, -1.9459, -1.9459]],\n",
            "       grad_fn=<LogSoftmaxBackward0>)\n",
            "Training: 626\n",
            "Epoch: 0627 loss_train: 0.6439 acc_train: 0.8000 loss_val: 1.0497 acc_val: 0.7000 time: 4.2647s\n",
            "loss_val:1.049707055091858, val_acc:0.7, out_features:tensor([[-1.3658e+01, -1.3632e+01, -5.9960e-05,  ..., -1.3612e+01,\n",
            "         -1.3642e+01, -1.2204e+01],\n",
            "        [-3.1987e+00, -7.2986e+00, -7.3624e+00,  ..., -5.1315e+00,\n",
            "         -6.6917e-02, -4.1295e+00],\n",
            "        [-2.1241e+00, -2.1649e+00, -2.8107e+00,  ..., -7.5257e-01,\n",
            "         -2.3548e+00, -2.3814e+00],\n",
            "        ...,\n",
            "        [-5.1938e+00, -4.1510e-02, -4.8517e+00,  ..., -4.5915e+00,\n",
            "         -4.8698e+00, -5.1909e+00],\n",
            "        [-5.1499e-02, -5.6733e+00, -5.7482e+00,  ..., -3.7580e+00,\n",
            "         -4.5989e+00, -5.4655e+00],\n",
            "        [-1.9459e+00, -1.9459e+00, -1.9459e+00,  ..., -1.9459e+00,\n",
            "         -1.9459e+00, -1.9459e+00]], grad_fn=<LogSoftmaxBackward0>)\n",
            "Training: 627\n",
            "Epoch: 0628 loss_train: 0.6522 acc_train: 0.8071 loss_val: 0.9736 acc_val: 0.6833 time: 4.4563s\n",
            "loss_val:0.9736126661300659, val_acc:0.6833333333333333, out_features:tensor([[-6.2010e+00, -5.9186e+00, -5.6237e-02,  ..., -4.0682e+00,\n",
            "         -6.1581e+00, -5.7586e+00],\n",
            "        [-2.3586e+00, -1.5721e+00, -3.5879e+00,  ..., -2.5067e+00,\n",
            "         -6.9114e-01, -2.9637e+00],\n",
            "        [-7.2900e+00, -8.7401e+00, -9.0242e+00,  ..., -1.5799e-03,\n",
            "         -8.5230e+00, -8.1087e+00],\n",
            "        ...,\n",
            "        [-2.8961e+00, -9.5161e-01, -2.5720e+00,  ..., -1.9459e+00,\n",
            "         -2.2525e+00, -2.5191e+00],\n",
            "        [-2.9026e-02, -7.0122e+00, -7.2585e+00,  ..., -3.9289e+00,\n",
            "         -5.2343e+00, -6.8008e+00],\n",
            "        [-2.3782e+00, -2.2520e+00, -2.2260e+00,  ..., -2.6263e+00,\n",
            "         -2.1560e+00, -1.3404e+00]], grad_fn=<LogSoftmaxBackward0>)\n",
            "Training: 628\n",
            "Epoch: 0629 loss_train: 0.6234 acc_train: 0.8429 loss_val: 1.0240 acc_val: 0.6600 time: 4.1698s\n",
            "loss_val:1.0240246057510376, val_acc:0.66, out_features:tensor([[-9.8575e+00, -1.0027e+01, -6.9749e-04,  ..., -9.9515e+00,\n",
            "         -1.0036e+01, -8.6057e+00],\n",
            "        [-1.9459e+00, -1.9459e+00, -1.9459e+00,  ..., -1.9459e+00,\n",
            "         -1.9459e+00, -1.9459e+00],\n",
            "        [-1.9216e+00, -2.7148e+00, -2.7970e+00,  ..., -1.1343e+00,\n",
            "         -1.7587e+00, -1.7764e+00],\n",
            "        ...,\n",
            "        [-2.4136e+00, -1.0215e+00, -2.2510e+00,  ..., -2.4415e+00,\n",
            "         -2.4238e+00, -2.0950e+00],\n",
            "        [-9.6598e-01, -3.3088e+00, -3.5378e+00,  ..., -1.9410e+00,\n",
            "         -1.8747e+00, -1.5490e+00],\n",
            "        [-2.0638e+00, -2.2002e+00, -1.5153e+00,  ..., -1.7655e+00,\n",
            "         -2.0110e+00, -2.1506e+00]], grad_fn=<LogSoftmaxBackward0>)\n",
            "Training: 629\n",
            "Epoch: 0630 loss_train: 0.5579 acc_train: 0.8143 loss_val: 1.0616 acc_val: 0.6700 time: 4.1278s\n",
            "loss_val:1.0615819692611694, val_acc:0.67, out_features:tensor([[-3.2149e+00, -2.7180e+00, -5.2562e-01,  ..., -2.7648e+00,\n",
            "         -3.2269e+00, -2.3373e+00],\n",
            "        [-1.9459e+00, -1.9459e+00, -1.9459e+00,  ..., -1.9459e+00,\n",
            "         -1.9459e+00, -1.9459e+00],\n",
            "        [-7.6320e+00, -6.8748e+00, -7.7148e+00,  ..., -2.9384e-03,\n",
            "         -7.9403e+00, -7.9524e+00],\n",
            "        ...,\n",
            "        [-2.3671e+00, -5.9140e-01, -3.1954e+00,  ..., -2.0714e+00,\n",
            "         -2.8271e+00, -2.3333e+00],\n",
            "        [-7.1121e-01, -3.3012e+00, -3.2150e+00,  ..., -1.4977e+00,\n",
            "         -2.6333e+00, -2.3508e+00],\n",
            "        [-5.2831e+00, -5.5484e+00, -5.2880e-02,  ..., -3.5163e+00,\n",
            "         -5.2350e+00, -5.6992e+00]], grad_fn=<LogSoftmaxBackward0>)\n",
            "Training: 630\n",
            "Epoch: 0631 loss_train: 0.6330 acc_train: 0.8357 loss_val: 1.0819 acc_val: 0.6533 time: 4.4366s\n",
            "loss_val:1.0819246768951416, val_acc:0.6533333333333333, out_features:tensor([[-5.7011, -5.4616, -0.0325,  ..., -5.3502, -5.6444, -4.7546],\n",
            "        [-2.2507, -2.4636, -1.7047,  ..., -1.6648, -1.4239, -1.9251],\n",
            "        [-2.5211, -3.7995, -3.7152,  ..., -0.2967, -2.8178, -3.0634],\n",
            "        ...,\n",
            "        [-3.0051, -0.4360, -2.8040,  ..., -2.7382, -2.8345, -2.7734],\n",
            "        [-0.7594, -2.2134, -2.4974,  ..., -2.0650, -2.4364, -2.7667],\n",
            "        [-6.4834, -6.0738, -0.0143,  ..., -6.8189, -5.7692, -5.3472]],\n",
            "       grad_fn=<LogSoftmaxBackward0>)\n",
            "Training: 631\n",
            "Epoch: 0632 loss_train: 0.5694 acc_train: 0.8286 loss_val: 1.0130 acc_val: 0.6700 time: 4.0881s\n",
            "loss_val:1.0129752159118652, val_acc:0.67, out_features:tensor([[-6.2516e+00, -5.8787e+00, -1.5719e-02,  ..., -6.1734e+00,\n",
            "         -5.9131e+00, -5.6755e+00],\n",
            "        [-2.8629e+00, -4.0962e+00, -4.2502e+00,  ..., -2.7751e+00,\n",
            "         -3.3420e-01, -2.1138e+00],\n",
            "        [-6.3903e+00, -7.4319e+00, -7.8176e+00,  ..., -5.8931e-03,\n",
            "         -6.5206e+00, -6.6181e+00],\n",
            "        ...,\n",
            "        [-4.8486e+00, -9.3296e-02, -5.2642e+00,  ..., -4.0100e+00,\n",
            "         -4.8020e+00, -3.1304e+00],\n",
            "        [-1.3038e-01, -4.5771e+00, -4.7697e+00,  ..., -3.2015e+00,\n",
            "         -3.0108e+00, -4.8896e+00],\n",
            "        [-1.2646e+01, -1.1275e+01, -2.8133e-05,  ..., -1.2707e+01,\n",
            "         -1.2533e+01, -1.2775e+01]], grad_fn=<LogSoftmaxBackward0>)\n",
            "Training: 632\n",
            "Epoch: 0633 loss_train: 0.5609 acc_train: 0.8357 loss_val: 0.9724 acc_val: 0.6900 time: 4.2921s\n",
            "loss_val:0.9723959565162659, val_acc:0.69, out_features:tensor([[-6.0930, -6.1513, -0.0325,  ..., -4.3192, -6.0146, -5.3737],\n",
            "        [-1.9459, -1.9459, -1.9459,  ..., -1.9459, -1.9459, -1.9459],\n",
            "        [-3.5928, -3.8988, -4.2656,  ..., -0.1206, -3.8773, -3.8256],\n",
            "        ...,\n",
            "        [-3.8215, -0.2008, -4.3204,  ..., -3.1805, -2.9642, -3.2153],\n",
            "        [-0.2212, -4.3071, -4.3492,  ..., -2.6221, -3.5923, -2.8316],\n",
            "        [-4.2832, -4.0521, -0.1468,  ..., -3.8111, -3.0227, -4.1470]],\n",
            "       grad_fn=<LogSoftmaxBackward0>)\n",
            "Training: 633\n",
            "Epoch: 0634 loss_train: 0.7049 acc_train: 0.8000 loss_val: 1.0855 acc_val: 0.6333 time: 4.4257s\n",
            "loss_val:1.0854628086090088, val_acc:0.6333333333333333, out_features:tensor([[-2.4990, -2.2077, -0.9116,  ..., -2.4739, -2.3461, -2.5187],\n",
            "        [-1.9459, -1.9459, -1.9459,  ..., -1.9459, -1.9459, -1.9459],\n",
            "        [-1.8779, -2.2700, -2.1886,  ..., -1.0005, -2.3883, -2.3023],\n",
            "        ...,\n",
            "        [-3.6878, -0.1508, -4.7338,  ..., -3.0564, -3.6207, -3.7265],\n",
            "        [-1.2261, -2.2779, -2.4717,  ..., -1.6302, -2.1346, -2.1354],\n",
            "        [-3.4813, -2.0620, -0.4257,  ..., -2.8045, -3.0598, -3.3904]],\n",
            "       grad_fn=<LogSoftmaxBackward0>)\n",
            "Training: 634\n",
            "Epoch: 0635 loss_train: 0.5692 acc_train: 0.8714 loss_val: 1.0626 acc_val: 0.6633 time: 4.1719s\n",
            "loss_val:1.062579870223999, val_acc:0.6633333333333333, out_features:tensor([[-1.9459e+00, -1.9459e+00, -1.9459e+00,  ..., -1.9459e+00,\n",
            "         -1.9459e+00, -1.9459e+00],\n",
            "        [-1.7515e+00, -2.4914e+00, -2.3468e+00,  ..., -1.7584e+00,\n",
            "         -1.2476e+00, -2.1811e+00],\n",
            "        [-1.0340e+01, -9.8214e+00, -1.0124e+01,  ..., -2.3374e-04,\n",
            "         -1.0207e+01, -1.0201e+01],\n",
            "        ...,\n",
            "        [-1.9222e+00, -1.5910e+00, -1.8576e+00,  ..., -2.0692e+00,\n",
            "         -1.9123e+00, -2.1580e+00],\n",
            "        [-1.1260e+00, -2.1034e+00, -2.6412e+00,  ..., -1.9857e+00,\n",
            "         -1.9761e+00, -2.5502e+00],\n",
            "        [-9.8380e+00, -8.8305e+00, -4.9066e-04,  ..., -9.8505e+00,\n",
            "         -9.7926e+00, -9.2309e+00]], grad_fn=<LogSoftmaxBackward0>)\n",
            "Training: 635\n",
            "Epoch: 0636 loss_train: 0.5497 acc_train: 0.8429 loss_val: 0.9609 acc_val: 0.6733 time: 4.3217s\n",
            "loss_val:0.9608932733535767, val_acc:0.6733333333333333, out_features:tensor([[-7.8124e+00, -6.3598e+00, -4.8897e-03,  ..., -7.7224e+00,\n",
            "         -7.8126e+00, -7.6551e+00],\n",
            "        [-3.8106e+00, -3.7022e+00, -3.8616e+00,  ..., -2.0801e+00,\n",
            "         -2.5063e-01, -3.9986e+00],\n",
            "        [-4.6937e+00, -4.2398e+00, -3.5787e+00,  ..., -8.4582e-02,\n",
            "         -4.8894e+00, -4.4203e+00],\n",
            "        ...,\n",
            "        [-3.5997e+00, -2.8612e-01, -3.6557e+00,  ..., -2.7248e+00,\n",
            "         -2.7814e+00, -3.1675e+00],\n",
            "        [-3.5318e-02, -4.4808e+00, -5.9668e+00,  ..., -5.8726e+00,\n",
            "         -4.4714e+00, -5.5668e+00],\n",
            "        [-1.9459e+00, -1.9459e+00, -1.9459e+00,  ..., -1.9459e+00,\n",
            "         -1.9459e+00, -1.9459e+00]], grad_fn=<LogSoftmaxBackward0>)\n",
            "Training: 636\n",
            "Epoch: 0637 loss_train: 0.5225 acc_train: 0.8357 loss_val: 1.0653 acc_val: 0.6700 time: 4.1638s\n",
            "loss_val:1.065322756767273, val_acc:0.67, out_features:tensor([[-6.4150, -6.3395, -0.0198,  ..., -4.8310, -6.4308, -6.0840],\n",
            "        [-3.2071, -5.2278, -4.5792,  ..., -3.1468, -0.3948, -1.5055],\n",
            "        [-2.0031, -2.1816, -2.7206,  ..., -0.7277, -2.6159, -2.5993],\n",
            "        ...,\n",
            "        [-3.6051, -0.2014, -3.7358,  ..., -3.4569, -3.1959, -3.2318],\n",
            "        [-0.3148, -4.0260, -4.2765,  ..., -2.4581, -2.6985, -2.7189],\n",
            "        [-1.9459, -1.9459, -1.9459,  ..., -1.9459, -1.9459, -1.9459]],\n",
            "       grad_fn=<LogSoftmaxBackward0>)\n",
            "Training: 637\n",
            "Epoch: 0638 loss_train: 0.7258 acc_train: 0.7500 loss_val: 0.9667 acc_val: 0.6800 time: 4.1354s\n",
            "loss_val:0.9666926860809326, val_acc:0.68, out_features:tensor([[-9.8147e+00, -9.8981e+00, -6.9320e-04,  ..., -9.5152e+00,\n",
            "         -9.8456e+00, -9.3981e+00],\n",
            "        [-1.1077e+01, -1.1967e+01, -1.1951e+01,  ..., -1.1207e+01,\n",
            "         -5.6925e-02, -2.8952e+00],\n",
            "        [-3.5094e+00, -4.1631e+00, -4.3257e+00,  ..., -1.1359e-01,\n",
            "         -4.0208e+00, -3.8981e+00],\n",
            "        ...,\n",
            "        [-2.3639e+00, -1.3237e+00, -2.0027e+00,  ..., -1.7456e+00,\n",
            "         -2.2020e+00, -2.0002e+00],\n",
            "        [-1.9459e+00, -1.9459e+00, -1.9459e+00,  ..., -1.9459e+00,\n",
            "         -1.9459e+00, -1.9459e+00],\n",
            "        [-2.2198e+00, -2.1822e+00, -1.5160e+00,  ..., -2.0707e+00,\n",
            "         -2.2113e+00, -2.0490e+00]], grad_fn=<LogSoftmaxBackward0>)\n",
            "Training: 638\n",
            "Epoch: 0639 loss_train: 0.6797 acc_train: 0.8071 loss_val: 1.0214 acc_val: 0.6633 time: 4.4291s\n",
            "loss_val:1.0213793516159058, val_acc:0.6633333333333333, out_features:tensor([[-7.5140e+00, -7.6762e+00, -5.6325e-03,  ..., -7.6797e+00,\n",
            "         -7.5172e+00, -6.4038e+00],\n",
            "        [-1.9429e+00, -2.2123e+00, -2.3133e+00,  ..., -2.6186e+00,\n",
            "         -1.0805e+00, -1.6563e+00],\n",
            "        [-3.9261e+00, -2.4634e+00, -4.1122e+00,  ..., -2.2380e-01,\n",
            "         -3.5066e+00, -3.3142e+00],\n",
            "        ...,\n",
            "        [-3.9907e+00, -1.3357e-01, -3.8639e+00,  ..., -3.6781e+00,\n",
            "         -3.5966e+00, -3.8701e+00],\n",
            "        [-3.5677e-01, -3.4960e+00, -3.8404e+00,  ..., -2.3269e+00,\n",
            "         -3.0307e+00, -3.3362e+00],\n",
            "        [-1.9459e+00, -1.9459e+00, -1.9459e+00,  ..., -1.9459e+00,\n",
            "         -1.9459e+00, -1.9459e+00]], grad_fn=<LogSoftmaxBackward0>)\n",
            "Training: 639\n",
            "Epoch: 0640 loss_train: 0.5865 acc_train: 0.8571 loss_val: 1.0210 acc_val: 0.6767 time: 4.1715s\n",
            "loss_val:1.020950436592102, val_acc:0.6766666666666666, out_features:tensor([[-5.1878e+00, -4.5359e+00, -5.0994e-02,  ..., -5.1136e+00,\n",
            "         -4.4698e+00, -4.8124e+00],\n",
            "        [-1.9459e+00, -1.9459e+00, -1.9459e+00,  ..., -1.9459e+00,\n",
            "         -1.9459e+00, -1.9459e+00],\n",
            "        [-7.5531e+00, -7.4636e+00, -7.7506e+00,  ..., -5.8898e-03,\n",
            "         -6.6105e+00, -5.9469e+00],\n",
            "        ...,\n",
            "        [-2.0937e+00, -6.6616e-01, -3.3880e+00,  ..., -2.0370e+00,\n",
            "         -2.1472e+00, -2.8779e+00],\n",
            "        [-1.9459e+00, -1.9459e+00, -1.9459e+00,  ..., -1.9459e+00,\n",
            "         -1.9459e+00, -1.9459e+00],\n",
            "        [-3.3472e+00, -2.6338e+00, -4.4116e-01,  ..., -2.9313e+00,\n",
            "         -3.0786e+00, -3.4570e+00]], grad_fn=<LogSoftmaxBackward0>)\n",
            "Training: 640\n",
            "Epoch: 0641 loss_train: 0.5876 acc_train: 0.8500 loss_val: 0.9733 acc_val: 0.6833 time: 4.1500s\n",
            "loss_val:0.9732785820960999, val_acc:0.6833333333333333, out_features:tensor([[-2.9502, -2.3578, -0.4658,  ..., -2.8785, -2.5910, -3.0784],\n",
            "        [-1.9459, -1.9459, -1.9459,  ..., -1.9459, -1.9459, -1.9459],\n",
            "        [-6.0688, -4.3153, -5.2462,  ..., -0.0249, -6.6366, -6.6463],\n",
            "        ...,\n",
            "        [-2.6596, -0.8078, -3.2856,  ..., -2.9423, -2.1492, -2.2075],\n",
            "        [-1.3994, -2.0535, -2.3612,  ..., -1.9139, -1.8804, -2.2051],\n",
            "        [-4.9605, -2.7149, -0.1282,  ..., -4.3365, -4.7828, -4.9422]],\n",
            "       grad_fn=<LogSoftmaxBackward0>)\n",
            "Training: 641\n",
            "Epoch: 0642 loss_train: 0.5754 acc_train: 0.8143 loss_val: 1.0161 acc_val: 0.6733 time: 4.5679s\n",
            "loss_val:1.0161303281784058, val_acc:0.6733333333333333, out_features:tensor([[-4.4739e+00, -3.1281e+00, -1.4500e-01,  ..., -3.5238e+00,\n",
            "         -4.2313e+00, -4.4919e+00],\n",
            "        [-1.9459e+00, -1.9459e+00, -1.9459e+00,  ..., -1.9459e+00,\n",
            "         -1.9459e+00, -1.9459e+00],\n",
            "        [-1.0181e+01, -1.0121e+01, -1.0268e+01,  ..., -4.6266e-04,\n",
            "         -8.4824e+00, -9.1077e+00],\n",
            "        ...,\n",
            "        [-5.2628e+00, -3.9193e-02, -6.0636e+00,  ..., -4.5561e+00,\n",
            "         -4.5915e+00, -4.8648e+00],\n",
            "        [-5.8115e-01, -2.8828e+00, -2.6591e+00,  ..., -2.2743e+00,\n",
            "         -2.2489e+00, -2.8533e+00],\n",
            "        [-5.1346e+00, -7.1725e+00, -1.3614e-02,  ..., -6.8165e+00,\n",
            "         -5.4848e+00, -7.0057e+00]], grad_fn=<LogSoftmaxBackward0>)\n",
            "Training: 642\n",
            "Epoch: 0643 loss_train: 0.6215 acc_train: 0.8286 loss_val: 1.0434 acc_val: 0.6900 time: 4.0432s\n",
            "loss_val:1.0433807373046875, val_acc:0.69, out_features:tensor([[-3.2678e+00, -2.7036e+00, -6.6767e-01,  ..., -2.6839e+00,\n",
            "         -3.2882e+00, -2.0490e+00],\n",
            "        [-7.2179e+00, -1.3231e+01, -1.3008e+01,  ..., -1.0440e+01,\n",
            "         -7.8838e-04, -1.0838e+01],\n",
            "        [-2.7613e+00, -1.9623e+00, -3.5512e+00,  ..., -4.7520e-01,\n",
            "         -2.4021e+00, -3.5186e+00],\n",
            "        ...,\n",
            "        [-3.1590e+00, -5.0244e-01, -3.3493e+00,  ..., -2.1080e+00,\n",
            "         -2.2446e+00, -2.7597e+00],\n",
            "        [-3.8425e-01, -3.2727e+00, -3.0787e+00,  ..., -2.9398e+00,\n",
            "         -2.4041e+00, -2.8887e+00],\n",
            "        [-4.2215e+00, -5.2000e+00, -7.8501e-02,  ..., -5.5990e+00,\n",
            "         -4.9723e+00, -3.2557e+00]], grad_fn=<LogSoftmaxBackward0>)\n",
            "Training: 643\n",
            "Epoch: 0644 loss_train: 0.6226 acc_train: 0.8143 loss_val: 0.9399 acc_val: 0.7100 time: 4.1044s\n",
            "loss_val:0.9398731589317322, val_acc:0.71, out_features:tensor([[-4.5739e+00, -4.5517e+00, -1.7864e-01,  ..., -4.2260e+00,\n",
            "         -4.3376e+00, -3.2200e+00],\n",
            "        [-4.6200e+00, -3.4895e+00, -4.8305e+00,  ..., -1.2960e+00,\n",
            "         -7.6606e-01, -1.5867e+00],\n",
            "        [-7.5297e+00, -7.0446e+00, -7.3685e+00,  ..., -4.5558e-03,\n",
            "         -6.8416e+00, -6.9802e+00],\n",
            "        ...,\n",
            "        [-1.9365e+00, -9.0369e-01, -2.9046e+00,  ..., -1.8740e+00,\n",
            "         -2.3285e+00, -2.3070e+00],\n",
            "        [-5.7940e-02, -5.2583e+00, -5.3178e+00,  ..., -3.7780e+00,\n",
            "         -4.3512e+00, -5.1511e+00],\n",
            "        [-5.5903e+00, -4.2647e+00, -4.5844e-02,  ..., -5.8286e+00,\n",
            "         -5.0333e+00, -4.3697e+00]], grad_fn=<LogSoftmaxBackward0>)\n",
            "Training: 644\n",
            "Epoch: 0645 loss_train: 0.6131 acc_train: 0.8143 loss_val: 1.0142 acc_val: 0.6767 time: 4.4109s\n",
            "loss_val:1.014195203781128, val_acc:0.6766666666666666, out_features:tensor([[-4.3876, -3.8239, -0.1790,  ..., -3.0525, -4.4314, -4.1506],\n",
            "        [-3.5182, -4.9878, -4.6351,  ..., -2.3708, -0.3740, -1.7964],\n",
            "        [-7.0669, -6.2793, -6.9075,  ..., -0.0082, -6.9133, -6.1564],\n",
            "        ...,\n",
            "        [-3.2954, -0.2192, -3.4169,  ..., -3.7197, -2.7152, -4.0102],\n",
            "        [-1.9459, -1.9459, -1.9459,  ..., -1.9459, -1.9459, -1.9459],\n",
            "        [-7.1603, -6.2126, -0.0113,  ..., -7.0159, -7.1999, -7.2548]],\n",
            "       grad_fn=<LogSoftmaxBackward0>)\n",
            "Training: 645\n",
            "Epoch: 0646 loss_train: 0.6259 acc_train: 0.8429 loss_val: 1.0508 acc_val: 0.6833 time: 4.0445s\n",
            "loss_val:1.0508391857147217, val_acc:0.6833333333333333, out_features:tensor([[-5.6344, -5.7564, -0.0349,  ..., -4.7397, -5.6238, -5.1305],\n",
            "        [-2.2629, -2.2719, -2.9504,  ..., -1.6985, -1.2412, -1.4618],\n",
            "        [-4.8089, -4.6556, -4.5283,  ..., -0.0576, -4.9464, -4.2798],\n",
            "        ...,\n",
            "        [-2.4669, -0.3787, -3.4809,  ..., -3.4808, -2.2588, -3.3104],\n",
            "        [-0.2689, -3.7340, -3.3309,  ..., -3.1448, -2.4781, -3.7209],\n",
            "        [-2.4222, -2.1202, -0.9078,  ..., -2.0358, -2.7454, -2.4169]],\n",
            "       grad_fn=<LogSoftmaxBackward0>)\n",
            "Training: 646\n",
            "Epoch: 0647 loss_train: 0.5481 acc_train: 0.8357 loss_val: 0.9996 acc_val: 0.6867 time: 4.1385s\n",
            "loss_val:0.9995864033699036, val_acc:0.6866666666666666, out_features:tensor([[-3.4300e+00, -3.5405e+00, -3.0100e-01,  ..., -2.4498e+00,\n",
            "         -3.2491e+00, -3.1173e+00],\n",
            "        [-2.6260e+00, -3.6568e+00, -3.4218e+00,  ..., -2.2153e+00,\n",
            "         -4.4292e-01, -2.3787e+00],\n",
            "        [-4.1104e+00, -4.0969e+00, -4.4050e+00,  ..., -8.5160e-02,\n",
            "         -4.4146e+00, -4.5264e+00],\n",
            "        ...,\n",
            "        [-9.5991e+00, -1.1925e-03, -9.7326e+00,  ..., -7.4781e+00,\n",
            "         -7.8727e+00, -9.6596e+00],\n",
            "        [-7.1935e-03, -6.4031e+00, -8.4758e+00,  ..., -7.2867e+00,\n",
            "         -5.4773e+00, -8.4216e+00],\n",
            "        [-2.2508e+00, -2.2566e+00, -5.8142e-01,  ..., -2.2995e+00,\n",
            "         -2.8245e+00, -3.4560e+00]], grad_fn=<LogSoftmaxBackward0>)\n",
            "Training: 647\n",
            "Epoch: 0648 loss_train: 0.6240 acc_train: 0.8214 loss_val: 1.0252 acc_val: 0.6633 time: 4.4726s\n",
            "loss_val:1.0252065658569336, val_acc:0.6633333333333333, out_features:tensor([[-3.3546, -3.1261, -0.4416,  ..., -1.9859, -3.3025, -3.1232],\n",
            "        [-1.9459, -1.9459, -1.9459,  ..., -1.9459, -1.9459, -1.9459],\n",
            "        [-6.5077, -6.0991, -6.9220,  ..., -0.0097, -6.7203, -5.8743],\n",
            "        ...,\n",
            "        [-5.1172, -0.0196, -6.3068,  ..., -5.9791, -5.2942, -6.0335],\n",
            "        [-0.3764, -3.1672, -3.9417,  ..., -2.5708, -2.0287, -3.7966],\n",
            "        [-3.5687, -3.4928, -0.3123,  ..., -2.3386, -3.3028, -3.2257]],\n",
            "       grad_fn=<LogSoftmaxBackward0>)\n",
            "Training: 648\n",
            "Epoch: 0649 loss_train: 0.6213 acc_train: 0.8429 loss_val: 1.1245 acc_val: 0.6667 time: 4.2977s\n",
            "loss_val:1.124549388885498, val_acc:0.6666666666666666, out_features:tensor([[-5.6166, -5.4167, -0.0973,  ..., -5.4988, -5.1931, -5.0049],\n",
            "        [-1.7459, -3.1357, -2.2534,  ..., -3.0687, -0.8258, -1.9175],\n",
            "        [-3.3869, -4.3202, -4.9204,  ..., -0.0867, -4.4176, -4.5779],\n",
            "        ...,\n",
            "        [-3.6085, -0.3122, -3.3811,  ..., -2.6981, -2.7439, -3.0212],\n",
            "        [-0.2445, -3.6054, -4.0634,  ..., -2.7171, -2.7520, -3.9568],\n",
            "        [-3.9797, -2.9068, -0.2386,  ..., -3.7190, -3.6113, -2.6558]],\n",
            "       grad_fn=<LogSoftmaxBackward0>)\n",
            "Training: 649\n",
            "Epoch: 0650 loss_train: 0.5767 acc_train: 0.8571 loss_val: 0.9727 acc_val: 0.6667 time: 4.2213s\n",
            "loss_val:0.9726709127426147, val_acc:0.6666666666666666, out_features:tensor([[-6.5747e+00, -6.1302e+00, -1.4867e-02,  ..., -5.8462e+00,\n",
            "         -6.4074e+00, -6.2736e+00],\n",
            "        [-1.7998e+00, -3.6388e+00, -3.3496e+00,  ..., -1.8887e+00,\n",
            "         -7.5763e-01, -2.0648e+00],\n",
            "        [-6.2575e+00, -6.6428e+00, -6.7955e+00,  ..., -1.2001e-02,\n",
            "         -5.9345e+00, -5.5214e+00],\n",
            "        ...,\n",
            "        [-7.5087e+00, -3.7642e-03, -8.3112e+00,  ..., -7.5031e+00,\n",
            "         -6.2579e+00, -8.2469e+00],\n",
            "        [-8.5522e-01, -2.0590e+00, -2.5617e+00,  ..., -1.9601e+00,\n",
            "         -2.6593e+00, -2.4942e+00],\n",
            "        [-6.0107e+00, -5.9277e+00, -3.6354e-02,  ..., -4.3668e+00,\n",
            "         -5.7918e+00, -6.0861e+00]], grad_fn=<LogSoftmaxBackward0>)\n",
            "Training: 650\n",
            "Epoch: 0651 loss_train: 0.5888 acc_train: 0.8143 loss_val: 1.0166 acc_val: 0.6767 time: 4.4400s\n",
            "loss_val:1.0166493654251099, val_acc:0.6766666666666666, out_features:tensor([[-1.2067e+01, -1.1915e+01, -8.3681e-05,  ..., -9.9798e+00,\n",
            "         -1.2051e+01, -1.1983e+01],\n",
            "        [-4.4074e+00, -4.2560e+00, -4.5371e+00,  ..., -4.3777e+00,\n",
            "         -1.1809e-01, -3.5171e+00],\n",
            "        [-1.3082e+01, -1.2327e+01, -1.2730e+01,  ..., -1.6928e-05,\n",
            "         -1.2847e+01, -1.2873e+01],\n",
            "        ...,\n",
            "        [-2.9505e+00, -3.4198e-01, -2.7936e+00,  ..., -3.0007e+00,\n",
            "         -2.6419e+00, -3.4323e+00],\n",
            "        [-9.2934e-01, -1.7469e+00, -3.1901e+00,  ..., -1.8002e+00,\n",
            "         -2.1800e+00, -2.6934e+00],\n",
            "        [-9.6749e+00, -9.9291e+00, -4.9507e-04,  ..., -1.0117e+01,\n",
            "         -1.0047e+01, -1.0190e+01]], grad_fn=<LogSoftmaxBackward0>)\n",
            "Training: 651\n",
            "Epoch: 0652 loss_train: 0.6191 acc_train: 0.8286 loss_val: 1.0715 acc_val: 0.6500 time: 4.5110s\n",
            "loss_val:1.0715222358703613, val_acc:0.65, out_features:tensor([[-8.6917e+00, -8.6131e+00, -1.3768e-03,  ..., -8.3770e+00,\n",
            "         -8.5415e+00, -8.2485e+00],\n",
            "        [-2.2269e+00, -2.6340e+00, -1.8363e+00,  ..., -1.9923e+00,\n",
            "         -1.3794e+00, -1.4658e+00],\n",
            "        [-1.9459e+00, -1.9459e+00, -1.9459e+00,  ..., -1.9459e+00,\n",
            "         -1.9459e+00, -1.9459e+00],\n",
            "        ...,\n",
            "        [-1.9043e+00, -8.9347e-01, -2.1805e+00,  ..., -2.8945e+00,\n",
            "         -1.8173e+00, -2.6204e+00],\n",
            "        [-1.3637e-01, -3.9369e+00, -4.5393e+00,  ..., -3.1642e+00,\n",
            "         -3.5995e+00, -4.0194e+00],\n",
            "        [-1.9459e+00, -1.9459e+00, -1.9459e+00,  ..., -1.9459e+00,\n",
            "         -1.9459e+00, -1.9459e+00]], grad_fn=<LogSoftmaxBackward0>)\n",
            "Training: 652\n",
            "Epoch: 0653 loss_train: 0.6608 acc_train: 0.8643 loss_val: 1.0409 acc_val: 0.6467 time: 4.3555s\n",
            "loss_val:1.0409424304962158, val_acc:0.6466666666666666, out_features:tensor([[-3.1907e+00, -2.9393e+00, -3.6976e-01,  ..., -2.4209e+00,\n",
            "         -3.2885e+00, -2.9588e+00],\n",
            "        [-3.2618e+00, -3.2561e+00, -4.7213e+00,  ..., -2.5534e+00,\n",
            "         -2.0391e-01, -4.6313e+00],\n",
            "        [-5.5384e+00, -4.3455e+00, -5.2406e+00,  ..., -4.2460e-02,\n",
            "         -5.2430e+00, -4.5513e+00],\n",
            "        ...,\n",
            "        [-1.5515e+00, -1.0445e+00, -2.8878e+00,  ..., -2.5160e+00,\n",
            "         -2.1352e+00, -1.9826e+00],\n",
            "        [-1.3237e-01, -3.8303e+00, -5.1618e+00,  ..., -2.7222e+00,\n",
            "         -4.0097e+00, -4.9383e+00],\n",
            "        [-8.0678e+00, -6.0288e+00, -4.3305e-03,  ..., -7.5819e+00,\n",
            "         -7.9138e+00, -8.1899e+00]], grad_fn=<LogSoftmaxBackward0>)\n",
            "Training: 653\n",
            "Epoch: 0654 loss_train: 0.6026 acc_train: 0.8571 loss_val: 1.0509 acc_val: 0.6800 time: 4.2008s\n",
            "loss_val:1.0508829355239868, val_acc:0.68, out_features:tensor([[-2.7240e+00, -2.6772e+00, -6.6179e-01,  ..., -2.5173e+00,\n",
            "         -2.7695e+00, -2.7278e+00],\n",
            "        [-4.8356e+00, -5.9909e+00, -3.4674e+00,  ..., -5.7899e+00,\n",
            "         -1.2372e-01, -2.7077e+00],\n",
            "        [-7.2067e+00, -7.4217e+00, -6.1227e+00,  ..., -5.7324e-03,\n",
            "         -7.4138e+00, -6.8543e+00],\n",
            "        ...,\n",
            "        [-3.9774e+00, -3.1892e-01, -3.3091e+00,  ..., -2.2049e+00,\n",
            "         -2.6348e+00, -3.7634e+00],\n",
            "        [-1.2549e-01, -3.7635e+00, -5.0322e+00,  ..., -4.6493e+00,\n",
            "         -2.8265e+00, -4.4896e+00],\n",
            "        [-3.3294e+00, -3.4738e+00, -1.7208e-01,  ..., -3.9830e+00,\n",
            "         -3.7515e+00, -4.2705e+00]], grad_fn=<LogSoftmaxBackward0>)\n",
            "Training: 654\n",
            "Epoch: 0655 loss_train: 0.5993 acc_train: 0.8071 loss_val: 0.9531 acc_val: 0.7233 time: 4.1527s\n",
            "loss_val:0.9531381130218506, val_acc:0.7233333333333334, out_features:tensor([[-4.8662, -4.6348, -0.0640,  ..., -4.5730, -4.7125, -4.2037],\n",
            "        [-3.0063, -6.5300, -6.1480,  ..., -6.7882, -0.0595, -6.1313],\n",
            "        [-4.8137, -5.6333, -5.6882,  ..., -0.0379, -5.0566, -4.4249],\n",
            "        ...,\n",
            "        [-3.5674, -0.3707, -2.3585,  ..., -2.5504, -3.3794, -3.4435],\n",
            "        [-0.0488, -5.0533, -5.4193,  ..., -4.5007, -4.1304, -5.3697],\n",
            "        [-4.4604, -3.5603, -0.1231,  ..., -4.3715, -4.5083, -4.5093]],\n",
            "       grad_fn=<LogSoftmaxBackward0>)\n",
            "Training: 655\n",
            "Epoch: 0656 loss_train: 0.6568 acc_train: 0.8000 loss_val: 1.0733 acc_val: 0.6800 time: 4.5072s\n",
            "loss_val:1.0732530355453491, val_acc:0.68, out_features:tensor([[-3.9903, -3.1686, -0.1993,  ..., -3.4335, -3.9755, -4.0868],\n",
            "        [-3.5678, -6.5464, -5.4389,  ..., -4.1158, -0.0988, -3.1606],\n",
            "        [-7.8285, -6.1590, -4.8689,  ..., -0.0117, -7.4242, -7.7264],\n",
            "        ...,\n",
            "        [-3.0734, -0.2669, -3.7072,  ..., -2.7001, -3.1295, -3.4218],\n",
            "        [-0.7077, -2.6897, -2.6589,  ..., -2.6438, -1.9770, -2.7413],\n",
            "        [-1.8580, -2.8644, -0.8975,  ..., -2.7298, -2.3472, -2.6399]],\n",
            "       grad_fn=<LogSoftmaxBackward0>)\n",
            "Training: 656\n",
            "Epoch: 0657 loss_train: 0.5041 acc_train: 0.8714 loss_val: 1.0462 acc_val: 0.6833 time: 4.0632s\n",
            "loss_val:1.0462441444396973, val_acc:0.6833333333333333, out_features:tensor([[-7.5490e+00, -7.3480e+00, -2.0574e-02,  ..., -7.4139e+00,\n",
            "         -7.4867e+00, -6.2581e+00],\n",
            "        [-5.4225e+00, -4.7535e+00, -3.0220e+00,  ..., -4.3675e+00,\n",
            "         -9.4931e-02, -4.3699e+00],\n",
            "        [-7.8653e+00, -7.7951e+00, -7.6689e+00,  ..., -2.7809e-03,\n",
            "         -7.1357e+00, -7.9198e+00],\n",
            "        ...,\n",
            "        [-1.9459e+00, -1.9459e+00, -1.9459e+00,  ..., -1.9459e+00,\n",
            "         -1.9459e+00, -1.9459e+00],\n",
            "        [-3.6700e-01, -3.3023e+00, -3.3147e+00,  ..., -3.2346e+00,\n",
            "         -2.3851e+00, -2.6915e+00],\n",
            "        [-2.5839e+00, -2.8702e+00, -7.0794e-01,  ..., -1.8804e+00,\n",
            "         -2.4757e+00, -2.5456e+00]], grad_fn=<LogSoftmaxBackward0>)\n",
            "Training: 657\n",
            "Epoch: 0658 loss_train: 0.5178 acc_train: 0.8429 loss_val: 1.0898 acc_val: 0.6367 time: 4.0250s\n",
            "loss_val:1.0897809267044067, val_acc:0.6366666666666667, out_features:tensor([[-7.0086e+00, -6.0969e+00, -7.6106e-03,  ..., -7.2532e+00,\n",
            "         -7.2856e+00, -6.1449e+00],\n",
            "        [-1.7552e+00, -3.0895e+00, -3.2926e+00,  ..., -3.8198e+00,\n",
            "         -8.3040e-01, -1.3208e+00],\n",
            "        [-2.6473e+00, -2.1603e+00, -2.3676e+00,  ..., -7.8648e-01,\n",
            "         -2.5358e+00, -2.2671e+00],\n",
            "        ...,\n",
            "        [-3.0475e+00, -5.3185e-01, -2.6312e+00,  ..., -2.0458e+00,\n",
            "         -2.8623e+00, -2.9676e+00],\n",
            "        [-4.8016e-03, -7.6735e+00, -8.1416e+00,  ..., -6.8760e+00,\n",
            "         -6.0710e+00, -7.7754e+00],\n",
            "        [-1.8921e+00, -3.0905e+00, -6.0379e-01,  ..., -2.3954e+00,\n",
            "         -3.1362e+00, -2.9824e+00]], grad_fn=<LogSoftmaxBackward0>)\n",
            "Training: 658\n",
            "Epoch: 0659 loss_train: 0.5971 acc_train: 0.8214 loss_val: 1.0442 acc_val: 0.6900 time: 4.3717s\n",
            "loss_val:1.0442060232162476, val_acc:0.69, out_features:tensor([[-2.3535, -2.0879, -1.0261,  ..., -2.2640, -2.0809, -2.3240],\n",
            "        [-5.7607, -6.3440, -5.4085,  ..., -6.0982, -0.0239, -4.6667],\n",
            "        [-6.4413, -5.9377, -5.7199,  ..., -0.0109, -6.7882, -6.6830],\n",
            "        ...,\n",
            "        [-1.9597, -0.9058, -2.2564,  ..., -2.4250, -2.2737, -2.2759],\n",
            "        [-0.1439, -3.1941, -4.5150,  ..., -3.3225, -3.8588, -4.2592],\n",
            "        [-5.4483, -3.8282, -0.0497,  ..., -5.0002, -5.2842, -5.1200]],\n",
            "       grad_fn=<LogSoftmaxBackward0>)\n",
            "Training: 659\n",
            "Epoch: 0660 loss_train: 0.6881 acc_train: 0.8143 loss_val: 1.0590 acc_val: 0.6633 time: 4.2328s\n",
            "loss_val:1.0590109825134277, val_acc:0.6633333333333333, out_features:tensor([[-5.7147, -6.0682, -0.0232,  ..., -5.0630, -6.1375, -5.3359],\n",
            "        [-1.9459, -1.9459, -1.9459,  ..., -1.9459, -1.9459, -1.9459],\n",
            "        [-5.6350, -6.0593, -6.2513,  ..., -0.0144, -5.9388, -6.0089],\n",
            "        ...,\n",
            "        [-2.0292, -1.0029, -2.6865,  ..., -2.3852, -2.1086, -2.0707],\n",
            "        [-0.5316, -3.5117, -3.5644,  ..., -3.5503, -1.8082, -3.2382],\n",
            "        [-5.5820, -5.7022, -0.0337,  ..., -5.4869, -4.3086, -5.4698]],\n",
            "       grad_fn=<LogSoftmaxBackward0>)\n",
            "Training: 660\n",
            "Epoch: 0661 loss_train: 0.6464 acc_train: 0.8071 loss_val: 1.0380 acc_val: 0.7100 time: 4.1105s\n",
            "loss_val:1.0379815101623535, val_acc:0.71, out_features:tensor([[-5.7090, -5.7223, -0.0385,  ..., -5.6533, -5.7104, -4.8900],\n",
            "        [-4.9005, -7.8788, -7.6934,  ..., -7.5261, -0.0560, -3.0952],\n",
            "        [-5.9987, -5.3510, -5.8573,  ..., -0.0229, -5.0212, -5.5607],\n",
            "        ...,\n",
            "        [-2.3167, -0.2877, -3.5810,  ..., -3.5697, -3.3723, -3.7507],\n",
            "        [-0.0916, -4.8681, -5.0606,  ..., -3.8608, -4.4679, -4.6654],\n",
            "        [-1.9459, -1.9459, -1.9459,  ..., -1.9459, -1.9459, -1.9459]],\n",
            "       grad_fn=<LogSoftmaxBackward0>)\n",
            "Training: 661\n",
            "Epoch: 0662 loss_train: 0.6117 acc_train: 0.8429 loss_val: 1.1654 acc_val: 0.6333 time: 4.5250s\n",
            "loss_val:1.1653889417648315, val_acc:0.6333333333333333, out_features:tensor([[-6.3906e+00, -6.0994e+00, -3.4896e-02,  ..., -6.1972e+00,\n",
            "         -6.5376e+00, -5.9453e+00],\n",
            "        [-4.7866e+00, -4.3788e+00, -6.8734e+00,  ..., -6.9972e+00,\n",
            "         -5.8828e-02, -3.3978e+00],\n",
            "        [-2.3952e+00, -2.1541e+00, -1.8485e+00,  ..., -8.4942e-01,\n",
            "         -2.6520e+00, -2.5011e+00],\n",
            "        ...,\n",
            "        [-7.1287e+00, -5.7246e-03, -7.4906e+00,  ..., -7.1622e+00,\n",
            "         -6.4228e+00, -6.5710e+00],\n",
            "        [-1.9459e+00, -1.9459e+00, -1.9459e+00,  ..., -1.9459e+00,\n",
            "         -1.9459e+00, -1.9459e+00],\n",
            "        [-2.4708e+00, -3.2953e+00, -5.1820e-01,  ..., -2.0649e+00,\n",
            "         -2.4334e+00, -3.3267e+00]], grad_fn=<LogSoftmaxBackward0>)\n",
            "Training: 662\n",
            "Epoch: 0663 loss_train: 0.6247 acc_train: 0.8143 loss_val: 1.0348 acc_val: 0.6967 time: 4.1783s\n",
            "loss_val:1.0348361730575562, val_acc:0.6966666666666667, out_features:tensor([[-8.5514e+00, -8.4275e+00, -3.5104e-03,  ..., -6.1437e+00,\n",
            "         -8.4416e+00, -7.5437e+00],\n",
            "        [-2.0917e+00, -3.0896e+00, -2.5333e+00,  ..., -2.6469e+00,\n",
            "         -1.0035e+00, -1.2545e+00],\n",
            "        [-5.9184e+00, -6.5935e+00, -5.7730e+00,  ..., -1.4549e-02,\n",
            "         -5.9690e+00, -5.7064e+00],\n",
            "        ...,\n",
            "        [-3.8807e+00, -2.8863e-01, -3.1649e+00,  ..., -1.9616e+00,\n",
            "         -4.1104e+00, -3.9535e+00],\n",
            "        [-1.6758e-01, -4.1069e+00, -3.9355e+00,  ..., -3.7539e+00,\n",
            "         -2.8345e+00, -3.6876e+00],\n",
            "        [-1.9459e+00, -1.9459e+00, -1.9459e+00,  ..., -1.9459e+00,\n",
            "         -1.9459e+00, -1.9459e+00]], grad_fn=<LogSoftmaxBackward0>)\n",
            "Training: 663\n",
            "Epoch: 0664 loss_train: 0.6639 acc_train: 0.7857 loss_val: 0.9108 acc_val: 0.7167 time: 4.1449s\n",
            "loss_val:0.9108368158340454, val_acc:0.7166666666666667, out_features:tensor([[-6.4010e+00, -6.3739e+00, -1.0197e-01,  ..., -5.8824e+00,\n",
            "         -6.3826e+00, -5.6442e+00],\n",
            "        [-1.9459e+00, -1.9459e+00, -1.9459e+00,  ..., -1.9459e+00,\n",
            "         -1.9459e+00, -1.9459e+00],\n",
            "        [-7.5532e+00, -7.4197e+00, -7.8717e+00,  ..., -2.5698e-03,\n",
            "         -7.4050e+00, -8.3223e+00],\n",
            "        ...,\n",
            "        [-2.4137e+00, -1.0263e+00, -2.3728e+00,  ..., -1.7084e+00,\n",
            "         -2.1678e+00, -2.1850e+00],\n",
            "        [-1.7538e-02, -6.7329e+00, -6.9540e+00,  ..., -4.7644e+00,\n",
            "         -5.4835e+00, -6.7613e+00],\n",
            "        [-2.2580e+00, -2.0819e+00, -1.2317e+00,  ..., -2.6342e+00,\n",
            "         -1.9781e+00, -2.7385e+00]], grad_fn=<LogSoftmaxBackward0>)\n",
            "Training: 664\n",
            "Epoch: 0665 loss_train: 0.5945 acc_train: 0.8214 loss_val: 1.0460 acc_val: 0.6967 time: 4.4240s\n",
            "loss_val:1.0460349321365356, val_acc:0.6966666666666667, out_features:tensor([[-3.7182, -3.3123, -0.2624,  ..., -2.8602, -3.5865, -3.1055],\n",
            "        [-1.6749, -3.2611, -3.4152,  ..., -1.5971, -1.3464, -1.3864],\n",
            "        [-3.2258, -2.2121, -3.2057,  ..., -0.4139, -2.9177, -2.9096],\n",
            "        ...,\n",
            "        [-4.6448, -0.1655, -2.4362,  ..., -4.4885, -3.7116, -4.5490],\n",
            "        [-0.0659, -5.1022, -5.7119,  ..., -3.6221, -3.9488, -5.5426],\n",
            "        [-2.6781, -2.2924, -1.1820,  ..., -1.4846, -2.2608, -2.5538]],\n",
            "       grad_fn=<LogSoftmaxBackward0>)\n",
            "Training: 665\n",
            "Epoch: 0666 loss_train: 0.6085 acc_train: 0.8143 loss_val: 1.0365 acc_val: 0.6467 time: 4.0504s\n",
            "loss_val:1.0365172624588013, val_acc:0.6466666666666666, out_features:tensor([[-6.4713, -6.2183, -0.0276,  ..., -5.4593, -6.4984, -5.9316],\n",
            "        [-1.9459, -1.9459, -1.9459,  ..., -1.9459, -1.9459, -1.9459],\n",
            "        [-4.8605, -4.0803, -3.7236,  ..., -0.0959, -4.3324, -3.8211],\n",
            "        ...,\n",
            "        [-1.9459, -1.9459, -1.9459,  ..., -1.9459, -1.9459, -1.9459],\n",
            "        [-1.0573, -2.1139, -2.9293,  ..., -1.7736, -2.2346, -2.4113],\n",
            "        [-4.0211, -3.5404, -0.1916,  ..., -4.0741, -2.7216, -4.0935]],\n",
            "       grad_fn=<LogSoftmaxBackward0>)\n",
            "Training: 666\n",
            "Epoch: 0667 loss_train: 0.6146 acc_train: 0.8071 loss_val: 1.0505 acc_val: 0.6700 time: 4.2013s\n",
            "loss_val:1.0504897832870483, val_acc:0.67, out_features:tensor([[-4.7450, -4.7231, -0.1223,  ..., -4.2533, -4.6462, -3.5745],\n",
            "        [-1.9459, -1.9459, -1.9459,  ..., -1.9459, -1.9459, -1.9459],\n",
            "        [-2.8979, -3.2879, -4.5560,  ..., -0.1609, -3.8253, -4.2476],\n",
            "        ...,\n",
            "        [-1.5096, -1.3216, -2.4628,  ..., -1.9892, -1.8221, -2.6539],\n",
            "        [-1.8119, -2.1376, -1.9381,  ..., -1.6595, -2.0903, -2.2541],\n",
            "        [-2.9404, -2.7909, -0.8288,  ..., -3.0128, -2.1862, -1.7671]],\n",
            "       grad_fn=<LogSoftmaxBackward0>)\n",
            "Training: 667\n",
            "Epoch: 0668 loss_train: 0.6554 acc_train: 0.8143 loss_val: 0.9898 acc_val: 0.6633 time: 4.3915s\n",
            "loss_val:0.989754855632782, val_acc:0.6633333333333333, out_features:tensor([[-6.8771, -6.1889, -0.0114,  ..., -5.8504, -6.7408, -6.5271],\n",
            "        [-1.7881, -2.4803, -3.1931,  ..., -3.1100, -1.0132, -1.3684],\n",
            "        [-5.8452, -5.8482, -4.9616,  ..., -0.0231, -5.8278, -5.2673],\n",
            "        ...,\n",
            "        [-2.8724, -0.4785, -3.4282,  ..., -2.3398, -2.1280, -3.1730],\n",
            "        [-0.1264, -4.5831, -4.7496,  ..., -3.7563, -2.9803, -4.1907],\n",
            "        [-2.7289, -3.0516, -0.4515,  ..., -3.1996, -2.5638, -2.6355]],\n",
            "       grad_fn=<LogSoftmaxBackward0>)\n",
            "Training: 668\n",
            "Epoch: 0669 loss_train: 0.6651 acc_train: 0.7857 loss_val: 1.0412 acc_val: 0.6733 time: 4.2288s\n",
            "loss_val:1.0412416458129883, val_acc:0.6733333333333333, out_features:tensor([[-7.9924e+00, -7.7361e+00, -6.5070e-03,  ..., -7.4737e+00,\n",
            "         -7.9655e+00, -5.9949e+00],\n",
            "        [-3.0894e+00, -4.0792e+00, -3.9572e+00,  ..., -2.0546e+00,\n",
            "         -5.5641e-01, -1.6227e+00],\n",
            "        [-2.7050e+00, -2.3124e+00, -2.2148e+00,  ..., -6.5454e-01,\n",
            "         -2.8257e+00, -2.3350e+00],\n",
            "        ...,\n",
            "        [-7.2896e+00, -7.4572e-03, -7.0902e+00,  ..., -7.0818e+00,\n",
            "         -5.7894e+00, -6.5781e+00],\n",
            "        [-8.1154e-02, -5.0897e+00, -5.2256e+00,  ..., -3.6027e+00,\n",
            "         -3.7846e+00, -4.8153e+00],\n",
            "        [-2.8024e+00, -2.1817e+00, -6.7071e-01,  ..., -2.1804e+00,\n",
            "         -2.5708e+00, -2.7919e+00]], grad_fn=<LogSoftmaxBackward0>)\n",
            "Training: 669\n",
            "Epoch: 0670 loss_train: 0.6866 acc_train: 0.8214 loss_val: 0.9864 acc_val: 0.6733 time: 4.1980s\n",
            "loss_val:0.9864313006401062, val_acc:0.6733333333333333, out_features:tensor([[-8.0793e+00, -7.8602e+00, -3.2595e-03,  ..., -6.7016e+00,\n",
            "         -8.0079e+00, -7.5319e+00],\n",
            "        [-4.1172e+00, -6.4702e+00, -7.3727e+00,  ..., -4.7017e+00,\n",
            "         -3.5779e-02, -4.9567e+00],\n",
            "        [-2.3706e+00, -2.7198e+00, -1.7127e+00,  ..., -8.3613e-01,\n",
            "         -2.4110e+00, -2.5880e+00],\n",
            "        ...,\n",
            "        [-4.9248e+00, -7.5584e-02, -4.1988e+00,  ..., -4.0584e+00,\n",
            "         -3.9125e+00, -4.9779e+00],\n",
            "        [-3.9544e-01, -3.2876e+00, -2.5496e+00,  ..., -2.9744e+00,\n",
            "         -2.8727e+00, -3.0028e+00],\n",
            "        [-8.9279e+00, -9.0678e+00, -9.8133e-04,  ..., -8.4960e+00,\n",
            "         -8.7884e+00, -8.5906e+00]], grad_fn=<LogSoftmaxBackward0>)\n",
            "Training: 670\n",
            "Epoch: 0671 loss_train: 0.5993 acc_train: 0.8214 loss_val: 1.0651 acc_val: 0.6667 time: 4.3153s\n",
            "loss_val:1.0650535821914673, val_acc:0.6666666666666666, out_features:tensor([[-5.6188, -4.8581, -0.0506,  ..., -4.8088, -5.5074, -5.7187],\n",
            "        [-1.9459, -1.9459, -1.9459,  ..., -1.9459, -1.9459, -1.9459],\n",
            "        [-4.4165, -2.9674, -2.7106,  ..., -0.1926, -3.9861, -4.2649],\n",
            "        ...,\n",
            "        [-2.6369, -0.5567, -2.8616,  ..., -2.6728, -2.2849, -2.6214],\n",
            "        [-0.6643, -3.3642, -3.1957,  ..., -1.9885, -2.5439, -1.8938],\n",
            "        [-1.9459, -1.9459, -1.9459,  ..., -1.9459, -1.9459, -1.9459]],\n",
            "       grad_fn=<LogSoftmaxBackward0>)\n",
            "Training: 671\n",
            "Epoch: 0672 loss_train: 0.7173 acc_train: 0.7857 loss_val: 1.0918 acc_val: 0.6300 time: 4.1032s\n",
            "loss_val:1.0917749404907227, val_acc:0.63, out_features:tensor([[-1.4298e+01, -1.4206e+01, -4.6492e-06,  ..., -1.3829e+01,\n",
            "         -1.4306e+01, -1.3674e+01],\n",
            "        [-1.9459e+00, -1.9459e+00, -1.9459e+00,  ..., -1.9459e+00,\n",
            "         -1.9459e+00, -1.9459e+00],\n",
            "        [-4.9262e+00, -4.3275e+00, -3.4685e+00,  ..., -8.1347e-02,\n",
            "         -4.6776e+00, -4.8981e+00],\n",
            "        ...,\n",
            "        [-2.1116e+00, -1.0373e+00, -1.6797e+00,  ..., -2.0484e+00,\n",
            "         -2.4102e+00, -2.8958e+00],\n",
            "        [-8.1178e-02, -4.6301e+00, -5.4066e+00,  ..., -3.9842e+00,\n",
            "         -3.4873e+00, -4.7102e+00],\n",
            "        [-1.8872e+00, -3.2910e+00, -6.4694e-01,  ..., -2.5490e+00,\n",
            "         -2.0777e+00, -3.0306e+00]], grad_fn=<LogSoftmaxBackward0>)\n",
            "Training: 672\n",
            "Epoch: 0673 loss_train: 0.5184 acc_train: 0.8500 loss_val: 0.9652 acc_val: 0.6867 time: 4.3302s\n",
            "loss_val:0.9652371406555176, val_acc:0.6866666666666666, out_features:tensor([[-1.1030e+01, -1.0558e+01, -2.0466e-04,  ..., -1.0005e+01,\n",
            "         -1.0988e+01, -1.0853e+01],\n",
            "        [-1.9459e+00, -1.9459e+00, -1.9459e+00,  ..., -1.9459e+00,\n",
            "         -1.9459e+00, -1.9459e+00],\n",
            "        [-4.9454e+00, -3.1994e+00, -5.0548e+00,  ..., -8.3013e-02,\n",
            "         -4.6706e+00, -4.5239e+00],\n",
            "        ...,\n",
            "        [-5.5503e+00, -2.6297e-02, -5.4251e+00,  ..., -5.3090e+00,\n",
            "         -5.3725e+00, -5.4521e+00],\n",
            "        [-7.3843e-03, -7.6434e+00, -7.7348e+00,  ..., -6.0107e+00,\n",
            "         -6.0408e+00, -7.3864e+00],\n",
            "        [-7.7748e+00, -6.4176e+00, -4.2274e-03,  ..., -7.9413e+00,\n",
            "         -7.9989e+00, -6.7642e+00]], grad_fn=<LogSoftmaxBackward0>)\n",
            "Training: 673\n",
            "Epoch: 0674 loss_train: 0.6157 acc_train: 0.8143 loss_val: 1.1121 acc_val: 0.6833 time: 4.2461s\n",
            "loss_val:1.1120754480361938, val_acc:0.6833333333333333, out_features:tensor([[-1.6610e+01, -1.4759e+01, -1.4305e-06,  ..., -1.4418e+01,\n",
            "         -1.6569e+01, -1.6610e+01],\n",
            "        [-1.7184e+00, -2.9336e+00, -1.6999e+00,  ..., -3.1055e+00,\n",
            "         -8.1090e-01, -2.9766e+00],\n",
            "        [-1.3153e+01, -1.1801e+01, -1.3255e+01,  ..., -1.5378e-05,\n",
            "         -1.3305e+01, -1.3578e+01],\n",
            "        ...,\n",
            "        [-5.0293e+00, -7.7353e-02, -5.1060e+00,  ..., -4.8403e+00,\n",
            "         -3.1348e+00, -5.1661e+00],\n",
            "        [-1.9459e+00, -1.9459e+00, -1.9459e+00,  ..., -1.9459e+00,\n",
            "         -1.9459e+00, -1.9459e+00],\n",
            "        [-1.9459e+00, -1.9459e+00, -1.9459e+00,  ..., -1.9459e+00,\n",
            "         -1.9459e+00, -1.9459e+00]], grad_fn=<LogSoftmaxBackward0>)\n",
            "Training: 674\n",
            "Epoch: 0675 loss_train: 0.6439 acc_train: 0.8143 loss_val: 1.0783 acc_val: 0.6333 time: 4.1288s\n",
            "loss_val:1.0782779455184937, val_acc:0.6333333333333333, out_features:tensor([[-3.6617e+00, -3.8115e+00, -2.4339e-01,  ..., -3.5850e+00,\n",
            "         -3.8454e+00, -3.1348e+00],\n",
            "        [-2.5856e+00, -3.3090e+00, -3.1840e+00,  ..., -1.2421e+00,\n",
            "         -1.0393e+00, -1.7690e+00],\n",
            "        [-5.5641e+00, -4.4022e+00, -4.9175e+00,  ..., -3.7601e-02,\n",
            "         -5.3071e+00, -5.2012e+00],\n",
            "        ...,\n",
            "        [-1.9459e+00, -1.9459e+00, -1.9459e+00,  ..., -1.9459e+00,\n",
            "         -1.9459e+00, -1.9459e+00],\n",
            "        [-3.9288e-01, -2.5751e+00, -3.7809e+00,  ..., -2.7937e+00,\n",
            "         -2.5195e+00, -3.0011e+00],\n",
            "        [-7.4733e+00, -7.1430e+00, -3.7589e-03,  ..., -7.5885e+00,\n",
            "         -7.2709e+00, -7.2752e+00]], grad_fn=<LogSoftmaxBackward0>)\n",
            "Training: 675\n",
            "Epoch: 0676 loss_train: 0.5928 acc_train: 0.8429 loss_val: 1.0357 acc_val: 0.6633 time: 4.4535s\n",
            "loss_val:1.035688877105713, val_acc:0.6633333333333333, out_features:tensor([[-5.4622, -5.2647, -0.0488,  ..., -4.0523, -5.1546, -5.0357],\n",
            "        [-2.4677, -3.4883, -2.4742,  ..., -2.0626, -1.2512, -1.0231],\n",
            "        [-4.0468, -3.7491, -3.6761,  ..., -0.1619, -3.6310, -3.1539],\n",
            "        ...,\n",
            "        [-3.5489, -0.2454, -3.6417,  ..., -3.4222, -2.8627, -3.0562],\n",
            "        [-0.1365, -4.5407, -4.8785,  ..., -3.4633, -2.8850, -4.4052],\n",
            "        [-4.0362, -3.5407, -0.1253,  ..., -3.7237, -3.9267, -4.1771]],\n",
            "       grad_fn=<LogSoftmaxBackward0>)\n",
            "Training: 676\n",
            "Epoch: 0677 loss_train: 0.6443 acc_train: 0.8286 loss_val: 1.0979 acc_val: 0.6333 time: 4.1140s\n",
            "loss_val:1.0979375839233398, val_acc:0.6333333333333333, out_features:tensor([[-1.9459, -1.9459, -1.9459,  ..., -1.9459, -1.9459, -1.9459],\n",
            "        [-1.9459, -1.9459, -1.9459,  ..., -1.9459, -1.9459, -1.9459],\n",
            "        [-3.0919, -2.7321, -2.4581,  ..., -0.3861, -2.8986, -3.1816],\n",
            "        ...,\n",
            "        [-2.3695, -0.5432, -3.1030,  ..., -2.8520, -1.9367, -3.2042],\n",
            "        [-0.5528, -3.3558, -3.6407,  ..., -1.8403, -2.2787, -2.8398],\n",
            "        [-2.6369, -2.3647, -0.7026,  ..., -2.4231, -2.7425, -2.2955]],\n",
            "       grad_fn=<LogSoftmaxBackward0>)\n",
            "Training: 677\n",
            "Epoch: 0678 loss_train: 0.5378 acc_train: 0.8714 loss_val: 1.0578 acc_val: 0.6600 time: 4.1580s\n",
            "loss_val:1.0577536821365356, val_acc:0.66, out_features:tensor([[-6.9309e+00, -6.6123e+00, -2.7519e-02,  ..., -6.6737e+00,\n",
            "         -6.9679e+00, -5.2647e+00],\n",
            "        [-3.9463e+00, -4.3443e+00, -5.0149e+00,  ..., -3.5715e+00,\n",
            "         -8.3454e-02, -4.8470e+00],\n",
            "        [-7.6111e+00, -7.3506e+00, -7.5486e+00,  ..., -3.3354e-03,\n",
            "         -7.2285e+00, -7.4745e+00],\n",
            "        ...,\n",
            "        [-2.0046e+00, -9.5321e-01, -2.5985e+00,  ..., -2.5137e+00,\n",
            "         -1.6693e+00, -2.5579e+00],\n",
            "        [-2.9139e-02, -7.1693e+00, -7.2983e+00,  ..., -6.5203e+00,\n",
            "         -3.8471e+00, -5.5885e+00],\n",
            "        [-3.7665e+00, -2.1068e+00, -3.2273e-01,  ..., -3.2234e+00,\n",
            "         -3.5083e+00, -3.4839e+00]], grad_fn=<LogSoftmaxBackward0>)\n",
            "Training: 678\n",
            "Epoch: 0679 loss_train: 0.6651 acc_train: 0.7714 loss_val: 1.0103 acc_val: 0.6600 time: 4.4579s\n",
            "loss_val:1.0103306770324707, val_acc:0.66, out_features:tensor([[-7.5700, -7.5222, -0.0085,  ..., -5.4555, -7.0981, -6.6134],\n",
            "        [-2.1426, -2.4408, -1.7624,  ..., -2.4387, -1.4936, -1.3257],\n",
            "        [-4.0146, -4.3574, -3.5088,  ..., -0.1083, -4.3245, -4.0475],\n",
            "        ...,\n",
            "        [-2.5788, -0.8114, -2.9141,  ..., -2.3982, -2.0402, -2.5856],\n",
            "        [-0.2127, -4.0479, -4.2621,  ..., -2.4893, -3.3594, -3.6018],\n",
            "        [-1.9459, -1.9459, -1.9459,  ..., -1.9459, -1.9459, -1.9459]],\n",
            "       grad_fn=<LogSoftmaxBackward0>)\n",
            "Training: 679\n",
            "Epoch: 0680 loss_train: 0.5358 acc_train: 0.8500 loss_val: 0.9927 acc_val: 0.6700 time: 4.1049s\n",
            "loss_val:0.9926578998565674, val_acc:0.67, out_features:tensor([[-3.7410, -3.3494, -0.2303,  ..., -3.4049, -3.4581, -2.9643],\n",
            "        [-1.9459, -1.9459, -1.9459,  ..., -1.9459, -1.9459, -1.9459],\n",
            "        [-1.9459, -1.9459, -1.9459,  ..., -1.9459, -1.9459, -1.9459],\n",
            "        ...,\n",
            "        [-4.1765, -0.0758, -5.0453,  ..., -3.3761, -5.0901, -5.0868],\n",
            "        [-0.6383, -2.7432, -3.1207,  ..., -1.8266, -2.3640, -2.6919],\n",
            "        [-5.2307, -4.3691, -0.0516,  ..., -5.2665, -5.1282, -4.9116]],\n",
            "       grad_fn=<LogSoftmaxBackward0>)\n",
            "Training: 680\n",
            "Epoch: 0681 loss_train: 0.6407 acc_train: 0.8214 loss_val: 1.1222 acc_val: 0.6733 time: 4.1087s\n",
            "loss_val:1.1222161054611206, val_acc:0.6733333333333333, out_features:tensor([[-1.1992e+01, -1.1985e+01, -2.0061e-04,  ..., -9.4803e+00,\n",
            "         -1.1987e+01, -1.1850e+01],\n",
            "        [-1.9459e+00, -1.9459e+00, -1.9459e+00,  ..., -1.9459e+00,\n",
            "         -1.9459e+00, -1.9459e+00],\n",
            "        [-5.7788e+00, -5.8586e+00, -6.1462e+00,  ..., -1.9931e-02,\n",
            "         -5.6754e+00, -5.0569e+00],\n",
            "        ...,\n",
            "        [-5.4368e+00, -2.8958e-02, -6.1512e+00,  ..., -5.3981e+00,\n",
            "         -4.3282e+00, -6.0958e+00],\n",
            "        [-6.1971e-01, -2.6137e+00, -3.2711e+00,  ..., -2.2834e+00,\n",
            "         -2.0517e+00, -2.9168e+00],\n",
            "        [-4.8604e+00, -5.4204e+00, -2.9404e-02,  ..., -5.2072e+00,\n",
            "         -5.6181e+00, -5.7671e+00]], grad_fn=<LogSoftmaxBackward0>)\n",
            "Training: 681\n",
            "Epoch: 0682 loss_train: 0.5889 acc_train: 0.8286 loss_val: 0.9512 acc_val: 0.6900 time: 4.3860s\n",
            "loss_val:0.9512408375740051, val_acc:0.69, out_features:tensor([[-9.1484e+00, -8.0636e+00, -9.8954e-04,  ..., -8.3031e+00,\n",
            "         -9.2231e+00, -8.9992e+00],\n",
            "        [-1.9459e+00, -1.9459e+00, -1.9459e+00,  ..., -1.9459e+00,\n",
            "         -1.9459e+00, -1.9459e+00],\n",
            "        [-4.9872e+00, -4.2009e+00, -4.9103e+00,  ..., -5.9281e-02,\n",
            "         -4.4107e+00, -4.6804e+00],\n",
            "        ...,\n",
            "        [-3.5596e+00, -2.5535e-01, -3.1233e+00,  ..., -3.3516e+00,\n",
            "         -2.8574e+00, -3.3095e+00],\n",
            "        [-1.2238e-01, -4.2660e+00, -4.6014e+00,  ..., -3.5150e+00,\n",
            "         -3.4256e+00, -4.4299e+00],\n",
            "        [-2.7552e+00, -2.2790e+00, -4.3698e-01,  ..., -3.2928e+00,\n",
            "         -3.3705e+00, -3.2409e+00]], grad_fn=<LogSoftmaxBackward0>)\n",
            "Training: 682\n",
            "Epoch: 0683 loss_train: 0.5591 acc_train: 0.8357 loss_val: 0.9769 acc_val: 0.6900 time: 4.1682s\n",
            "loss_val:0.9768854975700378, val_acc:0.69, out_features:tensor([[-8.3160e+00, -8.1776e+00, -3.4442e-03,  ..., -6.6040e+00,\n",
            "         -8.1999e+00, -8.0877e+00],\n",
            "        [-2.6798e+00, -2.5884e+00, -2.4998e+00,  ..., -2.8407e+00,\n",
            "         -7.7216e-01, -1.6435e+00],\n",
            "        [-4.9760e+00, -5.8887e+00, -4.5169e+00,  ..., -2.9247e-02,\n",
            "         -5.9270e+00, -5.9022e+00],\n",
            "        ...,\n",
            "        [-5.3460e+00, -4.9849e-02, -5.5241e+00,  ..., -4.2423e+00,\n",
            "         -4.0618e+00, -5.2850e+00],\n",
            "        [-8.9379e-02, -5.3929e+00, -5.6654e+00,  ..., -4.0000e+00,\n",
            "         -3.4305e+00, -3.7695e+00],\n",
            "        [-2.3371e+00, -2.3417e+00, -1.1768e+00,  ..., -2.1958e+00,\n",
            "         -2.1119e+00, -1.9392e+00]], grad_fn=<LogSoftmaxBackward0>)\n",
            "Training: 683\n",
            "Epoch: 0684 loss_train: 0.7046 acc_train: 0.7786 loss_val: 0.9823 acc_val: 0.6667 time: 4.1823s\n",
            "loss_val:0.9823240041732788, val_acc:0.6666666666666666, out_features:tensor([[-8.1085e+00, -8.0112e+00, -6.1591e-03,  ..., -6.2982e+00,\n",
            "         -8.0374e+00, -7.5695e+00],\n",
            "        [-1.9459e+00, -1.9459e+00, -1.9459e+00,  ..., -1.9459e+00,\n",
            "         -1.9459e+00, -1.9459e+00],\n",
            "        [-6.1830e+00, -5.1201e+00, -3.3310e+00,  ..., -5.1864e-02,\n",
            "         -5.8481e+00, -6.1550e+00],\n",
            "        ...,\n",
            "        [-2.1820e+00, -7.0267e-01, -3.2320e+00,  ..., -2.7895e+00,\n",
            "         -1.9622e+00, -2.2254e+00],\n",
            "        [-1.7274e+00, -2.0633e+00, -2.1041e+00,  ..., -1.7345e+00,\n",
            "         -1.8101e+00, -2.0484e+00],\n",
            "        [-5.5295e+00, -3.1660e+00, -7.8495e-02,  ..., -5.0704e+00,\n",
            "         -5.2790e+00, -5.5998e+00]], grad_fn=<LogSoftmaxBackward0>)\n",
            "Training: 684\n",
            "Epoch: 0685 loss_train: 0.6069 acc_train: 0.8429 loss_val: 1.0369 acc_val: 0.6567 time: 4.4339s\n",
            "loss_val:1.036912441253662, val_acc:0.6566666666666666, out_features:tensor([[-4.0163, -3.9107, -0.1829,  ..., -3.6080, -4.1170, -3.3413],\n",
            "        [-1.9459, -1.9459, -1.9459,  ..., -1.9459, -1.9459, -1.9459],\n",
            "        [-4.1224, -4.3168, -2.4291,  ..., -0.1710, -4.4213, -4.0380],\n",
            "        ...,\n",
            "        [-2.1032, -1.0420, -2.5100,  ..., -2.0693, -2.3103, -1.9078],\n",
            "        [-0.6888, -2.9057, -2.9257,  ..., -1.7207, -2.5354, -2.4302],\n",
            "        [-2.4173, -2.1828, -0.7344,  ..., -2.6017, -2.4776, -2.2758]],\n",
            "       grad_fn=<LogSoftmaxBackward0>)\n",
            "Training: 685\n",
            "Epoch: 0686 loss_train: 0.6760 acc_train: 0.7929 loss_val: 1.0838 acc_val: 0.6633 time: 4.2174s\n",
            "loss_val:1.083785057067871, val_acc:0.6633333333333333, out_features:tensor([[-4.7769, -4.3017, -0.0814,  ..., -3.6493, -4.6930, -4.4809],\n",
            "        [-1.9459, -1.9459, -1.9459,  ..., -1.9459, -1.9459, -1.9459],\n",
            "        [-1.9459, -1.9459, -1.9459,  ..., -1.9459, -1.9459, -1.9459],\n",
            "        ...,\n",
            "        [-2.2531, -1.7427, -1.3525,  ..., -1.7582, -2.0422, -2.4171],\n",
            "        [-1.0334, -2.0411, -2.1696,  ..., -2.3177, -2.1517, -2.0280],\n",
            "        [-1.5390, -3.0231, -1.5494,  ..., -2.2000, -1.3401, -2.2706]],\n",
            "       grad_fn=<LogSoftmaxBackward0>)\n",
            "Training: 686\n",
            "Epoch: 0687 loss_train: 0.6147 acc_train: 0.8214 loss_val: 1.0154 acc_val: 0.7033 time: 4.2303s\n",
            "loss_val:1.0154458284378052, val_acc:0.7033333333333334, out_features:tensor([[-5.1595, -5.0147, -0.0682,  ..., -3.9703, -4.8293, -4.1187],\n",
            "        [-2.6090, -3.3413, -3.1191,  ..., -1.6255, -1.0268, -1.3352],\n",
            "        [-2.0980, -2.7444, -2.1062,  ..., -0.7445, -2.6006, -2.6369],\n",
            "        ...,\n",
            "        [-5.1727, -0.0460, -4.8806,  ..., -4.4317, -4.8075, -5.1482],\n",
            "        [-0.5437, -2.9365, -3.2512,  ..., -2.1961, -2.3982, -2.9891],\n",
            "        [-3.3720, -2.5943, -0.3347,  ..., -3.4935, -3.3233, -3.1001]],\n",
            "       grad_fn=<LogSoftmaxBackward0>)\n",
            "Training: 687\n",
            "Epoch: 0688 loss_train: 0.5715 acc_train: 0.8714 loss_val: 1.2233 acc_val: 0.6267 time: 4.3845s\n",
            "loss_val:1.223270058631897, val_acc:0.6266666666666667, out_features:tensor([[-8.6153e+00, -8.5301e+00, -4.2584e-03,  ..., -7.8418e+00,\n",
            "         -8.5525e+00, -7.9796e+00],\n",
            "        [-1.9459e+00, -1.9459e+00, -1.9459e+00,  ..., -1.9459e+00,\n",
            "         -1.9459e+00, -1.9459e+00],\n",
            "        [-4.2998e+00, -5.8783e+00, -6.1151e+00,  ..., -3.6705e-02,\n",
            "         -4.4443e+00, -5.8251e+00],\n",
            "        ...,\n",
            "        [-3.0447e+00, -4.3468e-01, -3.3342e+00,  ..., -2.6538e+00,\n",
            "         -2.1731e+00, -2.9650e+00],\n",
            "        [-2.3510e-02, -5.3829e+00, -6.2641e+00,  ..., -4.7202e+00,\n",
            "         -5.8431e+00, -5.9177e+00],\n",
            "        [-7.5718e+00, -8.1203e+00, -2.2949e-03,  ..., -8.3027e+00,\n",
            "         -8.4013e+00, -8.4334e+00]], grad_fn=<LogSoftmaxBackward0>)\n",
            "Training: 688\n",
            "Epoch: 0689 loss_train: 0.6808 acc_train: 0.7857 loss_val: 1.0047 acc_val: 0.6633 time: 4.1616s\n",
            "loss_val:1.0047085285186768, val_acc:0.6633333333333333, out_features:tensor([[-4.4435e+00, -4.1727e+00, -1.2154e-01,  ..., -3.7790e+00,\n",
            "         -4.0458e+00, -3.4313e+00],\n",
            "        [-1.9459e+00, -1.9459e+00, -1.9459e+00,  ..., -1.9459e+00,\n",
            "         -1.9459e+00, -1.9459e+00],\n",
            "        [-1.0638e+01, -1.0330e+01, -1.0633e+01,  ..., -1.8881e-04,\n",
            "         -1.0281e+01, -1.0003e+01],\n",
            "        ...,\n",
            "        [-2.2867e+00, -6.3603e-01, -2.7993e+00,  ..., -2.5544e+00,\n",
            "         -2.6727e+00, -2.4958e+00],\n",
            "        [-9.7921e-01, -2.5718e+00, -2.8848e+00,  ..., -2.0507e+00,\n",
            "         -1.6728e+00, -2.1696e+00],\n",
            "        [-1.9459e+00, -1.9459e+00, -1.9459e+00,  ..., -1.9459e+00,\n",
            "         -1.9459e+00, -1.9459e+00]], grad_fn=<LogSoftmaxBackward0>)\n",
            "Training: 689\n",
            "Epoch: 0690 loss_train: 0.5869 acc_train: 0.8286 loss_val: 1.0959 acc_val: 0.6700 time: 4.2055s\n",
            "loss_val:1.095924735069275, val_acc:0.67, out_features:tensor([[-2.9919, -2.5410, -0.6336,  ..., -2.7116, -2.5403, -2.4247],\n",
            "        [-1.9459, -1.9459, -1.9459,  ..., -1.9459, -1.9459, -1.9459],\n",
            "        [-4.4586, -3.6103, -3.2771,  ..., -0.1227, -4.1810, -4.1995],\n",
            "        ...,\n",
            "        [-6.2484, -0.0286, -4.6268,  ..., -5.8907, -4.7391, -5.7697],\n",
            "        [-0.4305, -2.7540, -3.2901,  ..., -3.2499, -2.2268, -3.5277],\n",
            "        [-4.4110, -5.2327, -0.0463,  ..., -4.8509, -5.3316, -4.8417]],\n",
            "       grad_fn=<LogSoftmaxBackward0>)\n",
            "Training: 690\n",
            "Epoch: 0691 loss_train: 0.5707 acc_train: 0.8500 loss_val: 0.9546 acc_val: 0.6800 time: 4.3072s\n",
            "loss_val:0.9546210765838623, val_acc:0.68, out_features:tensor([[-1.9441e+01, -1.9327e+01, -1.1921e-07,  ..., -1.9415e+01,\n",
            "         -1.9423e+01, -1.9417e+01],\n",
            "        [-1.9459e+00, -1.9459e+00, -1.9459e+00,  ..., -1.9459e+00,\n",
            "         -1.9459e+00, -1.9459e+00],\n",
            "        [-7.2564e+00, -6.6853e+00, -6.2441e+00,  ..., -5.8647e-03,\n",
            "         -7.2387e+00, -7.2459e+00],\n",
            "        ...,\n",
            "        [-6.5446e+00, -9.5499e-03, -6.9453e+00,  ..., -5.7367e+00,\n",
            "         -6.1089e+00, -7.0458e+00],\n",
            "        [-1.3718e+00, -2.0294e+00, -2.0401e+00,  ..., -2.1513e+00,\n",
            "         -2.1382e+00, -2.1838e+00],\n",
            "        [-2.8356e+00, -2.3117e+00, -4.9291e-01,  ..., -2.8560e+00,\n",
            "         -2.9505e+00, -2.8263e+00]], grad_fn=<LogSoftmaxBackward0>)\n",
            "Training: 691\n",
            "Epoch: 0692 loss_train: 0.5017 acc_train: 0.8857 loss_val: 1.0896 acc_val: 0.6500 time: 4.1176s\n",
            "loss_val:1.0895708799362183, val_acc:0.65, out_features:tensor([[-1.5328e+01, -1.4356e+01, -1.7881e-06,  ..., -1.5282e+01,\n",
            "         -1.5154e+01, -1.5351e+01],\n",
            "        [-3.7080e+00, -4.1225e+00, -5.6719e+00,  ..., -4.5942e+00,\n",
            "         -6.4999e-02, -5.3605e+00],\n",
            "        [-1.9459e+00, -1.9459e+00, -1.9459e+00,  ..., -1.9459e+00,\n",
            "         -1.9459e+00, -1.9459e+00],\n",
            "        ...,\n",
            "        [-3.4380e+00, -1.2089e-01, -4.7145e+00,  ..., -3.0235e+00,\n",
            "         -4.4349e+00, -4.8829e+00],\n",
            "        [-3.3759e-01, -2.9323e+00, -3.8637e+00,  ..., -1.9642e+00,\n",
            "         -3.6992e+00, -3.6696e+00],\n",
            "        [-1.1957e+01, -1.2101e+01, -7.7960e-05,  ..., -9.8741e+00,\n",
            "         -1.2199e+01, -1.2260e+01]], grad_fn=<LogSoftmaxBackward0>)\n",
            "Training: 692\n",
            "Epoch: 0693 loss_train: 0.5725 acc_train: 0.8143 loss_val: 0.9909 acc_val: 0.7133 time: 4.3383s\n",
            "loss_val:0.9908658862113953, val_acc:0.7133333333333334, out_features:tensor([[-7.0135e+00, -7.1505e+00, -5.8929e-03,  ..., -6.6952e+00,\n",
            "         -6.7296e+00, -6.9541e+00],\n",
            "        [-1.9459e+00, -1.9459e+00, -1.9459e+00,  ..., -1.9459e+00,\n",
            "         -1.9459e+00, -1.9459e+00],\n",
            "        [-2.1286e+00, -3.2181e+00, -3.5303e+00,  ..., -5.4100e-01,\n",
            "         -2.0176e+00, -2.9021e+00],\n",
            "        ...,\n",
            "        [-3.1727e+00, -7.0564e-01, -2.2995e+00,  ..., -2.0075e+00,\n",
            "         -2.6376e+00, -2.0607e+00],\n",
            "        [-2.5430e-01, -3.6584e+00, -4.2881e+00,  ..., -2.5637e+00,\n",
            "         -3.2682e+00, -2.9116e+00],\n",
            "        [-7.7193e+00, -6.2350e+00, -4.9122e-03,  ..., -6.9063e+00,\n",
            "         -7.6255e+00, -7.7660e+00]], grad_fn=<LogSoftmaxBackward0>)\n",
            "Training: 693\n",
            "Epoch: 0694 loss_train: 0.6667 acc_train: 0.8429 loss_val: 1.0991 acc_val: 0.6633 time: 4.2551s\n",
            "loss_val:1.0990735292434692, val_acc:0.6633333333333333, out_features:tensor([[-4.2403, -4.0765, -0.1110,  ..., -4.3709, -4.5724, -3.7372],\n",
            "        [-4.3244, -4.4797, -4.1723,  ..., -2.0502, -0.2821, -2.7580],\n",
            "        [-5.4953, -5.8521, -4.5507,  ..., -0.0322, -5.3416, -5.1056],\n",
            "        ...,\n",
            "        [-4.1516, -0.1115, -4.5454,  ..., -4.3315, -3.4274, -3.9545],\n",
            "        [-0.1096, -4.5084, -4.9341,  ..., -4.5177, -2.8225, -4.9714],\n",
            "        [-3.1031, -3.2196, -0.1784,  ..., -3.8628, -3.8834, -4.1418]],\n",
            "       grad_fn=<LogSoftmaxBackward0>)\n",
            "Training: 694\n",
            "Epoch: 0695 loss_train: 0.5831 acc_train: 0.8286 loss_val: 1.0628 acc_val: 0.6333 time: 4.1227s\n",
            "loss_val:1.0628317594528198, val_acc:0.6333333333333333, out_features:tensor([[-1.4624e+01, -1.4200e+01, -5.8412e-06,  ..., -1.4296e+01,\n",
            "         -1.4592e+01, -1.4451e+01],\n",
            "        [-1.9459e+00, -1.9459e+00, -1.9459e+00,  ..., -1.9459e+00,\n",
            "         -1.9459e+00, -1.9459e+00],\n",
            "        [-8.2691e+00, -1.0240e+01, -1.0141e+01,  ..., -5.5131e-04,\n",
            "         -9.7295e+00, -8.9861e+00],\n",
            "        ...,\n",
            "        [-3.0343e+00, -4.3180e-01, -2.5900e+00,  ..., -2.8801e+00,\n",
            "         -2.7043e+00, -2.9843e+00],\n",
            "        [-5.0416e-01, -2.6662e+00, -3.6388e+00,  ..., -1.8600e+00,\n",
            "         -2.4133e+00, -3.5308e+00],\n",
            "        [-1.1414e+01, -9.8403e+00, -2.0180e-04,  ..., -9.1485e+00,\n",
            "         -1.1268e+01, -1.1559e+01]], grad_fn=<LogSoftmaxBackward0>)\n",
            "Training: 695\n",
            "Epoch: 0696 loss_train: 0.6551 acc_train: 0.8000 loss_val: 1.0892 acc_val: 0.6667 time: 4.5901s\n",
            "loss_val:1.0892045497894287, val_acc:0.6666666666666666, out_features:tensor([[-2.4236e+00, -2.3406e+00, -1.0612e+00,  ..., -2.2875e+00,\n",
            "         -2.3098e+00, -1.9596e+00],\n",
            "        [-2.3629e+00, -1.9435e+00, -2.7270e+00,  ..., -2.4054e+00,\n",
            "         -1.0626e+00, -2.4885e+00],\n",
            "        [-6.4544e+00, -7.7561e+00, -7.1630e+00,  ..., -4.0645e-03,\n",
            "         -7.3931e+00, -7.9000e+00],\n",
            "        ...,\n",
            "        [-4.8244e+00, -6.7147e-02, -5.6168e+00,  ..., -4.2604e+00,\n",
            "         -3.4644e+00, -5.3741e+00],\n",
            "        [-1.1450e+00, -1.8616e+00, -2.5671e+00,  ..., -2.3390e+00,\n",
            "         -1.6707e+00, -2.4394e+00],\n",
            "        [-4.5536e+00, -5.8638e+00, -3.8941e-02,  ..., -4.5210e+00,\n",
            "         -5.9381e+00, -6.0489e+00]], grad_fn=<LogSoftmaxBackward0>)\n",
            "Training: 696\n",
            "Epoch: 0697 loss_train: 0.5571 acc_train: 0.8071 loss_val: 0.9837 acc_val: 0.6733 time: 4.2452s\n",
            "loss_val:0.9836840629577637, val_acc:0.6733333333333333, out_features:tensor([[-5.2137e+00, -4.9246e+00, -4.4050e-02,  ..., -4.7310e+00,\n",
            "         -5.3191e+00, -5.0206e+00],\n",
            "        [-2.5253e+00, -1.5318e+00, -2.7040e+00,  ..., -3.3216e+00,\n",
            "         -6.0840e-01, -3.5334e+00],\n",
            "        [-5.8864e+00, -6.5739e+00, -6.7895e+00,  ..., -1.1592e-02,\n",
            "         -6.0891e+00, -6.2503e+00],\n",
            "        ...,\n",
            "        [-3.9121e+00, -9.3070e-02, -4.8587e+00,  ..., -4.7295e+00,\n",
            "         -3.4928e+00, -4.2331e+00],\n",
            "        [-4.8285e-01, -2.6440e+00, -3.3599e+00,  ..., -1.9036e+00,\n",
            "         -2.9924e+00, -3.1489e+00],\n",
            "        [-1.8221e+01, -1.6375e+01, -1.1921e-07,  ..., -1.7768e+01,\n",
            "         -1.7950e+01, -1.8218e+01]], grad_fn=<LogSoftmaxBackward0>)\n",
            "Training: 697\n",
            "Epoch: 0698 loss_train: 0.5671 acc_train: 0.8071 loss_val: 1.0260 acc_val: 0.6900 time: 4.1683s\n",
            "loss_val:1.0260032415390015, val_acc:0.69, out_features:tensor([[-5.0121e+00, -4.8791e+00, -6.0117e-02,  ..., -4.4984e+00,\n",
            "         -4.4496e+00, -4.6711e+00],\n",
            "        [-2.3663e+00, -3.3933e+00, -1.9605e+00,  ..., -2.4402e+00,\n",
            "         -6.4533e-01, -2.3411e+00],\n",
            "        [-1.0351e+01, -1.1214e+01, -1.1376e+01,  ..., -2.3386e-04,\n",
            "         -1.1301e+01, -8.7771e+00],\n",
            "        ...,\n",
            "        [-1.5446e+00, -2.2614e+00, -2.0614e+00,  ..., -1.9525e+00,\n",
            "         -1.8386e+00, -1.8538e+00],\n",
            "        [-1.0237e+00, -2.4894e+00, -2.6716e+00,  ..., -1.5973e+00,\n",
            "         -2.2011e+00, -2.1290e+00],\n",
            "        [-8.9449e+00, -9.6812e+00, -8.8498e-04,  ..., -9.7603e+00,\n",
            "         -7.5623e+00, -9.7538e+00]], grad_fn=<LogSoftmaxBackward0>)\n",
            "Training: 698\n",
            "Epoch: 0699 loss_train: 0.5601 acc_train: 0.8286 loss_val: 1.0225 acc_val: 0.6600 time: 4.3929s\n",
            "loss_val:1.0225352048873901, val_acc:0.66, out_features:tensor([[-4.7403e+00, -4.4257e+00, -1.1304e-01,  ..., -4.2530e+00,\n",
            "         -4.7304e+00, -4.3338e+00],\n",
            "        [-2.6057e+00, -2.3155e+00, -2.4664e+00,  ..., -2.6469e+00,\n",
            "         -7.2237e-01, -2.0611e+00],\n",
            "        [-1.8386e+00, -2.5335e+00, -3.0246e+00,  ..., -6.2560e-01,\n",
            "         -2.7602e+00, -2.6675e+00],\n",
            "        ...,\n",
            "        [-2.4342e+00, -8.9765e-01, -3.2737e+00,  ..., -2.3482e+00,\n",
            "         -2.2060e+00, -1.4905e+00],\n",
            "        [-5.2781e-02, -5.8015e+00, -5.8480e+00,  ..., -4.7449e+00,\n",
            "         -3.6594e+00, -4.8644e+00],\n",
            "        [-9.4706e+00, -8.6604e+00, -9.0582e-04,  ..., -9.3303e+00,\n",
            "         -9.4810e+00, -9.5619e+00]], grad_fn=<LogSoftmaxBackward0>)\n",
            "Training: 699\n",
            "Epoch: 0700 loss_train: 0.6569 acc_train: 0.7786 loss_val: 1.0549 acc_val: 0.6467 time: 4.1217s\n",
            "loss_val:1.054864764213562, val_acc:0.6466666666666666, out_features:tensor([[-7.2728e+00, -7.1531e+00, -2.7039e-02,  ..., -4.6540e+00,\n",
            "         -7.2316e+00, -6.5190e+00],\n",
            "        [-1.0387e+01, -1.2200e+01, -1.1338e+01,  ..., -1.0908e+01,\n",
            "         -8.0225e-05, -1.1593e+01],\n",
            "        [-9.7852e+00, -7.7683e+00, -9.4608e+00,  ..., -8.9093e-04,\n",
            "         -8.4117e+00, -9.6708e+00],\n",
            "        ...,\n",
            "        [-2.2845e+00, -1.4126e+00, -1.9277e+00,  ..., -2.2856e+00,\n",
            "         -2.0465e+00, -2.3307e+00],\n",
            "        [-2.0947e-01, -4.0184e+00, -4.3832e+00,  ..., -2.5523e+00,\n",
            "         -3.4669e+00, -3.3178e+00],\n",
            "        [-5.7542e+00, -5.0732e+00, -2.2823e-02,  ..., -5.4829e+00,\n",
            "         -5.6118e+00, -5.9607e+00]], grad_fn=<LogSoftmaxBackward0>)\n",
            "Training: 700\n",
            "Epoch: 0701 loss_train: 0.6373 acc_train: 0.8357 loss_val: 1.0854 acc_val: 0.6167 time: 4.1290s\n",
            "loss_val:1.0854377746582031, val_acc:0.6166666666666667, out_features:tensor([[-5.9294e+00, -6.0366e+00, -3.9082e-02,  ..., -5.8288e+00,\n",
            "         -6.0120e+00, -4.4524e+00],\n",
            "        [-1.9459e+00, -1.9459e+00, -1.9459e+00,  ..., -1.9459e+00,\n",
            "         -1.9459e+00, -1.9459e+00],\n",
            "        [-8.3081e+00, -6.7169e+00, -8.7776e+00,  ..., -2.7316e-03,\n",
            "         -8.2839e+00, -7.2483e+00],\n",
            "        ...,\n",
            "        [-6.1879e+00, -1.3399e-02, -5.8324e+00,  ..., -5.3180e+00,\n",
            "         -6.5950e+00, -6.7817e+00],\n",
            "        [-1.6875e+00, -1.7165e+00, -2.1061e+00,  ..., -1.6845e+00,\n",
            "         -1.9640e+00, -2.3636e+00],\n",
            "        [-5.8702e+00, -5.8242e+00, -2.3472e-02,  ..., -6.2751e+00,\n",
            "         -6.1202e+00, -4.5080e+00]], grad_fn=<LogSoftmaxBackward0>)\n",
            "Training: 701\n",
            "Epoch: 0702 loss_train: 0.5519 acc_train: 0.8500 loss_val: 1.0161 acc_val: 0.6633 time: 4.3699s\n",
            "loss_val:1.0160831212997437, val_acc:0.6633333333333333, out_features:tensor([[-1.1952e+01, -1.1278e+01, -6.2464e-05,  ..., -1.1050e+01,\n",
            "         -1.1351e+01, -1.1934e+01],\n",
            "        [-1.9459e+00, -1.9459e+00, -1.9459e+00,  ..., -1.9459e+00,\n",
            "         -1.9459e+00, -1.9459e+00],\n",
            "        [-2.7962e+00, -2.3591e+00, -3.0709e+00,  ..., -3.5024e-01,\n",
            "         -3.1956e+00, -3.4103e+00],\n",
            "        ...,\n",
            "        [-7.9907e+00, -7.6505e-03, -7.9633e+00,  ..., -5.1672e+00,\n",
            "         -7.3299e+00, -8.0302e+00],\n",
            "        [-1.8327e-01, -2.9714e+00, -4.3588e+00,  ..., -3.7015e+00,\n",
            "         -3.1744e+00, -3.9034e+00],\n",
            "        [-2.4338e+00, -2.5954e+00, -6.8933e-01,  ..., -2.7678e+00,\n",
            "         -2.7070e+00, -2.0921e+00]], grad_fn=<LogSoftmaxBackward0>)\n",
            "Training: 702\n",
            "Epoch: 0703 loss_train: 0.5961 acc_train: 0.8214 loss_val: 1.0527 acc_val: 0.6767 time: 4.1205s\n",
            "loss_val:1.0527021884918213, val_acc:0.6766666666666666, out_features:tensor([[-8.8482e+00, -8.9341e+00, -1.4694e-03,  ..., -7.8075e+00,\n",
            "         -8.9052e+00, -7.7314e+00],\n",
            "        [-1.9459e+00, -1.9459e+00, -1.9459e+00,  ..., -1.9459e+00,\n",
            "         -1.9459e+00, -1.9459e+00],\n",
            "        [-2.8392e+00, -2.7082e+00, -2.3823e+00,  ..., -4.7158e-01,\n",
            "         -2.9023e+00, -2.9316e+00],\n",
            "        ...,\n",
            "        [-3.0930e+00, -7.3413e-01, -2.1446e+00,  ..., -2.8543e+00,\n",
            "         -1.7274e+00, -2.4708e+00],\n",
            "        [-3.9264e-02, -5.7864e+00, -5.9652e+00,  ..., -5.5516e+00,\n",
            "         -3.8595e+00, -5.2418e+00],\n",
            "        [-2.5503e+00, -2.3998e+00, -6.5353e-01,  ..., -2.9751e+00,\n",
            "         -2.4921e+00, -2.2949e+00]], grad_fn=<LogSoftmaxBackward0>)\n",
            "Training: 703\n",
            "Epoch: 0704 loss_train: 0.5103 acc_train: 0.8357 loss_val: 1.0658 acc_val: 0.6700 time: 4.0816s\n",
            "loss_val:1.065847635269165, val_acc:0.67, out_features:tensor([[-8.6978e+00, -8.3509e+00, -1.6528e-03,  ..., -8.1506e+00,\n",
            "         -8.6589e+00, -8.6513e+00],\n",
            "        [-4.7278e+00, -5.7996e+00, -5.5476e+00,  ..., -3.7637e+00,\n",
            "         -4.5763e-02, -5.7198e+00],\n",
            "        [-6.8810e+00, -6.7957e+00, -6.2674e+00,  ..., -8.2647e-03,\n",
            "         -6.7354e+00, -6.9243e+00],\n",
            "        ...,\n",
            "        [-5.4742e+00, -4.1099e-02, -5.1218e+00,  ..., -4.3021e+00,\n",
            "         -4.7691e+00, -5.3725e+00],\n",
            "        [-4.1264e-02, -5.5176e+00, -5.3352e+00,  ..., -4.2301e+00,\n",
            "         -4.7064e+00, -5.4831e+00],\n",
            "        [-3.3391e+00, -2.7444e+00, -4.7726e-01,  ..., -2.2549e+00,\n",
            "         -3.3230e+00, -2.4336e+00]], grad_fn=<LogSoftmaxBackward0>)\n",
            "Training: 704\n",
            "Epoch: 0705 loss_train: 0.6371 acc_train: 0.8143 loss_val: 1.0871 acc_val: 0.6633 time: 4.4041s\n",
            "loss_val:1.087149739265442, val_acc:0.6633333333333333, out_features:tensor([[-2.2961, -2.4552, -1.0631,  ..., -2.2670, -2.2407, -1.8994],\n",
            "        [-1.2533, -2.9812, -3.0235,  ..., -2.3814, -1.3797, -1.4742],\n",
            "        [-4.3953, -4.2416, -3.1109,  ..., -0.1118, -4.4877, -4.5519],\n",
            "        ...,\n",
            "        [-1.9459, -1.9459, -1.9459,  ..., -1.9459, -1.9459, -1.9459],\n",
            "        [-0.6034, -1.5850, -3.3824,  ..., -3.0119, -2.9306, -3.0048],\n",
            "        [-4.1581, -3.1046, -0.1376,  ..., -3.3806, -4.0955, -4.7257]],\n",
            "       grad_fn=<LogSoftmaxBackward0>)\n",
            "Training: 705\n",
            "Epoch: 0706 loss_train: 0.5748 acc_train: 0.8500 loss_val: 0.9705 acc_val: 0.6833 time: 4.1739s\n",
            "loss_val:0.9705230593681335, val_acc:0.6833333333333333, out_features:tensor([[-6.3151, -5.8645, -0.0185,  ..., -5.4879, -6.2237, -5.9738],\n",
            "        [-2.1443, -6.4500, -6.0756,  ..., -6.2862, -0.1367, -5.6960],\n",
            "        [-1.9459, -1.9459, -1.9459,  ..., -1.9459, -1.9459, -1.9459],\n",
            "        ...,\n",
            "        [-1.3166, -1.7912, -2.6220,  ..., -2.1870, -1.7875, -2.0216],\n",
            "        [-1.9459, -1.9459, -1.9459,  ..., -1.9459, -1.9459, -1.9459],\n",
            "        [-1.5313, -2.3823, -0.9265,  ..., -2.2360, -2.6941, -2.7419]],\n",
            "       grad_fn=<LogSoftmaxBackward0>)\n",
            "Training: 706\n",
            "Epoch: 0707 loss_train: 0.5367 acc_train: 0.8500 loss_val: 0.9851 acc_val: 0.6733 time: 4.2066s\n",
            "loss_val:0.9850764870643616, val_acc:0.6733333333333333, out_features:tensor([[-6.8014, -7.0695, -0.0135,  ..., -6.9611, -7.0993, -5.8694],\n",
            "        [-1.9459, -1.9459, -1.9459,  ..., -1.9459, -1.9459, -1.9459],\n",
            "        [-1.9459, -1.9459, -1.9459,  ..., -1.9459, -1.9459, -1.9459],\n",
            "        ...,\n",
            "        [-3.2986, -0.6020, -2.2425,  ..., -1.9118, -2.4953, -3.3245],\n",
            "        [-2.0851, -2.1188, -2.4346,  ..., -1.9574, -1.1439, -2.4750],\n",
            "        [-4.1511, -3.6025, -0.1113,  ..., -4.1773, -4.0926, -4.2301]],\n",
            "       grad_fn=<LogSoftmaxBackward0>)\n",
            "Training: 707\n",
            "Epoch: 0708 loss_train: 0.6419 acc_train: 0.8214 loss_val: 1.1447 acc_val: 0.6200 time: 4.3526s\n",
            "loss_val:1.1447046995162964, val_acc:0.62, out_features:tensor([[-1.0100e+01, -9.6141e+00, -8.1685e-04,  ..., -8.4089e+00,\n",
            "         -1.0090e+01, -9.5736e+00],\n",
            "        [-3.5892e+00, -4.3906e+00, -4.7020e+00,  ..., -3.7222e+00,\n",
            "         -2.2886e-01, -2.0909e+00],\n",
            "        [-5.6933e+00, -6.9257e+00, -7.1696e+00,  ..., -1.3017e-02,\n",
            "         -6.4408e+00, -5.2438e+00],\n",
            "        ...,\n",
            "        [-3.6743e+00, -1.8872e-01, -3.9969e+00,  ..., -3.7048e+00,\n",
            "         -2.5858e+00, -4.0784e+00],\n",
            "        [-3.5449e-02, -5.3026e+00, -6.0793e+00,  ..., -4.1550e+00,\n",
            "         -5.2133e+00, -5.6337e+00],\n",
            "        [-2.3906e+00, -2.4298e+00, -1.0960e+00,  ..., -2.7942e+00,\n",
            "         -2.0488e+00, -1.5759e+00]], grad_fn=<LogSoftmaxBackward0>)\n",
            "Training: 708\n",
            "Epoch: 0709 loss_train: 0.5855 acc_train: 0.8143 loss_val: 0.9600 acc_val: 0.7000 time: 4.0911s\n",
            "loss_val:0.9599893093109131, val_acc:0.7, out_features:tensor([[-8.7963e+00, -8.9665e+00, -2.7463e-03,  ..., -8.0673e+00,\n",
            "         -8.9458e+00, -8.4478e+00],\n",
            "        [-1.9459e+00, -1.9459e+00, -1.9459e+00,  ..., -1.9459e+00,\n",
            "         -1.9459e+00, -1.9459e+00],\n",
            "        [-3.2448e+00, -2.9865e+00, -3.5092e+00,  ..., -2.4931e-01,\n",
            "         -3.4641e+00, -3.4151e+00],\n",
            "        ...,\n",
            "        [-3.3064e+00, -4.6793e-01, -3.3541e+00,  ..., -1.9475e+00,\n",
            "         -2.4360e+00, -3.2247e+00],\n",
            "        [-1.9173e-01, -3.9217e+00, -4.4325e+00,  ..., -3.2562e+00,\n",
            "         -2.6290e+00, -4.0894e+00],\n",
            "        [-2.7386e+00, -2.1242e+00, -7.2172e-01,  ..., -2.6950e+00,\n",
            "         -2.6181e+00, -2.1616e+00]], grad_fn=<LogSoftmaxBackward0>)\n",
            "Training: 709\n",
            "Epoch: 0710 loss_train: 0.6003 acc_train: 0.8214 loss_val: 1.0545 acc_val: 0.6933 time: 4.2411s\n",
            "loss_val:1.0545471906661987, val_acc:0.6933333333333334, out_features:tensor([[-5.7625e+00, -5.9026e+00, -2.0964e-02,  ..., -5.4003e+00,\n",
            "         -5.6070e+00, -5.6770e+00],\n",
            "        [-1.7923e+00, -3.1333e+00, -2.3767e+00,  ..., -2.4810e+00,\n",
            "         -9.1272e-01, -1.7437e+00],\n",
            "        [-1.0011e+01, -1.0220e+01, -9.7734e+00,  ..., -2.2814e-04,\n",
            "         -1.0353e+01, -1.0478e+01],\n",
            "        ...,\n",
            "        [-3.0401e+00, -2.1711e-01, -4.1163e+00,  ..., -3.2689e+00,\n",
            "         -2.9452e+00, -3.8709e+00],\n",
            "        [-3.6141e-02, -5.9352e+00, -6.2587e+00,  ..., -4.1288e+00,\n",
            "         -5.1320e+00, -5.0986e+00],\n",
            "        [-3.4382e+00, -2.9830e+00, -8.6210e-01,  ..., -3.3939e+00,\n",
            "         -2.9306e+00, -1.9403e+00]], grad_fn=<LogSoftmaxBackward0>)\n",
            "Training: 710\n",
            "Epoch: 0711 loss_train: 0.5625 acc_train: 0.8429 loss_val: 1.0148 acc_val: 0.6700 time: 4.3760s\n",
            "loss_val:1.0147647857666016, val_acc:0.67, out_features:tensor([[-6.3302, -6.3537, -0.0195,  ..., -6.0776, -6.1674, -5.2797],\n",
            "        [-4.4052, -7.1429, -7.1674,  ..., -6.8114, -0.0199, -5.5180],\n",
            "        [-2.3034, -2.5097, -2.2060,  ..., -0.8000, -2.4988, -2.2546],\n",
            "        ...,\n",
            "        [-5.8096, -0.0371, -4.3731,  ..., -4.9716, -4.9086, -5.6503],\n",
            "        [-0.0992, -4.3750, -4.7002,  ..., -3.1917, -4.0543, -4.8835],\n",
            "        [-1.0314, -3.4490, -1.3179,  ..., -3.4966, -2.4455, -1.6489]],\n",
            "       grad_fn=<LogSoftmaxBackward0>)\n",
            "Training: 711\n",
            "Epoch: 0712 loss_train: 0.6036 acc_train: 0.8214 loss_val: 1.0715 acc_val: 0.6700 time: 4.1887s\n",
            "loss_val:1.0715267658233643, val_acc:0.67, out_features:tensor([[-3.6810, -3.3840, -0.3116,  ..., -2.6302, -3.1843, -2.9966],\n",
            "        [-6.8323, -6.8540, -6.8450,  ..., -5.8754, -0.1053, -2.3987],\n",
            "        [-6.1504, -6.4946, -6.2880,  ..., -0.0140, -6.1107, -5.4001],\n",
            "        ...,\n",
            "        [-2.9320, -0.6419, -2.5418,  ..., -2.6993, -1.9568, -2.5159],\n",
            "        [-0.5107, -3.2144, -2.9634,  ..., -2.7787, -2.1862, -2.4001],\n",
            "        [-3.3123, -2.7209, -0.3654,  ..., -2.3021, -3.2413, -3.5692]],\n",
            "       grad_fn=<LogSoftmaxBackward0>)\n",
            "Training: 712\n",
            "Epoch: 0713 loss_train: 0.6069 acc_train: 0.8214 loss_val: 0.9653 acc_val: 0.6800 time: 4.3438s\n",
            "loss_val:0.9653199315071106, val_acc:0.68, out_features:tensor([[-4.7485, -4.7403, -0.0841,  ..., -3.8834, -4.5584, -4.3267],\n",
            "        [-1.9459, -1.9459, -1.9459,  ..., -1.9459, -1.9459, -1.9459],\n",
            "        [-5.5816, -5.7188, -4.3063,  ..., -0.0343, -5.7314, -4.9714],\n",
            "        ...,\n",
            "        [-5.7794, -0.0391, -6.4204,  ..., -4.0664, -4.3329, -6.3281],\n",
            "        [-1.4544, -2.1205, -2.2754,  ..., -1.8608, -1.9530, -2.1470],\n",
            "        [-4.7357, -5.1924, -0.0432,  ..., -4.9286, -5.0115, -5.0666]],\n",
            "       grad_fn=<LogSoftmaxBackward0>)\n",
            "Training: 713\n",
            "Epoch: 0714 loss_train: 0.5120 acc_train: 0.8500 loss_val: 1.0374 acc_val: 0.6467 time: 4.2331s\n",
            "loss_val:1.0374034643173218, val_acc:0.6466666666666666, out_features:tensor([[-2.3412, -2.8591, -0.5435,  ..., -2.4718, -2.9602, -2.7854],\n",
            "        [-2.1228, -3.2613, -2.8565,  ..., -1.7038, -1.1784, -1.3498],\n",
            "        [-1.9459, -1.9459, -1.9459,  ..., -1.9459, -1.9459, -1.9459],\n",
            "        ...,\n",
            "        [-3.5969, -0.1317, -3.9910,  ..., -3.8387, -3.8101, -3.9225],\n",
            "        [-1.9459, -1.9459, -1.9459,  ..., -1.9459, -1.9459, -1.9459],\n",
            "        [-4.9214, -6.4544, -0.0234,  ..., -6.0192, -4.6817, -6.6697]],\n",
            "       grad_fn=<LogSoftmaxBackward0>)\n",
            "Training: 714\n",
            "Epoch: 0715 loss_train: 0.6067 acc_train: 0.8071 loss_val: 1.0058 acc_val: 0.6467 time: 4.1786s\n",
            "loss_val:1.0058397054672241, val_acc:0.6466666666666666, out_features:tensor([[-1.0857e+01, -1.0875e+01, -5.1557e-04,  ..., -1.0801e+01,\n",
            "         -1.0873e+01, -1.0361e+01],\n",
            "        [-7.6118e+00, -9.1301e+00, -9.1799e+00,  ..., -9.1780e+00,\n",
            "         -2.3430e-02, -3.8203e+00],\n",
            "        [-4.7406e+00, -4.8700e+00, -4.4145e+00,  ..., -6.5644e-02,\n",
            "         -5.0320e+00, -3.8144e+00],\n",
            "        ...,\n",
            "        [-5.3638e+00, -1.5954e-01, -5.0740e+00,  ..., -3.0164e+00,\n",
            "         -2.5620e+00, -5.1705e+00],\n",
            "        [-1.9459e+00, -1.9459e+00, -1.9459e+00,  ..., -1.9459e+00,\n",
            "         -1.9459e+00, -1.9459e+00],\n",
            "        [-4.7030e+00, -3.3392e+00, -1.2281e-01,  ..., -3.4185e+00,\n",
            "         -4.5777e+00, -4.1757e+00]], grad_fn=<LogSoftmaxBackward0>)\n",
            "Training: 715\n",
            "Epoch: 0716 loss_train: 0.5480 acc_train: 0.8714 loss_val: 1.0437 acc_val: 0.6800 time: 4.4970s\n",
            "loss_val:1.0436984300613403, val_acc:0.68, out_features:tensor([[-5.2588e+00, -4.8197e+00, -4.4918e-02,  ..., -4.4959e+00,\n",
            "         -5.3355e+00, -4.5762e+00],\n",
            "        [-1.2373e+00, -3.3407e+00, -3.4513e+00,  ..., -3.0025e+00,\n",
            "         -1.1128e+00, -1.4760e+00],\n",
            "        [-6.3983e+00, -6.8001e+00, -7.0804e+00,  ..., -8.4587e-03,\n",
            "         -5.8385e+00, -6.8439e+00],\n",
            "        ...,\n",
            "        [-2.3978e+00, -6.4471e-01, -2.5035e+00,  ..., -2.2964e+00,\n",
            "         -2.7000e+00, -2.4139e+00],\n",
            "        [-7.4431e-01, -2.2060e+00, -3.0524e+00,  ..., -2.0674e+00,\n",
            "         -2.2378e+00, -2.3936e+00],\n",
            "        [-1.0714e+01, -1.0490e+01, -1.5281e-04,  ..., -1.0637e+01,\n",
            "         -1.0280e+01, -1.0797e+01]], grad_fn=<LogSoftmaxBackward0>)\n",
            "Training: 716\n",
            "Epoch: 0717 loss_train: 0.6782 acc_train: 0.7643 loss_val: 1.0263 acc_val: 0.7000 time: 4.2160s\n",
            "loss_val:1.0263147354125977, val_acc:0.7, out_features:tensor([[-3.6672e+00, -4.0346e+00, -2.2292e-01,  ..., -4.2393e+00,\n",
            "         -3.8998e+00, -2.4087e+00],\n",
            "        [-1.9459e+00, -1.9459e+00, -1.9459e+00,  ..., -1.9459e+00,\n",
            "         -1.9459e+00, -1.9459e+00],\n",
            "        [-3.6646e+00, -3.7753e+00, -3.6919e+00,  ..., -1.5645e-01,\n",
            "         -3.9214e+00, -3.3886e+00],\n",
            "        ...,\n",
            "        [-7.0833e+00, -1.0386e-02, -5.2864e+00,  ..., -6.8619e+00,\n",
            "         -6.5692e+00, -6.7456e+00],\n",
            "        [-8.1816e-01, -2.6329e+00, -2.7273e+00,  ..., -1.7075e+00,\n",
            "         -2.3437e+00, -2.3741e+00],\n",
            "        [-7.7378e+00, -6.3064e+00, -4.0277e-03,  ..., -7.6926e+00,\n",
            "         -7.6863e+00, -7.9643e+00]], grad_fn=<LogSoftmaxBackward0>)\n",
            "Training: 717\n",
            "Epoch: 0718 loss_train: 0.6041 acc_train: 0.8429 loss_val: 0.9454 acc_val: 0.7133 time: 4.1482s\n",
            "loss_val:0.9453591108322144, val_acc:0.7133333333333334, out_features:tensor([[-1.4481e+01, -1.4452e+01, -4.1723e-06,  ..., -1.4023e+01,\n",
            "         -1.4504e+01, -1.4059e+01],\n",
            "        [-2.2723e+00, -2.9940e+00, -3.1451e+00,  ..., -2.0674e+00,\n",
            "         -7.1129e-01, -1.8829e+00],\n",
            "        [-4.0062e+00, -3.0400e+00, -4.8249e+00,  ..., -1.0819e-01,\n",
            "         -4.7444e+00, -4.2702e+00],\n",
            "        ...,\n",
            "        [-2.2297e+00, -1.8040e+00, -1.9869e+00,  ..., -2.3866e+00,\n",
            "         -1.8354e+00, -1.4624e+00],\n",
            "        [-1.2403e-01, -4.1223e+00, -4.9550e+00,  ..., -4.1290e+00,\n",
            "         -2.9878e+00, -3.9351e+00],\n",
            "        [-7.7508e+00, -7.8990e+00, -4.7186e-03,  ..., -7.8231e+00,\n",
            "         -6.3836e+00, -6.4821e+00]], grad_fn=<LogSoftmaxBackward0>)\n",
            "Training: 718\n",
            "Epoch: 0719 loss_train: 0.6182 acc_train: 0.8286 loss_val: 1.0029 acc_val: 0.6800 time: 4.3786s\n",
            "loss_val:1.0029187202453613, val_acc:0.68, out_features:tensor([[-9.4034e+00, -9.5482e+00, -9.7168e-04,  ..., -8.8046e+00,\n",
            "         -9.6577e+00, -9.2117e+00],\n",
            "        [-3.5800e+00, -6.2639e+00, -6.1634e+00,  ..., -6.3982e+00,\n",
            "         -7.3046e-02, -3.3599e+00],\n",
            "        [-1.7333e+00, -1.9531e+00, -2.1698e+00,  ..., -1.3494e+00,\n",
            "         -2.2599e+00, -2.0680e+00],\n",
            "        ...,\n",
            "        [-6.5551e+00, -1.4822e-02, -6.8015e+00,  ..., -6.2410e+00,\n",
            "         -4.8459e+00, -6.5239e+00],\n",
            "        [-1.9459e+00, -1.9459e+00, -1.9459e+00,  ..., -1.9459e+00,\n",
            "         -1.9459e+00, -1.9459e+00],\n",
            "        [-3.5360e+00, -3.5735e+00, -2.8251e-01,  ..., -3.3434e+00,\n",
            "         -2.5991e+00, -3.6845e+00]], grad_fn=<LogSoftmaxBackward0>)\n",
            "Training: 719\n",
            "Epoch: 0720 loss_train: 0.6826 acc_train: 0.7643 loss_val: 1.0091 acc_val: 0.6667 time: 4.1723s\n",
            "loss_val:1.009082317352295, val_acc:0.6666666666666666, out_features:tensor([[-6.6500, -6.5094, -0.0179,  ..., -5.8339, -6.5289, -6.2588],\n",
            "        [-4.1592, -4.2759, -3.6070,  ..., -3.2487, -0.1330, -4.0742],\n",
            "        [-3.2879, -3.1968, -2.7440,  ..., -0.3735, -3.1849, -2.4886],\n",
            "        ...,\n",
            "        [-2.6902, -1.0595, -2.8822,  ..., -1.7665, -2.5299, -1.5256],\n",
            "        [-0.0285, -4.9398, -6.1510,  ..., -4.8427, -5.3763, -5.4389],\n",
            "        [-3.2915, -2.5265, -0.5104,  ..., -2.6424, -2.8610, -2.4331]],\n",
            "       grad_fn=<LogSoftmaxBackward0>)\n",
            "Training: 720\n",
            "Epoch: 0721 loss_train: 0.5763 acc_train: 0.8214 loss_val: 1.0505 acc_val: 0.6867 time: 4.1011s\n",
            "loss_val:1.0504978895187378, val_acc:0.6866666666666666, out_features:tensor([[-8.8600e+00, -8.5947e+00, -1.4169e-03,  ..., -7.7866e+00,\n",
            "         -8.8413e+00, -8.6943e+00],\n",
            "        [-3.0285e+00, -5.5423e+00, -7.2227e+00,  ..., -7.1768e+00,\n",
            "         -6.6101e-02, -7.2175e+00],\n",
            "        [-9.1727e+00, -8.6019e+00, -8.7509e+00,  ..., -7.8540e-04,\n",
            "         -9.0177e+00, -9.1171e+00],\n",
            "        ...,\n",
            "        [-2.2038e+00, -1.8281e+00, -2.0034e+00,  ..., -2.3910e+00,\n",
            "         -1.8217e+00, -1.3885e+00],\n",
            "        [-1.4744e-01, -3.8975e+00, -4.4725e+00,  ..., -3.9810e+00,\n",
            "         -3.3242e+00, -3.2265e+00],\n",
            "        [-3.7081e+00, -4.4201e+00, -6.1935e-02,  ..., -4.9943e+00,\n",
            "         -5.3291e+00, -5.3571e+00]], grad_fn=<LogSoftmaxBackward0>)\n",
            "Training: 721\n",
            "Epoch: 0722 loss_train: 0.5571 acc_train: 0.8071 loss_val: 1.0375 acc_val: 0.6767 time: 4.3666s\n",
            "loss_val:1.037543535232544, val_acc:0.6766666666666666, out_features:tensor([[-4.8805e+00, -4.4370e+00, -9.9398e-02,  ..., -4.4789e+00,\n",
            "         -4.7786e+00, -3.5777e+00],\n",
            "        [-1.9459e+00, -1.9459e+00, -1.9459e+00,  ..., -1.9459e+00,\n",
            "         -1.9459e+00, -1.9459e+00],\n",
            "        [-3.2120e+00, -4.7561e+00, -5.2157e+00,  ..., -9.5207e-02,\n",
            "         -5.0109e+00, -3.7636e+00],\n",
            "        ...,\n",
            "        [-4.7263e+00, -7.0686e-02, -4.9264e+00,  ..., -4.4681e+00,\n",
            "         -3.6490e+00, -4.7343e+00],\n",
            "        [-9.4020e-01, -2.8771e+00, -2.7581e+00,  ..., -2.3093e+00,\n",
            "         -1.7198e+00, -2.4574e+00],\n",
            "        [-8.0183e+00, -8.1840e+00, -1.4873e-03,  ..., -8.6418e+00,\n",
            "         -7.9066e+00, -8.5834e+00]], grad_fn=<LogSoftmaxBackward0>)\n",
            "Training: 722\n",
            "Epoch: 0723 loss_train: 0.4618 acc_train: 0.8929 loss_val: 1.0701 acc_val: 0.6700 time: 3.9823s\n",
            "loss_val:1.0700637102127075, val_acc:0.67, out_features:tensor([[-5.7065e+00, -5.3410e+00, -3.5942e-02,  ..., -4.9315e+00,\n",
            "         -5.6658e+00, -4.6901e+00],\n",
            "        [-1.0940e+00, -3.6069e+00, -3.3293e+00,  ..., -2.9270e+00,\n",
            "         -1.8211e+00, -1.0043e+00],\n",
            "        [-3.0186e+00, -3.5743e+00, -3.6573e+00,  ..., -2.1407e-01,\n",
            "         -3.6083e+00, -3.0873e+00],\n",
            "        ...,\n",
            "        [-2.6310e+00, -7.9226e-01, -2.4885e+00,  ..., -2.1090e+00,\n",
            "         -2.3704e+00, -2.5898e+00],\n",
            "        [-5.7311e-03, -7.8199e+00, -8.5631e+00,  ..., -7.9638e+00,\n",
            "         -5.4322e+00, -8.5324e+00],\n",
            "        [-2.8943e+00, -2.5568e+00, -4.2806e-01,  ..., -2.8745e+00,\n",
            "         -3.2082e+00, -2.7284e+00]], grad_fn=<LogSoftmaxBackward0>)\n",
            "Training: 723\n",
            "Epoch: 0724 loss_train: 0.5938 acc_train: 0.8286 loss_val: 1.0212 acc_val: 0.6667 time: 4.1636s\n",
            "loss_val:1.0212420225143433, val_acc:0.6666666666666666, out_features:tensor([[-4.5523, -4.1250, -0.1684,  ..., -3.8845, -4.2884, -4.4348],\n",
            "        [-1.9459, -1.9459, -1.9459,  ..., -1.9459, -1.9459, -1.9459],\n",
            "        [-1.9459, -1.9459, -1.9459,  ..., -1.9459, -1.9459, -1.9459],\n",
            "        ...,\n",
            "        [-1.9792, -1.8246, -2.1125,  ..., -1.8948, -1.8091, -1.9633],\n",
            "        [-0.0129, -6.8099, -6.9026,  ..., -5.7301, -5.2374, -6.6143],\n",
            "        [-4.8306, -6.5523, -0.0136,  ..., -6.7999, -6.6707, -7.0827]],\n",
            "       grad_fn=<LogSoftmaxBackward0>)\n",
            "Training: 724\n",
            "Epoch: 0725 loss_train: 0.6528 acc_train: 0.8071 loss_val: 1.1744 acc_val: 0.6233 time: 4.5067s\n",
            "loss_val:1.1744235754013062, val_acc:0.6233333333333333, out_features:tensor([[-6.0103e+00, -5.6932e+00, -2.7804e-02,  ..., -5.2777e+00,\n",
            "         -5.9736e+00, -5.7067e+00],\n",
            "        [-1.9459e+00, -1.9459e+00, -1.9459e+00,  ..., -1.9459e+00,\n",
            "         -1.9459e+00, -1.9459e+00],\n",
            "        [-6.2763e+00, -8.0647e+00, -7.9355e+00,  ..., -3.9165e-03,\n",
            "         -7.4346e+00, -7.7477e+00],\n",
            "        ...,\n",
            "        [-3.0202e+00, -2.1238e-01, -4.1844e+00,  ..., -3.5033e+00,\n",
            "         -3.7757e+00, -2.8104e+00],\n",
            "        [-1.5028e+00, -1.9994e+00, -2.4003e+00,  ..., -1.9336e+00,\n",
            "         -1.8125e+00, -2.2593e+00],\n",
            "        [-4.4544e+00, -5.0374e+00, -6.9800e-02,  ..., -4.7783e+00,\n",
            "         -4.6863e+00, -4.2728e+00]], grad_fn=<LogSoftmaxBackward0>)\n",
            "Training: 725\n",
            "Epoch: 0726 loss_train: 0.5747 acc_train: 0.8071 loss_val: 1.0016 acc_val: 0.6767 time: 4.1651s\n",
            "loss_val:1.0015848875045776, val_acc:0.6766666666666666, out_features:tensor([[-9.0558e+00, -9.3395e+00, -1.5815e-03,  ..., -9.2793e+00,\n",
            "         -9.3654e+00, -8.4115e+00],\n",
            "        [-1.9459e+00, -1.9459e+00, -1.9459e+00,  ..., -1.9459e+00,\n",
            "         -1.9459e+00, -1.9459e+00],\n",
            "        [-7.4707e+00, -8.9644e+00, -8.8608e+00,  ..., -1.7557e-03,\n",
            "         -7.3494e+00, -8.7585e+00],\n",
            "        ...,\n",
            "        [-3.1693e+00, -3.4425e-01, -2.9733e+00,  ..., -2.3457e+00,\n",
            "         -3.3267e+00, -3.6222e+00],\n",
            "        [-5.5135e-01, -2.9909e+00, -3.1532e+00,  ..., -1.7199e+00,\n",
            "         -2.9572e+00, -2.8071e+00],\n",
            "        [-2.1904e+00, -2.7342e+00, -1.3054e+00,  ..., -3.2182e+00,\n",
            "         -1.6732e+00, -2.2724e+00]], grad_fn=<LogSoftmaxBackward0>)\n",
            "Training: 726\n",
            "Epoch: 0727 loss_train: 0.5675 acc_train: 0.8429 loss_val: 1.0909 acc_val: 0.6500 time: 4.1886s\n",
            "loss_val:1.0909123420715332, val_acc:0.65, out_features:tensor([[-4.1031, -3.8911, -0.1580,  ..., -3.0223, -4.0693, -4.0431],\n",
            "        [-1.9029, -2.7555, -2.4111,  ..., -1.8505, -1.1533, -1.9797],\n",
            "        [-4.4155, -6.5243, -6.6601,  ..., -0.0222, -5.7250, -5.9728],\n",
            "        ...,\n",
            "        [-2.1333, -1.0923, -2.6178,  ..., -2.6117, -1.7530, -1.7325],\n",
            "        [-0.3819, -3.5695, -4.0044,  ..., -2.7315, -3.0421, -2.1520],\n",
            "        [-4.2560, -3.7706, -0.1016,  ..., -3.7140, -4.6294, -4.7256]],\n",
            "       grad_fn=<LogSoftmaxBackward0>)\n",
            "Training: 727\n",
            "Epoch: 0728 loss_train: 0.5104 acc_train: 0.8571 loss_val: 1.0572 acc_val: 0.6500 time: 4.3441s\n",
            "loss_val:1.057207465171814, val_acc:0.65, out_features:tensor([[-3.4781, -3.0359, -0.3704,  ..., -2.5542, -3.4986, -3.3911],\n",
            "        [-3.6773, -4.9577, -5.3875,  ..., -4.6934, -0.0678, -4.2181],\n",
            "        [-2.1172, -2.3287, -2.1832,  ..., -1.3774, -2.2139, -1.6950],\n",
            "        ...,\n",
            "        [-4.5001, -0.0931, -4.8978,  ..., -3.2922, -4.1288, -4.6103],\n",
            "        [-1.9459, -1.9459, -1.9459,  ..., -1.9459, -1.9459, -1.9459],\n",
            "        [-5.0265, -5.0235, -0.0605,  ..., -3.7918, -4.7724, -5.0497]],\n",
            "       grad_fn=<LogSoftmaxBackward0>)\n",
            "Training: 728\n",
            "Epoch: 0729 loss_train: 0.6318 acc_train: 0.8429 loss_val: 0.9454 acc_val: 0.6967 time: 4.2524s\n",
            "loss_val:0.9453566670417786, val_acc:0.6966666666666667, out_features:tensor([[-2.2420e+00, -2.3230e+00, -9.4841e-01,  ..., -2.2014e+00,\n",
            "         -2.5361e+00, -2.3695e+00],\n",
            "        [-1.9459e+00, -1.9459e+00, -1.9459e+00,  ..., -1.9459e+00,\n",
            "         -1.9459e+00, -1.9459e+00],\n",
            "        [-6.2608e+00, -7.4206e+00, -7.4805e+00,  ..., -5.2215e-03,\n",
            "         -7.1079e+00, -7.0425e+00],\n",
            "        ...,\n",
            "        [-2.4077e+00, -4.9724e-01, -3.1579e+00,  ..., -2.7693e+00,\n",
            "         -2.3323e+00, -2.7187e+00],\n",
            "        [-8.9234e-01, -2.7634e+00, -2.7754e+00,  ..., -2.2731e+00,\n",
            "         -1.7551e+00, -2.0191e+00],\n",
            "        [-7.6455e+00, -6.5182e+00, -6.4258e-03,  ..., -5.7589e+00,\n",
            "         -7.6403e+00, -7.8560e+00]], grad_fn=<LogSoftmaxBackward0>)\n",
            "Training: 729\n",
            "Epoch: 0730 loss_train: 0.6145 acc_train: 0.8357 loss_val: 1.0303 acc_val: 0.6800 time: 4.2933s\n",
            "loss_val:1.030265212059021, val_acc:0.68, out_features:tensor([[-6.8908e+00, -7.3746e+00, -5.8678e-03,  ..., -6.3482e+00,\n",
            "         -7.0624e+00, -7.3179e+00],\n",
            "        [-1.7487e+00, -3.2118e+00, -2.3464e+00,  ..., -1.3048e+00,\n",
            "         -1.4558e+00, -1.8998e+00],\n",
            "        [-5.5453e+00, -5.6368e+00, -4.1291e+00,  ..., -3.6356e-02,\n",
            "         -5.7142e+00, -5.3472e+00],\n",
            "        ...,\n",
            "        [-1.3249e+00, -2.3144e+00, -2.0138e+00,  ..., -2.4431e+00,\n",
            "         -1.8742e+00, -2.4139e+00],\n",
            "        [-1.8607e-02, -6.3888e+00, -6.7720e+00,  ..., -5.2967e+00,\n",
            "         -4.9263e+00, -6.1495e+00],\n",
            "        [-2.3237e+00, -2.4447e+00, -1.0808e+00,  ..., -1.8845e+00,\n",
            "         -1.8219e+00, -2.3231e+00]], grad_fn=<LogSoftmaxBackward0>)\n",
            "Training: 730\n",
            "Epoch: 0731 loss_train: 0.5531 acc_train: 0.8643 loss_val: 1.0322 acc_val: 0.7033 time: 4.2587s\n",
            "loss_val:1.0322198867797852, val_acc:0.7033333333333334, out_features:tensor([[-4.8173e+00, -4.7828e+00, -1.2974e-01,  ..., -4.3085e+00,\n",
            "         -4.5675e+00, -3.0440e+00],\n",
            "        [-2.4150e+00, -2.9532e+00, -3.0947e+00,  ..., -1.4737e+00,\n",
            "         -1.1288e+00, -1.5486e+00],\n",
            "        [-8.8096e+00, -7.7016e+00, -8.4186e+00,  ..., -1.2788e-03,\n",
            "         -8.8585e+00, -8.5632e+00],\n",
            "        ...,\n",
            "        [-3.3541e+00, -1.8882e-01, -4.3196e+00,  ..., -3.1143e+00,\n",
            "         -3.0754e+00, -3.9081e+00],\n",
            "        [-2.5531e-01, -3.4955e+00, -4.3890e+00,  ..., -3.6880e+00,\n",
            "         -3.2420e+00, -2.2402e+00],\n",
            "        [-2.9197e+00, -3.2303e+00, -3.0833e-01,  ..., -3.9675e+00,\n",
            "         -2.6220e+00, -2.9015e+00]], grad_fn=<LogSoftmaxBackward0>)\n",
            "Training: 731\n",
            "Epoch: 0732 loss_train: 0.5018 acc_train: 0.8714 loss_val: 1.0688 acc_val: 0.6767 time: 4.1739s\n",
            "loss_val:1.0687593221664429, val_acc:0.6766666666666666, out_features:tensor([[-5.5307, -5.5424, -0.0404,  ..., -4.5547, -5.0069, -5.5115],\n",
            "        [-1.9459, -1.9459, -1.9459,  ..., -1.9459, -1.9459, -1.9459],\n",
            "        [-2.7436, -3.4019, -4.3130,  ..., -0.2044, -3.2908, -3.7907],\n",
            "        ...,\n",
            "        [-2.3112, -0.8053, -2.6444,  ..., -2.3820, -2.3060, -2.0087],\n",
            "        [-1.4410, -2.2529, -2.1274,  ..., -1.7889, -2.1784, -2.1587],\n",
            "        [-3.7212, -3.4775, -0.1834,  ..., -4.3135, -2.7663, -3.9006]],\n",
            "       grad_fn=<LogSoftmaxBackward0>)\n",
            "Training: 732\n",
            "Epoch: 0733 loss_train: 0.6811 acc_train: 0.7786 loss_val: 0.9873 acc_val: 0.6800 time: 4.4517s\n",
            "loss_val:0.9872714281082153, val_acc:0.68, out_features:tensor([[-9.3318, -9.3321, -0.0133,  ..., -7.7045, -9.3476, -7.7742],\n",
            "        [-1.9459, -1.9459, -1.9459,  ..., -1.9459, -1.9459, -1.9459],\n",
            "        [-2.3791, -2.3337, -1.9288,  ..., -0.9822, -2.5611, -2.1863],\n",
            "        ...,\n",
            "        [-2.2449, -0.4755, -3.4179,  ..., -2.1050, -2.9632, -3.2165],\n",
            "        [-0.0928, -4.9098, -5.1639,  ..., -4.4972, -3.5607, -4.7361],\n",
            "        [-1.5060, -2.5561, -1.4706,  ..., -2.5976, -2.1945, -1.5284]],\n",
            "       grad_fn=<LogSoftmaxBackward0>)\n",
            "Training: 733\n",
            "Epoch: 0734 loss_train: 0.6160 acc_train: 0.8357 loss_val: 1.1226 acc_val: 0.6500 time: 4.1614s\n",
            "loss_val:1.1225568056106567, val_acc:0.65, out_features:tensor([[-5.5824e+00, -5.2776e+00, -3.3324e-02,  ..., -5.2141e+00,\n",
            "         -5.4208e+00, -4.9400e+00],\n",
            "        [-2.9366e+00, -5.3081e+00, -5.4547e+00,  ..., -5.3860e+00,\n",
            "         -3.5355e-01, -1.4837e+00],\n",
            "        [-2.6065e+00, -2.6103e+00, -1.9461e+00,  ..., -8.4305e-01,\n",
            "         -2.4653e+00, -2.2605e+00],\n",
            "        ...,\n",
            "        [-3.0480e+00, -4.0296e-01, -3.9666e+00,  ..., -1.7875e+00,\n",
            "         -2.8343e+00, -3.7770e+00],\n",
            "        [-6.9521e-01, -2.9558e+00, -2.5599e+00,  ..., -1.5633e+00,\n",
            "         -2.5561e+00, -3.1886e+00],\n",
            "        [-8.2022e+00, -7.9211e+00, -1.9068e-03,  ..., -8.7451e+00,\n",
            "         -8.0439e+00, -7.3882e+00]], grad_fn=<LogSoftmaxBackward0>)\n",
            "Training: 734\n",
            "Epoch: 0735 loss_train: 0.5603 acc_train: 0.8429 loss_val: 1.1412 acc_val: 0.6667 time: 4.1591s\n",
            "loss_val:1.1412217617034912, val_acc:0.6666666666666666, out_features:tensor([[-3.4308, -3.2233, -0.5954,  ..., -2.6901, -3.1437, -1.6859],\n",
            "        [-2.4971, -3.0577, -3.2598,  ..., -2.2293, -0.5714, -2.1203],\n",
            "        [-3.6800, -3.4808, -4.1822,  ..., -0.1228, -4.1622, -4.0284],\n",
            "        ...,\n",
            "        [-1.9982, -1.2831, -2.2490,  ..., -2.3842, -2.0903, -1.5256],\n",
            "        [-0.2522, -3.8987, -3.6528,  ..., -2.4592, -3.5303, -3.9628],\n",
            "        [-3.3648, -4.9928, -0.1181,  ..., -2.8971, -5.2717, -5.2669]],\n",
            "       grad_fn=<LogSoftmaxBackward0>)\n",
            "Training: 735\n",
            "Epoch: 0736 loss_train: 0.6914 acc_train: 0.7786 loss_val: 0.9674 acc_val: 0.7167 time: 4.5476s\n",
            "loss_val:0.9674223065376282, val_acc:0.7166666666666667, out_features:tensor([[-4.5213, -4.5866, -0.2812,  ..., -3.8261, -4.5127, -3.7044],\n",
            "        [-3.7573, -2.4329, -3.8136,  ..., -3.7372, -1.1687, -0.8553],\n",
            "        [-4.1727, -2.9788, -4.5548,  ..., -0.1570, -4.2592, -3.1268],\n",
            "        ...,\n",
            "        [-1.3933, -1.2838, -2.6099,  ..., -2.1724, -2.1394, -2.1878],\n",
            "        [-0.4446, -2.9749, -2.7295,  ..., -2.7177, -2.5656, -2.8480],\n",
            "        [-2.7953, -4.0939, -0.2704,  ..., -4.3545, -3.1714, -2.3638]],\n",
            "       grad_fn=<LogSoftmaxBackward0>)\n",
            "Training: 736\n",
            "Epoch: 0737 loss_train: 0.5546 acc_train: 0.8357 loss_val: 1.0856 acc_val: 0.6667 time: 4.1201s\n",
            "loss_val:1.0855945348739624, val_acc:0.6666666666666666, out_features:tensor([[-6.5827, -6.2689, -0.0112,  ..., -5.8831, -6.5119, -6.1560],\n",
            "        [-2.0578, -3.0716, -2.9064,  ..., -2.9285, -0.8543, -2.9526],\n",
            "        [-2.1391, -2.0509, -2.4249,  ..., -0.9474, -2.3862, -2.2909],\n",
            "        ...,\n",
            "        [-1.9459, -1.9459, -1.9459,  ..., -1.9459, -1.9459, -1.9459],\n",
            "        [-0.0998, -4.3938, -5.4607,  ..., -4.0633, -2.9557, -5.3693],\n",
            "        [-1.9459, -1.9459, -1.9459,  ..., -1.9459, -1.9459, -1.9459]],\n",
            "       grad_fn=<LogSoftmaxBackward0>)\n",
            "Training: 737\n",
            "Epoch: 0738 loss_train: 0.6220 acc_train: 0.8000 loss_val: 1.0091 acc_val: 0.7033 time: 4.1407s\n",
            "loss_val:1.0091458559036255, val_acc:0.7033333333333334, out_features:tensor([[-6.2315, -5.1897, -0.0168,  ..., -5.9831, -6.3183, -6.3802],\n",
            "        [-1.9459, -1.9459, -1.9459,  ..., -1.9459, -1.9459, -1.9459],\n",
            "        [-2.1171, -3.0188, -2.3143,  ..., -0.7033, -2.4496, -2.7038],\n",
            "        ...,\n",
            "        [-5.9947, -0.0264, -4.8749,  ..., -5.4277, -5.2191, -5.8989],\n",
            "        [-0.5305, -2.7306, -3.5979,  ..., -2.0519, -2.8086, -2.2737],\n",
            "        [-4.6807, -3.0200, -0.1161,  ..., -4.0856, -3.8608, -5.0423]],\n",
            "       grad_fn=<LogSoftmaxBackward0>)\n",
            "Training: 738\n",
            "Epoch: 0739 loss_train: 0.6717 acc_train: 0.8214 loss_val: 1.0613 acc_val: 0.6567 time: 4.4411s\n",
            "loss_val:1.0613229274749756, val_acc:0.6566666666666666, out_features:tensor([[-4.9055, -4.8111, -0.3172,  ..., -2.4994, -4.9250, -3.9258],\n",
            "        [-3.4223, -3.3460, -3.8732,  ..., -1.9678, -0.6588, -1.4470],\n",
            "        [-2.8615, -2.2502, -1.8956,  ..., -0.8190, -2.4051, -2.3535],\n",
            "        ...,\n",
            "        [-2.2130, -1.1546, -2.3196,  ..., -1.6632, -2.1194, -2.3836],\n",
            "        [-0.8156, -2.1926, -2.8880,  ..., -2.0847, -2.0161, -2.8440],\n",
            "        [-1.9459, -1.9459, -1.9459,  ..., -1.9459, -1.9459, -1.9459]],\n",
            "       grad_fn=<LogSoftmaxBackward0>)\n",
            "Training: 739\n",
            "Epoch: 0740 loss_train: 0.5492 acc_train: 0.8714 loss_val: 1.0691 acc_val: 0.6667 time: 4.1966s\n",
            "loss_val:1.069123387336731, val_acc:0.6666666666666666, out_features:tensor([[-2.6534e+00, -2.5748e+00, -7.0531e-01,  ..., -2.7285e+00,\n",
            "         -2.7356e+00, -2.2914e+00],\n",
            "        [-2.0487e+00, -5.9738e+00, -5.6308e+00,  ..., -6.0066e+00,\n",
            "         -2.0799e-01, -3.0370e+00],\n",
            "        [-2.4977e+00, -2.3504e+00, -2.1271e+00,  ..., -1.0090e+00,\n",
            "         -2.1179e+00, -1.9646e+00],\n",
            "        ...,\n",
            "        [-5.2377e+00, -5.4689e-02, -5.2861e+00,  ..., -4.3841e+00,\n",
            "         -4.7066e+00, -4.0876e+00],\n",
            "        [-5.5653e-01, -1.9514e+00, -3.1906e+00,  ..., -2.3375e+00,\n",
            "         -2.7011e+00, -3.0880e+00],\n",
            "        [-7.8155e+00, -5.7966e+00, -5.4920e-03,  ..., -7.2261e+00,\n",
            "         -7.7377e+00, -7.9310e+00]], grad_fn=<LogSoftmaxBackward0>)\n",
            "Training: 740\n",
            "Epoch: 0741 loss_train: 0.6250 acc_train: 0.8143 loss_val: 1.0493 acc_val: 0.6467 time: 4.0443s\n",
            "loss_val:1.0493154525756836, val_acc:0.6466666666666666, out_features:tensor([[-2.4697e+00, -2.8173e+00, -1.1381e+00,  ..., -2.5463e+00,\n",
            "         -2.6318e+00, -2.1055e+00],\n",
            "        [-1.9459e+00, -1.9459e+00, -1.9459e+00,  ..., -1.9459e+00,\n",
            "         -1.9459e+00, -1.9459e+00],\n",
            "        [-1.9459e+00, -1.9459e+00, -1.9459e+00,  ..., -1.9459e+00,\n",
            "         -1.9459e+00, -1.9459e+00],\n",
            "        ...,\n",
            "        [-1.2808e+01, -2.6345e-05, -1.2911e+01,  ..., -1.2693e+01,\n",
            "         -1.1212e+01, -1.2980e+01],\n",
            "        [-3.9909e-02, -5.7469e+00, -6.1200e+00,  ..., -4.0797e+00,\n",
            "         -4.6362e+00, -5.6733e+00],\n",
            "        [-6.0610e+00, -5.7835e+00, -1.8359e-02,  ..., -6.3775e+00,\n",
            "         -5.1632e+00, -6.1347e+00]], grad_fn=<LogSoftmaxBackward0>)\n",
            "Training: 741\n",
            "Epoch: 0742 loss_train: 0.4642 acc_train: 0.8857 loss_val: 1.0712 acc_val: 0.6500 time: 4.4434s\n",
            "loss_val:1.071194052696228, val_acc:0.65, out_features:tensor([[-2.3117, -2.0209, -0.9325,  ..., -2.2781, -2.7453, -2.1855],\n",
            "        [-1.9459, -1.9459, -1.9459,  ..., -1.9459, -1.9459, -1.9459],\n",
            "        [-6.7518, -5.9397, -5.9199,  ..., -0.0109, -6.4994, -6.4827],\n",
            "        ...,\n",
            "        [-2.5513, -0.9527, -2.7110,  ..., -1.9655, -2.1670, -1.8948],\n",
            "        [-0.0749, -4.7695, -5.4498,  ..., -3.5269, -3.9886, -5.0202],\n",
            "        [-6.6210, -5.8007, -0.0166,  ..., -6.2168, -6.6032, -5.6902]],\n",
            "       grad_fn=<LogSoftmaxBackward0>)\n",
            "Training: 742\n",
            "Epoch: 0743 loss_train: 0.5747 acc_train: 0.7929 loss_val: 1.0837 acc_val: 0.6400 time: 4.1265s\n",
            "loss_val:1.0836933851242065, val_acc:0.64, out_features:tensor([[-5.9372e+00, -5.7193e+00, -5.2693e-02,  ..., -5.7506e+00,\n",
            "         -5.8780e+00, -3.6939e+00],\n",
            "        [-3.0881e+00, -4.0539e+00, -4.0309e+00,  ..., -3.1721e+00,\n",
            "         -2.7282e-01, -2.3034e+00],\n",
            "        [-1.0101e+01, -9.2943e+00, -9.8694e+00,  ..., -2.9619e-04,\n",
            "         -1.0279e+01, -9.9660e+00],\n",
            "        ...,\n",
            "        [-4.3354e+00, -9.4429e-02, -4.7876e+00,  ..., -4.7235e+00,\n",
            "         -3.1049e+00, -4.7821e+00],\n",
            "        [-2.8453e-01, -3.1765e+00, -3.5506e+00,  ..., -2.4291e+00,\n",
            "         -3.3168e+00, -3.4163e+00],\n",
            "        [-7.2826e+00, -6.1349e+00, -7.7766e-03,  ..., -6.5487e+00,\n",
            "         -7.0649e+00, -6.9178e+00]], grad_fn=<LogSoftmaxBackward0>)\n",
            "Training: 743\n",
            "Epoch: 0744 loss_train: 0.5886 acc_train: 0.8214 loss_val: 0.9627 acc_val: 0.6867 time: 4.3654s\n",
            "loss_val:0.9626941680908203, val_acc:0.6866666666666666, out_features:tensor([[-7.1985, -6.5702, -0.0098,  ..., -7.1189, -6.9104, -5.9157],\n",
            "        [-4.1772, -5.7391, -5.8782,  ..., -5.0446, -0.0578, -3.6662],\n",
            "        [-2.4593, -3.9582, -3.9212,  ..., -0.2067, -3.6258, -3.7604],\n",
            "        ...,\n",
            "        [-4.9754, -0.0590, -4.9872,  ..., -4.4392, -4.6641, -4.3337],\n",
            "        [-0.9971, -1.9986, -2.8297,  ..., -2.2191, -2.0129, -2.0285],\n",
            "        [-5.6642, -6.3767, -0.0117,  ..., -5.9466, -6.2304, -6.8636]],\n",
            "       grad_fn=<LogSoftmaxBackward0>)\n",
            "Training: 744\n",
            "Epoch: 0745 loss_train: 0.6177 acc_train: 0.8143 loss_val: 1.0099 acc_val: 0.6800 time: 4.5178s\n",
            "loss_val:1.0098967552185059, val_acc:0.68, out_features:tensor([[-3.1219e+00, -2.3642e+00, -5.3130e-01,  ..., -2.9352e+00,\n",
            "         -2.6879e+00, -2.4173e+00],\n",
            "        [-1.3081e+01, -1.6186e+01, -1.1784e+01,  ..., -1.6183e+01,\n",
            "         -2.5102e-04, -8.3309e+00],\n",
            "        [-2.9983e+00, -2.4168e+00, -2.0691e+00,  ..., -6.6978e-01,\n",
            "         -2.5534e+00, -2.5011e+00],\n",
            "        ...,\n",
            "        [-4.3848e+00, -8.2336e-02, -5.1833e+00,  ..., -4.0012e+00,\n",
            "         -3.6360e+00, -4.5774e+00],\n",
            "        [-6.7358e-01, -2.7771e+00, -2.4617e+00,  ..., -2.8094e+00,\n",
            "         -1.7340e+00, -2.7091e+00],\n",
            "        [-1.6205e+00, -3.5315e+00, -5.8006e-01,  ..., -3.7370e+00,\n",
            "         -2.7866e+00, -2.2708e+00]], grad_fn=<LogSoftmaxBackward0>)\n",
            "Training: 745\n",
            "Epoch: 0746 loss_train: 0.6388 acc_train: 0.8214 loss_val: 1.1445 acc_val: 0.6500 time: 4.1777s\n",
            "loss_val:1.1445143222808838, val_acc:0.65, out_features:tensor([[-6.2672, -6.0509, -0.0221,  ..., -5.2694, -6.3542, -5.6487],\n",
            "        [-3.1766, -3.3379, -4.1607,  ..., -3.8921, -0.6209, -1.0856],\n",
            "        [-4.4289, -4.5121, -4.4529,  ..., -0.0662, -5.0981, -4.1208],\n",
            "        ...,\n",
            "        [-2.0435, -1.6326, -2.5533,  ..., -2.5799, -1.9501, -1.1285],\n",
            "        [-0.2356, -3.6370, -4.1645,  ..., -2.4938, -3.7044, -3.2339],\n",
            "        [-3.2570, -3.4991, -0.3543,  ..., -3.6309, -1.9763, -3.3793]],\n",
            "       grad_fn=<LogSoftmaxBackward0>)\n",
            "Training: 746\n",
            "Epoch: 0747 loss_train: 0.6484 acc_train: 0.8000 loss_val: 1.0054 acc_val: 0.6833 time: 4.3254s\n",
            "loss_val:1.0054339170455933, val_acc:0.6833333333333333, out_features:tensor([[-2.4186e+00, -2.5426e+00, -1.0415e+00,  ..., -2.0093e+00,\n",
            "         -2.6731e+00, -2.2871e+00],\n",
            "        [-1.7450e+00, -2.9363e+00, -3.0276e+00,  ..., -2.7183e+00,\n",
            "         -1.1942e+00, -1.1633e+00],\n",
            "        [-1.9459e+00, -1.9459e+00, -1.9459e+00,  ..., -1.9459e+00,\n",
            "         -1.9459e+00, -1.9459e+00],\n",
            "        ...,\n",
            "        [-3.3030e+00, -2.8810e-01, -3.2275e+00,  ..., -3.1225e+00,\n",
            "         -3.0223e+00, -2.9514e+00],\n",
            "        [-3.0817e-01, -4.0915e+00, -4.0460e+00,  ..., -2.1278e+00,\n",
            "         -3.1208e+00, -3.6319e+00],\n",
            "        [-8.0920e+00, -7.1810e+00, -2.1069e-03,  ..., -8.2690e+00,\n",
            "         -8.0307e+00, -8.3549e+00]], grad_fn=<LogSoftmaxBackward0>)\n",
            "Training: 747\n",
            "Epoch: 0748 loss_train: 0.5938 acc_train: 0.8143 loss_val: 1.1524 acc_val: 0.6300 time: 4.2552s\n",
            "loss_val:1.1524380445480347, val_acc:0.63, out_features:tensor([[-6.9403, -6.8950, -0.0171,  ..., -6.6439, -6.6877, -5.8017],\n",
            "        [-1.9459, -1.9459, -1.9459,  ..., -1.9459, -1.9459, -1.9459],\n",
            "        [-3.7496, -3.6407, -3.6667,  ..., -0.2022, -3.6367, -2.9740],\n",
            "        ...,\n",
            "        [-2.1305, -0.6253, -2.2145,  ..., -2.3093, -2.8014, -3.2034],\n",
            "        [-0.0730, -4.4815, -5.4013,  ..., -4.5008, -3.9714, -3.9555],\n",
            "        [-6.6982, -5.8087, -0.0160,  ..., -4.9525, -6.4208, -6.3572]],\n",
            "       grad_fn=<LogSoftmaxBackward0>)\n",
            "Training: 748\n",
            "Epoch: 0749 loss_train: 0.5899 acc_train: 0.8286 loss_val: 0.9904 acc_val: 0.6833 time: 4.1976s\n",
            "loss_val:0.9903838038444519, val_acc:0.6833333333333333, out_features:tensor([[-8.4433, -7.9581, -0.0116,  ..., -6.2123, -8.3375, -8.3135],\n",
            "        [-4.7561, -7.0078, -7.0015,  ..., -6.8385, -0.0133, -6.9300],\n",
            "        [-1.9459, -1.9459, -1.9459,  ..., -1.9459, -1.9459, -1.9459],\n",
            "        ...,\n",
            "        [-3.4256, -0.4379, -2.0610,  ..., -3.2774, -2.6583, -3.0191],\n",
            "        [-0.1378, -3.1118, -4.6946,  ..., -3.6530, -3.9564, -4.6038],\n",
            "        [-2.7670, -4.1000, -0.1908,  ..., -4.3678, -3.5685, -3.6140]],\n",
            "       grad_fn=<LogSoftmaxBackward0>)\n",
            "Training: 749\n",
            "Epoch: 0750 loss_train: 0.5029 acc_train: 0.8571 loss_val: 0.9576 acc_val: 0.7233 time: 4.3402s\n",
            "loss_val:0.9575589895248413, val_acc:0.7233333333333334, out_features:tensor([[-6.5966, -6.5427, -0.0219,  ..., -6.0815, -6.6210, -5.6575],\n",
            "        [-1.9459, -1.9459, -1.9459,  ..., -1.9459, -1.9459, -1.9459],\n",
            "        [-5.5377, -4.7162, -5.0518,  ..., -0.0336, -5.5626, -5.4371],\n",
            "        ...,\n",
            "        [-1.8521, -1.2478, -2.4686,  ..., -2.0651, -2.0866, -2.1112],\n",
            "        [-1.5064, -2.6522, -2.6932,  ..., -1.6922, -1.6269, -1.6152],\n",
            "        [-1.9459, -1.9459, -1.9459,  ..., -1.9459, -1.9459, -1.9459]],\n",
            "       grad_fn=<LogSoftmaxBackward0>)\n",
            "Training: 750\n",
            "Epoch: 0751 loss_train: 0.6228 acc_train: 0.8357 loss_val: 1.0108 acc_val: 0.6933 time: 4.3596s\n",
            "loss_val:1.010791301727295, val_acc:0.6933333333333334, out_features:tensor([[-9.0582e+00, -8.7612e+00, -2.6229e-03,  ..., -6.3091e+00,\n",
            "         -8.9475e+00, -8.8777e+00],\n",
            "        [-2.0032e+00, -2.5908e+00, -3.0602e+00,  ..., -2.3760e+00,\n",
            "         -1.1289e+00, -1.4462e+00],\n",
            "        [-7.9682e+00, -7.7376e+00, -6.6583e+00,  ..., -3.1799e-03,\n",
            "         -7.5356e+00, -8.1113e+00],\n",
            "        ...,\n",
            "        [-2.6890e+00, -1.1773e+00, -2.2429e+00,  ..., -2.5032e+00,\n",
            "         -2.0681e+00, -1.8085e+00],\n",
            "        [-1.4161e-01, -2.8069e+00, -4.6534e+00,  ..., -3.6346e+00,\n",
            "         -4.1868e+00, -4.8156e+00],\n",
            "        [-2.9375e+00, -2.6599e+00, -4.4256e-01,  ..., -3.3080e+00,\n",
            "         -2.1125e+00, -3.0974e+00]], grad_fn=<LogSoftmaxBackward0>)\n",
            "Training: 751\n",
            "Epoch: 0752 loss_train: 0.5692 acc_train: 0.8571 loss_val: 0.9456 acc_val: 0.6833 time: 4.1279s\n",
            "loss_val:0.9455958008766174, val_acc:0.6833333333333333, out_features:tensor([[-6.0125, -5.8836, -0.0331,  ..., -5.6399, -5.9558, -5.5548],\n",
            "        [-1.6731, -4.4218, -4.4518,  ..., -3.7991, -1.1408, -0.8315],\n",
            "        [-5.5248, -5.6429, -5.8771,  ..., -0.0204, -5.2467, -6.0900],\n",
            "        ...,\n",
            "        [-2.3574, -0.9660, -2.6995,  ..., -1.8317, -2.1089, -2.3682],\n",
            "        [-1.4320, -2.1549, -2.4612,  ..., -1.5378, -2.0613, -2.1633],\n",
            "        [-5.5174, -5.6229, -0.0256,  ..., -5.4041, -5.0025, -5.6327]],\n",
            "       grad_fn=<LogSoftmaxBackward0>)\n",
            "Training: 752\n",
            "Epoch: 0753 loss_train: 0.6637 acc_train: 0.7786 loss_val: 1.0557 acc_val: 0.6867 time: 4.4905s\n",
            "loss_val:1.055672526359558, val_acc:0.6866666666666666, out_features:tensor([[-6.9911, -7.0033, -0.0110,  ..., -5.2054, -7.0183, -6.6630],\n",
            "        [-3.0316, -5.1236, -5.1647,  ..., -4.6572, -0.2481, -2.1146],\n",
            "        [-6.2323, -6.4072, -6.9212,  ..., -0.0107, -5.4947, -6.8812],\n",
            "        ...,\n",
            "        [-3.6527, -0.2909, -3.3268,  ..., -2.8099, -2.7333, -3.3306],\n",
            "        [-0.3839, -3.3977, -3.6640,  ..., -2.8846, -2.2322, -3.4277],\n",
            "        [-4.6603, -4.8095, -0.1038,  ..., -4.5680, -4.6496, -3.0614]],\n",
            "       grad_fn=<LogSoftmaxBackward0>)\n",
            "Training: 753\n",
            "Epoch: 0754 loss_train: 0.6106 acc_train: 0.8429 loss_val: 1.0917 acc_val: 0.6533 time: 4.1481s\n",
            "loss_val:1.0916619300842285, val_acc:0.6533333333333333, out_features:tensor([[-1.6276e+01, -1.6166e+01, -7.1526e-07,  ..., -1.5960e+01,\n",
            "         -1.6266e+01, -1.6349e+01],\n",
            "        [-1.9459e+00, -1.9459e+00, -1.9459e+00,  ..., -1.9459e+00,\n",
            "         -1.9459e+00, -1.9459e+00],\n",
            "        [-2.8081e+00, -3.9232e+00, -3.8554e+00,  ..., -1.8931e-01,\n",
            "         -3.6340e+00, -3.6472e+00],\n",
            "        ...,\n",
            "        [-2.7376e+00, -8.0547e-01, -2.0096e+00,  ..., -1.8819e+00,\n",
            "         -2.5545e+00, -2.7241e+00],\n",
            "        [-1.4652e-02, -7.3609e+00, -7.5676e+00,  ..., -6.2454e+00,\n",
            "         -4.5979e+00, -7.0734e+00],\n",
            "        [-3.1727e+00, -2.3631e+00, -6.4010e-01,  ..., -3.2861e+00,\n",
            "         -2.6138e+00, -1.9653e+00]], grad_fn=<LogSoftmaxBackward0>)\n",
            "Training: 754\n",
            "Epoch: 0755 loss_train: 0.6772 acc_train: 0.7714 loss_val: 1.0207 acc_val: 0.6500 time: 4.1209s\n",
            "loss_val:1.020708680152893, val_acc:0.65, out_features:tensor([[-4.6995, -4.3040, -0.0835,  ..., -4.0651, -4.4472, -4.2546],\n",
            "        [-2.7131, -3.0926, -2.8001,  ..., -1.9183, -0.7286, -1.8291],\n",
            "        [-4.7169, -3.2882, -3.1254,  ..., -0.1225, -4.5705, -4.7404],\n",
            "        ...,\n",
            "        [-3.0433, -0.4157, -2.0203,  ..., -2.8921, -3.2941, -3.3723],\n",
            "        [-0.0397, -4.7316, -5.9055,  ..., -4.9393, -4.4176, -5.2021],\n",
            "        [-3.4205, -3.4874, -0.3802,  ..., -3.0675, -3.5234, -2.8272]],\n",
            "       grad_fn=<LogSoftmaxBackward0>)\n",
            "Training: 755\n",
            "Epoch: 0756 loss_train: 0.6183 acc_train: 0.8357 loss_val: 1.0425 acc_val: 0.6633 time: 4.4677s\n",
            "loss_val:1.0424736738204956, val_acc:0.6633333333333333, out_features:tensor([[-5.5896, -5.4534, -0.1048,  ..., -5.1245, -5.5962, -5.2822],\n",
            "        [-1.9459, -1.9459, -1.9459,  ..., -1.9459, -1.9459, -1.9459],\n",
            "        [-4.0350, -4.2037, -2.6098,  ..., -0.1576, -4.4030, -4.2372],\n",
            "        ...,\n",
            "        [-2.1924, -2.7011, -0.8118,  ..., -2.7090, -1.8678, -2.2372],\n",
            "        [-0.0871, -4.7933, -4.9311,  ..., -3.8919, -3.4226, -4.6474],\n",
            "        [-2.5785, -2.4340, -0.6644,  ..., -2.8730, -2.5412, -2.1374]],\n",
            "       grad_fn=<LogSoftmaxBackward0>)\n",
            "Training: 756\n",
            "Epoch: 0757 loss_train: 0.5304 acc_train: 0.8714 loss_val: 1.1140 acc_val: 0.6533 time: 4.1633s\n",
            "loss_val:1.114003300666809, val_acc:0.6533333333333333, out_features:tensor([[-3.7344e+00, -3.0295e+00, -2.9711e-01,  ..., -2.4838e+00,\n",
            "         -3.2364e+00, -3.2857e+00],\n",
            "        [-3.3037e+00, -3.7186e+00, -4.7383e+00,  ..., -3.4295e+00,\n",
            "         -1.4527e-01, -3.7181e+00],\n",
            "        [-6.1149e+00, -4.7664e+00, -5.8505e+00,  ..., -2.3885e-02,\n",
            "         -5.8688e+00, -5.7994e+00],\n",
            "        ...,\n",
            "        [-3.7058e+00, -2.0243e-01, -2.9483e+00,  ..., -3.6521e+00,\n",
            "         -3.4569e+00, -3.6367e+00],\n",
            "        [-4.2605e-03, -6.0575e+00, -8.9008e+00,  ..., -6.6916e+00,\n",
            "         -8.2389e+00, -8.8179e+00],\n",
            "        [-3.5555e+00, -4.1618e+00, -1.0885e-01,  ..., -4.2488e+00,\n",
            "         -3.9733e+00, -4.1842e+00]], grad_fn=<LogSoftmaxBackward0>)\n",
            "Training: 757\n",
            "Epoch: 0758 loss_train: 0.6563 acc_train: 0.8071 loss_val: 1.0431 acc_val: 0.6567 time: 4.0862s\n",
            "loss_val:1.0430959463119507, val_acc:0.6566666666666666, out_features:tensor([[-1.0499e+01, -1.0222e+01, -5.4237e-04,  ..., -1.0391e+01,\n",
            "         -1.0311e+01, -1.0502e+01],\n",
            "        [-1.9459e+00, -1.9459e+00, -1.9459e+00,  ..., -1.9459e+00,\n",
            "         -1.9459e+00, -1.9459e+00],\n",
            "        [-3.9936e+00, -3.7543e+00, -3.0710e+00,  ..., -1.8156e-01,\n",
            "         -3.9387e+00, -3.2820e+00],\n",
            "        ...,\n",
            "        [-4.5672e+00, -9.8933e-02, -4.2909e+00,  ..., -4.5202e+00,\n",
            "         -3.3438e+00, -4.4514e+00],\n",
            "        [-5.9313e-01, -1.9884e+00, -3.3273e+00,  ..., -2.7521e+00,\n",
            "         -2.3537e+00, -2.6890e+00],\n",
            "        [-1.3789e+01, -1.0336e+01, -4.0530e-05,  ..., -1.3202e+01,\n",
            "         -1.3839e+01, -1.3849e+01]], grad_fn=<LogSoftmaxBackward0>)\n",
            "Training: 758\n",
            "Epoch: 0759 loss_train: 0.6825 acc_train: 0.8071 loss_val: 0.9934 acc_val: 0.6700 time: 4.3503s\n",
            "loss_val:0.9933760762214661, val_acc:0.67, out_features:tensor([[-4.1476, -4.0567, -0.2906,  ..., -2.4862, -4.0642, -3.6112],\n",
            "        [-5.4099, -8.3697, -8.0686,  ..., -5.3474, -0.0221, -4.4363],\n",
            "        [-4.6601, -5.8949, -6.7679,  ..., -0.0203, -6.0803, -5.7248],\n",
            "        ...,\n",
            "        [-3.1944, -0.3095, -2.8756,  ..., -3.3478, -2.9826, -2.8874],\n",
            "        [-1.4861, -2.2981, -1.9449,  ..., -2.0849, -2.1742, -1.9588],\n",
            "        [-6.9839, -7.0917, -0.0246,  ..., -7.1432, -6.5851, -3.9341]],\n",
            "       grad_fn=<LogSoftmaxBackward0>)\n",
            "Training: 759\n",
            "Epoch: 0760 loss_train: 0.5976 acc_train: 0.8286 loss_val: 1.0081 acc_val: 0.6667 time: 4.1558s\n",
            "loss_val:1.0081361532211304, val_acc:0.6666666666666666, out_features:tensor([[-9.8869e+00, -9.2734e+00, -4.6576e-04,  ..., -9.0587e+00,\n",
            "         -9.8708e+00, -9.4659e+00],\n",
            "        [-1.9901e+00, -5.7954e+00, -5.3197e+00,  ..., -5.8465e+00,\n",
            "         -1.9899e-01, -3.5010e+00],\n",
            "        [-6.5848e+00, -5.4321e+00, -6.9415e+00,  ..., -8.9351e-03,\n",
            "         -7.0923e+00, -7.2632e+00],\n",
            "        ...,\n",
            "        [-6.0585e+00, -2.1874e-02, -5.5401e+00,  ..., -6.0841e+00,\n",
            "         -4.6804e+00, -6.2553e+00],\n",
            "        [-2.4562e-01, -2.8945e+00, -4.2541e+00,  ..., -3.8096e+00,\n",
            "         -2.5492e+00, -3.5690e+00],\n",
            "        [-3.1226e+00, -2.1159e+00, -3.9595e-01,  ..., -3.2549e+00,\n",
            "         -3.1749e+00, -3.3386e+00]], grad_fn=<LogSoftmaxBackward0>)\n",
            "Training: 760\n",
            "Epoch: 0761 loss_train: 0.5811 acc_train: 0.8357 loss_val: 0.9358 acc_val: 0.7033 time: 4.1635s\n",
            "loss_val:0.935806155204773, val_acc:0.7033333333333334, out_features:tensor([[-2.6652, -2.7000, -0.6765,  ..., -2.6969, -2.4934, -2.1017],\n",
            "        [-1.9459, -1.9459, -1.9459,  ..., -1.9459, -1.9459, -1.9459],\n",
            "        [-3.4897, -3.7727, -3.5289,  ..., -0.1695, -3.4373, -3.6345],\n",
            "        ...,\n",
            "        [-5.4306, -0.0526, -4.0049,  ..., -4.2294, -5.1556, -5.3855],\n",
            "        [-0.3796, -3.9041, -3.9447,  ..., -2.5728, -2.0720, -2.9350],\n",
            "        [-3.9111, -3.5312, -0.1405,  ..., -4.0581, -3.8737, -3.8098]],\n",
            "       grad_fn=<LogSoftmaxBackward0>)\n",
            "Training: 761\n",
            "Epoch: 0762 loss_train: 0.5827 acc_train: 0.8500 loss_val: 1.0062 acc_val: 0.6667 time: 4.3228s\n",
            "loss_val:1.0062392950057983, val_acc:0.6666666666666666, out_features:tensor([[-7.7540e+00, -7.9908e+00, -3.7544e-03,  ..., -8.0073e+00,\n",
            "         -8.0512e+00, -7.1880e+00],\n",
            "        [-1.9459e+00, -1.9459e+00, -1.9459e+00,  ..., -1.9459e+00,\n",
            "         -1.9459e+00, -1.9459e+00],\n",
            "        [-1.9459e+00, -1.9459e+00, -1.9459e+00,  ..., -1.9459e+00,\n",
            "         -1.9459e+00, -1.9459e+00],\n",
            "        ...,\n",
            "        [-3.3721e+00, -2.1596e-01, -3.4873e+00,  ..., -2.8058e+00,\n",
            "         -3.1463e+00, -4.3262e+00],\n",
            "        [-7.9823e-03, -6.3964e+00, -7.1322e+00,  ..., -6.9475e+00,\n",
            "         -5.9004e+00, -6.9231e+00],\n",
            "        [-1.1916e+01, -8.0980e+00, -3.4803e-04,  ..., -1.0942e+01,\n",
            "         -1.1792e+01, -1.2016e+01]], grad_fn=<LogSoftmaxBackward0>)\n",
            "Training: 762\n",
            "Epoch: 0763 loss_train: 0.5926 acc_train: 0.8357 loss_val: 1.0675 acc_val: 0.6233 time: 4.2171s\n",
            "loss_val:1.0675091743469238, val_acc:0.6233333333333333, out_features:tensor([[-9.3793e+00, -9.1443e+00, -1.0843e-03,  ..., -7.5758e+00,\n",
            "         -9.4358e+00, -8.7186e+00],\n",
            "        [-9.0783e+00, -9.9850e+00, -9.2084e+00,  ..., -7.3392e+00,\n",
            "         -1.0458e-03, -9.2652e+00],\n",
            "        [-2.2389e+00, -2.9545e+00, -1.6705e+00,  ..., -7.7847e-01,\n",
            "         -2.5869e+00, -2.7422e+00],\n",
            "        ...,\n",
            "        [-2.4981e+00, -5.7589e-01, -2.8430e+00,  ..., -2.2859e+00,\n",
            "         -2.6246e+00, -2.4759e+00],\n",
            "        [-1.9459e+00, -1.9459e+00, -1.9459e+00,  ..., -1.9459e+00,\n",
            "         -1.9459e+00, -1.9459e+00],\n",
            "        [-1.9459e+00, -1.9459e+00, -1.9459e+00,  ..., -1.9459e+00,\n",
            "         -1.9459e+00, -1.9459e+00]], grad_fn=<LogSoftmaxBackward0>)\n",
            "Training: 763\n",
            "Epoch: 0764 loss_train: 0.5543 acc_train: 0.8286 loss_val: 1.0558 acc_val: 0.6267 time: 4.2497s\n",
            "loss_val:1.0558359622955322, val_acc:0.6266666666666667, out_features:tensor([[-3.3069e+00, -3.4751e+00, -3.0885e-01,  ..., -3.2629e+00,\n",
            "         -2.6525e+00, -3.5049e+00],\n",
            "        [-1.9459e+00, -1.9459e+00, -1.9459e+00,  ..., -1.9459e+00,\n",
            "         -1.9459e+00, -1.9459e+00],\n",
            "        [-6.6766e+00, -7.8404e+00, -8.0180e+00,  ..., -3.7660e-03,\n",
            "         -7.7806e+00, -6.8362e+00],\n",
            "        ...,\n",
            "        [-2.9323e+00, -3.1130e-01, -3.2325e+00,  ..., -3.5185e+00,\n",
            "         -2.4616e+00, -3.4311e+00],\n",
            "        [-8.9959e-01, -3.0924e+00, -4.0449e+00,  ..., -9.1519e-01,\n",
            "         -2.6295e+00, -3.8854e+00],\n",
            "        [-6.1925e+00, -4.0587e+00, -2.9163e-02,  ..., -5.4215e+00,\n",
            "         -6.3326e+00, -6.4847e+00]], grad_fn=<LogSoftmaxBackward0>)\n",
            "Training: 764\n",
            "Epoch: 0765 loss_train: 0.6039 acc_train: 0.8214 loss_val: 0.9645 acc_val: 0.6800 time: 4.7169s\n",
            "loss_val:0.9644555449485779, val_acc:0.68, out_features:tensor([[-9.1773e+00, -8.7753e+00, -9.6787e-04,  ..., -7.9720e+00,\n",
            "         -9.0880e+00, -8.8715e+00],\n",
            "        [-1.9459e+00, -1.9459e+00, -1.9459e+00,  ..., -1.9459e+00,\n",
            "         -1.9459e+00, -1.9459e+00],\n",
            "        [-3.3741e+00, -3.3940e+00, -3.3124e+00,  ..., -1.9703e-01,\n",
            "         -3.5043e+00, -3.6049e+00],\n",
            "        ...,\n",
            "        [-3.9740e+00, -1.4273e-01, -4.0546e+00,  ..., -2.8815e+00,\n",
            "         -3.9265e+00, -4.5082e+00],\n",
            "        [-2.1287e-02, -5.8701e+00, -6.5552e+00,  ..., -4.8346e+00,\n",
            "         -5.2509e+00, -6.3310e+00],\n",
            "        [-7.6520e+00, -7.3776e+00, -4.5356e-03,  ..., -7.4131e+00,\n",
            "         -6.7815e+00, -7.2795e+00]], grad_fn=<LogSoftmaxBackward0>)\n",
            "Training: 765\n",
            "Epoch: 0766 loss_train: 0.5911 acc_train: 0.7929 loss_val: 1.0395 acc_val: 0.6833 time: 4.0947s\n",
            "loss_val:1.0395429134368896, val_acc:0.6833333333333333, out_features:tensor([[-1.9459e+00, -1.9459e+00, -1.9459e+00,  ..., -1.9459e+00,\n",
            "         -1.9459e+00, -1.9459e+00],\n",
            "        [-1.0585e+01, -1.1683e+01, -1.1259e+01,  ..., -8.8490e+00,\n",
            "         -2.9297e-04, -9.2646e+00],\n",
            "        [-3.3548e+00, -3.1935e+00, -3.7094e+00,  ..., -2.7029e-01,\n",
            "         -3.1945e+00, -2.6365e+00],\n",
            "        ...,\n",
            "        [-2.7893e+00, -6.2870e-01, -2.6332e+00,  ..., -1.9645e+00,\n",
            "         -2.8002e+00, -2.6454e+00],\n",
            "        [-3.4047e-01, -3.4095e+00, -3.5796e+00,  ..., -2.4988e+00,\n",
            "         -2.5739e+00, -3.2397e+00],\n",
            "        [-1.7898e+00, -2.2158e+00, -1.4558e+00,  ..., -2.0694e+00,\n",
            "         -2.0205e+00, -2.3056e+00]], grad_fn=<LogSoftmaxBackward0>)\n",
            "Training: 766\n",
            "Epoch: 0767 loss_train: 0.5522 acc_train: 0.8286 loss_val: 1.0756 acc_val: 0.6733 time: 4.3262s\n",
            "loss_val:1.0755728483200073, val_acc:0.6733333333333333, out_features:tensor([[-1.9459, -1.9459, -1.9459,  ..., -1.9459, -1.9459, -1.9459],\n",
            "        [-3.6838, -3.0234, -4.2127,  ..., -3.9088, -0.1502, -4.2283],\n",
            "        [-6.2077, -6.4319, -6.5333,  ..., -0.0274, -3.9989, -6.0899],\n",
            "        ...,\n",
            "        [-2.9542, -0.5251, -2.5171,  ..., -3.0483, -2.2428, -2.9698],\n",
            "        [-0.8307, -1.9809, -3.1021,  ..., -2.1034, -2.2826, -2.7255],\n",
            "        [-1.7983, -2.3231, -0.6556,  ..., -3.1328, -2.8465, -2.7619]],\n",
            "       grad_fn=<LogSoftmaxBackward0>)\n",
            "Training: 767\n",
            "Epoch: 0768 loss_train: 0.6071 acc_train: 0.8214 loss_val: 0.9807 acc_val: 0.6667 time: 4.2841s\n",
            "loss_val:0.9806510210037231, val_acc:0.6666666666666666, out_features:tensor([[-3.9572, -3.7740, -0.2442,  ..., -3.4590, -3.5982, -2.6717],\n",
            "        [-4.2296, -3.7614, -4.3913,  ..., -4.2112, -0.1782, -2.5188],\n",
            "        [-6.5103, -6.6962, -6.1005,  ..., -0.0125, -6.3615, -5.4668],\n",
            "        ...,\n",
            "        [-2.0277, -0.3748, -3.6737,  ..., -2.8593, -3.0586, -3.5119],\n",
            "        [-1.0961, -2.3838, -2.1954,  ..., -1.6974, -2.0493, -2.4890],\n",
            "        [-1.5367, -3.0347, -2.1059,  ..., -2.9124, -1.3119, -2.7830]],\n",
            "       grad_fn=<LogSoftmaxBackward0>)\n",
            "Training: 768\n",
            "Epoch: 0769 loss_train: 0.5513 acc_train: 0.8500 loss_val: 1.0993 acc_val: 0.6333 time: 4.1794s\n",
            "loss_val:1.0992987155914307, val_acc:0.6333333333333333, out_features:tensor([[-6.3419e+00, -4.9536e+00, -1.8630e-02,  ..., -5.7888e+00,\n",
            "         -6.3189e+00, -5.8929e+00],\n",
            "        [-1.9350e+00, -3.7958e+00, -3.5541e+00,  ..., -2.2394e+00,\n",
            "         -6.2970e-01, -1.9301e+00],\n",
            "        [-1.0837e+01, -1.0847e+01, -8.4320e+00,  ..., -3.0763e-04,\n",
            "         -1.0859e+01, -1.1031e+01],\n",
            "        ...,\n",
            "        [-1.9158e+00, -5.2885e-01, -3.4114e+00,  ..., -2.0165e+00,\n",
            "         -3.0366e+00, -3.5802e+00],\n",
            "        [-1.5163e-01, -4.4312e+00, -2.9898e+00,  ..., -3.6889e+00,\n",
            "         -3.8748e+00, -4.1007e+00],\n",
            "        [-8.5366e+00, -8.4014e+00, -1.9341e-03,  ..., -8.2405e+00,\n",
            "         -8.6439e+00, -8.3432e+00]], grad_fn=<LogSoftmaxBackward0>)\n",
            "Training: 769\n",
            "Epoch: 0770 loss_train: 0.6263 acc_train: 0.8214 loss_val: 1.0210 acc_val: 0.7100 time: 4.3718s\n",
            "loss_val:1.0210171937942505, val_acc:0.71, out_features:tensor([[-6.9241e+00, -5.8077e+00, -9.8313e-03,  ..., -6.1588e+00,\n",
            "         -6.7615e+00, -6.9546e+00],\n",
            "        [-1.8599e+00, -2.7273e+00, -2.5743e+00,  ..., -2.7810e+00,\n",
            "         -1.1133e+00, -1.3075e+00],\n",
            "        [-2.2241e+00, -1.9849e+00, -1.8018e+00,  ..., -1.0917e+00,\n",
            "         -2.4139e+00, -2.4349e+00],\n",
            "        ...,\n",
            "        [-2.2499e+00, -1.6062e+00, -2.4259e+00,  ..., -2.2025e+00,\n",
            "         -1.8858e+00, -1.8184e+00],\n",
            "        [-7.1930e-01, -2.5983e+00, -2.8098e+00,  ..., -2.0351e+00,\n",
            "         -2.2271e+00, -2.5902e+00],\n",
            "        [-1.3829e+01, -1.3420e+01, -1.1802e-05,  ..., -1.1951e+01,\n",
            "         -1.3808e+01, -1.3910e+01]], grad_fn=<LogSoftmaxBackward0>)\n",
            "Training: 770\n",
            "Epoch: 0771 loss_train: 0.6228 acc_train: 0.8143 loss_val: 0.8999 acc_val: 0.7233 time: 4.2006s\n",
            "loss_val:0.8998824954032898, val_acc:0.7233333333333334, out_features:tensor([[-9.2376e+00, -9.2142e+00, -8.6199e-04,  ..., -9.1106e+00,\n",
            "         -9.3444e+00, -7.9079e+00],\n",
            "        [-9.5409e+00, -8.8419e+00, -9.8757e+00,  ..., -9.2116e+00,\n",
            "         -4.8995e-04, -9.5490e+00],\n",
            "        [-7.5785e+00, -7.6158e+00, -7.1849e+00,  ..., -2.9987e-03,\n",
            "         -7.6460e+00, -7.8882e+00],\n",
            "        ...,\n",
            "        [-4.1167e+00, -1.8163e-01, -3.6993e+00,  ..., -3.8658e+00,\n",
            "         -3.7036e+00, -3.1136e+00],\n",
            "        [-3.1585e-02, -5.0516e+00, -6.2728e+00,  ..., -5.5044e+00,\n",
            "         -4.2260e+00, -6.1568e+00],\n",
            "        [-1.9459e+00, -1.9459e+00, -1.9459e+00,  ..., -1.9459e+00,\n",
            "         -1.9459e+00, -1.9459e+00]], grad_fn=<LogSoftmaxBackward0>)\n",
            "Training: 771\n",
            "Epoch: 0772 loss_train: 0.6229 acc_train: 0.8214 loss_val: 1.0448 acc_val: 0.6867 time: 4.1989s\n",
            "loss_val:1.044809341430664, val_acc:0.6866666666666666, out_features:tensor([[-8.3219e+00, -8.2763e+00, -3.4867e-03,  ..., -8.4276e+00,\n",
            "         -8.3091e+00, -6.2531e+00],\n",
            "        [-1.9459e+00, -1.9459e+00, -1.9459e+00,  ..., -1.9459e+00,\n",
            "         -1.9459e+00, -1.9459e+00],\n",
            "        [-8.1465e+00, -6.5350e+00, -8.7899e+00,  ..., -2.5614e-03,\n",
            "         -7.9193e+00, -8.7503e+00],\n",
            "        ...,\n",
            "        [-4.1472e+00, -1.6249e-01, -4.3894e+00,  ..., -3.8237e+00,\n",
            "         -2.5360e+00, -4.5187e+00],\n",
            "        [-2.4422e-01, -4.0680e+00, -4.1132e+00,  ..., -3.5841e+00,\n",
            "         -2.8656e+00, -2.5350e+00],\n",
            "        [-1.9459e+00, -1.9459e+00, -1.9459e+00,  ..., -1.9459e+00,\n",
            "         -1.9459e+00, -1.9459e+00]], grad_fn=<LogSoftmaxBackward0>)\n",
            "Training: 772\n",
            "Epoch: 0773 loss_train: 0.6148 acc_train: 0.8357 loss_val: 0.9743 acc_val: 0.6667 time: 4.4970s\n",
            "loss_val:0.9742720723152161, val_acc:0.6666666666666666, out_features:tensor([[-6.4661, -6.1506, -0.0222,  ..., -5.8881, -6.3229, -5.6601],\n",
            "        [-1.9459, -1.9459, -1.9459,  ..., -1.9459, -1.9459, -1.9459],\n",
            "        [-4.8077, -4.9250, -4.7651,  ..., -0.0617, -4.8569, -3.7958],\n",
            "        ...,\n",
            "        [-3.1767, -0.7437, -2.0638,  ..., -3.0908, -2.6818, -1.5437],\n",
            "        [-0.3388, -3.1004, -3.1995,  ..., -3.2511, -2.5772, -3.3600],\n",
            "        [-1.9459, -1.9459, -1.9459,  ..., -1.9459, -1.9459, -1.9459]],\n",
            "       grad_fn=<LogSoftmaxBackward0>)\n",
            "Training: 773\n",
            "Epoch: 0774 loss_train: 0.5130 acc_train: 0.8643 loss_val: 1.0296 acc_val: 0.6900 time: 4.2248s\n",
            "loss_val:1.0296268463134766, val_acc:0.69, out_features:tensor([[-5.5809, -4.3196, -0.0531,  ..., -4.6693, -5.4737, -5.4743],\n",
            "        [-6.4400, -6.3987, -6.8592,  ..., -6.5357, -0.0115, -5.3969],\n",
            "        [-3.5964, -3.1005, -4.2272,  ..., -0.1708, -3.8022, -3.3446],\n",
            "        ...,\n",
            "        [-2.2078, -0.9744, -2.5748,  ..., -2.7761, -1.7169, -1.8916],\n",
            "        [-0.0878, -3.3690, -4.8990,  ..., -4.5793, -4.1488, -4.8638],\n",
            "        [-3.5685, -3.6454, -0.3331,  ..., -2.1579, -2.7140, -3.7983]],\n",
            "       grad_fn=<LogSoftmaxBackward0>)\n",
            "Training: 774\n",
            "Epoch: 0775 loss_train: 0.5689 acc_train: 0.8286 loss_val: 0.9816 acc_val: 0.6767 time: 4.2545s\n",
            "loss_val:0.9816040992736816, val_acc:0.6766666666666666, out_features:tensor([[-4.8159, -3.5498, -0.1132,  ..., -3.2149, -4.6213, -4.6099],\n",
            "        [-1.9459, -1.9459, -1.9459,  ..., -1.9459, -1.9459, -1.9459],\n",
            "        [-3.7090, -3.9026, -3.4596,  ..., -0.1194, -4.2505, -4.3299],\n",
            "        ...,\n",
            "        [-2.6966, -0.3972, -2.8271,  ..., -3.2189, -2.7401, -2.7682],\n",
            "        [-0.1664, -4.3485, -3.7934,  ..., -3.7771, -2.7372, -4.0036],\n",
            "        [-5.5938, -4.3802, -0.0410,  ..., -5.9521, -4.8634, -4.7601]],\n",
            "       grad_fn=<LogSoftmaxBackward0>)\n",
            "Training: 775\n",
            "Epoch: 0776 loss_train: 0.5548 acc_train: 0.8286 loss_val: 0.9908 acc_val: 0.6700 time: 4.4615s\n",
            "loss_val:0.9907541871070862, val_acc:0.67, out_features:tensor([[-1.9459, -1.9459, -1.9459,  ..., -1.9459, -1.9459, -1.9459],\n",
            "        [-3.6933, -5.3254, -5.2600,  ..., -2.6950, -0.1251, -4.5905],\n",
            "        [-4.0146, -4.0883, -3.5206,  ..., -0.1282, -3.8019, -3.9639],\n",
            "        ...,\n",
            "        [-1.9459, -1.9459, -1.9459,  ..., -1.9459, -1.9459, -1.9459],\n",
            "        [-1.9459, -1.9459, -1.9459,  ..., -1.9459, -1.9459, -1.9459],\n",
            "        [-3.6275, -3.5661, -0.2529,  ..., -3.5968, -3.3276, -2.9062]],\n",
            "       grad_fn=<LogSoftmaxBackward0>)\n",
            "Training: 776\n",
            "Epoch: 0777 loss_train: 0.5130 acc_train: 0.9000 loss_val: 1.0209 acc_val: 0.6500 time: 4.1540s\n",
            "loss_val:1.020907998085022, val_acc:0.65, out_features:tensor([[-4.0455e+00, -3.4856e+00, -1.7126e-01,  ..., -3.8075e+00,\n",
            "         -4.1918e+00, -3.4590e+00],\n",
            "        [-1.9459e+00, -1.9459e+00, -1.9459e+00,  ..., -1.9459e+00,\n",
            "         -1.9459e+00, -1.9459e+00],\n",
            "        [-9.6073e+00, -9.1263e+00, -6.1411e+00,  ..., -2.5204e-03,\n",
            "         -9.7022e+00, -9.6701e+00],\n",
            "        ...,\n",
            "        [-2.4059e+00, -9.0206e-01, -2.2425e+00,  ..., -2.2071e+00,\n",
            "         -2.3610e+00, -2.6223e+00],\n",
            "        [-8.2530e-04, -9.5959e+00, -9.9265e+00,  ..., -8.2885e+00,\n",
            "         -8.1976e+00, -8.9401e+00],\n",
            "        [-1.9459e+00, -1.9459e+00, -1.9459e+00,  ..., -1.9459e+00,\n",
            "         -1.9459e+00, -1.9459e+00]], grad_fn=<LogSoftmaxBackward0>)\n",
            "Training: 777\n",
            "Epoch: 0778 loss_train: 0.6073 acc_train: 0.8000 loss_val: 0.9597 acc_val: 0.7033 time: 4.1962s\n",
            "loss_val:0.9596943259239197, val_acc:0.7033333333333334, out_features:tensor([[-6.5140, -6.3424, -0.0250,  ..., -5.1245, -6.4827, -6.0745],\n",
            "        [-1.9459, -1.9459, -1.9459,  ..., -1.9459, -1.9459, -1.9459],\n",
            "        [-4.4200, -3.9669, -4.8215,  ..., -0.0815, -4.0638, -4.6059],\n",
            "        ...,\n",
            "        [-4.2599, -0.1009, -5.2065,  ..., -4.2380, -2.9954, -4.9461],\n",
            "        [-0.5462, -3.1549, -3.5864,  ..., -1.6060, -2.5480, -3.1744],\n",
            "        [-1.9459, -1.9459, -1.9459,  ..., -1.9459, -1.9459, -1.9459]],\n",
            "       grad_fn=<LogSoftmaxBackward0>)\n",
            "Training: 778\n",
            "Epoch: 0779 loss_train: 0.6491 acc_train: 0.8000 loss_val: 1.0711 acc_val: 0.6567 time: 4.4485s\n",
            "loss_val:1.071058750152588, val_acc:0.6566666666666666, out_features:tensor([[-9.6546e+00, -9.6503e+00, -6.6747e-04,  ..., -9.4979e+00,\n",
            "         -9.7175e+00, -8.9219e+00],\n",
            "        [-2.7686e+00, -3.2317e+00, -3.0230e+00,  ..., -2.3846e+00,\n",
            "         -6.7349e-01, -1.5347e+00],\n",
            "        [-4.6565e+00, -4.5251e+00, -3.1754e+00,  ..., -9.8881e-02,\n",
            "         -4.5861e+00, -4.3270e+00],\n",
            "        ...,\n",
            "        [-4.3966e+00, -1.3717e-01, -4.2119e+00,  ..., -3.1258e+00,\n",
            "         -4.4773e+00, -4.3960e+00],\n",
            "        [-1.0465e+00, -1.9057e+00, -2.3261e+00,  ..., -2.0186e+00,\n",
            "         -2.1854e+00, -2.5084e+00],\n",
            "        [-3.2576e+00, -2.9288e+00, -6.8245e-01,  ..., -2.6690e+00,\n",
            "         -3.3271e+00, -2.8308e+00]], grad_fn=<LogSoftmaxBackward0>)\n",
            "Training: 779\n",
            "Epoch: 0780 loss_train: 0.6948 acc_train: 0.7571 loss_val: 1.0647 acc_val: 0.6733 time: 4.1220s\n",
            "loss_val:1.0647430419921875, val_acc:0.6733333333333333, out_features:tensor([[-1.2223e+01, -1.2032e+01, -4.8912e-04,  ..., -1.2157e+01,\n",
            "         -1.2212e+01, -8.0293e+00],\n",
            "        [-1.9459e+00, -1.9459e+00, -1.9459e+00,  ..., -1.9459e+00,\n",
            "         -1.9459e+00, -1.9459e+00],\n",
            "        [-5.3069e+00, -6.2428e+00, -6.0232e+00,  ..., -1.9431e-02,\n",
            "         -5.7920e+00, -5.3729e+00],\n",
            "        ...,\n",
            "        [-1.9891e+00, -3.8149e-01, -4.1808e+00,  ..., -2.4080e+00,\n",
            "         -3.0836e+00, -4.1647e+00],\n",
            "        [-7.1753e-01, -3.4329e+00, -3.5804e+00,  ..., -2.0493e+00,\n",
            "         -1.7329e+00, -2.2253e+00],\n",
            "        [-4.3392e+00, -4.7576e+00, -7.7890e-02,  ..., -5.5044e+00,\n",
            "         -4.5611e+00, -3.3570e+00]], grad_fn=<LogSoftmaxBackward0>)\n",
            "Training: 780\n",
            "Epoch: 0781 loss_train: 0.5674 acc_train: 0.8429 loss_val: 1.0295 acc_val: 0.6967 time: 4.2780s\n",
            "loss_val:1.0295394659042358, val_acc:0.6966666666666667, out_features:tensor([[-2.4014, -1.9088, -1.2973,  ..., -2.0277, -2.3314, -2.1444],\n",
            "        [-1.9459, -1.9459, -1.9459,  ..., -1.9459, -1.9459, -1.9459],\n",
            "        [-3.0271, -3.7218, -3.7236,  ..., -0.2660, -3.1413, -2.6074],\n",
            "        ...,\n",
            "        [-2.5509, -0.4978, -2.5694,  ..., -2.7454, -2.2999, -3.4038],\n",
            "        [-0.3239, -2.9912, -3.5893,  ..., -2.9451, -2.6787, -3.0035],\n",
            "        [-1.9459, -1.9459, -1.9459,  ..., -1.9459, -1.9459, -1.9459]],\n",
            "       grad_fn=<LogSoftmaxBackward0>)\n",
            "Training: 781\n",
            "Epoch: 0782 loss_train: 0.5633 acc_train: 0.8286 loss_val: 0.9732 acc_val: 0.6667 time: 4.4483s\n",
            "loss_val:0.9731560349464417, val_acc:0.6666666666666666, out_features:tensor([[-3.9367e+00, -3.8565e+00, -1.2302e-01,  ..., -4.2904e+00,\n",
            "         -4.1800e+00, -3.8705e+00],\n",
            "        [-4.1420e+00, -6.2721e+00, -7.0572e+00,  ..., -6.4141e+00,\n",
            "         -3.0237e-02, -4.7494e+00],\n",
            "        [-3.9534e+00, -3.3326e+00, -3.6579e+00,  ..., -2.0147e-01,\n",
            "         -3.8204e+00, -3.8395e+00],\n",
            "        ...,\n",
            "        [-4.2613e+00, -1.5784e-01, -4.0907e+00,  ..., -3.2488e+00,\n",
            "         -3.9011e+00, -3.1711e+00],\n",
            "        [-4.8249e-01, -2.3619e+00, -2.9145e+00,  ..., -2.6323e+00,\n",
            "         -2.4766e+00, -3.1379e+00],\n",
            "        [-7.0189e+00, -7.4465e+00, -6.7324e-03,  ..., -5.6713e+00,\n",
            "         -7.4198e+00, -7.3681e+00]], grad_fn=<LogSoftmaxBackward0>)\n",
            "Training: 782\n",
            "Epoch: 0783 loss_train: 0.5183 acc_train: 0.8500 loss_val: 1.0383 acc_val: 0.6900 time: 4.2271s\n",
            "loss_val:1.0382708311080933, val_acc:0.69, out_features:tensor([[-5.7912e+00, -5.7177e+00, -2.4114e-02,  ..., -5.3976e+00,\n",
            "         -5.8186e+00, -5.7026e+00],\n",
            "        [-1.9459e+00, -1.9459e+00, -1.9459e+00,  ..., -1.9459e+00,\n",
            "         -1.9459e+00, -1.9459e+00],\n",
            "        [-5.4973e+00, -5.7663e+00, -5.9142e+00,  ..., -2.7528e-02,\n",
            "         -5.7391e+00, -4.4552e+00],\n",
            "        ...,\n",
            "        [-6.8609e+00, -4.9786e-03, -7.6070e+00,  ..., -7.3797e+00,\n",
            "         -6.5786e+00, -7.0582e+00],\n",
            "        [-7.7416e-01, -2.8201e+00, -3.0935e+00,  ..., -1.9997e+00,\n",
            "         -1.8527e+00, -2.2560e+00],\n",
            "        [-3.6436e+00, -3.7837e+00, -1.8704e-01,  ..., -2.9134e+00,\n",
            "         -3.7490e+00, -4.1847e+00]], grad_fn=<LogSoftmaxBackward0>)\n",
            "Training: 783\n",
            "Epoch: 0784 loss_train: 0.5748 acc_train: 0.8214 loss_val: 1.0863 acc_val: 0.6900 time: 4.4281s\n",
            "loss_val:1.0863059759140015, val_acc:0.69, out_features:tensor([[-8.2734e+00, -8.5258e+00, -1.7974e-03,  ..., -7.8618e+00,\n",
            "         -8.3173e+00, -8.3943e+00],\n",
            "        [-1.1140e+01, -1.5441e+01, -1.5440e+01,  ..., -9.1535e+00,\n",
            "         -1.3362e-04, -1.1282e+01],\n",
            "        [-2.3690e+00, -2.3834e+00, -2.3900e+00,  ..., -7.6428e-01,\n",
            "         -2.2960e+00, -2.2871e+00],\n",
            "        ...,\n",
            "        [-6.0136e+00, -1.7910e-02, -5.6744e+00,  ..., -5.4289e+00,\n",
            "         -5.6405e+00, -6.2747e+00],\n",
            "        [-5.4000e-01, -2.4656e+00, -2.8912e+00,  ..., -2.4158e+00,\n",
            "         -2.5788e+00, -2.9615e+00],\n",
            "        [-4.3054e+00, -5.1911e+00, -6.3121e-02,  ..., -5.1622e+00,\n",
            "         -5.3398e+00, -5.6703e+00]], grad_fn=<LogSoftmaxBackward0>)\n",
            "Training: 784\n",
            "Epoch: 0785 loss_train: 0.6239 acc_train: 0.8286 loss_val: 0.9782 acc_val: 0.6900 time: 4.2897s\n",
            "loss_val:0.978166401386261, val_acc:0.69, out_features:tensor([[-4.4127, -4.3359, -0.2693,  ..., -3.1379, -4.3002, -3.7536],\n",
            "        [-4.2517, -9.2632, -9.1828,  ..., -6.7975, -0.0929, -2.6158],\n",
            "        [-2.5152, -1.9668, -1.9101,  ..., -0.8812, -2.7255, -2.5106],\n",
            "        ...,\n",
            "        [-2.7154, -0.6816, -2.8631,  ..., -2.0844, -2.2391, -2.4444],\n",
            "        [-0.0721, -5.2753, -5.4876,  ..., -5.2157, -3.5116, -3.8657],\n",
            "        [-3.7708, -3.1159, -0.2528,  ..., -2.2643, -4.0916, -4.2359]],\n",
            "       grad_fn=<LogSoftmaxBackward0>)\n",
            "Training: 785\n",
            "Epoch: 0786 loss_train: 0.5599 acc_train: 0.8571 loss_val: 0.9861 acc_val: 0.7033 time: 4.1648s\n",
            "loss_val:0.9861389398574829, val_acc:0.7033333333333334, out_features:tensor([[-8.5959e+00, -8.3581e+00, -1.7792e-03,  ..., -8.4345e+00,\n",
            "         -8.5385e+00, -7.7477e+00],\n",
            "        [-1.9459e+00, -1.9459e+00, -1.9459e+00,  ..., -1.9459e+00,\n",
            "         -1.9459e+00, -1.9459e+00],\n",
            "        [-4.3483e+00, -3.6098e+00, -4.0281e+00,  ..., -1.0747e-01,\n",
            "         -4.0684e+00, -4.0790e+00],\n",
            "        ...,\n",
            "        [-3.1500e+00, -3.5895e-01, -3.2388e+00,  ..., -2.6902e+00,\n",
            "         -2.3919e+00, -3.4420e+00],\n",
            "        [-1.9459e+00, -1.9459e+00, -1.9459e+00,  ..., -1.9459e+00,\n",
            "         -1.9459e+00, -1.9459e+00],\n",
            "        [-1.8465e+00, -1.6445e+00, -1.6494e+00,  ..., -2.8513e+00,\n",
            "         -1.7260e+00, -1.9804e+00]], grad_fn=<LogSoftmaxBackward0>)\n",
            "Training: 786\n",
            "Epoch: 0787 loss_train: 0.6010 acc_train: 0.8357 loss_val: 1.0318 acc_val: 0.6900 time: 4.4776s\n",
            "loss_val:1.03179931640625, val_acc:0.69, out_features:tensor([[-2.9456, -2.7522, -0.6973,  ..., -2.6896, -2.8352, -2.5071],\n",
            "        [-1.4259, -2.7999, -4.2809,  ..., -2.5271, -0.7499, -2.1270],\n",
            "        [-4.1895, -3.2945, -4.5970,  ..., -0.1293, -3.7503, -3.8109],\n",
            "        ...,\n",
            "        [-1.9459, -1.9459, -1.9459,  ..., -1.9459, -1.9459, -1.9459],\n",
            "        [-0.8187, -2.5184, -2.9884,  ..., -1.9847, -2.2488, -2.1182],\n",
            "        [-1.9459, -1.9459, -1.9459,  ..., -1.9459, -1.9459, -1.9459]],\n",
            "       grad_fn=<LogSoftmaxBackward0>)\n",
            "Training: 787\n",
            "Epoch: 0788 loss_train: 0.6183 acc_train: 0.8286 loss_val: 1.0768 acc_val: 0.7033 time: 4.1924s\n",
            "loss_val:1.0767902135849, val_acc:0.7033333333333334, out_features:tensor([[-1.9459, -1.9459, -1.9459,  ..., -1.9459, -1.9459, -1.9459],\n",
            "        [-1.9459, -1.9459, -1.9459,  ..., -1.9459, -1.9459, -1.9459],\n",
            "        [-1.9459, -1.9459, -1.9459,  ..., -1.9459, -1.9459, -1.9459],\n",
            "        ...,\n",
            "        [-2.8449, -0.4244, -2.9803,  ..., -2.7726, -2.2205, -3.1942],\n",
            "        [-0.1308, -4.4878, -4.8940,  ..., -3.2497, -3.5255, -3.6008],\n",
            "        [-2.1568, -1.9205, -1.4453,  ..., -2.1720, -1.7633, -2.2877]],\n",
            "       grad_fn=<LogSoftmaxBackward0>)\n",
            "Training: 788\n",
            "Epoch: 0789 loss_train: 0.6524 acc_train: 0.7929 loss_val: 1.1578 acc_val: 0.6267 time: 4.1477s\n",
            "loss_val:1.157772421836853, val_acc:0.6266666666666667, out_features:tensor([[-5.9664, -5.9143, -0.0323,  ..., -4.2885, -5.9830, -5.7136],\n",
            "        [-2.6048, -3.6739, -3.3283,  ..., -1.2160, -0.9827, -1.7439],\n",
            "        [-4.2832, -4.5851, -4.5872,  ..., -0.0786, -3.8033, -4.6764],\n",
            "        ...,\n",
            "        [-1.9459, -1.9459, -1.9459,  ..., -1.9459, -1.9459, -1.9459],\n",
            "        [-0.8021, -2.6782, -2.7049,  ..., -1.8823, -2.1839, -2.6454],\n",
            "        [-5.4526, -4.6169, -0.0505,  ..., -4.0397, -4.9990, -5.3861]],\n",
            "       grad_fn=<LogSoftmaxBackward0>)\n",
            "Training: 789\n",
            "Epoch: 0790 loss_train: 0.7756 acc_train: 0.7500 loss_val: 1.0055 acc_val: 0.6833 time: 4.5309s\n",
            "loss_val:1.0055416822433472, val_acc:0.6833333333333333, out_features:tensor([[-7.6468, -7.6126, -0.0125,  ..., -6.8567, -7.7218, -5.4755],\n",
            "        [-1.9459, -1.9459, -1.9459,  ..., -1.9459, -1.9459, -1.9459],\n",
            "        [-1.9459, -1.9459, -1.9459,  ..., -1.9459, -1.9459, -1.9459],\n",
            "        ...,\n",
            "        [-4.1446, -0.2556, -4.2892,  ..., -1.9305, -4.0215, -3.8032],\n",
            "        [-0.2611, -3.2687, -4.0846,  ..., -2.7034, -3.0401, -3.2000],\n",
            "        [-1.9459, -1.9459, -1.9459,  ..., -1.9459, -1.9459, -1.9459]],\n",
            "       grad_fn=<LogSoftmaxBackward0>)\n",
            "Training: 790\n",
            "Epoch: 0791 loss_train: 0.5527 acc_train: 0.8571 loss_val: 0.9466 acc_val: 0.7067 time: 4.0910s\n",
            "loss_val:0.9466338157653809, val_acc:0.7066666666666667, out_features:tensor([[-3.5817, -4.0354, -0.1641,  ..., -3.4432, -3.9518, -3.9472],\n",
            "        [-2.2667, -2.0343, -2.2721,  ..., -2.0116, -1.1646, -2.0065],\n",
            "        [-4.5063, -4.6448, -5.4907,  ..., -0.0415, -5.1451, -5.5314],\n",
            "        ...,\n",
            "        [-2.0213, -0.7286, -2.2390,  ..., -2.7346, -1.9990, -3.1330],\n",
            "        [-0.1209, -4.4487, -4.4764,  ..., -3.3899, -3.7677, -3.6820],\n",
            "        [-3.3727, -3.3365, -0.3367,  ..., -2.1985, -3.5349, -3.1958]],\n",
            "       grad_fn=<LogSoftmaxBackward0>)\n",
            "Training: 791\n",
            "Epoch: 0792 loss_train: 0.6594 acc_train: 0.7857 loss_val: 1.0378 acc_val: 0.6700 time: 4.0553s\n",
            "loss_val:1.0377875566482544, val_acc:0.67, out_features:tensor([[-9.4215e+00, -9.1850e+00, -1.2490e-03,  ..., -8.3514e+00,\n",
            "         -9.4133e+00, -8.4785e+00],\n",
            "        [-1.9459e+00, -1.9459e+00, -1.9459e+00,  ..., -1.9459e+00,\n",
            "         -1.9459e+00, -1.9459e+00],\n",
            "        [-6.4408e+00, -6.8094e+00, -6.5616e+00,  ..., -1.2260e-02,\n",
            "         -6.6993e+00, -5.1524e+00],\n",
            "        ...,\n",
            "        [-3.3405e+00, -3.3450e-01, -2.5534e+00,  ..., -2.5561e+00,\n",
            "         -3.4789e+00, -3.3936e+00],\n",
            "        [-7.9997e-01, -2.1897e+00, -2.9535e+00,  ..., -2.5196e+00,\n",
            "         -2.0146e+00, -2.1357e+00],\n",
            "        [-3.5655e+00, -2.9071e+00, -3.3451e-01,  ..., -3.1593e+00,\n",
            "         -3.5948e+00, -3.7360e+00]], grad_fn=<LogSoftmaxBackward0>)\n",
            "Training: 792\n",
            "Epoch: 0793 loss_train: 0.5681 acc_train: 0.8357 loss_val: 1.0679 acc_val: 0.6367 time: 4.3981s\n",
            "loss_val:1.0678644180297852, val_acc:0.6366666666666667, out_features:tensor([[-4.0102, -3.4392, -0.3116,  ..., -2.5519, -3.9690, -3.4359],\n",
            "        [-4.3408, -5.0586, -2.8721,  ..., -5.0205, -0.2459, -3.5821],\n",
            "        [-3.5531, -4.1999, -3.9791,  ..., -0.1397, -4.1770, -3.1475],\n",
            "        ...,\n",
            "        [-2.5527, -0.6345, -2.1340,  ..., -2.5753, -2.4890, -2.8413],\n",
            "        [-0.1023, -4.9873, -5.0691,  ..., -4.1911, -3.2445, -3.7413],\n",
            "        [-1.8356, -2.4912, -0.6218,  ..., -2.8454, -3.1082, -2.9104]],\n",
            "       grad_fn=<LogSoftmaxBackward0>)\n",
            "Training: 793\n",
            "Epoch: 0794 loss_train: 0.6479 acc_train: 0.7857 loss_val: 0.9571 acc_val: 0.7000 time: 4.1787s\n",
            "loss_val:0.9570934176445007, val_acc:0.7, out_features:tensor([[-8.8964, -8.8195, -0.0108,  ..., -8.4027, -8.8780, -6.3371],\n",
            "        [-1.9459, -1.9459, -1.9459,  ..., -1.9459, -1.9459, -1.9459],\n",
            "        [-5.1119, -5.3995, -6.1409,  ..., -0.0219, -5.4616, -5.8017],\n",
            "        ...,\n",
            "        [-3.2567, -0.2783, -3.8940,  ..., -3.4474, -2.1973, -3.6813],\n",
            "        [-0.0298, -6.5935, -7.0927,  ..., -6.4245, -3.8604, -5.6192],\n",
            "        [-2.9801, -2.5664, -0.5283,  ..., -3.6614, -2.8197, -1.7879]],\n",
            "       grad_fn=<LogSoftmaxBackward0>)\n",
            "Training: 794\n",
            "Epoch: 0795 loss_train: 0.5960 acc_train: 0.8214 loss_val: 1.0554 acc_val: 0.6800 time: 4.1710s\n",
            "loss_val:1.0553534030914307, val_acc:0.68, out_features:tensor([[-3.8733, -4.0209, -0.1542,  ..., -3.1264, -4.0295, -3.8817],\n",
            "        [-4.0608, -4.7231, -5.3182,  ..., -4.0471, -0.1121, -2.9325],\n",
            "        [-2.9199, -2.6909, -2.2679,  ..., -0.5052, -3.1981, -2.3285],\n",
            "        ...,\n",
            "        [-1.9459, -1.9459, -1.9459,  ..., -1.9459, -1.9459, -1.9459],\n",
            "        [-0.2729, -5.9845, -6.4768,  ..., -5.9750, -1.6425, -6.4306],\n",
            "        [-1.9459, -1.9459, -1.9459,  ..., -1.9459, -1.9459, -1.9459]],\n",
            "       grad_fn=<LogSoftmaxBackward0>)\n",
            "Training: 795\n",
            "Epoch: 0796 loss_train: 0.5900 acc_train: 0.8429 loss_val: 1.1340 acc_val: 0.6233 time: 4.5815s\n",
            "loss_val:1.134029746055603, val_acc:0.6233333333333333, out_features:tensor([[-3.9280, -3.8585, -0.2509,  ..., -2.9352, -4.0698, -3.4251],\n",
            "        [-2.2982, -3.2002, -3.2458,  ..., -2.2960, -0.6210, -1.8773],\n",
            "        [-2.5534, -2.8661, -3.3809,  ..., -0.4817, -3.0737, -2.3294],\n",
            "        ...,\n",
            "        [-2.1285, -0.4611, -3.3574,  ..., -2.9397, -2.5705, -2.9340],\n",
            "        [-0.0550, -5.0049, -5.5997,  ..., -4.3607, -3.8717, -5.4768],\n",
            "        [-5.5773, -4.9326, -0.0303,  ..., -5.7682, -4.9852, -5.3743]],\n",
            "       grad_fn=<LogSoftmaxBackward0>)\n",
            "Training: 796\n",
            "Epoch: 0797 loss_train: 0.5469 acc_train: 0.8143 loss_val: 0.9893 acc_val: 0.6567 time: 4.1294s\n",
            "loss_val:0.9892720580101013, val_acc:0.6566666666666666, out_features:tensor([[-3.7237e+00, -3.8182e+00, -2.2332e-01,  ..., -2.9708e+00,\n",
            "         -3.9026e+00, -3.1377e+00],\n",
            "        [-2.5789e+00, -4.1920e+00, -4.7321e+00,  ..., -4.5326e+00,\n",
            "         -2.0448e-01, -2.7594e+00],\n",
            "        [-2.8434e+00, -2.3131e+00, -3.2418e+00,  ..., -5.3604e-01,\n",
            "         -2.3132e+00, -2.6480e+00],\n",
            "        ...,\n",
            "        [-7.2228e+00, -7.9409e-03, -7.1955e+00,  ..., -5.4543e+00,\n",
            "         -7.1624e+00, -7.1631e+00],\n",
            "        [-9.3605e-02, -4.9586e+00, -5.0472e+00,  ..., -3.4570e+00,\n",
            "         -3.6487e+00, -4.9104e+00],\n",
            "        [-7.8936e+00, -7.2588e+00, -3.7996e-03,  ..., -6.3165e+00,\n",
            "         -8.2212e+00, -7.8803e+00]], grad_fn=<LogSoftmaxBackward0>)\n",
            "Training: 797\n",
            "Epoch: 0798 loss_train: 0.5130 acc_train: 0.8571 loss_val: 1.0075 acc_val: 0.6833 time: 4.2919s\n",
            "loss_val:1.007543683052063, val_acc:0.6833333333333333, out_features:tensor([[-5.8693, -5.5357, -0.0237,  ..., -5.0243, -5.7337, -5.9432],\n",
            "        [-8.1213, -8.5153, -9.2820,  ..., -9.2895, -0.1620, -1.9088],\n",
            "        [-1.9140, -2.5124, -2.7693,  ..., -1.0828, -2.1015, -1.6640],\n",
            "        ...,\n",
            "        [-2.3690, -0.6723, -2.6226,  ..., -2.0834, -2.7965, -2.5285],\n",
            "        [-1.0193, -2.7950, -2.6500,  ..., -1.5563, -1.8642, -2.4762],\n",
            "        [-3.7529, -4.4398, -0.1421,  ..., -4.7236, -4.6626, -3.3510]],\n",
            "       grad_fn=<LogSoftmaxBackward0>)\n",
            "Training: 798\n",
            "Epoch: 0799 loss_train: 0.5999 acc_train: 0.8143 loss_val: 0.9811 acc_val: 0.6900 time: 4.3502s\n",
            "loss_val:0.9811146855354309, val_acc:0.69, out_features:tensor([[-1.0512e+01, -1.0281e+01, -3.1752e-04,  ..., -9.3811e+00,\n",
            "         -1.0450e+01, -1.0251e+01],\n",
            "        [-1.1660e+00, -4.4331e+00, -4.2643e+00,  ..., -1.4169e+00,\n",
            "         -1.1288e+00, -2.4877e+00],\n",
            "        [-7.7947e+00, -6.4418e+00, -7.5687e+00,  ..., -3.5744e-03,\n",
            "         -7.8827e+00, -7.9101e+00],\n",
            "        ...,\n",
            "        [-4.1209e+00, -2.4994e-01, -4.2438e+00,  ..., -4.2973e+00,\n",
            "         -1.8967e+00, -4.1458e+00],\n",
            "        [-4.4403e-02, -5.8697e+00, -5.6177e+00,  ..., -3.7067e+00,\n",
            "         -5.5133e+00, -5.3353e+00],\n",
            "        [-1.9459e+00, -1.9459e+00, -1.9459e+00,  ..., -1.9459e+00,\n",
            "         -1.9459e+00, -1.9459e+00]], grad_fn=<LogSoftmaxBackward0>)\n",
            "Training: 799\n",
            "Epoch: 0800 loss_train: 0.5803 acc_train: 0.8429 loss_val: 0.9724 acc_val: 0.7167 time: 4.1484s\n",
            "loss_val:0.9724045991897583, val_acc:0.7166666666666667, out_features:tensor([[-6.1842, -5.9198, -0.0218,  ..., -5.1911, -6.2003, -5.6732],\n",
            "        [-2.0192, -2.9635, -2.1175,  ..., -1.8477, -1.2319, -1.6279],\n",
            "        [-4.8583, -3.7965, -3.8703,  ..., -0.0817, -4.4432, -4.6401],\n",
            "        ...,\n",
            "        [-2.2363, -0.5884, -2.9831,  ..., -2.9409, -2.6591, -2.2983],\n",
            "        [-0.7891, -2.7177, -2.8575,  ..., -1.9678, -1.9911, -2.9313],\n",
            "        [-1.9459, -1.9459, -1.9459,  ..., -1.9459, -1.9459, -1.9459]],\n",
            "       grad_fn=<LogSoftmaxBackward0>)\n",
            "Training: 800\n",
            "Epoch: 0801 loss_train: 0.5310 acc_train: 0.8357 loss_val: 1.0708 acc_val: 0.6733 time: 4.2525s\n",
            "loss_val:1.0708271265029907, val_acc:0.6733333333333333, out_features:tensor([[-5.7428e+00, -5.8208e+00, -2.5289e-02,  ..., -5.5552e+00,\n",
            "         -5.6648e+00, -5.3044e+00],\n",
            "        [-1.9459e+00, -1.9459e+00, -1.9459e+00,  ..., -1.9459e+00,\n",
            "         -1.9459e+00, -1.9459e+00],\n",
            "        [-3.0965e+00, -2.5785e+00, -1.9493e+00,  ..., -5.1632e-01,\n",
            "         -2.6152e+00, -3.2983e+00],\n",
            "        ...,\n",
            "        [-4.0251e+00, -3.0432e-01, -4.1611e+00,  ..., -2.4403e+00,\n",
            "         -2.3009e+00, -3.4756e+00],\n",
            "        [-7.1008e-03, -7.6520e+00, -8.2227e+00,  ..., -6.7042e+00,\n",
            "         -5.7671e+00, -8.1933e+00],\n",
            "        [-3.3479e+00, -3.5441e+00, -4.2380e-01,  ..., -3.5863e+00,\n",
            "         -2.4851e+00, -2.7817e+00]], grad_fn=<LogSoftmaxBackward0>)\n",
            "Training: 801\n",
            "Epoch: 0802 loss_train: 0.6275 acc_train: 0.8143 loss_val: 1.0185 acc_val: 0.6500 time: 4.3646s\n",
            "loss_val:1.0185282230377197, val_acc:0.65, out_features:tensor([[-3.4915e+00, -3.2817e+00, -3.1240e-01,  ..., -3.3829e+00,\n",
            "         -3.2965e+00, -3.4821e+00],\n",
            "        [-1.4340e+01, -1.8068e+01, -1.8062e+01,  ..., -1.0347e+01,\n",
            "         -3.3259e-05, -1.4481e+01],\n",
            "        [-1.9459e+00, -1.9459e+00, -1.9459e+00,  ..., -1.9459e+00,\n",
            "         -1.9459e+00, -1.9459e+00],\n",
            "        ...,\n",
            "        [-1.9459e+00, -1.9459e+00, -1.9459e+00,  ..., -1.9459e+00,\n",
            "         -1.9459e+00, -1.9459e+00],\n",
            "        [-3.6273e-01, -3.7707e+00, -4.0126e+00,  ..., -2.4382e+00,\n",
            "         -2.6280e+00, -2.5132e+00],\n",
            "        [-5.7150e+00, -7.3150e+00, -8.4746e-03,  ..., -7.1027e+00,\n",
            "         -6.8579e+00, -6.6370e+00]], grad_fn=<LogSoftmaxBackward0>)\n",
            "Training: 802\n",
            "Epoch: 0803 loss_train: 0.5319 acc_train: 0.8786 loss_val: 1.0113 acc_val: 0.6933 time: 4.2989s\n",
            "loss_val:1.011307716369629, val_acc:0.6933333333333334, out_features:tensor([[-6.4188e+00, -6.3292e+00, -9.2273e-02,  ..., -6.3141e+00,\n",
            "         -6.2862e+00, -4.7429e+00],\n",
            "        [-1.8939e+00, -3.3843e+00, -2.6236e+00,  ..., -2.8718e+00,\n",
            "         -1.0065e+00, -1.2548e+00],\n",
            "        [-7.7699e+00, -8.0213e+00, -7.5339e+00,  ..., -2.4674e-03,\n",
            "         -7.8870e+00, -7.9579e+00],\n",
            "        ...,\n",
            "        [-4.6062e+00, -1.6129e-01, -2.3529e+00,  ..., -4.4581e+00,\n",
            "         -4.3908e+00, -4.5070e+00],\n",
            "        [-1.3891e-01, -4.0359e+00, -4.6585e+00,  ..., -3.0765e+00,\n",
            "         -3.5601e+00, -4.0149e+00],\n",
            "        [-1.9459e+00, -1.9459e+00, -1.9459e+00,  ..., -1.9459e+00,\n",
            "         -1.9459e+00, -1.9459e+00]], grad_fn=<LogSoftmaxBackward0>)\n",
            "Training: 803\n",
            "Epoch: 0804 loss_train: 0.7104 acc_train: 0.8000 loss_val: 1.0235 acc_val: 0.6467 time: 4.6012s\n",
            "loss_val:1.0235071182250977, val_acc:0.6466666666666666, out_features:tensor([[-2.7632, -2.1732, -0.7015,  ..., -2.7870, -2.7765, -2.2550],\n",
            "        [-1.9459, -1.9459, -1.9459,  ..., -1.9459, -1.9459, -1.9459],\n",
            "        [-1.8768, -2.4643, -2.3277,  ..., -1.1052, -2.2087, -2.1290],\n",
            "        ...,\n",
            "        [-1.9459, -1.9459, -1.9459,  ..., -1.9459, -1.9459, -1.9459],\n",
            "        [-0.8093, -2.9288, -2.6283,  ..., -1.8262, -2.0620, -2.7138],\n",
            "        [-6.4324, -6.0100, -0.0153,  ..., -5.8923, -5.8102, -5.6724]],\n",
            "       grad_fn=<LogSoftmaxBackward0>)\n",
            "Training: 804\n",
            "Epoch: 0805 loss_train: 0.5933 acc_train: 0.8143 loss_val: 0.9863 acc_val: 0.6900 time: 4.0902s\n",
            "loss_val:0.986345112323761, val_acc:0.69, out_features:tensor([[-1.0350e+01, -1.0330e+01, -8.5734e-04,  ..., -8.8411e+00,\n",
            "         -1.0320e+01, -1.0175e+01],\n",
            "        [-1.9881e+00, -3.0111e+00, -2.8729e+00,  ..., -1.8689e+00,\n",
            "         -1.1790e+00, -1.3759e+00],\n",
            "        [-2.9492e+00, -1.8178e+00, -2.4566e+00,  ..., -6.7391e-01,\n",
            "         -2.6149e+00, -2.5441e+00],\n",
            "        ...,\n",
            "        [-2.0241e+00, -1.7435e+00, -1.5392e+00,  ..., -2.1067e+00,\n",
            "         -2.0746e+00, -2.0788e+00],\n",
            "        [-1.2198e-02, -5.6659e+00, -7.4098e+00,  ..., -7.3781e+00,\n",
            "         -5.1461e+00, -7.1321e+00],\n",
            "        [-2.3821e+00, -2.9048e+00, -6.7640e-01,  ..., -1.7096e+00,\n",
            "         -2.8662e+00, -3.0417e+00]], grad_fn=<LogSoftmaxBackward0>)\n",
            "Training: 805\n",
            "Epoch: 0806 loss_train: 0.7450 acc_train: 0.7357 loss_val: 1.0798 acc_val: 0.6467 time: 4.0324s\n",
            "loss_val:1.079840898513794, val_acc:0.6466666666666666, out_features:tensor([[-9.6324e+00, -9.3133e+00, -7.2453e-04,  ..., -9.3193e+00,\n",
            "         -9.4594e+00, -9.4882e+00],\n",
            "        [-1.9459e+00, -1.9459e+00, -1.9459e+00,  ..., -1.9459e+00,\n",
            "         -1.9459e+00, -1.9459e+00],\n",
            "        [-2.2056e+00, -2.3806e+00, -2.1618e+00,  ..., -9.9612e-01,\n",
            "         -2.1404e+00, -2.0412e+00],\n",
            "        ...,\n",
            "        [-2.3997e+00, -8.4301e-01, -2.1310e+00,  ..., -2.6702e+00,\n",
            "         -2.3100e+00, -2.2604e+00],\n",
            "        [-5.4687e-01, -3.1999e+00, -3.5485e+00,  ..., -1.6087e+00,\n",
            "         -2.6043e+00, -3.1123e+00],\n",
            "        [-1.9791e+00, -2.3244e+00, -1.3180e+00,  ..., -2.2671e+00,\n",
            "         -1.7700e+00, -1.8858e+00]], grad_fn=<LogSoftmaxBackward0>)\n",
            "Training: 806\n",
            "Epoch: 0807 loss_train: 0.4962 acc_train: 0.8857 loss_val: 0.9700 acc_val: 0.6633 time: 4.4138s\n",
            "loss_val:0.9699771404266357, val_acc:0.6633333333333333, out_features:tensor([[-6.1695e+00, -5.9493e+00, -2.1651e-02,  ..., -5.4818e+00,\n",
            "         -6.1195e+00, -6.1335e+00],\n",
            "        [-1.3326e+01, -1.6710e+01, -1.6725e+01,  ..., -1.0363e+01,\n",
            "         -3.3974e-05, -1.4404e+01],\n",
            "        [-7.8175e+00, -6.1510e+00, -5.0481e+00,  ..., -9.7592e-03,\n",
            "         -8.2151e+00, -8.3157e+00],\n",
            "        ...,\n",
            "        [-2.2924e+00, -1.9346e-01, -4.4955e+00,  ..., -4.4499e+00,\n",
            "         -3.7249e+00, -3.9786e+00],\n",
            "        [-6.6781e-01, -1.9672e+00, -2.8967e+00,  ..., -2.3826e+00,\n",
            "         -2.6885e+00, -2.6532e+00],\n",
            "        [-4.3212e+00, -3.9296e+00, -1.1654e-01,  ..., -3.6569e+00,\n",
            "         -4.4808e+00, -3.5162e+00]], grad_fn=<LogSoftmaxBackward0>)\n",
            "Training: 807\n",
            "Epoch: 0808 loss_train: 0.5775 acc_train: 0.8286 loss_val: 1.2209 acc_val: 0.6167 time: 4.0697s\n",
            "loss_val:1.2208571434020996, val_acc:0.6166666666666667, out_features:tensor([[-5.1869, -4.2512, -0.0719,  ..., -3.9463, -5.0483, -4.6325],\n",
            "        [-6.3090, -6.3073, -5.9148,  ..., -5.6634, -0.0415, -3.5250],\n",
            "        [-5.4244, -5.2458, -7.1735,  ..., -0.0139, -6.4608, -6.9839],\n",
            "        ...,\n",
            "        [-3.2289, -0.2377, -2.4753,  ..., -3.8744, -3.6012, -3.7087],\n",
            "        [-0.0112, -7.2709, -7.4844,  ..., -6.0865, -5.1362, -7.2608],\n",
            "        [-3.3384, -3.2646, -0.1993,  ..., -3.4217, -3.6830, -3.8275]],\n",
            "       grad_fn=<LogSoftmaxBackward0>)\n",
            "Training: 808\n",
            "Epoch: 0809 loss_train: 0.6071 acc_train: 0.8357 loss_val: 1.0663 acc_val: 0.6500 time: 4.1033s\n",
            "loss_val:1.0663448572158813, val_acc:0.65, out_features:tensor([[-7.1798e+00, -7.1414e+00, -6.8110e-03,  ..., -6.5709e+00,\n",
            "         -7.0675e+00, -6.4692e+00],\n",
            "        [-5.4980e+00, -7.9477e+00, -6.2487e+00,  ..., -5.5095e+00,\n",
            "         -1.1957e-02, -6.8087e+00],\n",
            "        [-1.9459e+00, -1.9459e+00, -1.9459e+00,  ..., -1.9459e+00,\n",
            "         -1.9459e+00, -1.9459e+00],\n",
            "        ...,\n",
            "        [-2.3065e+00, -7.6746e-01, -2.5454e+00,  ..., -2.4591e+00,\n",
            "         -1.9578e+00, -2.4625e+00],\n",
            "        [-3.5408e-01, -3.5211e+00, -3.8363e+00,  ..., -2.9077e+00,\n",
            "         -2.1267e+00, -2.9374e+00],\n",
            "        [-1.5833e+01, -1.3513e+01, -2.0266e-06,  ..., -1.5426e+01,\n",
            "         -1.5842e+01, -1.5885e+01]], grad_fn=<LogSoftmaxBackward0>)\n",
            "Training: 809\n",
            "Epoch: 0810 loss_train: 0.6518 acc_train: 0.7714 loss_val: 1.0386 acc_val: 0.6733 time: 4.4531s\n",
            "loss_val:1.0385618209838867, val_acc:0.6733333333333333, out_features:tensor([[-1.7984e+01, -1.7874e+01, -4.7684e-07,  ..., -1.5533e+01,\n",
            "         -1.7980e+01, -1.7947e+01],\n",
            "        [-1.9459e+00, -1.9459e+00, -1.9459e+00,  ..., -1.9459e+00,\n",
            "         -1.9459e+00, -1.9459e+00],\n",
            "        [-5.7511e+00, -5.7328e+00, -6.0078e+00,  ..., -1.7116e-02,\n",
            "         -5.9860e+00, -5.6032e+00],\n",
            "        ...,\n",
            "        [-2.2113e+00, -9.0117e-01, -2.0598e+00,  ..., -2.4045e+00,\n",
            "         -2.3280e+00, -2.3501e+00],\n",
            "        [-1.9459e+00, -1.9459e+00, -1.9459e+00,  ..., -1.9459e+00,\n",
            "         -1.9459e+00, -1.9459e+00],\n",
            "        [-5.5497e+00, -4.9292e+00, -2.6979e-02,  ..., -5.8805e+00,\n",
            "         -5.1419e+00, -5.7589e+00]], grad_fn=<LogSoftmaxBackward0>)\n",
            "Training: 810\n",
            "Epoch: 0811 loss_train: 0.6767 acc_train: 0.8071 loss_val: 1.0398 acc_val: 0.6733 time: 4.1682s\n",
            "loss_val:1.039752721786499, val_acc:0.6733333333333333, out_features:tensor([[-1.9459e+00, -1.9459e+00, -1.9459e+00,  ..., -1.9459e+00,\n",
            "         -1.9459e+00, -1.9459e+00],\n",
            "        [-1.9459e+00, -1.9459e+00, -1.9459e+00,  ..., -1.9459e+00,\n",
            "         -1.9459e+00, -1.9459e+00],\n",
            "        [-5.4867e+00, -5.1478e+00, -5.5604e+00,  ..., -3.4386e-02,\n",
            "         -4.5999e+00, -5.0461e+00],\n",
            "        ...,\n",
            "        [-2.3955e+00, -3.6445e-01, -2.8145e+00,  ..., -2.9800e+00,\n",
            "         -3.2786e+00, -3.2249e+00],\n",
            "        [-1.4129e-02, -6.9076e+00, -6.9834e+00,  ..., -4.9836e+00,\n",
            "         -6.0918e+00, -6.4728e+00],\n",
            "        [-1.0677e+01, -1.0303e+01, -2.9238e-04,  ..., -1.0458e+01,\n",
            "         -1.0564e+01, -1.0599e+01]], grad_fn=<LogSoftmaxBackward0>)\n",
            "Training: 811\n",
            "Epoch: 0812 loss_train: 0.6539 acc_train: 0.8071 loss_val: 1.0543 acc_val: 0.6633 time: 4.1518s\n",
            "loss_val:1.054331660270691, val_acc:0.6633333333333333, out_features:tensor([[-2.0975, -2.3251, -1.0455,  ..., -2.4773, -2.4998, -2.2710],\n",
            "        [-3.8675, -4.0337, -4.2132,  ..., -3.6734, -0.1791, -2.6278],\n",
            "        [-5.1411, -5.2777, -4.8296,  ..., -0.0461, -4.8543, -4.2809],\n",
            "        ...,\n",
            "        [-4.4954, -0.0592, -4.1633,  ..., -4.5047, -4.5522, -5.4042],\n",
            "        [-1.9459, -1.9459, -1.9459,  ..., -1.9459, -1.9459, -1.9459],\n",
            "        [-1.9904, -2.6166, -1.1162,  ..., -2.3786, -2.0113, -1.8946]],\n",
            "       grad_fn=<LogSoftmaxBackward0>)\n",
            "Training: 812\n",
            "Epoch: 0813 loss_train: 0.6057 acc_train: 0.8143 loss_val: 0.9240 acc_val: 0.6967 time: 4.4118s\n",
            "loss_val:0.9240034222602844, val_acc:0.6966666666666667, out_features:tensor([[-1.1697e+01, -1.1658e+01, -3.8259e-04,  ..., -1.1384e+01,\n",
            "         -1.1668e+01, -1.0523e+01],\n",
            "        [-1.9459e+00, -1.9459e+00, -1.9459e+00,  ..., -1.9459e+00,\n",
            "         -1.9459e+00, -1.9459e+00],\n",
            "        [-3.7913e+00, -3.5225e+00, -3.2715e+00,  ..., -2.1468e-01,\n",
            "         -3.7744e+00, -3.2067e+00],\n",
            "        ...,\n",
            "        [-7.6481e+00, -6.7744e-03, -7.8084e+00,  ..., -6.8055e+00,\n",
            "         -5.5407e+00, -7.6834e+00],\n",
            "        [-1.5020e-02, -6.7145e+00, -7.1586e+00,  ..., -4.8470e+00,\n",
            "         -5.7798e+00, -6.7901e+00],\n",
            "        [-3.3796e+00, -3.1336e+00, -3.8627e-01,  ..., -3.2338e+00,\n",
            "         -3.3854e+00, -2.9033e+00]], grad_fn=<LogSoftmaxBackward0>)\n",
            "Training: 813\n",
            "Epoch: 0814 loss_train: 0.5772 acc_train: 0.8429 loss_val: 0.9310 acc_val: 0.6800 time: 4.1541s\n",
            "loss_val:0.9309991598129272, val_acc:0.68, out_features:tensor([[-1.0092e+01, -9.8850e+00, -3.9701e-04,  ..., -9.9035e+00,\n",
            "         -1.0031e+01, -9.7887e+00],\n",
            "        [-2.3679e+00, -3.2731e+00, -1.6121e+00,  ..., -2.9551e+00,\n",
            "         -9.5579e-01, -1.6119e+00],\n",
            "        [-2.7546e+00, -2.7207e+00, -2.4527e+00,  ..., -6.7770e-01,\n",
            "         -2.6658e+00, -1.9428e+00],\n",
            "        ...,\n",
            "        [-3.6195e+00, -2.4562e-01, -3.9875e+00,  ..., -3.2731e+00,\n",
            "         -3.5875e+00, -2.4687e+00],\n",
            "        [-1.9459e+00, -1.9459e+00, -1.9459e+00,  ..., -1.9459e+00,\n",
            "         -1.9459e+00, -1.9459e+00],\n",
            "        [-2.8634e+00, -3.3617e+00, -3.0949e-01,  ..., -3.6914e+00,\n",
            "         -3.1961e+00, -2.4830e+00]], grad_fn=<LogSoftmaxBackward0>)\n",
            "Training: 814\n",
            "Epoch: 0815 loss_train: 0.5646 acc_train: 0.8571 loss_val: 0.9789 acc_val: 0.7067 time: 4.1912s\n",
            "loss_val:0.9789161086082458, val_acc:0.7066666666666667, out_features:tensor([[-5.8297, -5.8183, -0.0388,  ..., -5.5632, -5.9798, -5.1225],\n",
            "        [-2.6696, -5.5030, -5.2312,  ..., -4.0723, -0.1900, -2.6135],\n",
            "        [-5.9711, -5.9143, -5.6660,  ..., -0.0314, -5.2353, -4.2155],\n",
            "        ...,\n",
            "        [-5.6599, -0.0262, -6.0144,  ..., -5.1707, -5.5356, -4.8934],\n",
            "        [-0.5418, -2.7696, -3.1987,  ..., -1.8724, -2.7484, -2.8063],\n",
            "        [-4.1700, -4.5934, -0.0941,  ..., -4.3452, -3.9274, -4.1462]],\n",
            "       grad_fn=<LogSoftmaxBackward0>)\n",
            "Training: 815\n",
            "Epoch: 0816 loss_train: 0.5563 acc_train: 0.8429 loss_val: 1.1358 acc_val: 0.6333 time: 4.4201s\n",
            "loss_val:1.1357935667037964, val_acc:0.6333333333333333, out_features:tensor([[-1.7718e+01, -1.7668e+01, -3.5763e-07,  ..., -1.5988e+01,\n",
            "         -1.7714e+01, -1.7140e+01],\n",
            "        [-6.3171e+00, -1.1228e+01, -1.1300e+01,  ..., -1.0264e+01,\n",
            "         -1.9146e-03, -1.0357e+01],\n",
            "        [-6.3126e+00, -5.8805e+00, -6.6478e+00,  ..., -1.1373e-02,\n",
            "         -6.4270e+00, -5.9111e+00],\n",
            "        ...,\n",
            "        [-2.4826e+00, -1.0174e+00, -2.3473e+00,  ..., -2.3302e+00,\n",
            "         -1.4472e+00, -2.7851e+00],\n",
            "        [-1.4464e-02, -5.4663e+00, -6.9700e+00,  ..., -6.4598e+00,\n",
            "         -5.2052e+00, -6.7296e+00],\n",
            "        [-7.2879e+00, -7.3223e+00, -8.7622e-03,  ..., -5.5675e+00,\n",
            "         -6.3970e+00, -7.3217e+00]], grad_fn=<LogSoftmaxBackward0>)\n",
            "Training: 816\n",
            "Epoch: 0817 loss_train: 0.7070 acc_train: 0.7714 loss_val: 1.0033 acc_val: 0.6667 time: 4.1476s\n",
            "loss_val:1.0033189058303833, val_acc:0.6666666666666666, out_features:tensor([[-1.2878e+01, -1.2781e+01, -2.4328e-04,  ..., -1.2462e+01,\n",
            "         -1.2885e+01, -1.1696e+01],\n",
            "        [-2.2950e+00, -2.2640e+00, -2.9816e+00,  ..., -1.6097e+00,\n",
            "         -1.3763e+00, -1.4511e+00],\n",
            "        [-1.9459e+00, -1.9459e+00, -1.9459e+00,  ..., -1.9459e+00,\n",
            "         -1.9459e+00, -1.9459e+00],\n",
            "        ...,\n",
            "        [-5.0103e+00, -6.4883e-02, -4.6397e+00,  ..., -3.8073e+00,\n",
            "         -4.5210e+00, -4.7864e+00],\n",
            "        [-8.4888e-02, -4.6951e+00, -5.1381e+00,  ..., -4.7328e+00,\n",
            "         -3.6759e+00, -4.1354e+00],\n",
            "        [-3.4409e+00, -3.7462e+00, -4.4364e-01,  ..., -4.0108e+00,\n",
            "         -2.6862e+00, -1.6905e+00]], grad_fn=<LogSoftmaxBackward0>)\n",
            "Training: 817\n",
            "Epoch: 0818 loss_train: 0.5703 acc_train: 0.8429 loss_val: 1.1385 acc_val: 0.6667 time: 4.2182s\n",
            "loss_val:1.138511300086975, val_acc:0.6666666666666666, out_features:tensor([[-6.4542e+00, -5.9698e+00, -2.6135e-02,  ..., -5.8646e+00,\n",
            "         -6.3335e+00, -6.2414e+00],\n",
            "        [-2.8490e+00, -3.6422e+00, -2.6932e+00,  ..., -3.1466e+00,\n",
            "         -1.1288e+00, -7.8319e-01],\n",
            "        [-3.0947e+00, -2.4355e+00, -2.1740e+00,  ..., -5.9619e-01,\n",
            "         -2.9118e+00, -2.6856e+00],\n",
            "        ...,\n",
            "        [-7.5384e+00, -6.2609e-03, -7.0711e+00,  ..., -5.8393e+00,\n",
            "         -7.4163e+00, -7.1258e+00],\n",
            "        [-3.8893e-02, -4.9560e+00, -6.0252e+00,  ..., -4.0336e+00,\n",
            "         -5.3423e+00, -5.6552e+00],\n",
            "        [-2.3654e+00, -1.9809e+00, -1.2473e+00,  ..., -2.2880e+00,\n",
            "         -2.1254e+00, -2.3150e+00]], grad_fn=<LogSoftmaxBackward0>)\n",
            "Training: 818\n",
            "Epoch: 0819 loss_train: 0.5287 acc_train: 0.8643 loss_val: 0.9087 acc_val: 0.6933 time: 4.3803s\n",
            "loss_val:0.908706784248352, val_acc:0.6933333333333334, out_features:tensor([[-1.5104e+01, -1.4900e+01, -2.6226e-06,  ..., -1.3799e+01,\n",
            "         -1.5012e+01, -1.4825e+01],\n",
            "        [-1.1289e+01, -1.2519e+01, -1.3137e+01,  ..., -1.3141e+01,\n",
            "         -3.6239e-05, -1.2990e+01],\n",
            "        [-8.3826e+00, -7.7866e+00, -9.3128e+00,  ..., -1.1074e-03,\n",
            "         -8.8134e+00, -8.9543e+00],\n",
            "        ...,\n",
            "        [-2.8045e+00, -3.9288e-01, -2.7771e+00,  ..., -3.0120e+00,\n",
            "         -2.6654e+00, -3.1280e+00],\n",
            "        [-8.9345e-02, -4.6016e+00, -5.0660e+00,  ..., -3.8665e+00,\n",
            "         -3.4827e+00, -4.9680e+00],\n",
            "        [-2.3431e+00, -2.6141e+00, -1.1298e+00,  ..., -2.2162e+00,\n",
            "         -2.0180e+00, -1.7024e+00]], grad_fn=<LogSoftmaxBackward0>)\n",
            "Training: 819\n",
            "Epoch: 0820 loss_train: 0.5404 acc_train: 0.8214 loss_val: 0.9267 acc_val: 0.7133 time: 4.1521s\n",
            "loss_val:0.9266521334648132, val_acc:0.7133333333333334, out_features:tensor([[-1.1529e+01, -1.0927e+01, -3.4696e-04,  ..., -1.1505e+01,\n",
            "         -1.1483e+01, -1.0847e+01],\n",
            "        [-1.9805e+00, -2.7827e+00, -3.1121e+00,  ..., -1.5756e+00,\n",
            "         -8.5723e-01, -2.4623e+00],\n",
            "        [-4.5801e+00, -4.8843e+00, -6.0853e+00,  ..., -2.8686e-02,\n",
            "         -5.8756e+00, -5.9722e+00],\n",
            "        ...,\n",
            "        [-3.6157e+00, -3.0728e-01, -2.3423e+00,  ..., -3.1792e+00,\n",
            "         -3.4639e+00, -3.2453e+00],\n",
            "        [-6.9410e-01, -2.3668e+00, -3.1283e+00,  ..., -2.2337e+00,\n",
            "         -1.9131e+00, -3.1336e+00],\n",
            "        [-4.4856e+00, -3.4092e+00, -1.5023e-01,  ..., -2.9336e+00,\n",
            "         -4.4218e+00, -4.2001e+00]], grad_fn=<LogSoftmaxBackward0>)\n",
            "Training: 820\n",
            "Epoch: 0821 loss_train: 0.5676 acc_train: 0.8571 loss_val: 1.0214 acc_val: 0.6633 time: 4.1899s\n",
            "loss_val:1.0214409828186035, val_acc:0.6633333333333333, out_features:tensor([[-2.2272, -2.6201, -0.9214,  ..., -2.1359, -2.7487, -2.6730],\n",
            "        [-2.4736, -3.6584, -3.4839,  ..., -1.5489, -0.7807, -1.8024],\n",
            "        [-5.6834, -6.2393, -6.0028,  ..., -0.0169, -5.6312, -5.5555],\n",
            "        ...,\n",
            "        [-2.8302, -0.4281, -2.9936,  ..., -2.4187, -2.5477, -3.2134],\n",
            "        [-0.6239, -3.1030, -3.4709,  ..., -2.3024, -1.8939, -2.3801],\n",
            "        [-6.0348, -5.6504, -0.0240,  ..., -5.6900, -5.7286, -5.4322]],\n",
            "       grad_fn=<LogSoftmaxBackward0>)\n",
            "Training: 821\n",
            "Epoch: 0822 loss_train: 0.5814 acc_train: 0.8357 loss_val: 1.0207 acc_val: 0.6667 time: 4.3014s\n",
            "loss_val:1.0206962823867798, val_acc:0.6666666666666666, out_features:tensor([[-1.0816e+01, -1.0817e+01, -5.7990e-04,  ..., -7.7540e+00,\n",
            "         -1.0784e+01, -1.0125e+01],\n",
            "        [-1.9459e+00, -1.9459e+00, -1.9459e+00,  ..., -1.9459e+00,\n",
            "         -1.9459e+00, -1.9459e+00],\n",
            "        [-5.3492e+00, -4.0191e+00, -5.5257e+00,  ..., -5.0608e-02,\n",
            "         -4.2374e+00, -5.4965e+00],\n",
            "        ...,\n",
            "        [-3.6838e+00, -5.1898e-02, -5.6215e+00,  ..., -4.6546e+00,\n",
            "         -5.2699e+00, -5.6714e+00],\n",
            "        [-1.1896e+00, -2.9849e+00, -3.1500e+00,  ..., -9.8575e-01,\n",
            "         -2.7801e+00, -2.7354e+00],\n",
            "        [-3.7079e+00, -3.6480e+00, -2.4965e-01,  ..., -3.7505e+00,\n",
            "         -3.8208e+00, -2.2887e+00]], grad_fn=<LogSoftmaxBackward0>)\n",
            "Training: 822\n",
            "Epoch: 0823 loss_train: 0.6828 acc_train: 0.7786 loss_val: 0.9783 acc_val: 0.7033 time: 4.1138s\n",
            "loss_val:0.9782683253288269, val_acc:0.7033333333333334, out_features:tensor([[-9.2988e+00, -9.2166e+00, -1.8819e-03,  ..., -8.6505e+00,\n",
            "         -9.3435e+00, -7.7545e+00],\n",
            "        [-1.5942e+00, -2.8292e+00, -2.6137e+00,  ..., -2.1818e+00,\n",
            "         -1.6055e+00, -1.2017e+00],\n",
            "        [-2.7514e+00, -3.7057e+00, -3.1788e+00,  ..., -2.5045e-01,\n",
            "         -3.1125e+00, -3.7288e+00],\n",
            "        ...,\n",
            "        [-1.9459e+00, -1.9459e+00, -1.9459e+00,  ..., -1.9459e+00,\n",
            "         -1.9459e+00, -1.9459e+00],\n",
            "        [-2.8096e-01, -3.3798e+00, -4.2890e+00,  ..., -2.5568e+00,\n",
            "         -2.5572e+00, -3.7183e+00],\n",
            "        [-5.8796e+00, -5.5213e+00, -3.0094e-02,  ..., -5.2777e+00,\n",
            "         -5.7426e+00, -4.6014e+00]], grad_fn=<LogSoftmaxBackward0>)\n",
            "Training: 823\n",
            "Epoch: 0824 loss_train: 0.6544 acc_train: 0.7929 loss_val: 0.9741 acc_val: 0.6967 time: 4.4782s\n",
            "loss_val:0.974131166934967, val_acc:0.6966666666666667, out_features:tensor([[-5.0057e+00, -5.0874e+00, -1.0343e-01,  ..., -4.4898e+00,\n",
            "         -5.2221e+00, -3.8310e+00],\n",
            "        [-1.3417e+01, -1.3321e+01, -1.3541e+01,  ..., -1.3462e+01,\n",
            "         -2.3484e-05, -1.3507e+01],\n",
            "        [-5.0241e+00, -5.1896e+00, -5.6479e+00,  ..., -3.2238e-02,\n",
            "         -5.5424e+00, -4.8514e+00],\n",
            "        ...,\n",
            "        [-2.0723e+00, -5.3937e-01, -3.0563e+00,  ..., -2.4668e+00,\n",
            "         -2.6777e+00, -2.9381e+00],\n",
            "        [-1.1726e-02, -7.2690e+00, -7.5390e+00,  ..., -5.5054e+00,\n",
            "         -5.2727e+00, -7.2206e+00],\n",
            "        [-9.6335e+00, -9.3115e+00, -6.7497e-04,  ..., -9.1517e+00,\n",
            "         -9.6025e+00, -9.6858e+00]], grad_fn=<LogSoftmaxBackward0>)\n",
            "Training: 824\n",
            "Epoch: 0825 loss_train: 0.5343 acc_train: 0.8500 loss_val: 1.0701 acc_val: 0.6767 time: 4.1749s\n",
            "loss_val:1.070069432258606, val_acc:0.6766666666666666, out_features:tensor([[-3.6957e+00, -3.5099e+00, -2.3940e-01,  ..., -3.8058e+00,\n",
            "         -4.1345e+00, -3.4448e+00],\n",
            "        [-5.5808e+00, -8.0671e+00, -1.0793e+01,  ..., -1.0441e+01,\n",
            "         -4.1930e-03, -1.0387e+01],\n",
            "        [-4.6764e+00, -3.9255e+00, -3.6738e+00,  ..., -1.0165e-01,\n",
            "         -3.9313e+00, -4.3611e+00],\n",
            "        ...,\n",
            "        [-2.5235e+00, -7.9029e-01, -2.0872e+00,  ..., -1.8528e+00,\n",
            "         -2.8066e+00, -2.4333e+00],\n",
            "        [-7.7643e-02, -4.9727e+00, -5.4467e+00,  ..., -3.3341e+00,\n",
            "         -4.0281e+00, -5.3206e+00],\n",
            "        [-2.6254e+00, -2.7511e+00, -2.4084e-01,  ..., -4.1125e+00,\n",
            "         -3.7539e+00, -3.8117e+00]], grad_fn=<LogSoftmaxBackward0>)\n",
            "Training: 825\n",
            "Epoch: 0826 loss_train: 0.5666 acc_train: 0.8429 loss_val: 1.0652 acc_val: 0.6567 time: 4.1606s\n",
            "loss_val:1.0652343034744263, val_acc:0.6566666666666666, out_features:tensor([[-6.0567e+00, -6.1068e+00, -1.8209e-02,  ..., -5.7702e+00,\n",
            "         -5.8712e+00, -6.0808e+00],\n",
            "        [-4.8241e+00, -4.6481e+00, -4.7470e+00,  ..., -2.9651e+00,\n",
            "         -2.6502e-01, -1.9018e+00],\n",
            "        [-5.4719e+00, -5.3711e+00, -4.4157e+00,  ..., -3.9685e-02,\n",
            "         -5.2524e+00, -4.9563e+00],\n",
            "        ...,\n",
            "        [-2.6868e+00, -5.9366e-01, -2.8588e+00,  ..., -2.5782e+00,\n",
            "         -2.4990e+00, -2.2124e+00],\n",
            "        [-1.2835e-01, -4.6113e+00, -4.6911e+00,  ..., -3.3465e+00,\n",
            "         -4.4221e+00, -4.1174e+00],\n",
            "        [-1.0470e+01, -9.3141e+00, -2.5603e-04,  ..., -1.0066e+01,\n",
            "         -1.0367e+01, -1.0319e+01]], grad_fn=<LogSoftmaxBackward0>)\n",
            "Training: 826\n",
            "Epoch: 0827 loss_train: 0.5950 acc_train: 0.8071 loss_val: 1.0216 acc_val: 0.6500 time: 4.3662s\n",
            "loss_val:1.0216196775436401, val_acc:0.65, out_features:tensor([[-7.1691, -7.0112, -0.0121,  ..., -5.5659, -6.9374, -6.7364],\n",
            "        [-2.6909, -2.8068, -2.1712,  ..., -2.8902, -0.9957, -1.3366],\n",
            "        [-5.4126, -5.8947, -5.3053,  ..., -0.0242, -5.5485, -5.2027],\n",
            "        ...,\n",
            "        [-2.7954, -0.5608, -2.5001,  ..., -2.3089, -2.4588, -2.8730],\n",
            "        [-0.0878, -4.1614, -4.7225,  ..., -4.5623, -3.8739, -4.4463],\n",
            "        [-7.2074, -4.9047, -0.0236,  ..., -4.4475, -6.8317, -7.1728]],\n",
            "       grad_fn=<LogSoftmaxBackward0>)\n",
            "Training: 827\n",
            "Epoch: 0828 loss_train: 0.5776 acc_train: 0.8286 loss_val: 0.9654 acc_val: 0.6600 time: 4.2182s\n",
            "loss_val:0.9653663039207458, val_acc:0.66, out_features:tensor([[-5.6232, -5.4912, -0.0342,  ..., -4.3165, -5.6646, -5.4551],\n",
            "        [-1.9459, -1.9459, -1.9459,  ..., -1.9459, -1.9459, -1.9459],\n",
            "        [-2.6944, -2.2246, -2.2412,  ..., -0.6943, -2.4301, -2.5718],\n",
            "        ...,\n",
            "        [-3.3775, -0.4125, -2.3878,  ..., -2.7492, -2.9537, -2.8590],\n",
            "        [-0.1780, -3.4843, -5.0295,  ..., -2.4905, -3.5816, -4.6973],\n",
            "        [-5.2350, -3.7077, -0.1188,  ..., -2.7501, -5.0473, -5.1811]],\n",
            "       grad_fn=<LogSoftmaxBackward0>)\n",
            "Training: 828\n",
            "Epoch: 0829 loss_train: 0.5903 acc_train: 0.8286 loss_val: 1.0404 acc_val: 0.6867 time: 4.1397s\n",
            "loss_val:1.0403785705566406, val_acc:0.6866666666666666, out_features:tensor([[-4.2937, -3.9401, -0.2298,  ..., -3.9193, -4.1608, -2.7213],\n",
            "        [-1.9819, -3.4777, -2.8455,  ..., -2.1343, -0.5223, -3.3553],\n",
            "        [-5.0531, -3.9598, -3.1879,  ..., -0.0864, -5.1435, -5.1840],\n",
            "        ...,\n",
            "        [-3.8800, -0.1474, -3.6546,  ..., -3.8969, -3.6936, -4.0229],\n",
            "        [-0.9928, -2.6762, -2.2244,  ..., -2.3147, -1.7798, -2.4498],\n",
            "        [-1.9459, -1.9459, -1.9459,  ..., -1.9459, -1.9459, -1.9459]],\n",
            "       grad_fn=<LogSoftmaxBackward0>)\n",
            "Training: 829\n",
            "Epoch: 0830 loss_train: 0.6463 acc_train: 0.7786 loss_val: 1.0639 acc_val: 0.6567 time: 4.3606s\n",
            "loss_val:1.0639492273330688, val_acc:0.6566666666666666, out_features:tensor([[-9.5117e+00, -9.3939e+00, -7.2775e-04,  ..., -8.3409e+00,\n",
            "         -9.3809e+00, -8.7540e+00],\n",
            "        [-8.4493e+00, -7.9795e+00, -6.4191e+00,  ..., -8.4260e+00,\n",
            "         -1.1972e-02, -4.8215e+00],\n",
            "        [-5.3213e+00, -5.6259e+00, -5.8983e+00,  ..., -2.7780e-02,\n",
            "         -4.5428e+00, -5.7131e+00],\n",
            "        ...,\n",
            "        [-9.0750e+00, -1.0885e-03, -9.2148e+00,  ..., -7.8886e+00,\n",
            "         -8.1076e+00, -9.2075e+00],\n",
            "        [-1.5086e-01, -3.8453e+00, -4.6765e+00,  ..., -2.9863e+00,\n",
            "         -3.4933e+00, -3.9810e+00],\n",
            "        [-1.8795e+00, -2.0616e+00, -1.8415e+00,  ..., -1.9719e+00,\n",
            "         -2.0479e+00, -1.8033e+00]], grad_fn=<LogSoftmaxBackward0>)\n",
            "Training: 830\n",
            "Epoch: 0831 loss_train: 0.5747 acc_train: 0.8357 loss_val: 1.0891 acc_val: 0.6600 time: 4.0295s\n",
            "loss_val:1.089113712310791, val_acc:0.66, out_features:tensor([[-5.2313, -5.4906, -0.0430,  ..., -4.2336, -5.2739, -4.7595],\n",
            "        [-3.3475, -3.0376, -3.3004,  ..., -2.6475, -0.7491, -2.4789],\n",
            "        [-4.5518, -5.0568, -4.5063,  ..., -0.0706, -4.8198, -3.7017],\n",
            "        ...,\n",
            "        [-1.9858, -0.9861, -2.9776,  ..., -2.0862, -1.7756, -2.3872],\n",
            "        [-0.1871, -4.1885, -4.7139,  ..., -3.1655, -2.5552, -4.1445],\n",
            "        [-1.9459, -1.9459, -1.9459,  ..., -1.9459, -1.9459, -1.9459]],\n",
            "       grad_fn=<LogSoftmaxBackward0>)\n",
            "Training: 831\n",
            "Epoch: 0832 loss_train: 0.6115 acc_train: 0.8071 loss_val: 1.1057 acc_val: 0.6733 time: 4.1341s\n",
            "loss_val:1.1056674718856812, val_acc:0.6733333333333333, out_features:tensor([[-2.4185, -2.7653, -0.7088,  ..., -2.3440, -2.8038, -2.1702],\n",
            "        [-2.0785, -3.2460, -3.3351,  ..., -2.4589, -0.9467, -1.2291],\n",
            "        [-3.1369, -2.6854, -2.5168,  ..., -0.4210, -3.2166, -3.0862],\n",
            "        ...,\n",
            "        [-2.0250, -1.4076, -2.7396,  ..., -2.5952, -1.9101, -1.3017],\n",
            "        [-0.1937, -3.5006, -4.3955,  ..., -2.9888, -2.9424, -3.9757],\n",
            "        [-2.0233, -1.7798, -1.2278,  ..., -2.1406, -1.9960, -2.5603]],\n",
            "       grad_fn=<LogSoftmaxBackward0>)\n",
            "Training: 832\n",
            "Epoch: 0833 loss_train: 0.5703 acc_train: 0.8286 loss_val: 1.0403 acc_val: 0.6467 time: 4.4038s\n",
            "loss_val:1.0402799844741821, val_acc:0.6466666666666666, out_features:tensor([[-5.5083, -5.2590, -0.0587,  ..., -4.9475, -5.4043, -4.8785],\n",
            "        [-1.9459, -1.9459, -1.9459,  ..., -1.9459, -1.9459, -1.9459],\n",
            "        [-5.6267, -4.8362, -3.9848,  ..., -0.0427, -5.6548, -5.6426],\n",
            "        ...,\n",
            "        [-2.8374, -0.6526, -2.4869,  ..., -2.6914, -2.2948, -2.2687],\n",
            "        [-1.1060, -2.5270, -2.4759,  ..., -1.8753, -1.9325, -2.5565],\n",
            "        [-1.9459, -1.9459, -1.9459,  ..., -1.9459, -1.9459, -1.9459]],\n",
            "       grad_fn=<LogSoftmaxBackward0>)\n",
            "Training: 833\n",
            "Epoch: 0834 loss_train: 0.5244 acc_train: 0.8500 loss_val: 1.1244 acc_val: 0.6600 time: 4.1045s\n",
            "loss_val:1.124419093132019, val_acc:0.66, out_features:tensor([[-9.6910e+00, -9.7366e+00, -6.8093e-04,  ..., -8.5663e+00,\n",
            "         -9.7359e+00, -9.5137e+00],\n",
            "        [-4.7806e+00, -5.5426e+00, -3.1414e+00,  ..., -1.3511e+00,\n",
            "         -4.2360e-01, -3.6159e+00],\n",
            "        [-2.4298e+00, -2.1411e+00, -2.0384e+00,  ..., -1.0819e+00,\n",
            "         -2.3350e+00, -2.2124e+00],\n",
            "        ...,\n",
            "        [-3.3530e+00, -3.3428e-01, -2.5642e+00,  ..., -2.8707e+00,\n",
            "         -3.1010e+00, -3.4519e+00],\n",
            "        [-1.2608e+00, -2.3900e+00, -2.3109e+00,  ..., -1.6005e+00,\n",
            "         -2.1710e+00, -2.3471e+00],\n",
            "        [-1.1460e+01, -1.0507e+01, -1.1122e-04,  ..., -1.0373e+01,\n",
            "         -1.1120e+01, -1.1470e+01]], grad_fn=<LogSoftmaxBackward0>)\n",
            "Training: 834\n",
            "Epoch: 0835 loss_train: 0.6160 acc_train: 0.8214 loss_val: 1.1012 acc_val: 0.6333 time: 4.1211s\n",
            "loss_val:1.1012126207351685, val_acc:0.6333333333333333, out_features:tensor([[-9.4600e+00, -9.1491e+00, -8.1041e-04,  ..., -8.7303e+00,\n",
            "         -9.3446e+00, -8.8842e+00],\n",
            "        [-3.3485e+00, -3.2235e+00, -2.6099e+00,  ..., -1.3839e+00,\n",
            "         -7.4206e-01, -2.2484e+00],\n",
            "        [-2.9414e+00, -3.1250e+00, -2.7085e+00,  ..., -3.6969e-01,\n",
            "         -3.1695e+00, -2.6445e+00],\n",
            "        ...,\n",
            "        [-1.9459e+00, -1.9459e+00, -1.9459e+00,  ..., -1.9459e+00,\n",
            "         -1.9459e+00, -1.9459e+00],\n",
            "        [-7.3459e-01, -2.8818e+00, -3.0070e+00,  ..., -2.1666e+00,\n",
            "         -2.0863e+00, -2.3005e+00],\n",
            "        [-8.5535e+00, -7.8697e+00, -1.5664e-03,  ..., -8.7521e+00,\n",
            "         -8.3892e+00, -7.6963e+00]], grad_fn=<LogSoftmaxBackward0>)\n",
            "Training: 835\n",
            "Epoch: 0836 loss_train: 0.5522 acc_train: 0.8500 loss_val: 1.0608 acc_val: 0.6733 time: 4.4065s\n",
            "loss_val:1.060762882232666, val_acc:0.6733333333333333, out_features:tensor([[-7.0928, -6.8240, -0.0130,  ..., -6.2775, -6.7444, -6.7578],\n",
            "        [-1.9459, -1.9459, -1.9459,  ..., -1.9459, -1.9459, -1.9459],\n",
            "        [-4.3774, -3.3497, -3.3658,  ..., -0.1262, -4.2589, -4.3204],\n",
            "        ...,\n",
            "        [-3.9696, -0.1096, -4.5783,  ..., -4.3416, -3.2554, -4.3760],\n",
            "        [-0.3456, -2.4369, -4.1910,  ..., -2.7056, -2.4102, -4.1089],\n",
            "        [-1.9661, -2.5205, -1.2894,  ..., -2.0675, -1.6311, -2.3115]],\n",
            "       grad_fn=<LogSoftmaxBackward0>)\n",
            "Training: 836\n",
            "Epoch: 0837 loss_train: 0.5803 acc_train: 0.8143 loss_val: 1.0912 acc_val: 0.6567 time: 4.1213s\n",
            "loss_val:1.0912284851074219, val_acc:0.6566666666666666, out_features:tensor([[-7.4123e+00, -6.8371e+00, -7.1812e-03,  ..., -6.4024e+00,\n",
            "         -7.4408e+00, -6.6748e+00],\n",
            "        [-5.0678e+00, -5.6952e+00, -5.1653e+00,  ..., -5.5901e+00,\n",
            "         -1.0918e-01, -2.5273e+00],\n",
            "        [-6.2649e+00, -6.1914e+00, -5.1912e+00,  ..., -1.4974e-02,\n",
            "         -6.1320e+00, -6.4787e+00],\n",
            "        ...,\n",
            "        [-9.2598e+00, -7.0690e-04, -9.3141e+00,  ..., -9.1019e+00,\n",
            "         -8.2865e+00, -9.4153e+00],\n",
            "        [-9.6804e-02, -4.4443e+00, -4.8898e+00,  ..., -4.2591e+00,\n",
            "         -3.4032e+00, -4.0645e+00],\n",
            "        [-4.9168e+00, -4.7204e+00, -6.8723e-02,  ..., -4.1735e+00,\n",
            "         -4.4488e+00, -4.0537e+00]], grad_fn=<LogSoftmaxBackward0>)\n",
            "Training: 837\n",
            "Epoch: 0838 loss_train: 0.6915 acc_train: 0.7714 loss_val: 1.0793 acc_val: 0.6433 time: 4.2362s\n",
            "loss_val:1.0792527198791504, val_acc:0.6433333333333333, out_features:tensor([[-6.9443e+00, -6.5452e+00, -8.9492e-03,  ..., -5.9583e+00,\n",
            "         -6.6011e+00, -6.6390e+00],\n",
            "        [-1.1843e+01, -1.1858e+01, -1.1916e+01,  ..., -1.1898e+01,\n",
            "         -9.5924e-03, -4.6554e+00],\n",
            "        [-1.9459e+00, -1.9459e+00, -1.9459e+00,  ..., -1.9459e+00,\n",
            "         -1.9459e+00, -1.9459e+00],\n",
            "        ...,\n",
            "        [-2.1282e+00, -1.4896e+00, -1.8633e+00,  ..., -2.0042e+00,\n",
            "         -1.7487e+00, -2.1891e+00],\n",
            "        [-8.5832e-02, -4.8274e+00, -5.3545e+00,  ..., -4.4555e+00,\n",
            "         -3.4402e+00, -3.8589e+00],\n",
            "        [-2.9932e+00, -2.0564e+00, -4.3277e-01,  ..., -3.1346e+00,\n",
            "         -3.1756e+00, -3.3062e+00]], grad_fn=<LogSoftmaxBackward0>)\n",
            "Training: 838\n",
            "Epoch: 0839 loss_train: 0.6900 acc_train: 0.8071 loss_val: 0.9752 acc_val: 0.7000 time: 4.3344s\n",
            "loss_val:0.97515469789505, val_acc:0.7, out_features:tensor([[-7.1247e+00, -6.8114e+00, -3.8974e-02,  ..., -6.0557e+00,\n",
            "         -7.0190e+00, -6.8087e+00],\n",
            "        [-1.9459e+00, -1.9459e+00, -1.9459e+00,  ..., -1.9459e+00,\n",
            "         -1.9459e+00, -1.9459e+00],\n",
            "        [-1.9459e+00, -1.9459e+00, -1.9459e+00,  ..., -1.9459e+00,\n",
            "         -1.9459e+00, -1.9459e+00],\n",
            "        ...,\n",
            "        [-4.6160e+00, -7.6511e-02, -4.7248e+00,  ..., -4.2455e+00,\n",
            "         -4.6484e+00, -4.8847e+00],\n",
            "        [-4.3391e-05, -1.3113e+01, -1.3218e+01,  ..., -1.0766e+01,\n",
            "         -1.1253e+01, -1.2534e+01],\n",
            "        [-1.9459e+00, -1.9459e+00, -1.9459e+00,  ..., -1.9459e+00,\n",
            "         -1.9459e+00, -1.9459e+00]], grad_fn=<LogSoftmaxBackward0>)\n",
            "Training: 839\n",
            "Epoch: 0840 loss_train: 0.5900 acc_train: 0.8357 loss_val: 1.1223 acc_val: 0.6400 time: 4.1903s\n",
            "loss_val:1.1223305463790894, val_acc:0.64, out_features:tensor([[-9.0953e+00, -8.0357e+00, -1.3032e-03,  ..., -8.3608e+00,\n",
            "         -9.0455e+00, -8.1137e+00],\n",
            "        [-1.7556e+00, -2.1619e+00, -2.0880e+00,  ..., -2.2735e+00,\n",
            "         -1.3467e+00, -1.7782e+00],\n",
            "        [-3.0236e+00, -4.7885e+00, -4.9907e+00,  ..., -9.2802e-02,\n",
            "         -5.0978e+00, -4.3367e+00],\n",
            "        ...,\n",
            "        [-2.9337e+00, -4.6782e-01, -2.7577e+00,  ..., -2.4075e+00,\n",
            "         -2.7212e+00, -2.7105e+00],\n",
            "        [-8.0388e-01, -2.6462e+00, -2.3180e+00,  ..., -2.2781e+00,\n",
            "         -2.1129e+00, -2.7136e+00],\n",
            "        [-4.4190e+00, -4.6858e+00, -9.9305e-02,  ..., -4.6889e+00,\n",
            "         -3.5096e+00, -3.9211e+00]], grad_fn=<LogSoftmaxBackward0>)\n",
            "Training: 840\n",
            "Epoch: 0841 loss_train: 0.6271 acc_train: 0.8143 loss_val: 1.0405 acc_val: 0.6633 time: 4.2777s\n",
            "loss_val:1.0405229330062866, val_acc:0.6633333333333333, out_features:tensor([[-5.5155, -5.0346, -0.0946,  ..., -4.7932, -5.5232, -5.2963],\n",
            "        [-1.7422, -5.8348, -3.8712,  ..., -5.7087, -0.2880, -3.0983],\n",
            "        [-3.3403, -3.1682, -4.4666,  ..., -0.1702, -3.2984, -3.9163],\n",
            "        ...,\n",
            "        [-3.5838, -0.3000, -3.5080,  ..., -2.1236, -3.3021, -3.6001],\n",
            "        [-0.4203, -2.8263, -3.4281,  ..., -2.2333, -2.6243, -3.1762],\n",
            "        [-3.0074, -3.3523, -0.4339,  ..., -1.8866, -3.4730, -2.9845]],\n",
            "       grad_fn=<LogSoftmaxBackward0>)\n",
            "Training: 841\n",
            "Epoch: 0842 loss_train: 0.6573 acc_train: 0.8071 loss_val: 1.0835 acc_val: 0.6567 time: 4.2071s\n",
            "loss_val:1.0834612846374512, val_acc:0.6566666666666666, out_features:tensor([[-7.2546e+00, -7.0413e+00, -1.8066e-02,  ..., -6.0740e+00,\n",
            "         -7.2429e+00, -5.7929e+00],\n",
            "        [-1.9459e+00, -1.9459e+00, -1.9459e+00,  ..., -1.9459e+00,\n",
            "         -1.9459e+00, -1.9459e+00],\n",
            "        [-7.9781e+00, -7.5911e+00, -7.7169e+00,  ..., -2.5449e-03,\n",
            "         -7.4861e+00, -7.8302e+00],\n",
            "        ...,\n",
            "        [-9.3540e+00, -7.0952e-04, -9.6154e+00,  ..., -8.3236e+00,\n",
            "         -8.6530e+00, -9.5324e+00],\n",
            "        [-1.5350e-03, -8.2843e+00, -9.0860e+00,  ..., -7.9831e+00,\n",
            "         -7.4917e+00, -8.9586e+00],\n",
            "        [-1.6092e+01, -1.4608e+01, -1.1921e-06,  ..., -1.5054e+01,\n",
            "         -1.6117e+01, -1.6103e+01]], grad_fn=<LogSoftmaxBackward0>)\n",
            "Training: 842\n",
            "Epoch: 0843 loss_train: 0.6590 acc_train: 0.7857 loss_val: 1.0216 acc_val: 0.6633 time: 4.0805s\n",
            "loss_val:1.0215917825698853, val_acc:0.6633333333333333, out_features:tensor([[-1.1410e+01, -1.1329e+01, -2.0454e-04,  ..., -9.0823e+00,\n",
            "         -1.1052e+01, -1.1349e+01],\n",
            "        [-1.9459e+00, -1.9459e+00, -1.9459e+00,  ..., -1.9459e+00,\n",
            "         -1.9459e+00, -1.9459e+00],\n",
            "        [-8.4403e+00, -8.1495e+00, -7.8806e+00,  ..., -1.7001e-03,\n",
            "         -7.8086e+00, -8.5432e+00],\n",
            "        ...,\n",
            "        [-1.7253e+00, -8.8782e-01, -2.8359e+00,  ..., -2.0384e+00,\n",
            "         -2.5668e+00, -2.5570e+00],\n",
            "        [-2.4640e-01, -3.1934e+00, -3.7537e+00,  ..., -3.5888e+00,\n",
            "         -2.5451e+00, -3.8200e+00],\n",
            "        [-3.3737e+00, -3.7694e+00, -2.9698e-01,  ..., -2.9594e+00,\n",
            "         -2.6960e+00, -3.2526e+00]], grad_fn=<LogSoftmaxBackward0>)\n",
            "Training: 843\n",
            "Epoch: 0844 loss_train: 0.5702 acc_train: 0.8071 loss_val: 1.0557 acc_val: 0.6800 time: 4.4935s\n",
            "loss_val:1.055667519569397, val_acc:0.68, out_features:tensor([[-4.7189, -3.7217, -0.1290,  ..., -3.2776, -4.5505, -4.4829],\n",
            "        [-3.1076, -4.2744, -3.6121,  ..., -4.8147, -0.1758, -2.8255],\n",
            "        [-3.7111, -4.2506, -2.5148,  ..., -0.2023, -3.5849, -3.8534],\n",
            "        ...,\n",
            "        [-2.0458, -1.7490, -1.5324,  ..., -1.9325, -2.2495, -2.0522],\n",
            "        [-0.5351, -2.7353, -3.8755,  ..., -3.5650, -1.4189, -3.2995],\n",
            "        [-4.2458, -3.6467, -0.1540,  ..., -3.3777, -3.0613, -4.4321]],\n",
            "       grad_fn=<LogSoftmaxBackward0>)\n",
            "Training: 844\n",
            "Epoch: 0845 loss_train: 0.5832 acc_train: 0.8286 loss_val: 1.0077 acc_val: 0.7033 time: 4.3009s\n",
            "loss_val:1.0076860189437866, val_acc:0.7033333333333334, out_features:tensor([[-7.1217e+00, -6.8957e+00, -9.1493e-03,  ..., -5.5647e+00,\n",
            "         -6.6674e+00, -7.0334e+00],\n",
            "        [-2.4055e+00, -6.7098e+00, -6.7104e+00,  ..., -3.7270e+00,\n",
            "         -1.4030e-01, -4.3409e+00],\n",
            "        [-4.6860e+00, -4.8608e+00, -4.0777e+00,  ..., -6.2311e-02,\n",
            "         -4.6375e+00, -4.5039e+00],\n",
            "        ...,\n",
            "        [-7.1999e+00, -4.3785e-03, -6.3286e+00,  ..., -7.6511e+00,\n",
            "         -7.2708e+00, -7.9493e+00],\n",
            "        [-1.0210e+00, -2.7326e+00, -2.2589e+00,  ..., -1.8409e+00,\n",
            "         -1.8039e+00, -2.4883e+00],\n",
            "        [-7.7917e+00, -7.9553e+00, -1.8763e-03,  ..., -8.6426e+00,\n",
            "         -7.3819e+00, -8.8006e+00]], grad_fn=<LogSoftmaxBackward0>)\n",
            "Training: 845\n",
            "Epoch: 0846 loss_train: 0.6879 acc_train: 0.7857 loss_val: 1.0462 acc_val: 0.6733 time: 4.1502s\n",
            "loss_val:1.0461814403533936, val_acc:0.6733333333333333, out_features:tensor([[-5.9075, -5.2362, -0.0665,  ..., -5.6530, -5.7391, -5.4770],\n",
            "        [-2.2615, -2.5155, -3.8691,  ..., -2.8886, -0.3274, -4.6644],\n",
            "        [-3.8303, -3.8743, -3.6601,  ..., -0.1210, -4.0160, -4.3261],\n",
            "        ...,\n",
            "        [-2.5951, -1.2566, -1.7409,  ..., -1.7578, -2.1655, -2.1356],\n",
            "        [-0.3943, -3.7676, -3.8655,  ..., -2.8169, -2.2327, -2.3508],\n",
            "        [-1.9459, -1.9459, -1.9459,  ..., -1.9459, -1.9459, -1.9459]],\n",
            "       grad_fn=<LogSoftmaxBackward0>)\n",
            "Training: 846\n",
            "Epoch: 0847 loss_train: 0.5460 acc_train: 0.8214 loss_val: 1.0596 acc_val: 0.6433 time: 4.3762s\n",
            "loss_val:1.059632420539856, val_acc:0.6433333333333333, out_features:tensor([[-6.7616e+00, -6.1667e+00, -1.6504e-02,  ..., -4.6963e+00,\n",
            "         -6.6476e+00, -6.7347e+00],\n",
            "        [-1.9459e+00, -1.9459e+00, -1.9459e+00,  ..., -1.9459e+00,\n",
            "         -1.9459e+00, -1.9459e+00],\n",
            "        [-1.1472e+01, -1.1566e+01, -1.1366e+01,  ..., -7.2715e-05,\n",
            "         -1.0563e+01, -1.1714e+01],\n",
            "        ...,\n",
            "        [-2.2437e+00, -6.4838e-01, -2.8646e+00,  ..., -2.6421e+00,\n",
            "         -2.2693e+00, -2.6718e+00],\n",
            "        [-4.2915e-01, -3.5916e+00, -3.8074e+00,  ..., -2.8372e+00,\n",
            "         -2.1195e+00, -2.3703e+00],\n",
            "        [-1.9459e+00, -1.9459e+00, -1.9459e+00,  ..., -1.9459e+00,\n",
            "         -1.9459e+00, -1.9459e+00]], grad_fn=<LogSoftmaxBackward0>)\n",
            "Training: 847\n",
            "Epoch: 0848 loss_train: 0.6267 acc_train: 0.7929 loss_val: 1.0342 acc_val: 0.6733 time: 4.1548s\n",
            "loss_val:1.034196376800537, val_acc:0.6733333333333333, out_features:tensor([[-4.7398e+00, -4.8418e+00, -7.5276e-02,  ..., -3.9802e+00,\n",
            "         -4.7635e+00, -4.2340e+00],\n",
            "        [-1.9459e+00, -1.9459e+00, -1.9459e+00,  ..., -1.9459e+00,\n",
            "         -1.9459e+00, -1.9459e+00],\n",
            "        [-1.0004e+01, -8.7944e+00, -1.0114e+01,  ..., -3.7198e-04,\n",
            "         -9.7756e+00, -1.0018e+01],\n",
            "        ...,\n",
            "        [-5.6444e+00, -3.1908e-02, -5.3993e+00,  ..., -5.1062e+00,\n",
            "         -4.6545e+00, -5.4492e+00],\n",
            "        [-1.9459e+00, -1.9459e+00, -1.9459e+00,  ..., -1.9459e+00,\n",
            "         -1.9459e+00, -1.9459e+00],\n",
            "        [-3.6040e+00, -2.8314e+00, -3.9781e-01,  ..., -3.4209e+00,\n",
            "         -3.4114e+00, -2.1687e+00]], grad_fn=<LogSoftmaxBackward0>)\n",
            "Training: 848\n",
            "Epoch: 0849 loss_train: 0.6503 acc_train: 0.8214 loss_val: 1.0528 acc_val: 0.6600 time: 4.0306s\n",
            "loss_val:1.052831768989563, val_acc:0.66, out_features:tensor([[-1.5049e+01, -1.4994e+01, -3.4571e-06,  ..., -1.3338e+01,\n",
            "         -1.5018e+01, -1.4959e+01],\n",
            "        [-1.8433e+00, -2.4593e+00, -2.3774e+00,  ..., -2.1649e+00,\n",
            "         -1.1337e+00, -1.8597e+00],\n",
            "        [-4.4785e+00, -4.6763e+00, -3.7605e+00,  ..., -7.3282e-02,\n",
            "         -4.5434e+00, -4.5626e+00],\n",
            "        ...,\n",
            "        [-1.9459e+00, -1.9459e+00, -1.9459e+00,  ..., -1.9459e+00,\n",
            "         -1.9459e+00, -1.9459e+00],\n",
            "        [-3.4670e-01, -3.8097e+00, -3.7720e+00,  ..., -2.3227e+00,\n",
            "         -2.4092e+00, -3.3035e+00],\n",
            "        [-2.9680e+00, -2.7686e+00, -4.4937e-01,  ..., -3.1779e+00,\n",
            "         -2.9605e+00, -2.3309e+00]], grad_fn=<LogSoftmaxBackward0>)\n",
            "Training: 849\n",
            "Epoch: 0850 loss_train: 0.6040 acc_train: 0.8143 loss_val: 1.0172 acc_val: 0.6900 time: 4.4298s\n",
            "loss_val:1.017167329788208, val_acc:0.69, out_features:tensor([[-4.3676e+00, -4.4392e+00, -1.1411e-01,  ..., -4.2440e+00,\n",
            "         -4.1994e+00, -4.4339e+00],\n",
            "        [-5.5542e+00, -5.4851e+00, -5.4829e+00,  ..., -4.5252e+00,\n",
            "         -9.4479e-02, -2.7455e+00],\n",
            "        [-1.2002e+01, -1.2433e+01, -1.2955e+01,  ..., -2.9206e-05,\n",
            "         -1.2836e+01, -1.1364e+01],\n",
            "        ...,\n",
            "        [-2.4524e+00, -8.9470e-01, -2.7930e+00,  ..., -1.6787e+00,\n",
            "         -1.9328e+00, -2.6976e+00],\n",
            "        [-8.6494e-02, -4.5296e+00, -5.2047e+00,  ..., -3.2887e+00,\n",
            "         -4.2554e+00, -4.7987e+00],\n",
            "        [-1.9459e+00, -1.9459e+00, -1.9459e+00,  ..., -1.9459e+00,\n",
            "         -1.9459e+00, -1.9459e+00]], grad_fn=<LogSoftmaxBackward0>)\n",
            "Training: 850\n",
            "Epoch: 0851 loss_train: 0.6641 acc_train: 0.7786 loss_val: 0.9623 acc_val: 0.7133 time: 4.0040s\n",
            "loss_val:0.9622612595558167, val_acc:0.7133333333333334, out_features:tensor([[-5.2263, -5.1756, -0.0764,  ..., -3.4253, -5.3490, -5.1294],\n",
            "        [-1.9459, -1.9459, -1.9459,  ..., -1.9459, -1.9459, -1.9459],\n",
            "        [-2.7838, -1.9796, -2.2547,  ..., -0.7141, -2.8830, -2.8354],\n",
            "        ...,\n",
            "        [-2.7020, -0.2835, -3.8942,  ..., -3.2163, -2.4831, -3.9375],\n",
            "        [-0.2996, -4.5860, -4.7420,  ..., -1.6287, -3.7847, -4.5102],\n",
            "        [-6.8506, -6.8106, -0.0101,  ..., -6.7227, -6.7682, -6.5427]],\n",
            "       grad_fn=<LogSoftmaxBackward0>)\n",
            "Training: 851\n",
            "Epoch: 0852 loss_train: 0.5671 acc_train: 0.8500 loss_val: 0.9604 acc_val: 0.6967 time: 4.2773s\n",
            "loss_val:0.9604456424713135, val_acc:0.6966666666666667, out_features:tensor([[-2.4195e+00, -2.2397e+00, -1.3975e+00,  ..., -1.6767e+00,\n",
            "         -2.1797e+00, -1.7934e+00],\n",
            "        [-1.9459e+00, -1.9459e+00, -1.9459e+00,  ..., -1.9459e+00,\n",
            "         -1.9459e+00, -1.9459e+00],\n",
            "        [-8.1911e+00, -5.9556e+00, -7.8210e+00,  ..., -4.6059e-03,\n",
            "         -8.0216e+00, -7.2156e+00],\n",
            "        ...,\n",
            "        [-2.5323e+00, -8.7386e-01, -2.6673e+00,  ..., -2.3537e+00,\n",
            "         -1.4102e+00, -2.8575e+00],\n",
            "        [-1.0467e-01, -3.9525e+00, -4.5939e+00,  ..., -4.0588e+00,\n",
            "         -3.7087e+00, -4.6858e+00],\n",
            "        [-2.6903e+00, -2.4184e+00, -8.3927e-01,  ..., -2.0383e+00,\n",
            "         -2.6726e+00, -2.6024e+00]], grad_fn=<LogSoftmaxBackward0>)\n",
            "Training: 852\n",
            "Epoch: 0853 loss_train: 0.5271 acc_train: 0.8357 loss_val: 1.0662 acc_val: 0.6700 time: 4.4742s\n",
            "loss_val:1.0662360191345215, val_acc:0.67, out_features:tensor([[-3.2178, -2.9523, -0.4221,  ..., -2.5829, -2.9979, -3.0578],\n",
            "        [-1.9459, -1.9459, -1.9459,  ..., -1.9459, -1.9459, -1.9459],\n",
            "        [-2.3110, -2.3053, -1.6361,  ..., -1.1389, -2.2323, -2.2405],\n",
            "        ...,\n",
            "        [-1.9459, -1.9459, -1.9459,  ..., -1.9459, -1.9459, -1.9459],\n",
            "        [-0.4503, -2.7688, -3.6460,  ..., -2.3248, -2.3621, -2.9023],\n",
            "        [-1.8585, -2.6662, -1.9452,  ..., -2.2932, -1.3954, -1.7422]],\n",
            "       grad_fn=<LogSoftmaxBackward0>)\n",
            "Training: 853\n",
            "Epoch: 0854 loss_train: 0.6451 acc_train: 0.8071 loss_val: 1.0684 acc_val: 0.6833 time: 4.1974s\n",
            "loss_val:1.0684216022491455, val_acc:0.6833333333333333, out_features:tensor([[-1.9459e+00, -1.9459e+00, -1.9459e+00,  ..., -1.9459e+00,\n",
            "         -1.9459e+00, -1.9459e+00],\n",
            "        [-2.4831e+00, -4.1345e+00, -4.2709e+00,  ..., -6.6987e-01,\n",
            "         -1.0848e+00, -3.8639e+00],\n",
            "        [-3.4498e+00, -3.1026e+00, -3.2262e+00,  ..., -2.3345e-01,\n",
            "         -3.6747e+00, -3.1454e+00],\n",
            "        ...,\n",
            "        [-3.2897e+00, -1.9965e-01, -3.6317e+00,  ..., -3.5207e+00,\n",
            "         -3.3845e+00, -3.4676e+00],\n",
            "        [-3.8750e-01, -3.1038e+00, -3.5485e+00,  ..., -3.1977e+00,\n",
            "         -2.3280e+00, -3.3669e+00],\n",
            "        [-9.3325e+00, -9.3238e+00, -1.4091e-03,  ..., -7.6071e+00,\n",
            "         -7.5174e+00, -9.4390e+00]], grad_fn=<LogSoftmaxBackward0>)\n",
            "Training: 854\n",
            "Epoch: 0855 loss_train: 0.6713 acc_train: 0.7857 loss_val: 1.0569 acc_val: 0.6500 time: 4.1172s\n",
            "loss_val:1.056905746459961, val_acc:0.65, out_features:tensor([[-3.8061, -3.0383, -0.4525,  ..., -1.7664, -3.8098, -3.5590],\n",
            "        [-1.9459, -1.9459, -1.9459,  ..., -1.9459, -1.9459, -1.9459],\n",
            "        [-2.3634, -2.5087, -2.2837,  ..., -0.7202, -2.2395, -2.4731],\n",
            "        ...,\n",
            "        [-6.7272, -0.0121, -6.8616,  ..., -5.2053, -6.0251, -6.9760],\n",
            "        [-0.1027, -4.0652, -4.5757,  ..., -3.5090, -4.2529, -4.1923],\n",
            "        [-2.3041, -2.1360, -0.8969,  ..., -2.9125, -2.2124, -2.5037]],\n",
            "       grad_fn=<LogSoftmaxBackward0>)\n",
            "Training: 855\n",
            "Epoch: 0856 loss_train: 0.6667 acc_train: 0.8000 loss_val: 1.1374 acc_val: 0.6433 time: 4.4101s\n",
            "loss_val:1.137438178062439, val_acc:0.6433333333333333, out_features:tensor([[-7.5830e+00, -7.7173e+00, -4.1536e-03,  ..., -6.7442e+00,\n",
            "         -7.9125e+00, -7.3517e+00],\n",
            "        [-2.2593e+00, -2.9600e+00, -3.0473e+00,  ..., -3.1514e+00,\n",
            "         -6.4815e-01, -1.7068e+00],\n",
            "        [-4.4007e+00, -3.1780e+00, -4.5030e+00,  ..., -1.2140e-01,\n",
            "         -3.9121e+00, -4.0320e+00],\n",
            "        ...,\n",
            "        [-1.9459e+00, -1.9459e+00, -1.9459e+00,  ..., -1.9459e+00,\n",
            "         -1.9459e+00, -1.9459e+00],\n",
            "        [-3.0745e-01, -3.0590e+00, -4.1761e+00,  ..., -2.8552e+00,\n",
            "         -2.2438e+00, -3.9449e+00],\n",
            "        [-2.1735e+00, -2.9592e+00, -8.2622e-01,  ..., -2.4478e+00,\n",
            "         -2.4624e+00, -2.8040e+00]], grad_fn=<LogSoftmaxBackward0>)\n",
            "Training: 856\n",
            "Epoch: 0857 loss_train: 0.6005 acc_train: 0.7857 loss_val: 1.0134 acc_val: 0.6667 time: 4.1113s\n",
            "loss_val:1.0134389400482178, val_acc:0.6666666666666666, out_features:tensor([[-7.4761e+00, -7.3886e+00, -1.1220e-02,  ..., -4.9599e+00,\n",
            "         -7.3746e+00, -7.0662e+00],\n",
            "        [-2.2206e+00, -3.2625e+00, -3.4902e+00,  ..., -3.0245e+00,\n",
            "         -1.0442e+00, -9.4969e-01],\n",
            "        [-9.5133e+00, -8.0565e+00, -8.0740e+00,  ..., -9.1713e-04,\n",
            "         -9.5686e+00, -9.4072e+00],\n",
            "        ...,\n",
            "        [-4.6405e+00, -5.9872e-02, -5.0269e+00,  ..., -4.4865e+00,\n",
            "         -4.0719e+00, -5.1121e+00],\n",
            "        [-2.9448e-02, -6.1152e+00, -7.2135e+00,  ..., -3.9231e+00,\n",
            "         -5.3386e+00, -7.1685e+00],\n",
            "        [-3.1656e+00, -3.2516e+00, -4.5463e-01,  ..., -2.2260e+00,\n",
            "         -2.1140e+00, -3.4720e+00]], grad_fn=<LogSoftmaxBackward0>)\n",
            "Training: 857\n",
            "Epoch: 0858 loss_train: 0.6035 acc_train: 0.7929 loss_val: 1.0433 acc_val: 0.7033 time: 4.2960s\n",
            "loss_val:1.0432629585266113, val_acc:0.7033333333333334, out_features:tensor([[-2.9678, -2.6985, -0.6151,  ..., -2.1946, -3.1229, -2.4187],\n",
            "        [-2.4072, -3.9197, -4.3967,  ..., -3.8254, -0.1858, -4.4043],\n",
            "        [-1.9459, -1.9459, -1.9459,  ..., -1.9459, -1.9459, -1.9459],\n",
            "        ...,\n",
            "        [-6.0621, -0.0288, -6.2176,  ..., -4.6534, -4.5361, -6.2144],\n",
            "        [-1.2087, -2.4169, -1.9955,  ..., -2.1279, -1.9580, -1.9734],\n",
            "        [-3.0435, -2.5149, -0.7375,  ..., -2.6628, -2.4589, -1.8917]],\n",
            "       grad_fn=<LogSoftmaxBackward0>)\n",
            "Training: 858\n",
            "Epoch: 0859 loss_train: 0.5079 acc_train: 0.8643 loss_val: 1.1203 acc_val: 0.6233 time: 4.2772s\n",
            "loss_val:1.1202689409255981, val_acc:0.6233333333333333, out_features:tensor([[-2.9433, -2.6618, -0.7787,  ..., -2.0269, -2.8594, -2.3750],\n",
            "        [-1.9459, -1.9459, -1.9459,  ..., -1.9459, -1.9459, -1.9459],\n",
            "        [-2.8578, -3.1544, -2.8262,  ..., -0.4567, -2.9434, -2.4469],\n",
            "        ...,\n",
            "        [-1.9743, -0.8982, -2.6297,  ..., -2.1051, -2.0505, -2.7794],\n",
            "        [-0.0840, -5.1553, -5.3788,  ..., -3.8489, -3.2541, -5.3232],\n",
            "        [-6.4522, -6.0183, -0.0087,  ..., -6.3365, -6.9760, -6.9633]],\n",
            "       grad_fn=<LogSoftmaxBackward0>)\n",
            "Training: 859\n",
            "Epoch: 0860 loss_train: 0.5487 acc_train: 0.8429 loss_val: 1.1291 acc_val: 0.6500 time: 4.1477s\n",
            "loss_val:1.1291236877441406, val_acc:0.65, out_features:tensor([[-5.3063e+00, -5.4615e+00, -3.7222e-02,  ..., -5.5327e+00,\n",
            "         -5.4614e+00, -4.8602e+00],\n",
            "        [-1.9459e+00, -1.9459e+00, -1.9459e+00,  ..., -1.9459e+00,\n",
            "         -1.9459e+00, -1.9459e+00],\n",
            "        [-5.0528e+00, -6.1395e+00, -6.2193e+00,  ..., -1.7797e-02,\n",
            "         -6.3453e+00, -5.5367e+00],\n",
            "        ...,\n",
            "        [-1.9459e+00, -1.9459e+00, -1.9459e+00,  ..., -1.9459e+00,\n",
            "         -1.9459e+00, -1.9459e+00],\n",
            "        [-6.2125e-04, -1.0587e+01, -1.0704e+01,  ..., -1.0319e+01,\n",
            "         -7.8386e+00, -1.0231e+01],\n",
            "        [-8.4682e+00, -1.0018e+01, -1.1393e-03,  ..., -9.9947e+00,\n",
            "         -1.0050e+01, -1.0140e+01]], grad_fn=<LogSoftmaxBackward0>)\n",
            "Training: 860\n",
            "Epoch: 0861 loss_train: 0.6365 acc_train: 0.8214 loss_val: 1.2138 acc_val: 0.6433 time: 4.2789s\n",
            "loss_val:1.2138481140136719, val_acc:0.6433333333333333, out_features:tensor([[-2.9646e+00, -2.6168e+00, -7.4280e-01,  ..., -2.3888e+00,\n",
            "         -2.7549e+00, -2.0942e+00],\n",
            "        [-1.9459e+00, -1.9459e+00, -1.9459e+00,  ..., -1.9459e+00,\n",
            "         -1.9459e+00, -1.9459e+00],\n",
            "        [-6.2698e+00, -7.1329e+00, -6.5460e+00,  ..., -6.7236e-03,\n",
            "         -6.9000e+00, -7.0378e+00],\n",
            "        ...,\n",
            "        [-2.6027e+00, -3.9902e-01, -2.8876e+00,  ..., -2.8337e+00,\n",
            "         -2.6541e+00, -3.2900e+00],\n",
            "        [-5.3879e-01, -2.9742e+00, -3.1507e+00,  ..., -2.2891e+00,\n",
            "         -2.0049e+00, -2.8557e+00],\n",
            "        [-5.1326e+00, -4.3604e+00, -6.5427e-02,  ..., -4.6416e+00,\n",
            "         -4.6802e+00, -4.7142e+00]], grad_fn=<LogSoftmaxBackward0>)\n",
            "Training: 861\n",
            "Epoch: 0862 loss_train: 0.5658 acc_train: 0.8286 loss_val: 0.9976 acc_val: 0.6700 time: 4.2643s\n",
            "loss_val:0.9975537061691284, val_acc:0.67, out_features:tensor([[-1.8008e+00, -2.8695e+00, -7.5119e-01,  ..., -2.8533e+00,\n",
            "         -3.1173e+00, -1.9647e+00],\n",
            "        [-5.3801e+00, -5.7246e+00, -5.0239e+00,  ..., -5.7575e+00,\n",
            "         -9.8685e-02, -2.6173e+00],\n",
            "        [-2.1589e+00, -2.8550e+00, -2.8601e+00,  ..., -5.3136e-01,\n",
            "         -2.9194e+00, -2.5599e+00],\n",
            "        ...,\n",
            "        [-2.5455e+00, -7.9059e-01, -2.4482e+00,  ..., -2.6241e+00,\n",
            "         -1.8762e+00, -2.3587e+00],\n",
            "        [-1.4842e+00, -2.1583e+00, -2.0483e+00,  ..., -1.5927e+00,\n",
            "         -2.1989e+00, -2.3014e+00],\n",
            "        [-1.2110e+01, -1.1149e+01, -5.5073e-05,  ..., -1.0979e+01,\n",
            "         -1.2048e+01, -1.2163e+01]], grad_fn=<LogSoftmaxBackward0>)\n",
            "Training: 862\n",
            "Epoch: 0863 loss_train: 0.6752 acc_train: 0.8071 loss_val: 1.0567 acc_val: 0.6400 time: 4.1760s\n",
            "loss_val:1.0566906929016113, val_acc:0.64, out_features:tensor([[-6.4671e+00, -7.1626e+00, -6.8598e-03,  ..., -6.8532e+00,\n",
            "         -7.2524e+00, -6.5294e+00],\n",
            "        [-2.5653e+00, -3.2718e+00, -3.3977e+00,  ..., -3.7508e+00,\n",
            "         -3.5161e-01, -2.2990e+00],\n",
            "        [-1.6883e+00, -2.4885e+00, -2.7086e+00,  ..., -1.3265e+00,\n",
            "         -1.9928e+00, -1.7364e+00],\n",
            "        ...,\n",
            "        [-1.5980e+00, -7.6122e-01, -3.1292e+00,  ..., -2.2128e+00,\n",
            "         -2.5245e+00, -2.7470e+00],\n",
            "        [-9.6420e-01, -2.3030e+00, -2.5301e+00,  ..., -1.6982e+00,\n",
            "         -2.1796e+00, -2.4011e+00],\n",
            "        [-2.2537e+00, -2.6955e+00, -1.0238e+00,  ..., -2.9452e+00,\n",
            "         -1.7471e+00, -1.8571e+00]], grad_fn=<LogSoftmaxBackward0>)\n",
            "Training: 863\n",
            "Epoch: 0864 loss_train: 0.5795 acc_train: 0.8143 loss_val: 1.0608 acc_val: 0.6400 time: 4.4047s\n",
            "loss_val:1.0607835054397583, val_acc:0.64, out_features:tensor([[-5.5492e+00, -4.8711e+00, -3.5800e-02,  ..., -5.0237e+00,\n",
            "         -5.2310e+00, -5.0938e+00],\n",
            "        [-4.8705e+00, -1.0552e+01, -1.0618e+01,  ..., -1.0521e+01,\n",
            "         -7.8733e-03, -9.5612e+00],\n",
            "        [-6.4615e+00, -7.2482e+00, -6.6814e+00,  ..., -5.6889e-03,\n",
            "         -7.0537e+00, -7.2169e+00],\n",
            "        ...,\n",
            "        [-1.9367e+00, -7.0334e-01, -2.7957e+00,  ..., -2.1947e+00,\n",
            "         -2.2096e+00, -3.0750e+00],\n",
            "        [-1.7016e-02, -6.5883e+00, -7.1300e+00,  ..., -6.7767e+00,\n",
            "         -4.4415e+00, -6.9741e+00],\n",
            "        [-3.6486e+00, -3.5486e+00, -1.8165e-01,  ..., -3.9659e+00,\n",
            "         -3.2047e+00, -3.7813e+00]], grad_fn=<LogSoftmaxBackward0>)\n",
            "Training: 864\n",
            "Epoch: 0865 loss_train: 0.6606 acc_train: 0.7714 loss_val: 1.0539 acc_val: 0.6700 time: 4.1521s\n",
            "loss_val:1.0538890361785889, val_acc:0.67, out_features:tensor([[-5.5461, -4.7929, -0.0494,  ..., -4.8242, -5.2607, -5.4165],\n",
            "        [-1.9255, -4.5551, -4.3092,  ..., -4.8698, -0.2284, -4.0924],\n",
            "        [-1.9550, -2.4669, -2.8212,  ..., -0.7549, -2.5920, -2.2646],\n",
            "        ...,\n",
            "        [-4.8800, -0.0472, -5.4888,  ..., -4.9212, -3.9262, -5.4751],\n",
            "        [-0.4037, -3.5195, -3.4233,  ..., -1.7984, -2.8666, -3.5373],\n",
            "        [-1.9459, -1.9459, -1.9459,  ..., -1.9459, -1.9459, -1.9459]],\n",
            "       grad_fn=<LogSoftmaxBackward0>)\n",
            "Training: 865\n",
            "Epoch: 0866 loss_train: 0.6023 acc_train: 0.7786 loss_val: 1.0121 acc_val: 0.6967 time: 4.1478s\n",
            "loss_val:1.0121172666549683, val_acc:0.6966666666666667, out_features:tensor([[-7.7692e+00, -7.2508e+00, -4.8025e-03,  ..., -6.3111e+00,\n",
            "         -7.7026e+00, -7.7686e+00],\n",
            "        [-2.1391e+00, -5.8095e+00, -5.7812e+00,  ..., -5.9949e+00,\n",
            "         -5.7604e-01, -1.1744e+00],\n",
            "        [-8.8540e+00, -8.7667e+00, -9.0761e+00,  ..., -6.5258e-04,\n",
            "         -9.2456e+00, -9.4919e+00],\n",
            "        ...,\n",
            "        [-6.7603e+00, -2.0595e-02, -6.4712e+00,  ..., -5.3707e+00,\n",
            "         -4.5419e+00, -6.5969e+00],\n",
            "        [-1.0038e+00, -2.2604e+00, -2.2568e+00,  ..., -2.1409e+00,\n",
            "         -2.2655e+00, -2.1488e+00],\n",
            "        [-4.7121e+00, -4.2067e+00, -8.7659e-02,  ..., -4.9698e+00,\n",
            "         -4.4834e+00, -4.2904e+00]], grad_fn=<LogSoftmaxBackward0>)\n",
            "Training: 866\n",
            "Epoch: 0867 loss_train: 0.6047 acc_train: 0.8357 loss_val: 0.9870 acc_val: 0.6900 time: 4.5012s\n",
            "loss_val:0.9870281219482422, val_acc:0.69, out_features:tensor([[-2.7383, -2.6679, -0.6226,  ..., -2.7653, -2.4943, -2.4739],\n",
            "        [-2.7412, -2.9095, -2.6469,  ..., -2.4464, -0.5634, -2.2464],\n",
            "        [-2.8438, -3.8901, -3.0256,  ..., -0.2254, -3.5281, -3.6856],\n",
            "        ...,\n",
            "        [-3.5814, -0.3198, -2.3636,  ..., -3.1600, -3.0168, -3.5278],\n",
            "        [-0.0249, -6.2033, -6.3180,  ..., -5.0053, -4.5288, -6.3510],\n",
            "        [-3.1360, -4.3719, -0.1491,  ..., -3.9243, -4.5244, -4.6368]],\n",
            "       grad_fn=<LogSoftmaxBackward0>)\n",
            "Training: 867\n",
            "Epoch: 0868 loss_train: 0.5329 acc_train: 0.8643 loss_val: 0.9908 acc_val: 0.6800 time: 4.0648s\n",
            "loss_val:0.9907772541046143, val_acc:0.68, out_features:tensor([[-3.8402, -3.5759, -0.3468,  ..., -3.5095, -3.2973, -2.8153],\n",
            "        [-2.4912, -3.1470, -2.0368,  ..., -1.5149, -1.0286, -2.0071],\n",
            "        [-2.8933, -3.4788, -4.0613,  ..., -0.2524, -2.5618, -3.5592],\n",
            "        ...,\n",
            "        [-1.8246, -1.0846, -1.5989,  ..., -2.3473, -2.2704, -2.8975],\n",
            "        [-0.2705, -3.9346, -4.0518,  ..., -2.6697, -2.2992, -4.0151],\n",
            "        [-4.4474, -3.9369, -0.3472,  ..., -3.1605, -4.3199, -4.0469]],\n",
            "       grad_fn=<LogSoftmaxBackward0>)\n",
            "Training: 868\n",
            "Epoch: 0869 loss_train: 0.5628 acc_train: 0.8357 loss_val: 1.0236 acc_val: 0.6567 time: 4.3207s\n",
            "loss_val:1.0236001014709473, val_acc:0.6566666666666666, out_features:tensor([[-4.6620, -4.5137, -0.1119,  ..., -3.9760, -4.6120, -4.0627],\n",
            "        [-3.6719, -5.1320, -5.2262,  ..., -1.9973, -0.2613, -2.9717],\n",
            "        [-4.4597, -7.5161, -7.5872,  ..., -0.0150, -6.8595, -7.4501],\n",
            "        ...,\n",
            "        [-2.4506, -1.1362, -2.2003,  ..., -1.8758, -2.0230, -2.0970],\n",
            "        [-1.3579, -2.1321, -2.1888,  ..., -1.6758, -2.0727, -2.2646],\n",
            "        [-2.7835, -2.5334, -0.7265,  ..., -2.9659, -2.6132, -1.7735]],\n",
            "       grad_fn=<LogSoftmaxBackward0>)\n",
            "Training: 869\n",
            "Epoch: 0870 loss_train: 0.6241 acc_train: 0.8357 loss_val: 1.0344 acc_val: 0.6567 time: 4.3816s\n",
            "loss_val:1.034420132637024, val_acc:0.6566666666666666, out_features:tensor([[-1.1509e+01, -1.1192e+01, -1.1241e-04,  ..., -1.1690e+01,\n",
            "         -1.1703e+01, -1.0696e+01],\n",
            "        [-2.5938e+00, -3.7832e+00, -4.2253e+00,  ..., -1.3024e+00,\n",
            "         -7.6490e-01, -3.9319e+00],\n",
            "        [-2.1151e+00, -2.2079e+00, -3.0595e+00,  ..., -6.7608e-01,\n",
            "         -2.6261e+00, -2.8737e+00],\n",
            "        ...,\n",
            "        [-1.9453e+00, -1.5332e+00, -2.1337e+00,  ..., -1.9020e+00,\n",
            "         -1.9298e+00, -2.1963e+00],\n",
            "        [-4.2892e-03, -9.1460e+00, -9.2653e+00,  ..., -8.7342e+00,\n",
            "         -5.6288e+00, -8.4389e+00],\n",
            "        [-9.8664e-01, -4.2456e+00, -8.1476e-01,  ..., -4.0852e+00,\n",
            "         -2.4093e+00, -3.0317e+00]], grad_fn=<LogSoftmaxBackward0>)\n",
            "Training: 870\n",
            "Epoch: 0871 loss_train: 0.5799 acc_train: 0.8214 loss_val: 0.9853 acc_val: 0.6733 time: 4.1657s\n",
            "loss_val:0.9852691888809204, val_acc:0.6733333333333333, out_features:tensor([[-8.3071e+00, -8.7074e+00, -1.6918e-03,  ..., -7.5334e+00,\n",
            "         -8.3538e+00, -8.1886e+00],\n",
            "        [-5.0142e+00, -6.7594e+00, -6.6591e+00,  ..., -6.8430e+00,\n",
            "         -1.6065e-02, -5.3352e+00],\n",
            "        [-6.5172e+00, -5.3862e+00, -5.7900e+00,  ..., -1.2838e-02,\n",
            "         -6.7827e+00, -6.6130e+00],\n",
            "        ...,\n",
            "        [-3.5484e+00, -4.7518e-01, -3.2464e+00,  ..., -1.9995e+00,\n",
            "         -2.1197e+00, -3.5491e+00],\n",
            "        [-1.2509e-02, -6.8388e+00, -6.9635e+00,  ..., -5.0185e+00,\n",
            "         -6.0926e+00, -7.0603e+00],\n",
            "        [-2.2498e+00, -2.1532e+00, -1.2552e+00,  ..., -2.2460e+00,\n",
            "         -1.9684e+00, -1.7965e+00]], grad_fn=<LogSoftmaxBackward0>)\n",
            "Training: 871\n",
            "Epoch: 0872 loss_train: 0.5093 acc_train: 0.8571 loss_val: 1.0400 acc_val: 0.6833 time: 4.0489s\n",
            "loss_val:1.0400141477584839, val_acc:0.6833333333333333, out_features:tensor([[-5.1357, -5.0400, -0.0547,  ..., -4.4429, -5.2242, -4.7252],\n",
            "        [-3.0432, -1.9902, -2.7871,  ..., -3.2634, -0.6002, -2.3928],\n",
            "        [-5.1221, -4.8935, -3.4171,  ..., -0.0681, -5.1802, -4.7118],\n",
            "        ...,\n",
            "        [-3.8158, -0.2822, -2.8981,  ..., -3.1940, -2.6458, -3.2620],\n",
            "        [-0.0226, -6.2226, -6.6342,  ..., -4.4636, -5.3686, -6.4830],\n",
            "        [-3.3609, -2.9508, -0.4625,  ..., -1.6628, -3.6746, -3.6966]],\n",
            "       grad_fn=<LogSoftmaxBackward0>)\n",
            "Training: 872\n",
            "Epoch: 0873 loss_train: 0.6810 acc_train: 0.7786 loss_val: 1.0477 acc_val: 0.7067 time: 4.3737s\n",
            "loss_val:1.0476821660995483, val_acc:0.7066666666666667, out_features:tensor([[-4.5192, -4.1868, -0.1751,  ..., -4.0126, -4.3399, -3.6406],\n",
            "        [-1.9459, -1.9459, -1.9459,  ..., -1.9459, -1.9459, -1.9459],\n",
            "        [-2.4373, -3.2924, -4.3603,  ..., -0.3008, -2.5362, -3.4646],\n",
            "        ...,\n",
            "        [-4.5883, -0.0297, -6.0307,  ..., -5.5473, -5.3724, -5.1635],\n",
            "        [-0.2904, -3.0867, -3.2576,  ..., -3.4366, -2.8936, -3.0217],\n",
            "        [-2.2953, -3.2036, -0.3491,  ..., -3.8753, -3.3757, -3.1684]],\n",
            "       grad_fn=<LogSoftmaxBackward0>)\n",
            "Training: 873\n",
            "Epoch: 0874 loss_train: 0.6557 acc_train: 0.8000 loss_val: 0.9470 acc_val: 0.6967 time: 4.0322s\n",
            "loss_val:0.9470182061195374, val_acc:0.6966666666666667, out_features:tensor([[-1.3063e+01, -1.3043e+01, -3.5762e-05,  ..., -1.2620e+01,\n",
            "         -1.3035e+01, -1.2838e+01],\n",
            "        [-7.6002e+00, -8.9212e+00, -8.9758e+00,  ..., -8.8636e+00,\n",
            "         -1.7632e-02, -4.1084e+00],\n",
            "        [-8.8472e+00, -8.7392e+00, -8.9619e+00,  ..., -9.8478e-04,\n",
            "         -8.7505e+00, -8.1924e+00],\n",
            "        ...,\n",
            "        [-3.8828e+00, -1.6515e-01, -3.0803e+00,  ..., -3.4911e+00,\n",
            "         -3.6673e+00, -4.2108e+00],\n",
            "        [-1.8290e-01, -4.1945e+00, -4.2416e+00,  ..., -3.0853e+00,\n",
            "         -3.0420e+00, -3.8923e+00],\n",
            "        [-2.5562e+00, -2.4255e+00, -6.3871e-01,  ..., -2.6321e+00,\n",
            "         -2.5057e+00, -2.7869e+00]], grad_fn=<LogSoftmaxBackward0>)\n",
            "Training: 874\n",
            "Epoch: 0875 loss_train: 0.6197 acc_train: 0.8214 loss_val: 1.0461 acc_val: 0.6767 time: 4.0640s\n",
            "loss_val:1.046130657196045, val_acc:0.6766666666666666, out_features:tensor([[-1.0147e+01, -1.0252e+01, -3.6185e-04,  ..., -9.5542e+00,\n",
            "         -1.0354e+01, -9.3476e+00],\n",
            "        [-1.9459e+00, -1.9459e+00, -1.9459e+00,  ..., -1.9459e+00,\n",
            "         -1.9459e+00, -1.9459e+00],\n",
            "        [-7.5979e+00, -7.3020e+00, -6.9970e+00,  ..., -3.5982e-03,\n",
            "         -7.6567e+00, -7.4176e+00],\n",
            "        ...,\n",
            "        [-2.1506e+00, -1.3671e+00, -2.1190e+00,  ..., -1.9320e+00,\n",
            "         -1.9662e+00, -2.0688e+00],\n",
            "        [-1.3297e-02, -6.3116e+00, -6.8042e+00,  ..., -5.8473e+00,\n",
            "         -5.4982e+00, -6.3197e+00],\n",
            "        [-1.9459e+00, -1.9459e+00, -1.9459e+00,  ..., -1.9459e+00,\n",
            "         -1.9459e+00, -1.9459e+00]], grad_fn=<LogSoftmaxBackward0>)\n",
            "Training: 875\n",
            "Epoch: 0876 loss_train: 0.5259 acc_train: 0.8286 loss_val: 1.0614 acc_val: 0.6967 time: 4.3227s\n",
            "loss_val:1.0613914728164673, val_acc:0.6966666666666667, out_features:tensor([[-1.3965e+01, -1.3398e+01, -2.4199e-05,  ..., -1.0862e+01,\n",
            "         -1.3951e+01, -1.3940e+01],\n",
            "        [-1.9459e+00, -1.9459e+00, -1.9459e+00,  ..., -1.9459e+00,\n",
            "         -1.9459e+00, -1.9459e+00],\n",
            "        [-5.0873e+00, -3.5988e+00, -5.5916e+00,  ..., -5.4844e-02,\n",
            "         -5.1859e+00, -5.0720e+00],\n",
            "        ...,\n",
            "        [-1.9459e+00, -1.9459e+00, -1.9459e+00,  ..., -1.9459e+00,\n",
            "         -1.9459e+00, -1.9459e+00],\n",
            "        [-2.3936e-01, -3.4976e+00, -4.1415e+00,  ..., -3.5068e+00,\n",
            "         -3.2652e+00, -3.3372e+00],\n",
            "        [-1.3504e+01, -1.3544e+01, -8.1062e-06,  ..., -1.3608e+01,\n",
            "         -1.3282e+01, -1.3516e+01]], grad_fn=<LogSoftmaxBackward0>)\n",
            "Training: 876\n",
            "Epoch: 0877 loss_train: 0.6486 acc_train: 0.8143 loss_val: 0.9862 acc_val: 0.6533 time: 4.0964s\n",
            "loss_val:0.9861829876899719, val_acc:0.6533333333333333, out_features:tensor([[-4.5418, -4.1632, -0.1293,  ..., -3.1989, -4.3823, -4.0211],\n",
            "        [-5.9072, -6.6593, -3.9426,  ..., -4.2714, -0.0468, -4.9446],\n",
            "        [-4.1040, -3.7322, -3.6026,  ..., -0.1500, -4.0075, -3.3051],\n",
            "        ...,\n",
            "        [-2.1240, -0.8974, -2.0275,  ..., -2.6315, -1.9582, -2.5137],\n",
            "        [-0.1914, -2.8263, -4.4925,  ..., -3.5720, -3.0404, -4.1021],\n",
            "        [-6.4450, -6.6908, -0.0223,  ..., -4.1220, -6.5272, -7.1598]],\n",
            "       grad_fn=<LogSoftmaxBackward0>)\n",
            "Training: 877\n",
            "Epoch: 0878 loss_train: 0.6561 acc_train: 0.7857 loss_val: 0.9966 acc_val: 0.6867 time: 4.1806s\n",
            "loss_val:0.9965853691101074, val_acc:0.6866666666666666, out_features:tensor([[-6.4442, -6.7454, -0.0311,  ..., -6.6215, -6.7890, -3.7438],\n",
            "        [-1.7252, -2.4974, -2.3405,  ..., -2.0904, -1.2474, -1.8786],\n",
            "        [-3.9217, -4.8453, -4.9833,  ..., -0.0696, -4.5807, -4.0755],\n",
            "        ...,\n",
            "        [-2.3233, -0.7316, -2.3578,  ..., -2.7819, -2.2689, -2.4027],\n",
            "        [-0.3993, -2.9263, -3.3651,  ..., -2.9163, -2.4217, -3.4756],\n",
            "        [-1.9459, -1.9459, -1.9459,  ..., -1.9459, -1.9459, -1.9459]],\n",
            "       grad_fn=<LogSoftmaxBackward0>)\n",
            "Training: 878\n",
            "Epoch: 0879 loss_train: 0.5848 acc_train: 0.8286 loss_val: 1.0008 acc_val: 0.6800 time: 4.3251s\n",
            "loss_val:1.0007847547531128, val_acc:0.68, out_features:tensor([[-1.9459e+00, -1.9459e+00, -1.9459e+00,  ..., -1.9459e+00,\n",
            "         -1.9459e+00, -1.9459e+00],\n",
            "        [-1.9459e+00, -1.9459e+00, -1.9459e+00,  ..., -1.9459e+00,\n",
            "         -1.9459e+00, -1.9459e+00],\n",
            "        [-1.9459e+00, -1.9459e+00, -1.9459e+00,  ..., -1.9459e+00,\n",
            "         -1.9459e+00, -1.9459e+00],\n",
            "        ...,\n",
            "        [-3.7247e+00, -1.6375e-01, -4.2388e+00,  ..., -3.6779e+00,\n",
            "         -4.2277e+00, -4.2115e+00],\n",
            "        [-6.3481e-01, -2.8403e+00, -2.9226e+00,  ..., -2.7401e+00,\n",
            "         -1.6968e+00, -2.9022e+00],\n",
            "        [-8.3643e+00, -7.8888e+00, -4.1309e-03,  ..., -8.1960e+00,\n",
            "         -8.2068e+00, -8.0805e+00]], grad_fn=<LogSoftmaxBackward0>)\n",
            "Training: 879\n",
            "Epoch: 0880 loss_train: 0.5393 acc_train: 0.8214 loss_val: 0.9444 acc_val: 0.6867 time: 4.0591s\n",
            "loss_val:0.9443808794021606, val_acc:0.6866666666666666, out_features:tensor([[-5.6402, -6.0408, -0.0536,  ..., -6.0931, -5.9637, -5.1494],\n",
            "        [-1.9459, -1.9459, -1.9459,  ..., -1.9459, -1.9459, -1.9459],\n",
            "        [-5.8070, -5.6828, -5.2928,  ..., -0.0298, -5.1082, -4.6848],\n",
            "        ...,\n",
            "        [-3.5050, -0.0959, -5.0937,  ..., -3.5550, -4.1973, -5.0765],\n",
            "        [-1.4580, -2.0611, -2.5188,  ..., -1.5726, -1.8078, -2.1719],\n",
            "        [-3.9632, -5.4103, -0.0772,  ..., -5.4042, -3.4699, -4.6645]],\n",
            "       grad_fn=<LogSoftmaxBackward0>)\n",
            "Training: 880\n",
            "Epoch: 0881 loss_train: 0.5542 acc_train: 0.8357 loss_val: 0.9405 acc_val: 0.6933 time: 4.1733s\n",
            "loss_val:0.940481960773468, val_acc:0.6933333333333334, out_features:tensor([[-1.0131e+01, -9.9259e+00, -7.5824e-04,  ..., -9.6278e+00,\n",
            "         -1.0102e+01, -9.3886e+00],\n",
            "        [-2.9699e+00, -5.7884e+00, -5.6972e+00,  ..., -3.7135e+00,\n",
            "         -1.6616e-01, -2.6887e+00],\n",
            "        [-3.3023e+00, -3.6333e+00, -5.1410e+00,  ..., -1.0137e-01,\n",
            "         -4.3048e+00, -4.8133e+00],\n",
            "        ...,\n",
            "        [-2.4596e+00, -6.8011e-01, -2.2825e+00,  ..., -2.7444e+00,\n",
            "         -2.1985e+00, -2.9866e+00],\n",
            "        [-2.6429e-01, -3.5583e+00, -3.7566e+00,  ..., -2.7202e+00,\n",
            "         -3.1024e+00, -3.1110e+00],\n",
            "        [-4.2233e+00, -5.0541e+00, -1.2210e-01,  ..., -5.1378e+00,\n",
            "         -2.8852e+00, -3.5947e+00]], grad_fn=<LogSoftmaxBackward0>)\n",
            "Training: 881\n",
            "Epoch: 0882 loss_train: 0.7209 acc_train: 0.7714 loss_val: 1.0332 acc_val: 0.6767 time: 4.4370s\n",
            "loss_val:1.0331813097000122, val_acc:0.6766666666666666, out_features:tensor([[-2.6697, -2.8007, -0.7285,  ..., -2.2486, -2.5924, -2.3249],\n",
            "        [-1.4225, -6.3380, -6.3374,  ..., -5.6268, -0.3537, -3.0388],\n",
            "        [-6.5489, -4.5687, -4.8607,  ..., -0.0232, -6.5194, -6.8423],\n",
            "        ...,\n",
            "        [-4.1199, -0.1872, -3.7034,  ..., -3.7660, -3.8810, -3.4679],\n",
            "        [-0.3446, -3.5214, -3.7911,  ..., -1.9277, -3.2422, -3.5653],\n",
            "        [-2.7360, -3.6088, -0.3985,  ..., -3.5735, -2.7335, -2.5900]],\n",
            "       grad_fn=<LogSoftmaxBackward0>)\n",
            "Training: 882\n",
            "Epoch: 0883 loss_train: 0.5495 acc_train: 0.8714 loss_val: 0.9616 acc_val: 0.6967 time: 4.0267s\n",
            "loss_val:0.9616283178329468, val_acc:0.6966666666666667, out_features:tensor([[-4.5612, -4.6448, -0.1404,  ..., -3.5738, -4.3462, -4.0707],\n",
            "        [-1.9459, -1.9459, -1.9459,  ..., -1.9459, -1.9459, -1.9459],\n",
            "        [-4.3969, -4.6706, -4.8837,  ..., -0.0655, -4.3951, -4.1392],\n",
            "        ...,\n",
            "        [-1.7852, -1.6476, -2.1505,  ..., -1.9600, -2.2330, -1.6195],\n",
            "        [-0.3907, -3.3470, -3.3811,  ..., -2.5309, -2.4058, -2.9078],\n",
            "        [-5.2071, -4.5235, -0.0344,  ..., -5.3174, -5.3009, -5.5430]],\n",
            "       grad_fn=<LogSoftmaxBackward0>)\n",
            "Training: 883\n",
            "Epoch: 0884 loss_train: 0.6865 acc_train: 0.7714 loss_val: 1.1129 acc_val: 0.6533 time: 4.2705s\n",
            "loss_val:1.1129361391067505, val_acc:0.6533333333333333, out_features:tensor([[-1.9459, -1.9459, -1.9459,  ..., -1.9459, -1.9459, -1.9459],\n",
            "        [-2.1111, -3.0956, -2.7310,  ..., -2.0818, -0.7165, -2.1232],\n",
            "        [-7.0829, -6.4179, -4.9927,  ..., -0.0117, -6.9859, -7.1150],\n",
            "        ...,\n",
            "        [-3.6810, -0.2424, -2.7953,  ..., -3.6180, -2.8138, -3.8943],\n",
            "        [-0.3537, -3.3328, -3.8409,  ..., -3.4944, -2.0904, -2.7439],\n",
            "        [-1.9459, -1.9459, -1.9459,  ..., -1.9459, -1.9459, -1.9459]],\n",
            "       grad_fn=<LogSoftmaxBackward0>)\n",
            "Training: 884\n",
            "Epoch: 0885 loss_train: 0.6568 acc_train: 0.8143 loss_val: 1.0560 acc_val: 0.6867 time: 4.3098s\n",
            "loss_val:1.055974006652832, val_acc:0.6866666666666666, out_features:tensor([[-9.7944e+00, -9.5979e+00, -1.0862e-03,  ..., -8.7384e+00,\n",
            "         -9.7836e+00, -9.1688e+00],\n",
            "        [-2.6010e+00, -6.5163e+00, -5.3872e+00,  ..., -3.3657e+00,\n",
            "         -4.1670e-01, -1.4938e+00],\n",
            "        [-2.0498e+00, -2.6962e+00, -2.2290e+00,  ..., -8.5779e-01,\n",
            "         -2.2669e+00, -2.2798e+00],\n",
            "        ...,\n",
            "        [-2.4030e+00, -9.3250e-01, -2.4880e+00,  ..., -2.6523e+00,\n",
            "         -1.9606e+00, -1.8419e+00],\n",
            "        [-3.7526e-01, -2.8094e+00, -3.1397e+00,  ..., -2.9995e+00,\n",
            "         -2.4847e+00, -3.2994e+00],\n",
            "        [-8.6636e+00, -9.2732e+00, -7.1607e-04,  ..., -8.8908e+00,\n",
            "         -9.3730e+00, -9.5276e+00]], grad_fn=<LogSoftmaxBackward0>)\n",
            "Training: 885\n",
            "Epoch: 0886 loss_train: 0.5705 acc_train: 0.8429 loss_val: 1.0598 acc_val: 0.6500 time: 4.1651s\n",
            "loss_val:1.0598385334014893, val_acc:0.65, out_features:tensor([[-9.1252e+00, -8.7242e+00, -1.7144e-03,  ..., -8.5293e+00,\n",
            "         -8.9696e+00, -9.0529e+00],\n",
            "        [-1.9459e+00, -1.9459e+00, -1.9459e+00,  ..., -1.9459e+00,\n",
            "         -1.9459e+00, -1.9459e+00],\n",
            "        [-5.6018e+00, -5.5444e+00, -5.3042e+00,  ..., -2.7885e-02,\n",
            "         -5.2271e+00, -4.9978e+00],\n",
            "        ...,\n",
            "        [-3.1826e+00, -4.3113e-01, -3.0479e+00,  ..., -3.3530e+00,\n",
            "         -1.8494e+00, -3.2871e+00],\n",
            "        [-1.0123e-02, -6.5938e+00, -7.5119e+00,  ..., -6.0075e+00,\n",
            "         -5.4662e+00, -7.0343e+00],\n",
            "        [-6.0687e+00, -4.5229e+00, -3.1017e-02,  ..., -5.9312e+00,\n",
            "         -5.4218e+00, -5.0735e+00]], grad_fn=<LogSoftmaxBackward0>)\n",
            "Training: 886\n",
            "Epoch: 0887 loss_train: 0.5139 acc_train: 0.8714 loss_val: 1.0646 acc_val: 0.6500 time: 4.3310s\n",
            "loss_val:1.0646300315856934, val_acc:0.65, out_features:tensor([[-1.4759e+01, -1.4569e+01, -5.3644e-06,  ..., -1.2911e+01,\n",
            "         -1.4765e+01, -1.4487e+01],\n",
            "        [-1.0450e+00, -4.3063e+00, -3.2676e+00,  ..., -3.8070e+00,\n",
            "         -6.6403e-01, -3.1278e+00],\n",
            "        [-4.5704e+00, -4.7253e+00, -3.8685e+00,  ..., -7.1449e-02,\n",
            "         -4.8472e+00, -4.5855e+00],\n",
            "        ...,\n",
            "        [-1.9579e+00, -8.5060e-01, -2.9893e+00,  ..., -1.9508e+00,\n",
            "         -2.1379e+00, -2.5702e+00],\n",
            "        [-5.6289e-01, -2.2127e+00, -3.0178e+00,  ..., -2.6181e+00,\n",
            "         -2.3599e+00, -2.9182e+00],\n",
            "        [-8.9968e+00, -9.5040e+00, -7.4895e-04,  ..., -8.7569e+00,\n",
            "         -9.2412e+00, -9.2875e+00]], grad_fn=<LogSoftmaxBackward0>)\n",
            "Training: 887\n",
            "Epoch: 0888 loss_train: 0.6185 acc_train: 0.8143 loss_val: 1.1095 acc_val: 0.6667 time: 4.2396s\n",
            "loss_val:1.1094980239868164, val_acc:0.6666666666666666, out_features:tensor([[-3.9285, -4.3286, -0.1245,  ..., -3.9669, -4.2869, -3.9843],\n",
            "        [-1.6569, -2.5965, -2.4996,  ..., -1.9759, -1.5400, -1.4662],\n",
            "        [-6.1610, -6.6221, -6.0336,  ..., -0.0096, -6.5685, -6.5305],\n",
            "        ...,\n",
            "        [-4.3240, -0.1169, -4.7470,  ..., -3.6711, -3.8444, -3.4092],\n",
            "        [-0.1172, -3.6202, -4.7510,  ..., -4.5235, -3.3094, -4.0745],\n",
            "        [-5.4547, -3.9509, -0.0589,  ..., -5.1360, -4.7733, -5.0701]],\n",
            "       grad_fn=<LogSoftmaxBackward0>)\n",
            "Training: 888\n",
            "Epoch: 0889 loss_train: 0.5877 acc_train: 0.8286 loss_val: 0.9270 acc_val: 0.6867 time: 4.0482s\n",
            "loss_val:0.9269921779632568, val_acc:0.6866666666666666, out_features:tensor([[-7.2192, -7.1439, -0.0097,  ..., -7.1434, -7.2031, -6.0999],\n",
            "        [-2.1345, -2.7278, -2.7650,  ..., -2.1560, -0.9326, -1.6339],\n",
            "        [-1.9459, -1.9459, -1.9459,  ..., -1.9459, -1.9459, -1.9459],\n",
            "        ...,\n",
            "        [-2.5519, -0.7158, -2.2380,  ..., -2.7641, -2.1056, -2.5730],\n",
            "        [-0.4313, -2.9552, -3.2811,  ..., -2.4234, -2.4658, -2.9614],\n",
            "        [-7.5375, -6.4749, -0.0145,  ..., -7.5784, -7.5764, -4.5238]],\n",
            "       grad_fn=<LogSoftmaxBackward0>)\n",
            "Training: 889\n",
            "Epoch: 0890 loss_train: 0.6954 acc_train: 0.8214 loss_val: 1.0138 acc_val: 0.6600 time: 4.4897s\n",
            "loss_val:1.0137561559677124, val_acc:0.66, out_features:tensor([[-3.1596, -3.2763, -0.6195,  ..., -3.1405, -3.2608, -2.7951],\n",
            "        [-2.6349, -4.5298, -5.6976,  ..., -5.7351, -0.1280, -3.6570],\n",
            "        [-2.6172, -2.5732, -1.9398,  ..., -0.7280, -2.7999, -2.5165],\n",
            "        ...,\n",
            "        [-3.9825, -0.2031, -3.6217,  ..., -3.1240, -3.0096, -3.7637],\n",
            "        [-0.0342, -5.0493, -5.7730,  ..., -4.8943, -4.8121, -5.7514],\n",
            "        [-4.6785, -4.2199, -0.0891,  ..., -4.8668, -3.2060, -5.1463]],\n",
            "       grad_fn=<LogSoftmaxBackward0>)\n",
            "Training: 890\n",
            "Epoch: 0891 loss_train: 0.6062 acc_train: 0.8357 loss_val: 1.0111 acc_val: 0.6800 time: 4.0729s\n",
            "loss_val:1.011085033416748, val_acc:0.68, out_features:tensor([[-1.9459, -1.9459, -1.9459,  ..., -1.9459, -1.9459, -1.9459],\n",
            "        [-1.9459, -1.9459, -1.9459,  ..., -1.9459, -1.9459, -1.9459],\n",
            "        [-6.5468, -5.4090, -4.9780,  ..., -0.0173, -6.5948, -6.4777],\n",
            "        ...,\n",
            "        [-3.8358, -0.2840, -2.2116,  ..., -3.5814, -3.2458, -3.8315],\n",
            "        [-1.1912, -2.4266, -2.0271,  ..., -2.1645, -1.6145, -2.3333],\n",
            "        [-2.4478, -2.4153, -0.9040,  ..., -2.0964, -1.6833, -2.6560]],\n",
            "       grad_fn=<LogSoftmaxBackward0>)\n",
            "Training: 891\n",
            "Epoch: 0892 loss_train: 0.5799 acc_train: 0.8357 loss_val: 0.9781 acc_val: 0.6667 time: 4.1475s\n",
            "loss_val:0.9781388640403748, val_acc:0.6666666666666666, out_features:tensor([[-5.9939, -5.7647, -0.0555,  ..., -5.1766, -5.9344, -5.8709],\n",
            "        [-1.9459, -1.9459, -1.9459,  ..., -1.9459, -1.9459, -1.9459],\n",
            "        [-2.5093, -2.5399, -2.7505,  ..., -0.7056, -2.2157, -2.1925],\n",
            "        ...,\n",
            "        [-6.3769, -0.0123, -6.7163,  ..., -6.9960, -5.0850, -6.6573],\n",
            "        [-0.4949, -2.7641, -3.3112,  ..., -2.3463, -2.1546, -3.1269],\n",
            "        [-4.3198, -3.9354, -0.1503,  ..., -3.1466, -3.7824, -3.6091]],\n",
            "       grad_fn=<LogSoftmaxBackward0>)\n",
            "Training: 892\n",
            "Epoch: 0893 loss_train: 0.4541 acc_train: 0.8857 loss_val: 1.1438 acc_val: 0.6367 time: 4.4500s\n",
            "loss_val:1.1437880992889404, val_acc:0.6366666666666667, out_features:tensor([[-3.9605, -3.9167, -0.2834,  ..., -3.4254, -4.0229, -3.9126],\n",
            "        [-1.5987, -3.8665, -3.9860,  ..., -2.4205, -0.4657, -3.7395],\n",
            "        [-5.6820, -5.4018, -5.0805,  ..., -0.0328, -5.1661, -4.6218],\n",
            "        ...,\n",
            "        [-2.5587, -0.8332, -2.2098,  ..., -1.7762, -2.4331, -2.5766],\n",
            "        [-0.9257, -2.3349, -2.6732,  ..., -2.1829, -1.9783, -2.1938],\n",
            "        [-4.5880, -4.8390, -0.1073,  ..., -3.5765, -3.9125, -3.5457]],\n",
            "       grad_fn=<LogSoftmaxBackward0>)\n",
            "Training: 893\n",
            "Epoch: 0894 loss_train: 0.5603 acc_train: 0.8643 loss_val: 1.1243 acc_val: 0.6533 time: 4.2004s\n",
            "loss_val:1.1242765188217163, val_acc:0.6533333333333333, out_features:tensor([[-3.2596e+00, -3.1481e+00, -6.6329e-01,  ..., -2.3198e+00,\n",
            "         -3.1973e+00, -2.2903e+00],\n",
            "        [-1.4355e+00, -2.8801e+00, -2.2094e+00,  ..., -3.1141e+00,\n",
            "         -1.1026e+00, -1.8358e+00],\n",
            "        [-8.8173e+00, -7.3395e+00, -8.8975e+00,  ..., -1.3395e-03,\n",
            "         -8.7440e+00, -8.8616e+00],\n",
            "        ...,\n",
            "        [-4.9946e+00, -7.5883e-02, -5.2987e+00,  ..., -3.2111e+00,\n",
            "         -4.3686e+00, -5.4375e+00],\n",
            "        [-9.7402e-01, -2.0052e+00, -2.6470e+00,  ..., -2.2729e+00,\n",
            "         -1.9323e+00, -2.6643e+00],\n",
            "        [-5.4154e+00, -5.0533e+00, -2.0215e-02,  ..., -6.6686e+00,\n",
            "         -5.1585e+00, -6.8565e+00]], grad_fn=<LogSoftmaxBackward0>)\n",
            "Training: 894\n",
            "Epoch: 0895 loss_train: 0.5367 acc_train: 0.8357 loss_val: 1.0527 acc_val: 0.6600 time: 4.1058s\n",
            "loss_val:1.0526878833770752, val_acc:0.66, out_features:tensor([[-9.4204e+00, -9.4170e+00, -7.9052e-04,  ..., -8.4145e+00,\n",
            "         -9.4494e+00, -8.7686e+00],\n",
            "        [-3.3200e+00, -3.0989e+00, -2.8542e+00,  ..., -3.3842e+00,\n",
            "         -1.2048e+00, -2.0983e+00],\n",
            "        [-2.6039e+00, -2.3407e+00, -2.5217e+00,  ..., -7.1846e-01,\n",
            "         -2.6884e+00, -2.0924e+00],\n",
            "        ...,\n",
            "        [-5.2202e+00, -4.4094e-02, -5.1781e+00,  ..., -4.9187e+00,\n",
            "         -4.6775e+00, -5.0753e+00],\n",
            "        [-1.5491e-01, -4.4943e+00, -4.1164e+00,  ..., -3.1335e+00,\n",
            "         -3.1048e+00, -4.3237e+00],\n",
            "        [-2.6128e+00, -2.8267e+00, -8.3327e-01,  ..., -3.2174e+00,\n",
            "         -2.5514e+00, -2.2745e+00]], grad_fn=<LogSoftmaxBackward0>)\n",
            "Training: 895\n",
            "Epoch: 0896 loss_train: 0.5418 acc_train: 0.8357 loss_val: 1.0469 acc_val: 0.6500 time: 4.3690s\n",
            "loss_val:1.0468685626983643, val_acc:0.65, out_features:tensor([[-5.0276, -4.3360, -0.0770,  ..., -3.7699, -4.7853, -4.8126],\n",
            "        [-1.8598, -1.9018, -2.0506,  ..., -1.9219, -1.9781, -1.9472],\n",
            "        [-2.7835, -2.8345, -2.1013,  ..., -0.6730, -2.8329, -1.9872],\n",
            "        ...,\n",
            "        [-1.9459, -1.9459, -1.9459,  ..., -1.9459, -1.9459, -1.9459],\n",
            "        [-1.9459, -1.9459, -1.9459,  ..., -1.9459, -1.9459, -1.9459],\n",
            "        [-3.6112, -3.3187, -0.3347,  ..., -3.6173, -2.4421, -2.6481]],\n",
            "       grad_fn=<LogSoftmaxBackward0>)\n",
            "Training: 896\n",
            "Epoch: 0897 loss_train: 0.5663 acc_train: 0.8286 loss_val: 1.0297 acc_val: 0.7000 time: 4.1982s\n",
            "loss_val:1.029680848121643, val_acc:0.7, out_features:tensor([[-7.2233, -6.9771, -0.0134,  ..., -7.0209, -7.0239, -6.7942],\n",
            "        [-1.5417, -3.6088, -2.7309,  ..., -2.5460, -0.9040, -1.6835],\n",
            "        [-2.4919, -3.0521, -2.7928,  ..., -0.3993, -3.0278, -2.8584],\n",
            "        ...,\n",
            "        [-2.5779, -0.6834, -2.7416,  ..., -3.0483, -1.5295, -2.7563],\n",
            "        [-1.4377, -2.3592, -2.6367,  ..., -2.6281, -1.3447, -2.2053],\n",
            "        [-2.0495, -2.8010, -0.7477,  ..., -2.1751, -2.4156, -2.4376]],\n",
            "       grad_fn=<LogSoftmaxBackward0>)\n",
            "Training: 897\n",
            "Epoch: 0898 loss_train: 0.6014 acc_train: 0.8214 loss_val: 1.0844 acc_val: 0.6367 time: 4.1325s\n",
            "loss_val:1.084415078163147, val_acc:0.6366666666666667, out_features:tensor([[-2.6197e+00, -2.2920e+00, -9.0569e-01,  ..., -2.0570e+00,\n",
            "         -2.3048e+00, -2.5069e+00],\n",
            "        [-1.9377e+00, -3.3036e+00, -3.3005e+00,  ..., -1.7229e+00,\n",
            "         -7.5442e-01, -2.2480e+00],\n",
            "        [-6.4802e+00, -6.3727e+00, -6.2090e+00,  ..., -7.3021e-03,\n",
            "         -7.1544e+00, -7.3266e+00],\n",
            "        ...,\n",
            "        [-3.7327e+00, -8.4950e-02, -5.0845e+00,  ..., -3.5544e+00,\n",
            "         -4.4861e+00, -5.1125e+00],\n",
            "        [-1.6277e-03, -8.5594e+00, -9.6921e+00,  ..., -8.4668e+00,\n",
            "         -6.9398e+00, -8.9236e+00],\n",
            "        [-3.0059e+00, -3.2212e+00, -4.2415e-01,  ..., -2.1717e+00,\n",
            "         -2.4430e+00, -3.4251e+00]], grad_fn=<LogSoftmaxBackward0>)\n",
            "Training: 898\n",
            "Epoch: 0899 loss_train: 0.5949 acc_train: 0.8071 loss_val: 1.1458 acc_val: 0.6500 time: 4.3273s\n",
            "loss_val:1.1458202600479126, val_acc:0.65, out_features:tensor([[-1.9459, -1.9459, -1.9459,  ..., -1.9459, -1.9459, -1.9459],\n",
            "        [-5.0711, -6.8825, -7.3367,  ..., -6.8950, -0.0135, -5.5937],\n",
            "        [-2.8000, -2.7866, -2.4139,  ..., -0.4124, -3.1829, -2.9666],\n",
            "        ...,\n",
            "        [-1.9459, -1.9459, -1.9459,  ..., -1.9459, -1.9459, -1.9459],\n",
            "        [-0.0110, -6.0290, -7.0460,  ..., -5.6192, -6.0888, -7.0183],\n",
            "        [-1.9459, -1.9459, -1.9459,  ..., -1.9459, -1.9459, -1.9459]],\n",
            "       grad_fn=<LogSoftmaxBackward0>)\n",
            "Training: 899\n",
            "Epoch: 0900 loss_train: 0.6005 acc_train: 0.8214 loss_val: 1.0858 acc_val: 0.6700 time: 4.1571s\n",
            "loss_val:1.0857844352722168, val_acc:0.67, out_features:tensor([[-5.9400, -5.4765, -0.0421,  ..., -3.7959, -5.9608, -5.2206],\n",
            "        [-2.4326, -3.9342, -2.5790,  ..., -2.9234, -0.3508, -3.3836],\n",
            "        [-6.5465, -6.3317, -5.7833,  ..., -0.0125, -6.3520, -5.7599],\n",
            "        ...,\n",
            "        [-6.2503, -0.0162, -6.4202,  ..., -5.3445, -5.6291, -6.0207],\n",
            "        [-0.8642, -2.4352, -2.6997,  ..., -2.2047, -2.0197, -2.3818],\n",
            "        [-3.2367, -3.1453, -0.3092,  ..., -3.2271, -3.4808, -3.7562]],\n",
            "       grad_fn=<LogSoftmaxBackward0>)\n",
            "Training: 900\n",
            "Epoch: 0901 loss_train: 0.5376 acc_train: 0.8714 loss_val: 0.9932 acc_val: 0.6867 time: 4.2396s\n",
            "loss_val:0.993195116519928, val_acc:0.6866666666666666, out_features:tensor([[-5.4446, -4.6113, -0.0470,  ..., -4.5862, -5.0638, -5.2374],\n",
            "        [-2.5308, -4.2600, -2.6793,  ..., -4.3699, -0.3007, -2.7228],\n",
            "        [-2.8820, -2.8456, -2.9474,  ..., -0.4875, -2.2804, -2.6549],\n",
            "        ...,\n",
            "        [-5.3535, -0.0388, -5.4531,  ..., -4.1990, -5.0903, -5.3909],\n",
            "        [-0.7303, -3.4449, -3.6707,  ..., -2.6684, -1.7796, -2.2517],\n",
            "        [-2.6083, -3.3264, -0.6594,  ..., -3.5379, -2.8989, -1.4514]],\n",
            "       grad_fn=<LogSoftmaxBackward0>)\n",
            "Training: 901\n",
            "Epoch: 0902 loss_train: 0.6622 acc_train: 0.8071 loss_val: 0.9543 acc_val: 0.6700 time: 4.3648s\n",
            "loss_val:0.9542562961578369, val_acc:0.67, out_features:tensor([[-5.2184e+00, -5.4193e+00, -5.0508e-02,  ..., -4.1262e+00,\n",
            "         -4.9150e+00, -5.1076e+00],\n",
            "        [-1.9459e+00, -1.9459e+00, -1.9459e+00,  ..., -1.9459e+00,\n",
            "         -1.9459e+00, -1.9459e+00],\n",
            "        [-4.0201e+00, -2.9683e+00, -3.9053e+00,  ..., -1.4711e-01,\n",
            "         -4.0896e+00, -3.9198e+00],\n",
            "        ...,\n",
            "        [-7.2856e+00, -5.5368e-03, -7.5436e+00,  ..., -6.2855e+00,\n",
            "         -6.7237e+00, -7.2378e+00],\n",
            "        [-3.6434e-03, -7.8458e+00, -8.1587e+00,  ..., -6.9096e+00,\n",
            "         -6.8876e+00, -7.3656e+00],\n",
            "        [-5.8449e+00, -5.6413e+00, -3.6712e-02,  ..., -3.6262e+00,\n",
            "         -6.7993e+00, -6.9388e+00]], grad_fn=<LogSoftmaxBackward0>)\n",
            "Training: 902\n",
            "Epoch: 0903 loss_train: 0.5797 acc_train: 0.8500 loss_val: 1.0914 acc_val: 0.6367 time: 4.1970s\n",
            "loss_val:1.0913832187652588, val_acc:0.6366666666666667, out_features:tensor([[-4.1142, -3.9423, -0.2218,  ..., -3.2806, -4.1190, -3.3932],\n",
            "        [-2.0944, -2.6035, -1.0702,  ..., -2.9518, -1.3675, -2.7539],\n",
            "        [-4.5664, -3.7864, -5.3547,  ..., -0.0669, -4.2426, -4.8455],\n",
            "        ...,\n",
            "        [-4.9300, -0.0544, -5.3463,  ..., -3.6530, -5.1726, -5.1674],\n",
            "        [-0.0596, -5.4076, -5.5478,  ..., -3.6316, -4.4198, -5.3536],\n",
            "        [-5.4967, -5.0481, -0.0423,  ..., -4.9495, -5.6411, -4.2077]],\n",
            "       grad_fn=<LogSoftmaxBackward0>)\n",
            "Training: 903\n",
            "Epoch: 0904 loss_train: 0.5668 acc_train: 0.8286 loss_val: 1.0614 acc_val: 0.6800 time: 4.2956s\n",
            "loss_val:1.0613583326339722, val_acc:0.68, out_features:tensor([[-5.9780, -5.7904, -0.0220,  ..., -6.1854, -5.4758, -5.6259],\n",
            "        [-2.4830, -2.6196, -2.0438,  ..., -2.7156, -1.1272, -1.3352],\n",
            "        [-2.6999, -1.9224, -1.9478,  ..., -0.7688, -2.6819, -2.7202],\n",
            "        ...,\n",
            "        [-2.4884, -0.9514, -2.7318,  ..., -1.7509, -2.0840, -2.1894],\n",
            "        [-0.0324, -6.5595, -6.9719,  ..., -6.6916, -5.1465, -3.8398],\n",
            "        [-3.6003, -3.7106, -0.1980,  ..., -2.9076, -3.6990, -3.6893]],\n",
            "       grad_fn=<LogSoftmaxBackward0>)\n",
            "Training: 904\n",
            "Epoch: 0905 loss_train: 0.6248 acc_train: 0.8143 loss_val: 1.0451 acc_val: 0.6300 time: 4.2471s\n",
            "loss_val:1.0451470613479614, val_acc:0.63, out_features:tensor([[-4.6628e+00, -4.7251e+00, -1.0381e-01,  ..., -3.9172e+00,\n",
            "         -4.8943e+00, -3.5876e+00],\n",
            "        [-7.0979e+00, -7.2511e+00, -8.4560e+00,  ..., -8.3820e+00,\n",
            "         -6.3794e-03, -5.8813e+00],\n",
            "        [-3.6800e+00, -3.1943e+00, -2.6255e+00,  ..., -2.6407e-01,\n",
            "         -3.4397e+00, -3.4026e+00],\n",
            "        ...,\n",
            "        [-4.0321e+00, -1.3088e-01, -3.9577e+00,  ..., -3.0729e+00,\n",
            "         -3.9343e+00, -4.4838e+00],\n",
            "        [-3.4146e-02, -6.4133e+00, -6.6778e+00,  ..., -4.8015e+00,\n",
            "         -3.9637e+00, -6.1194e+00],\n",
            "        [-3.5916e+00, -2.5160e+00, -2.8808e-01,  ..., -3.2800e+00,\n",
            "         -3.2493e+00, -3.1268e+00]], grad_fn=<LogSoftmaxBackward0>)\n",
            "Training: 905\n",
            "Epoch: 0906 loss_train: 0.6118 acc_train: 0.8429 loss_val: 1.0758 acc_val: 0.6867 time: 4.1505s\n",
            "loss_val:1.0757558345794678, val_acc:0.6866666666666666, out_features:tensor([[-5.6067, -5.4712, -0.0619,  ..., -3.3511, -5.2676, -5.3250],\n",
            "        [-1.9459, -1.9459, -1.9459,  ..., -1.9459, -1.9459, -1.9459],\n",
            "        [-6.4078, -5.2827, -6.7260,  ..., -0.0123, -6.4192, -6.4888],\n",
            "        ...,\n",
            "        [-2.4567, -0.6610, -2.7816,  ..., -2.1419, -2.1871, -2.9432],\n",
            "        [-1.2794, -2.0884, -2.1124,  ..., -2.0579, -2.1008, -2.0440],\n",
            "        [-4.5401, -5.3015, -0.0670,  ..., -3.6711, -4.2302, -5.3746]],\n",
            "       grad_fn=<LogSoftmaxBackward0>)\n",
            "Training: 906\n",
            "Epoch: 0907 loss_train: 0.6011 acc_train: 0.8071 loss_val: 1.0330 acc_val: 0.6833 time: 4.2881s\n",
            "loss_val:1.0330100059509277, val_acc:0.6833333333333333, out_features:tensor([[-8.3067e+00, -7.4576e+00, -2.5827e-03,  ..., -7.3029e+00,\n",
            "         -8.1650e+00, -8.1566e+00],\n",
            "        [-1.9459e+00, -1.9459e+00, -1.9459e+00,  ..., -1.9459e+00,\n",
            "         -1.9459e+00, -1.9459e+00],\n",
            "        [-5.4360e+00, -4.9579e+00, -4.4313e+00,  ..., -4.1690e-02,\n",
            "         -5.1188e+00, -4.8365e+00],\n",
            "        ...,\n",
            "        [-8.4664e+00, -2.7772e-03, -7.8581e+00,  ..., -6.4421e+00,\n",
            "         -8.4733e+00, -8.5788e+00],\n",
            "        [-4.5879e-01, -2.0710e+00, -3.7370e+00,  ..., -2.9015e+00,\n",
            "         -3.0805e+00, -2.3655e+00],\n",
            "        [-1.9459e+00, -1.9459e+00, -1.9459e+00,  ..., -1.9459e+00,\n",
            "         -1.9459e+00, -1.9459e+00]], grad_fn=<LogSoftmaxBackward0>)\n",
            "Training: 907\n",
            "Epoch: 0908 loss_train: 0.5294 acc_train: 0.8500 loss_val: 0.9799 acc_val: 0.6767 time: 4.2565s\n",
            "loss_val:0.9799057245254517, val_acc:0.6766666666666666, out_features:tensor([[-6.1229e+00, -5.9905e+00, -2.3122e-02,  ..., -5.8964e+00,\n",
            "         -5.4463e+00, -6.1345e+00],\n",
            "        [-1.5951e+00, -2.9895e+00, -1.9444e+00,  ..., -3.4805e+00,\n",
            "         -8.1049e-01, -3.3291e+00],\n",
            "        [-4.4967e+00, -4.0865e+00, -4.2584e+00,  ..., -7.1542e-02,\n",
            "         -4.5035e+00, -4.7343e+00],\n",
            "        ...,\n",
            "        [-8.0511e+00, -2.8919e-03, -7.8581e+00,  ..., -7.9639e+00,\n",
            "         -7.0084e+00, -7.3567e+00],\n",
            "        [-9.9897e-01, -2.2819e+00, -2.9408e+00,  ..., -2.0869e+00,\n",
            "         -1.8525e+00, -2.0737e+00],\n",
            "        [-2.5528e+00, -2.4861e+00, -1.0291e+00,  ..., -2.8516e+00,\n",
            "         -2.4720e+00, -2.1857e+00]], grad_fn=<LogSoftmaxBackward0>)\n",
            "Training: 908\n",
            "Epoch: 0909 loss_train: 0.5882 acc_train: 0.8286 loss_val: 1.0711 acc_val: 0.6600 time: 4.1438s\n",
            "loss_val:1.0710750818252563, val_acc:0.66, out_features:tensor([[-6.3229, -6.3094, -0.0136,  ..., -6.3737, -6.3475, -6.0584],\n",
            "        [-1.9459, -1.9459, -1.9459,  ..., -1.9459, -1.9459, -1.9459],\n",
            "        [-3.8428, -3.7516, -3.7590,  ..., -0.1064, -4.1846, -4.7019],\n",
            "        ...,\n",
            "        [-2.9494, -0.6200, -2.4375,  ..., -2.9470, -2.0411, -2.2776],\n",
            "        [-1.9459, -1.9459, -1.9459,  ..., -1.9459, -1.9459, -1.9459],\n",
            "        [-5.1570, -5.7849, -0.0159,  ..., -6.5411, -6.1233, -6.3677]],\n",
            "       grad_fn=<LogSoftmaxBackward0>)\n",
            "Training: 909\n",
            "Epoch: 0910 loss_train: 0.5351 acc_train: 0.8143 loss_val: 1.0947 acc_val: 0.6500 time: 4.4672s\n",
            "loss_val:1.094722032546997, val_acc:0.65, out_features:tensor([[-6.7029e+00, -6.9826e+00, -1.0448e-02,  ..., -6.5978e+00,\n",
            "         -6.8532e+00, -6.6936e+00],\n",
            "        [-2.6428e+00, -4.8975e+00, -4.8556e+00,  ..., -2.0833e+00,\n",
            "         -4.6278e-01, -1.8768e+00],\n",
            "        [-9.6236e+00, -8.5176e+00, -7.6268e+00,  ..., -9.0772e-04,\n",
            "         -9.7326e+00, -9.9398e+00],\n",
            "        ...,\n",
            "        [-1.9459e+00, -1.9459e+00, -1.9459e+00,  ..., -1.9459e+00,\n",
            "         -1.9459e+00, -1.9459e+00],\n",
            "        [-3.6003e-01, -2.3608e+00, -3.7383e+00,  ..., -2.5644e+00,\n",
            "         -2.8225e+00, -3.6718e+00],\n",
            "        [-2.3887e+00, -3.7547e+00, -4.5023e-01,  ..., -3.3203e+00,\n",
            "         -2.3519e+00, -2.4417e+00]], grad_fn=<LogSoftmaxBackward0>)\n",
            "Training: 910\n",
            "Epoch: 0911 loss_train: 0.6341 acc_train: 0.7857 loss_val: 1.0334 acc_val: 0.6567 time: 4.1681s\n",
            "loss_val:1.0333918333053589, val_acc:0.6566666666666666, out_features:tensor([[-1.7263e+01, -1.7080e+01, -1.5497e-06,  ..., -1.3432e+01,\n",
            "         -1.7204e+01, -1.7253e+01],\n",
            "        [-1.9459e+00, -1.9459e+00, -1.9459e+00,  ..., -1.9459e+00,\n",
            "         -1.9459e+00, -1.9459e+00],\n",
            "        [-3.4340e+00, -3.5977e+00, -3.1360e+00,  ..., -2.2073e-01,\n",
            "         -3.3117e+00, -3.4717e+00],\n",
            "        ...,\n",
            "        [-2.0378e+00, -1.0115e+00, -2.1596e+00,  ..., -2.3226e+00,\n",
            "         -2.0621e+00, -2.3202e+00],\n",
            "        [-3.3354e-01, -3.1514e+00, -2.8201e+00,  ..., -3.6351e+00,\n",
            "         -2.8269e+00, -2.9104e+00],\n",
            "        [-4.7803e+00, -4.3980e+00, -1.0172e-01,  ..., -4.8094e+00,\n",
            "         -3.6783e+00, -3.5641e+00]], grad_fn=<LogSoftmaxBackward0>)\n",
            "Training: 911\n",
            "Epoch: 0912 loss_train: 0.5648 acc_train: 0.8214 loss_val: 1.0614 acc_val: 0.6467 time: 4.0987s\n",
            "loss_val:1.0613644123077393, val_acc:0.6466666666666666, out_features:tensor([[-9.9900e+00, -9.8716e+00, -4.0773e-04,  ..., -9.5219e+00,\n",
            "         -9.8722e+00, -9.2796e+00],\n",
            "        [-4.3235e+00, -4.2278e+00, -4.5679e+00,  ..., -3.3144e+00,\n",
            "         -2.5530e-01, -1.9381e+00],\n",
            "        [-6.7419e+00, -5.4237e+00, -6.6700e+00,  ..., -1.1228e-02,\n",
            "         -6.2863e+00, -6.6960e+00],\n",
            "        ...,\n",
            "        [-3.5704e+00, -2.9016e-01, -2.3896e+00,  ..., -3.3853e+00,\n",
            "         -2.8918e+00, -3.6290e+00],\n",
            "        [-7.9536e-01, -2.5311e+00, -2.6264e+00,  ..., -2.1949e+00,\n",
            "         -2.0224e+00, -2.4002e+00],\n",
            "        [-3.8274e+00, -3.7469e+00, -1.7218e-01,  ..., -3.0028e+00,\n",
            "         -4.0850e+00, -4.1613e+00]], grad_fn=<LogSoftmaxBackward0>)\n",
            "Training: 912\n",
            "Epoch: 0913 loss_train: 0.5334 acc_train: 0.8714 loss_val: 0.9977 acc_val: 0.6800 time: 4.3681s\n",
            "loss_val:0.9977198243141174, val_acc:0.68, out_features:tensor([[-3.6332e+00, -3.5907e+00, -1.8154e-01,  ..., -3.7391e+00,\n",
            "         -3.9114e+00, -3.6709e+00],\n",
            "        [-1.9459e+00, -1.9459e+00, -1.9459e+00,  ..., -1.9459e+00,\n",
            "         -1.9459e+00, -1.9459e+00],\n",
            "        [-1.1030e+01, -1.1189e+01, -1.0058e+01,  ..., -1.1634e-04,\n",
            "         -1.1006e+01, -1.1096e+01],\n",
            "        ...,\n",
            "        [-2.4564e+00, -1.1196e+00, -2.2399e+00,  ..., -2.1845e+00,\n",
            "         -2.0579e+00, -2.0560e+00],\n",
            "        [-1.5236e+00, -2.3648e+00, -2.4526e+00,  ..., -1.7698e+00,\n",
            "         -1.4591e+00, -2.1891e+00],\n",
            "        [-4.8526e+00, -4.8976e+00, -4.6291e-02,  ..., -5.8902e+00,\n",
            "         -3.9894e+00, -5.0975e+00]], grad_fn=<LogSoftmaxBackward0>)\n",
            "Training: 913\n",
            "Epoch: 0914 loss_train: 0.5826 acc_train: 0.8000 loss_val: 1.0043 acc_val: 0.7100 time: 4.0551s\n",
            "loss_val:1.0043455362319946, val_acc:0.71, out_features:tensor([[-3.0476, -3.0634, -0.3356,  ..., -2.7713, -3.0628, -3.2154],\n",
            "        [-6.2263, -6.9016, -3.7657,  ..., -6.8087, -0.0308, -6.2880],\n",
            "        [-4.6850, -4.4514, -5.1502,  ..., -0.0601, -4.2876, -4.4525],\n",
            "        ...,\n",
            "        [-5.3680, -0.0325, -5.7563,  ..., -5.0250, -4.5164, -5.6959],\n",
            "        [-0.4153, -3.1550, -3.3162,  ..., -3.1443, -3.3663, -2.4325],\n",
            "        [-5.4888, -4.0129, -0.0469,  ..., -5.0455, -5.0449, -5.6140]],\n",
            "       grad_fn=<LogSoftmaxBackward0>)\n",
            "Training: 914\n",
            "Epoch: 0915 loss_train: 0.5646 acc_train: 0.8429 loss_val: 1.0489 acc_val: 0.6600 time: 4.1353s\n",
            "loss_val:1.0489009618759155, val_acc:0.66, out_features:tensor([[-4.8335, -4.6739, -0.0568,  ..., -4.5347, -4.7987, -4.5321],\n",
            "        [-1.8443, -2.7625, -2.7601,  ..., -2.2303, -1.1786, -1.5188],\n",
            "        [-1.9459, -1.9459, -1.9459,  ..., -1.9459, -1.9459, -1.9459],\n",
            "        ...,\n",
            "        [-2.7923, -0.3725, -2.7854,  ..., -2.8564, -2.8907, -3.2519],\n",
            "        [-0.9714, -2.1085, -2.2136,  ..., -1.9730, -2.5743, -2.1718],\n",
            "        [-5.4528, -5.6787, -0.0328,  ..., -5.5681, -4.2507, -5.6359]],\n",
            "       grad_fn=<LogSoftmaxBackward0>)\n",
            "Training: 915\n",
            "Epoch: 0916 loss_train: 0.6048 acc_train: 0.8357 loss_val: 1.0408 acc_val: 0.6733 time: 4.4381s\n",
            "loss_val:1.0407580137252808, val_acc:0.6733333333333333, out_features:tensor([[-3.3431, -3.5086, -0.4390,  ..., -2.9849, -3.4840, -2.3646],\n",
            "        [-1.8196, -2.8476, -3.1914,  ..., -2.0591, -0.7494, -2.3012],\n",
            "        [-2.4495, -2.2895, -2.2578,  ..., -0.6927, -2.6235, -2.4839],\n",
            "        ...,\n",
            "        [-2.9499, -0.5802, -2.8984,  ..., -2.1797, -2.8544, -2.6471],\n",
            "        [-0.3250, -3.1487, -3.9190,  ..., -3.2416, -2.4571, -2.7942],\n",
            "        [-5.2434, -4.4315, -0.0417,  ..., -5.2331, -4.9433, -5.1706]],\n",
            "       grad_fn=<LogSoftmaxBackward0>)\n",
            "Training: 916\n",
            "Epoch: 0917 loss_train: 0.6654 acc_train: 0.7857 loss_val: 1.0816 acc_val: 0.6700 time: 4.1238s\n",
            "loss_val:1.0815529823303223, val_acc:0.67, out_features:tensor([[-9.2414e+00, -8.7248e+00, -8.4376e-04,  ..., -8.9371e+00,\n",
            "         -8.9011e+00, -9.2008e+00],\n",
            "        [-1.0336e+01, -1.2277e+01, -1.2295e+01,  ..., -1.2141e+01,\n",
            "         -5.9603e-05, -1.2062e+01],\n",
            "        [-3.3879e+00, -2.7709e+00, -3.3978e+00,  ..., -2.7102e-01,\n",
            "         -3.4876e+00, -2.9787e+00],\n",
            "        ...,\n",
            "        [-3.6861e+00, -1.5426e-01, -3.9278e+00,  ..., -3.1501e+00,\n",
            "         -4.0017e+00, -3.8937e+00],\n",
            "        [-1.5486e+00, -2.9678e+00, -2.0237e+00,  ..., -1.6903e+00,\n",
            "         -1.9420e+00, -1.5837e+00],\n",
            "        [-9.3985e+00, -8.6881e+00, -7.9147e-04,  ..., -8.7691e+00,\n",
            "         -8.6102e+00, -9.4344e+00]], grad_fn=<LogSoftmaxBackward0>)\n",
            "Training: 917\n",
            "Epoch: 0918 loss_train: 0.7129 acc_train: 0.7643 loss_val: 1.0806 acc_val: 0.6367 time: 4.1661s\n",
            "loss_val:1.0805599689483643, val_acc:0.6366666666666667, out_features:tensor([[-5.6975, -5.1921, -0.0456,  ..., -4.0380, -5.4657, -5.4076],\n",
            "        [-1.7440, -2.8859, -2.5923,  ..., -2.0640, -1.0580, -1.8044],\n",
            "        [-2.1633, -2.2519, -1.7887,  ..., -1.0590, -2.4108, -2.5026],\n",
            "        ...,\n",
            "        [-6.1467, -0.0233, -6.3525,  ..., -5.6599, -5.0139, -4.9278],\n",
            "        [-0.0275, -6.1735, -6.6308,  ..., -5.4665, -4.1589, -6.4841],\n",
            "        [-2.1955, -2.1836, -1.4532,  ..., -2.6523, -1.9729, -2.4087]],\n",
            "       grad_fn=<LogSoftmaxBackward0>)\n",
            "Training: 918\n",
            "Epoch: 0919 loss_train: 0.6329 acc_train: 0.8357 loss_val: 1.0002 acc_val: 0.6833 time: 4.5025s\n",
            "loss_val:1.0001786947250366, val_acc:0.6833333333333333, out_features:tensor([[-1.4471e+01, -1.4373e+01, -3.0875e-05,  ..., -1.4230e+01,\n",
            "         -1.4436e+01, -1.4147e+01],\n",
            "        [-2.0061e+00, -3.4052e+00, -3.1581e+00,  ..., -1.9665e+00,\n",
            "         -9.6161e-01, -1.4337e+00],\n",
            "        [-4.6194e+00, -5.0953e+00, -5.4282e+00,  ..., -3.9420e-02,\n",
            "         -5.1915e+00, -4.7810e+00],\n",
            "        ...,\n",
            "        [-2.6010e+00, -1.0299e+00, -2.4598e+00,  ..., -1.8144e+00,\n",
            "         -2.0475e+00, -2.3937e+00],\n",
            "        [-1.4599e+00, -2.2066e+00, -2.0590e+00,  ..., -2.2597e+00,\n",
            "         -1.7528e+00, -1.8964e+00],\n",
            "        [-6.8612e+00, -6.6351e+00, -7.1952e-03,  ..., -7.3460e+00,\n",
            "         -7.1860e+00, -6.7386e+00]], grad_fn=<LogSoftmaxBackward0>)\n",
            "Training: 919\n",
            "Epoch: 0920 loss_train: 0.4859 acc_train: 0.8786 loss_val: 1.0475 acc_val: 0.6833 time: 4.1230s\n",
            "loss_val:1.0475155115127563, val_acc:0.6833333333333333, out_features:tensor([[-5.5962e+00, -5.4025e+00, -3.2553e-02,  ..., -5.0364e+00,\n",
            "         -5.5714e+00, -5.2563e+00],\n",
            "        [-1.9522e+00, -2.9207e+00, -3.0058e+00,  ..., -2.5851e+00,\n",
            "         -1.0048e+00, -1.3209e+00],\n",
            "        [-7.5168e+00, -7.3961e+00, -7.5260e+00,  ..., -5.5764e-03,\n",
            "         -7.4005e+00, -6.0143e+00],\n",
            "        ...,\n",
            "        [-3.3430e+00, -2.2348e-01, -3.5973e+00,  ..., -3.3855e+00,\n",
            "         -3.1953e+00, -3.3129e+00],\n",
            "        [-1.2893e-01, -3.4995e+00, -4.3162e+00,  ..., -3.4905e+00,\n",
            "         -3.7544e+00, -4.4030e+00],\n",
            "        [-1.9459e+00, -1.9459e+00, -1.9459e+00,  ..., -1.9459e+00,\n",
            "         -1.9459e+00, -1.9459e+00]], grad_fn=<LogSoftmaxBackward0>)\n",
            "Training: 920\n",
            "Epoch: 0921 loss_train: 0.6222 acc_train: 0.8143 loss_val: 0.9991 acc_val: 0.6967 time: 4.2671s\n",
            "loss_val:0.9990870952606201, val_acc:0.6966666666666667, out_features:tensor([[-1.3369e+01, -1.3159e+01, -2.3126e-05,  ..., -1.1642e+01,\n",
            "         -1.3195e+01, -1.3352e+01],\n",
            "        [-1.9459e+00, -1.9459e+00, -1.9459e+00,  ..., -1.9459e+00,\n",
            "         -1.9459e+00, -1.9459e+00],\n",
            "        [-2.6826e+00, -2.1703e+00, -1.7505e+00,  ..., -8.9837e-01,\n",
            "         -2.4976e+00, -2.3648e+00],\n",
            "        ...,\n",
            "        [-2.6121e+00, -6.1954e-01, -3.2224e+00,  ..., -3.2880e+00,\n",
            "         -2.4004e+00, -1.7439e+00],\n",
            "        [-1.9459e+00, -1.9459e+00, -1.9459e+00,  ..., -1.9459e+00,\n",
            "         -1.9459e+00, -1.9459e+00],\n",
            "        [-5.1129e+00, -4.5387e+00, -7.8259e-02,  ..., -4.7356e+00,\n",
            "         -3.2828e+00, -5.1748e+00]], grad_fn=<LogSoftmaxBackward0>)\n",
            "Training: 921\n",
            "Epoch: 0922 loss_train: 0.6507 acc_train: 0.7500 loss_val: 1.0760 acc_val: 0.6533 time: 4.4164s\n",
            "loss_val:1.075980544090271, val_acc:0.6533333333333333, out_features:tensor([[-4.9802, -4.8504, -0.1153,  ..., -2.7536, -4.4949, -4.8429],\n",
            "        [-1.9459, -1.9459, -1.9459,  ..., -1.9459, -1.9459, -1.9459],\n",
            "        [-3.0938, -3.3066, -3.1167,  ..., -0.2665, -3.1948, -3.4976],\n",
            "        ...,\n",
            "        [-1.9998, -1.3537, -2.3493,  ..., -1.8154, -2.0682, -2.0358],\n",
            "        [-1.1170, -2.2772, -2.2735,  ..., -1.9423, -2.0018, -2.5931],\n",
            "        [-3.7656, -3.5693, -0.1079,  ..., -4.6150, -3.9774, -4.2716]],\n",
            "       grad_fn=<LogSoftmaxBackward0>)\n",
            "Training: 922\n",
            "Epoch: 0923 loss_train: 0.6237 acc_train: 0.8071 loss_val: 1.0259 acc_val: 0.7167 time: 4.1567s\n",
            "loss_val:1.0259451866149902, val_acc:0.7166666666666667, out_features:tensor([[-5.1091, -4.6984, -0.0593,  ..., -3.9486, -5.1217, -4.9724],\n",
            "        [-1.9459, -1.9459, -1.9459,  ..., -1.9459, -1.9459, -1.9459],\n",
            "        [-6.7039, -5.3798, -6.8102,  ..., -0.0132, -5.6504, -6.3338],\n",
            "        ...,\n",
            "        [-2.5865, -0.6510, -2.7380,  ..., -2.6241, -2.4452, -2.2197],\n",
            "        [-0.3403, -3.4297, -3.7938,  ..., -2.1358, -2.7676, -3.5175],\n",
            "        [-2.6185, -3.1484, -0.5793,  ..., -3.4203, -2.0727, -3.0413]],\n",
            "       grad_fn=<LogSoftmaxBackward0>)\n",
            "Training: 923\n",
            "Epoch: 0924 loss_train: 0.6628 acc_train: 0.8071 loss_val: 1.0448 acc_val: 0.6967 time: 4.2370s\n",
            "loss_val:1.0448335409164429, val_acc:0.6966666666666667, out_features:tensor([[-7.4031, -7.3317, -0.0301,  ..., -5.7416, -7.3662, -5.8077],\n",
            "        [-1.9459, -1.9459, -1.9459,  ..., -1.9459, -1.9459, -1.9459],\n",
            "        [-3.2476, -3.5137, -3.9026,  ..., -0.1803, -3.5540, -3.3954],\n",
            "        ...,\n",
            "        [-3.5811, -0.1628, -4.2615,  ..., -3.1879, -3.3307, -4.1269],\n",
            "        [-0.1551, -3.6881, -3.3930,  ..., -3.3911, -3.9173, -3.9678],\n",
            "        [-4.2682, -2.2519, -0.2405,  ..., -3.6199, -4.0822, -4.1762]],\n",
            "       grad_fn=<LogSoftmaxBackward0>)\n",
            "Training: 924\n",
            "Epoch: 0925 loss_train: 0.5997 acc_train: 0.8143 loss_val: 1.0565 acc_val: 0.6433 time: 4.2006s\n",
            "loss_val:1.0565247535705566, val_acc:0.6433333333333333, out_features:tensor([[-4.3426, -4.2226, -0.1637,  ..., -3.3292, -4.2327, -4.0357],\n",
            "        [-1.6647, -7.8133, -7.8674,  ..., -6.6468, -0.2137, -7.2510],\n",
            "        [-4.9442, -4.5655, -4.7151,  ..., -0.0471, -5.1567, -5.1552],\n",
            "        ...,\n",
            "        [-2.1844, -1.2120, -2.2986,  ..., -1.6906, -2.2830, -2.2841],\n",
            "        [-0.6886, -2.4789, -3.1187,  ..., -2.4728, -2.0017, -2.5017],\n",
            "        [-2.2312, -2.6879, -1.1018,  ..., -1.6886, -2.5567, -2.0548]],\n",
            "       grad_fn=<LogSoftmaxBackward0>)\n",
            "Training: 925\n",
            "Epoch: 0926 loss_train: 0.6146 acc_train: 0.8214 loss_val: 1.0407 acc_val: 0.6533 time: 4.0681s\n",
            "loss_val:1.0407463312149048, val_acc:0.6533333333333333, out_features:tensor([[-7.5789e+00, -7.8495e+00, -4.8268e-03,  ..., -6.3292e+00,\n",
            "         -7.8535e+00, -7.2778e+00],\n",
            "        [-2.2484e+00, -2.8419e+00, -2.9353e+00,  ..., -2.3702e+00,\n",
            "         -8.1773e-01, -1.5872e+00],\n",
            "        [-3.5363e+00, -4.1273e+00, -4.3343e+00,  ..., -1.3340e-01,\n",
            "         -3.4347e+00, -3.8518e+00],\n",
            "        ...,\n",
            "        [-4.5182e+00, -7.3827e-02, -3.9427e+00,  ..., -4.7779e+00,\n",
            "         -4.5087e+00, -4.7579e+00],\n",
            "        [-3.8130e-01, -2.6333e+00, -3.1733e+00,  ..., -2.8371e+00,\n",
            "         -2.5646e+00, -3.5830e+00],\n",
            "        [-7.4058e+00, -7.4926e+00, -7.6391e-03,  ..., -5.4547e+00,\n",
            "         -6.8011e+00, -7.5553e+00]], grad_fn=<LogSoftmaxBackward0>)\n",
            "Training: 926\n",
            "Epoch: 0927 loss_train: 0.5277 acc_train: 0.8357 loss_val: 0.9736 acc_val: 0.7033 time: 4.4126s\n",
            "loss_val:0.9735813140869141, val_acc:0.7033333333333334, out_features:tensor([[-8.4660e+00, -8.2923e+00, -2.4908e-03,  ..., -7.5722e+00,\n",
            "         -8.4378e+00, -7.8569e+00],\n",
            "        [-1.9541e+00, -3.1779e+00, -2.7140e+00,  ..., -2.0825e+00,\n",
            "         -8.1962e-01, -1.9302e+00],\n",
            "        [-7.7066e+00, -6.3521e+00, -8.1627e+00,  ..., -4.2285e-03,\n",
            "         -6.8717e+00, -7.7835e+00],\n",
            "        ...,\n",
            "        [-2.7396e+00, -6.6789e-01, -3.0173e+00,  ..., -1.9371e+00,\n",
            "         -2.1470e+00, -2.7956e+00],\n",
            "        [-7.1150e-01, -2.1955e+00, -2.9593e+00,  ..., -2.4751e+00,\n",
            "         -1.9627e+00, -2.6174e+00],\n",
            "        [-9.4983e+00, -8.1015e+00, -1.3321e-03,  ..., -9.6380e+00,\n",
            "         -7.6841e+00, -9.6110e+00]], grad_fn=<LogSoftmaxBackward0>)\n",
            "Training: 927\n",
            "Epoch: 0928 loss_train: 0.5788 acc_train: 0.8500 loss_val: 1.0976 acc_val: 0.6633 time: 4.1379s\n",
            "loss_val:1.0975613594055176, val_acc:0.6633333333333333, out_features:tensor([[-4.9446e+00, -4.5410e+00, -8.4952e-02,  ..., -4.3418e+00,\n",
            "         -4.9475e+00, -4.4503e+00],\n",
            "        [-4.1378e+00, -6.5310e+00, -6.1721e+00,  ..., -5.6084e+00,\n",
            "         -3.0465e-02, -5.2137e+00],\n",
            "        [-7.0707e+00, -7.3748e+00, -7.5987e+00,  ..., -4.3778e-03,\n",
            "         -6.6966e+00, -7.2579e+00],\n",
            "        ...,\n",
            "        [-3.1739e+00, -5.6572e-01, -1.6247e+00,  ..., -3.0788e+00,\n",
            "         -2.7926e+00, -2.9938e+00],\n",
            "        [-1.9289e-01, -3.7433e+00, -3.9041e+00,  ..., -3.3860e+00,\n",
            "         -3.0582e+00, -3.9776e+00],\n",
            "        [-1.9459e+00, -1.9459e+00, -1.9459e+00,  ..., -1.9459e+00,\n",
            "         -1.9459e+00, -1.9459e+00]], grad_fn=<LogSoftmaxBackward0>)\n",
            "Training: 928\n",
            "Epoch: 0929 loss_train: 0.6033 acc_train: 0.8357 loss_val: 1.0365 acc_val: 0.6767 time: 4.1439s\n",
            "loss_val:1.036494255065918, val_acc:0.6766666666666666, out_features:tensor([[-6.4071, -5.8213, -0.0410,  ..., -5.1197, -6.3982, -5.2892],\n",
            "        [-1.9459, -1.9459, -1.9459,  ..., -1.9459, -1.9459, -1.9459],\n",
            "        [-5.3746, -6.7035, -5.8424,  ..., -0.0152, -5.7825, -6.2485],\n",
            "        ...,\n",
            "        [-6.2828, -0.0163, -6.0339,  ..., -5.2273, -5.8645, -6.4114],\n",
            "        [-0.6785, -2.9582, -2.7124,  ..., -2.2115, -2.1233, -2.7790],\n",
            "        [-1.9459, -1.9459, -1.9459,  ..., -1.9459, -1.9459, -1.9459]],\n",
            "       grad_fn=<LogSoftmaxBackward0>)\n",
            "Training: 929\n",
            "Epoch: 0930 loss_train: 0.5266 acc_train: 0.8714 loss_val: 1.0821 acc_val: 0.6467 time: 4.5376s\n",
            "loss_val:1.0821384191513062, val_acc:0.6466666666666666, out_features:tensor([[-7.4827, -7.1139, -0.0080,  ..., -6.9610, -7.3912, -7.3570],\n",
            "        [-3.8430, -7.4427, -7.8111,  ..., -7.7116, -0.0241, -7.7223],\n",
            "        [-2.4965, -1.9078, -2.1484,  ..., -0.8019, -2.7818, -2.7394],\n",
            "        ...,\n",
            "        [-3.2066, -0.3678, -3.1183,  ..., -2.8334, -2.3191, -3.3941],\n",
            "        [-0.8737, -1.9348, -2.8859,  ..., -2.7080, -1.6907, -2.6485],\n",
            "        [-2.3671, -2.7812, -1.0471,  ..., -2.8451, -1.6051, -2.2831]],\n",
            "       grad_fn=<LogSoftmaxBackward0>)\n",
            "Training: 930\n",
            "Epoch: 0931 loss_train: 0.5995 acc_train: 0.8357 loss_val: 1.0565 acc_val: 0.6533 time: 4.1352s\n",
            "loss_val:1.0565320253372192, val_acc:0.6533333333333333, out_features:tensor([[-4.8500, -4.7684, -0.0850,  ..., -4.6784, -4.6064, -4.6513],\n",
            "        [-1.5048, -3.7493, -4.0252,  ..., -1.7617, -0.8431, -2.1611],\n",
            "        [-1.9459, -1.9459, -1.9459,  ..., -1.9459, -1.9459, -1.9459],\n",
            "        ...,\n",
            "        [-1.8454, -1.3855, -2.1808,  ..., -2.1511, -1.8712, -2.1144],\n",
            "        [-0.1011, -5.2337, -5.4710,  ..., -2.8100, -4.0890, -5.3085],\n",
            "        [-1.9459, -1.9459, -1.9459,  ..., -1.9459, -1.9459, -1.9459]],\n",
            "       grad_fn=<LogSoftmaxBackward0>)\n",
            "Training: 931\n",
            "Epoch: 0932 loss_train: 0.5435 acc_train: 0.8714 loss_val: 1.0438 acc_val: 0.6567 time: 4.1960s\n",
            "loss_val:1.0437861680984497, val_acc:0.6566666666666666, out_features:tensor([[-5.3138, -4.5305, -0.0799,  ..., -5.1020, -5.0409, -4.8700],\n",
            "        [-3.4089, -4.8119, -4.5878,  ..., -1.6842, -0.3386, -3.1654],\n",
            "        [-5.5870, -6.2055, -6.4192,  ..., -0.0119, -6.6885, -6.1135],\n",
            "        ...,\n",
            "        [-2.0577, -1.0342, -2.5726,  ..., -2.7500, -2.3179, -1.9061],\n",
            "        [-0.1094, -4.1604, -4.9686,  ..., -3.0191, -3.9005, -5.0883],\n",
            "        [-4.2635, -4.3358, -0.2107,  ..., -4.3697, -3.9776, -2.6388]],\n",
            "       grad_fn=<LogSoftmaxBackward0>)\n",
            "Training: 932\n",
            "Epoch: 0933 loss_train: 0.6540 acc_train: 0.7857 loss_val: 0.9873 acc_val: 0.6933 time: 4.4533s\n",
            "loss_val:0.9872714281082153, val_acc:0.6933333333333334, out_features:tensor([[-3.0789e+00, -2.1266e+00, -7.2713e-01,  ..., -2.7470e+00,\n",
            "         -2.7475e+00, -2.7977e+00],\n",
            "        [-2.3231e+00, -4.1932e+00, -3.4822e+00,  ..., -3.4537e+00,\n",
            "         -3.1872e-01, -2.5223e+00],\n",
            "        [-7.8586e+00, -8.4425e+00, -8.2694e+00,  ..., -1.4663e-03,\n",
            "         -8.4849e+00, -8.4848e+00],\n",
            "        ...,\n",
            "        [-4.2891e+00, -3.3630e-02, -5.8426e+00,  ..., -5.3920e+00,\n",
            "         -5.5230e+00, -5.6054e+00],\n",
            "        [-7.6649e-01, -2.0281e+00, -3.0783e+00,  ..., -2.1683e+00,\n",
            "         -2.0520e+00, -2.7309e+00],\n",
            "        [-1.0208e+01, -8.9811e+00, -9.1582e-04,  ..., -1.0042e+01,\n",
            "         -1.0085e+01, -1.0004e+01]], grad_fn=<LogSoftmaxBackward0>)\n",
            "Training: 933\n",
            "Epoch: 0934 loss_train: 0.7310 acc_train: 0.7786 loss_val: 0.9724 acc_val: 0.6833 time: 4.1664s\n",
            "loss_val:0.9723572731018066, val_acc:0.6833333333333333, out_features:tensor([[-7.3440e+00, -6.8249e+00, -6.8182e-03,  ..., -7.2869e+00,\n",
            "         -6.6214e+00, -6.3617e+00],\n",
            "        [-2.4620e+00, -2.9789e+00, -1.8855e+00,  ..., -1.4092e+00,\n",
            "         -1.1541e+00, -2.2050e+00],\n",
            "        [-4.4047e+00, -3.4706e+00, -3.1208e+00,  ..., -1.2247e-01,\n",
            "         -4.6233e+00, -4.6026e+00],\n",
            "        ...,\n",
            "        [-6.3012e+00, -1.1143e-02, -6.4006e+00,  ..., -6.1950e+00,\n",
            "         -6.4451e+00, -6.0650e+00],\n",
            "        [-4.9923e-01, -3.1570e+00, -3.4167e+00,  ..., -2.0848e+00,\n",
            "         -2.2011e+00, -3.4477e+00],\n",
            "        [-1.9459e+00, -1.9459e+00, -1.9459e+00,  ..., -1.9459e+00,\n",
            "         -1.9459e+00, -1.9459e+00]], grad_fn=<LogSoftmaxBackward0>)\n",
            "Training: 934\n",
            "Epoch: 0935 loss_train: 0.5283 acc_train: 0.8643 loss_val: 1.0087 acc_val: 0.6900 time: 4.1427s\n",
            "loss_val:1.0086833238601685, val_acc:0.69, out_features:tensor([[-4.4934, -3.9910, -0.1907,  ..., -4.2779, -4.1277, -4.3433],\n",
            "        [-1.9459, -1.9459, -1.9459,  ..., -1.9459, -1.9459, -1.9459],\n",
            "        [-2.7968, -2.3033, -1.6992,  ..., -0.7834, -2.5576, -2.6740],\n",
            "        ...,\n",
            "        [-2.4058, -1.3142, -1.9346,  ..., -1.7523, -2.0304, -2.1657],\n",
            "        [-0.3414, -3.9370, -3.9379,  ..., -3.3780, -2.5258, -2.1346],\n",
            "        [-1.9459, -1.9459, -1.9459,  ..., -1.9459, -1.9459, -1.9459]],\n",
            "       grad_fn=<LogSoftmaxBackward0>)\n",
            "Training: 935\n",
            "Epoch: 0936 loss_train: 0.6301 acc_train: 0.8214 loss_val: 1.0276 acc_val: 0.6767 time: 4.4569s\n",
            "loss_val:1.027625322341919, val_acc:0.6766666666666666, out_features:tensor([[-5.6512, -5.3942, -0.0341,  ..., -4.9154, -5.3491, -5.1585],\n",
            "        [-5.7040, -6.7121, -6.5322,  ..., -5.8787, -0.0141, -6.5575],\n",
            "        [-2.5320, -2.6163, -2.4336,  ..., -0.8547, -2.6766, -2.1630],\n",
            "        ...,\n",
            "        [-1.9459, -1.9459, -1.9459,  ..., -1.9459, -1.9459, -1.9459],\n",
            "        [-0.9318, -3.1190, -3.1769,  ..., -2.8249, -1.6777, -1.5676],\n",
            "        [-3.1400, -2.2791, -0.4154,  ..., -2.9048, -3.3585, -3.3226]],\n",
            "       grad_fn=<LogSoftmaxBackward0>)\n",
            "Training: 936\n",
            "Epoch: 0937 loss_train: 0.6446 acc_train: 0.8071 loss_val: 1.0246 acc_val: 0.6500 time: 4.2625s\n",
            "loss_val:1.0245599746704102, val_acc:0.65, out_features:tensor([[-5.3738e+00, -5.5079e+00, -7.7862e-02,  ..., -5.2574e+00,\n",
            "         -5.4749e+00, -3.6953e+00],\n",
            "        [-2.4127e+00, -2.6217e+00, -2.6055e+00,  ..., -2.3278e+00,\n",
            "         -7.7187e-01, -2.2507e+00],\n",
            "        [-9.9384e+00, -1.0488e+01, -1.0799e+01,  ..., -3.2646e-04,\n",
            "         -9.3396e+00, -9.0046e+00],\n",
            "        ...,\n",
            "        [-2.2317e+00, -6.7742e-01, -3.0098e+00,  ..., -2.3130e+00,\n",
            "         -2.0947e+00, -2.6592e+00],\n",
            "        [-2.3817e-02, -6.0903e+00, -6.2439e+00,  ..., -5.8712e+00,\n",
            "         -4.5133e+00, -6.0029e+00],\n",
            "        [-4.1237e+00, -4.6984e+00, -8.0340e-02,  ..., -4.3383e+00,\n",
            "         -4.7933e+00, -4.5858e+00]], grad_fn=<LogSoftmaxBackward0>)\n",
            "Training: 937\n",
            "Epoch: 0938 loss_train: 0.6263 acc_train: 0.8214 loss_val: 1.0508 acc_val: 0.6567 time: 4.2501s\n",
            "loss_val:1.0508437156677246, val_acc:0.6566666666666666, out_features:tensor([[-5.8935e+00, -5.7299e+00, -5.6465e-02,  ..., -3.6884e+00,\n",
            "         -5.7496e+00, -5.6578e+00],\n",
            "        [-3.8780e+00, -3.2008e+00, -3.8058e+00,  ..., -3.5710e+00,\n",
            "         -3.3163e-01, -3.4719e+00],\n",
            "        [-4.2889e+00, -3.3647e+00, -3.0656e+00,  ..., -1.4304e-01,\n",
            "         -4.4466e+00, -4.0890e+00],\n",
            "        ...,\n",
            "        [-1.0225e+01, -1.9751e-04, -1.0840e+01,  ..., -1.0600e+01,\n",
            "         -9.3968e+00, -1.0983e+01],\n",
            "        [-1.9459e+00, -1.9459e+00, -1.9459e+00,  ..., -1.9459e+00,\n",
            "         -1.9459e+00, -1.9459e+00],\n",
            "        [-2.9032e+00, -5.3094e+00, -9.3074e-02,  ..., -4.3335e+00,\n",
            "         -4.9385e+00, -5.4084e+00]], grad_fn=<LogSoftmaxBackward0>)\n",
            "Training: 938\n",
            "Epoch: 0939 loss_train: 0.5962 acc_train: 0.8286 loss_val: 0.9803 acc_val: 0.6767 time: 4.3039s\n",
            "loss_val:0.9803339838981628, val_acc:0.6766666666666666, out_features:tensor([[-4.8698, -4.2791, -0.0771,  ..., -4.1898, -4.4546, -4.7791],\n",
            "        [-7.6850, -8.5970, -9.0841,  ..., -9.2775, -0.0315, -3.5036],\n",
            "        [-1.9459, -1.9459, -1.9459,  ..., -1.9459, -1.9459, -1.9459],\n",
            "        ...,\n",
            "        [-4.0633, -0.1446, -3.4464,  ..., -3.7454, -3.7715, -3.8203],\n",
            "        [-0.1424, -3.9444, -4.5212,  ..., -3.3399, -3.1211, -4.3773],\n",
            "        [-6.1172, -5.2087, -0.0170,  ..., -6.2220, -5.9435, -6.2047]],\n",
            "       grad_fn=<LogSoftmaxBackward0>)\n",
            "Training: 939\n",
            "Epoch: 0940 loss_train: 0.5907 acc_train: 0.8500 loss_val: 1.0883 acc_val: 0.6700 time: 4.2159s\n",
            "loss_val:1.0883277654647827, val_acc:0.67, out_features:tensor([[-6.6761, -6.9262, -0.0179,  ..., -6.4757, -6.7967, -5.2763],\n",
            "        [-1.9459, -1.9459, -1.9459,  ..., -1.9459, -1.9459, -1.9459],\n",
            "        [-3.8931, -3.8679, -4.1297,  ..., -0.1309, -4.0279, -3.3922],\n",
            "        ...,\n",
            "        [-3.5247, -0.4676, -2.6799,  ..., -1.5879, -3.4866, -3.8529],\n",
            "        [-0.0926, -3.4583, -5.3998,  ..., -4.5212, -3.5518, -4.7917],\n",
            "        [-7.3079, -6.6203, -0.0135,  ..., -7.4239, -4.7313, -6.7236]],\n",
            "       grad_fn=<LogSoftmaxBackward0>)\n",
            "Training: 940\n",
            "Epoch: 0941 loss_train: 0.6227 acc_train: 0.8071 loss_val: 1.0333 acc_val: 0.6933 time: 4.3363s\n",
            "loss_val:1.0333422422409058, val_acc:0.6933333333333334, out_features:tensor([[-5.7499, -5.7004, -0.0893,  ..., -5.1721, -5.5709, -5.1727],\n",
            "        [-2.2367, -3.3473, -3.2143,  ..., -2.2787, -0.8126, -1.4042],\n",
            "        [-4.4277, -5.4583, -5.7176,  ..., -0.0343, -5.4152, -5.0314],\n",
            "        ...,\n",
            "        [-2.2402, -0.6226, -2.6530,  ..., -2.4262, -2.5721, -2.6385],\n",
            "        [-0.0174, -5.7791, -6.6037,  ..., -6.1968, -4.9784, -5.9989],\n",
            "        [-1.9459, -1.9459, -1.9459,  ..., -1.9459, -1.9459, -1.9459]],\n",
            "       grad_fn=<LogSoftmaxBackward0>)\n",
            "Training: 941\n",
            "Epoch: 0942 loss_train: 0.4844 acc_train: 0.8714 loss_val: 1.0570 acc_val: 0.6733 time: 4.3568s\n",
            "loss_val:1.0569877624511719, val_acc:0.6733333333333333, out_features:tensor([[-1.2789e+01, -1.2708e+01, -2.8967e-05,  ..., -1.2674e+01,\n",
            "         -1.2477e+01, -1.1492e+01],\n",
            "        [-1.9459e+00, -1.9459e+00, -1.9459e+00,  ..., -1.9459e+00,\n",
            "         -1.9459e+00, -1.9459e+00],\n",
            "        [-6.3031e+00, -6.2651e+00, -4.2797e+00,  ..., -2.3759e-02,\n",
            "         -6.3276e+00, -6.0175e+00],\n",
            "        ...,\n",
            "        [-3.8701e+00, -1.3020e-01, -4.9992e+00,  ..., -3.6236e+00,\n",
            "         -2.9504e+00, -4.7065e+00],\n",
            "        [-1.0926e+00, -2.5467e+00, -2.7489e+00,  ..., -1.6522e+00,\n",
            "         -1.8665e+00, -2.0957e+00],\n",
            "        [-1.9459e+00, -1.9459e+00, -1.9459e+00,  ..., -1.9459e+00,\n",
            "         -1.9459e+00, -1.9459e+00]], grad_fn=<LogSoftmaxBackward0>)\n",
            "Training: 942\n",
            "Epoch: 0943 loss_train: 0.5568 acc_train: 0.8357 loss_val: 1.0667 acc_val: 0.6633 time: 4.2099s\n",
            "loss_val:1.0666903257369995, val_acc:0.6633333333333333, out_features:tensor([[-8.8785e+00, -8.7182e+00, -1.1199e-03,  ..., -8.4527e+00,\n",
            "         -8.8828e+00, -8.3750e+00],\n",
            "        [-6.7423e+00, -8.3882e+00, -8.2909e+00,  ..., -8.3793e+00,\n",
            "         -5.1375e-02, -3.0552e+00],\n",
            "        [-3.8436e+00, -4.2977e+00, -3.9018e+00,  ..., -1.1103e-01,\n",
            "         -3.8382e+00, -4.2478e+00],\n",
            "        ...,\n",
            "        [-2.9261e+00, -7.6004e-01, -2.0817e+00,  ..., -2.8538e+00,\n",
            "         -2.2967e+00, -2.2213e+00],\n",
            "        [-6.0921e-01, -3.3054e+00, -3.0598e+00,  ..., -1.8705e+00,\n",
            "         -2.6098e+00, -3.0747e+00],\n",
            "        [-7.4334e+00, -7.4890e+00, -8.7600e-03,  ..., -7.4418e+00,\n",
            "         -6.2058e+00, -5.9584e+00]], grad_fn=<LogSoftmaxBackward0>)\n",
            "Training: 943\n",
            "Epoch: 0944 loss_train: 0.5884 acc_train: 0.8214 loss_val: 0.9466 acc_val: 0.7067 time: 4.3112s\n",
            "loss_val:0.9465783834457397, val_acc:0.7066666666666667, out_features:tensor([[-5.4546e+00, -4.3717e+00, -5.9432e-02,  ..., -4.6614e+00,\n",
            "         -5.1321e+00, -4.9394e+00],\n",
            "        [-9.1904e+00, -1.1887e+01, -1.2106e+01,  ..., -1.2035e+01,\n",
            "         -4.6052e-04, -8.0035e+00],\n",
            "        [-7.4521e+00, -7.3008e+00, -8.8428e+00,  ..., -2.0252e-03,\n",
            "         -8.1047e+00, -8.8576e+00],\n",
            "        ...,\n",
            "        [-2.5956e+00, -7.2519e-01, -2.4887e+00,  ..., -2.4927e+00,\n",
            "         -2.5212e+00, -2.3183e+00],\n",
            "        [-1.8639e-01, -3.6689e+00, -4.4878e+00,  ..., -3.7687e+00,\n",
            "         -2.5989e+00, -3.7880e+00],\n",
            "        [-1.9459e+00, -1.9459e+00, -1.9459e+00,  ..., -1.9459e+00,\n",
            "         -1.9459e+00, -1.9459e+00]], grad_fn=<LogSoftmaxBackward0>)\n",
            "Training: 944\n",
            "Epoch: 0945 loss_train: 0.6278 acc_train: 0.7929 loss_val: 0.9857 acc_val: 0.6833 time: 4.1903s\n",
            "loss_val:0.9857171773910522, val_acc:0.6833333333333333, out_features:tensor([[-1.3403e+01, -1.2142e+01, -2.2053e-05,  ..., -1.1554e+01,\n",
            "         -1.3361e+01, -1.3308e+01],\n",
            "        [-1.9459e+00, -1.9459e+00, -1.9459e+00,  ..., -1.9459e+00,\n",
            "         -1.9459e+00, -1.9459e+00],\n",
            "        [-8.5483e+00, -8.2470e+00, -5.3179e+00,  ..., -6.1540e-03,\n",
            "         -8.5285e+00, -8.5554e+00],\n",
            "        ...,\n",
            "        [-1.9405e+00, -1.2654e+00, -2.1241e+00,  ..., -1.7284e+00,\n",
            "         -2.0246e+00, -2.3913e+00],\n",
            "        [-1.5523e+00, -2.7097e+00, -1.8008e+00,  ..., -1.7838e+00,\n",
            "         -2.0517e+00, -2.1913e+00],\n",
            "        [-6.7877e+00, -5.4307e+00, -1.2205e-02,  ..., -6.3714e+00,\n",
            "         -6.6034e+00, -6.4754e+00]], grad_fn=<LogSoftmaxBackward0>)\n",
            "Training: 945\n",
            "Epoch: 0946 loss_train: 0.6165 acc_train: 0.8214 loss_val: 1.0250 acc_val: 0.6633 time: 4.2109s\n",
            "loss_val:1.024985432624817, val_acc:0.6633333333333333, out_features:tensor([[-9.1963e+00, -9.1522e+00, -1.3845e-03,  ..., -7.2221e+00,\n",
            "         -9.1684e+00, -8.9618e+00],\n",
            "        [-1.9459e+00, -1.9459e+00, -1.9459e+00,  ..., -1.9459e+00,\n",
            "         -1.9459e+00, -1.9459e+00],\n",
            "        [-4.9848e+00, -6.5513e+00, -6.5277e+00,  ..., -1.6877e-02,\n",
            "         -5.7653e+00, -5.9655e+00],\n",
            "        ...,\n",
            "        [-3.4213e+00, -2.7841e-01, -3.0483e+00,  ..., -2.8692e+00,\n",
            "         -3.1950e+00, -3.3998e+00],\n",
            "        [-6.7617e-01, -2.8230e+00, -2.6515e+00,  ..., -1.7772e+00,\n",
            "         -2.2786e+00, -2.9304e+00],\n",
            "        [-7.6163e+00, -8.1501e+00, -1.5109e-03,  ..., -9.0764e+00,\n",
            "         -7.8772e+00, -9.1030e+00]], grad_fn=<LogSoftmaxBackward0>)\n",
            "Training: 946\n",
            "Epoch: 0947 loss_train: 0.7511 acc_train: 0.7357 loss_val: 1.1055 acc_val: 0.6833 time: 4.4255s\n",
            "loss_val:1.1054565906524658, val_acc:0.6833333333333333, out_features:tensor([[-3.3811e+00, -2.2091e+00, -5.2278e-01,  ..., -1.8599e+00,\n",
            "         -3.1100e+00, -3.4672e+00],\n",
            "        [-1.9459e+00, -1.9459e+00, -1.9459e+00,  ..., -1.9459e+00,\n",
            "         -1.9459e+00, -1.9459e+00],\n",
            "        [-8.7736e+00, -8.1917e+00, -7.7540e+00,  ..., -1.1370e-03,\n",
            "         -9.2485e+00, -9.3083e+00],\n",
            "        ...,\n",
            "        [-3.7180e+00, -2.1987e-01, -3.9839e+00,  ..., -2.5440e+00,\n",
            "         -3.6684e+00, -3.6748e+00],\n",
            "        [-1.9459e+00, -1.9459e+00, -1.9459e+00,  ..., -1.9459e+00,\n",
            "         -1.9459e+00, -1.9459e+00],\n",
            "        [-1.1939e+01, -8.8391e+00, -1.8702e-04,  ..., -1.1117e+01,\n",
            "         -1.1911e+01, -1.1829e+01]], grad_fn=<LogSoftmaxBackward0>)\n",
            "Training: 947\n",
            "Epoch: 0948 loss_train: 0.6503 acc_train: 0.8000 loss_val: 1.0206 acc_val: 0.6733 time: 4.0451s\n",
            "loss_val:1.020579218864441, val_acc:0.6733333333333333, out_features:tensor([[-6.7661, -6.3319, -0.0217,  ..., -6.1468, -6.7037, -6.7665],\n",
            "        [-1.9459, -1.9459, -1.9459,  ..., -1.9459, -1.9459, -1.9459],\n",
            "        [-2.8137, -3.3333, -3.5689,  ..., -0.3123, -2.4320, -3.4255],\n",
            "        ...,\n",
            "        [-1.8535, -0.8977, -2.8379,  ..., -2.9476, -2.0806, -2.1364],\n",
            "        [-0.7875, -3.4281, -3.3454,  ..., -1.1498, -2.9163, -3.1596],\n",
            "        [-4.2034, -4.0596, -0.1940,  ..., -4.2074, -2.7871, -3.5262]],\n",
            "       grad_fn=<LogSoftmaxBackward0>)\n",
            "Training: 948\n",
            "Epoch: 0949 loss_train: 0.6269 acc_train: 0.7786 loss_val: 0.9995 acc_val: 0.6667 time: 4.0551s\n",
            "loss_val:0.9994884133338928, val_acc:0.6666666666666666, out_features:tensor([[-1.9459e+00, -1.9459e+00, -1.9459e+00,  ..., -1.9459e+00,\n",
            "         -1.9459e+00, -1.9459e+00],\n",
            "        [-1.9459e+00, -1.9459e+00, -1.9459e+00,  ..., -1.9459e+00,\n",
            "         -1.9459e+00, -1.9459e+00],\n",
            "        [-6.6314e+00, -6.4575e+00, -6.1359e+00,  ..., -9.6264e-03,\n",
            "         -6.4116e+00, -6.4136e+00],\n",
            "        ...,\n",
            "        [-2.3571e+00, -7.2875e-01, -2.2852e+00,  ..., -2.5587e+00,\n",
            "         -2.3711e+00, -2.6348e+00],\n",
            "        [-1.2444e-02, -7.7525e+00, -7.8213e+00,  ..., -7.6040e+00,\n",
            "         -4.8068e+00, -6.0700e+00],\n",
            "        [-7.7771e+00, -6.2770e+00, -4.6256e-03,  ..., -7.4365e+00,\n",
            "         -7.5237e+00, -7.7691e+00]], grad_fn=<LogSoftmaxBackward0>)\n",
            "Training: 949\n",
            "Epoch: 0950 loss_train: 0.5162 acc_train: 0.8500 loss_val: 1.0675 acc_val: 0.6667 time: 4.4656s\n",
            "loss_val:1.067475438117981, val_acc:0.6666666666666666, out_features:tensor([[-3.6185e+00, -3.7144e+00, -4.1793e-01,  ..., -2.1700e+00,\n",
            "         -3.7291e+00, -2.8673e+00],\n",
            "        [-1.9459e+00, -1.9459e+00, -1.9459e+00,  ..., -1.9459e+00,\n",
            "         -1.9459e+00, -1.9459e+00],\n",
            "        [-1.2593e+01, -1.1557e+01, -1.2484e+01,  ..., -2.8610e-05,\n",
            "         -1.2252e+01, -1.2488e+01],\n",
            "        ...,\n",
            "        [-5.0418e+00, -8.1316e-02, -5.2014e+00,  ..., -4.2187e+00,\n",
            "         -3.4794e+00, -4.1921e+00],\n",
            "        [-7.7290e-03, -7.3927e+00, -7.7455e+00,  ..., -7.4118e+00,\n",
            "         -5.3358e+00, -7.1254e+00],\n",
            "        [-1.3063e+00, -2.1192e+00, -2.0306e+00,  ..., -2.6459e+00,\n",
            "         -1.7342e+00, -2.8123e+00]], grad_fn=<LogSoftmaxBackward0>)\n",
            "Training: 950\n",
            "Epoch: 0951 loss_train: 0.7195 acc_train: 0.7643 loss_val: 1.0301 acc_val: 0.6667 time: 4.1146s\n",
            "loss_val:1.0300647020339966, val_acc:0.6666666666666666, out_features:tensor([[-1.1608e+01, -1.1550e+01, -2.1718e-04,  ..., -1.0021e+01,\n",
            "         -1.1633e+01, -1.0625e+01],\n",
            "        [-2.1858e+00, -2.8972e+00, -2.2984e+00,  ..., -2.7697e+00,\n",
            "         -1.1917e+00, -1.2671e+00],\n",
            "        [-2.8971e+00, -2.7624e+00, -2.7815e+00,  ..., -4.3945e-01,\n",
            "         -3.0952e+00, -3.1029e+00],\n",
            "        ...,\n",
            "        [-2.7251e+00, -9.7154e-01, -2.5432e+00,  ..., -1.9489e+00,\n",
            "         -1.7197e+00, -2.4126e+00],\n",
            "        [-3.1997e-01, -2.9586e+00, -3.9327e+00,  ..., -3.0933e+00,\n",
            "         -2.2974e+00, -3.3051e+00],\n",
            "        [-6.2385e+00, -5.9751e+00, -4.0394e-02,  ..., -5.9084e+00,\n",
            "         -6.0251e+00, -6.1384e+00]], grad_fn=<LogSoftmaxBackward0>)\n",
            "Training: 951\n",
            "Epoch: 0952 loss_train: 0.5614 acc_train: 0.8571 loss_val: 1.0357 acc_val: 0.6633 time: 4.1174s\n",
            "loss_val:1.0357069969177246, val_acc:0.6633333333333333, out_features:tensor([[-3.2876, -2.7374, -0.4987,  ..., -2.2681, -2.7204, -2.6960],\n",
            "        [-1.9459, -1.9459, -1.9459,  ..., -1.9459, -1.9459, -1.9459],\n",
            "        [-2.9240, -2.7602, -1.8106,  ..., -0.6535, -2.7802, -2.4759],\n",
            "        ...,\n",
            "        [-1.9459, -1.9459, -1.9459,  ..., -1.9459, -1.9459, -1.9459],\n",
            "        [-0.8210, -2.6667, -2.8172,  ..., -1.9969, -2.0694, -2.1957],\n",
            "        [-3.0735, -2.4304, -0.4921,  ..., -3.3499, -2.7680, -2.7406]],\n",
            "       grad_fn=<LogSoftmaxBackward0>)\n",
            "Training: 952\n",
            "Epoch: 0953 loss_train: 0.5745 acc_train: 0.8143 loss_val: 1.0852 acc_val: 0.6533 time: 4.4096s\n",
            "loss_val:1.0851577520370483, val_acc:0.6533333333333333, out_features:tensor([[-1.4729e+01, -1.4570e+01, -5.0068e-06,  ..., -1.4102e+01,\n",
            "         -1.4687e+01, -1.4598e+01],\n",
            "        [-4.5369e+00, -4.0847e+00, -5.2891e+00,  ..., -5.0378e+00,\n",
            "         -8.0934e-02, -3.3517e+00],\n",
            "        [-6.6058e+00, -7.2414e+00, -7.3080e+00,  ..., -1.3705e-02,\n",
            "         -4.7497e+00, -6.4175e+00],\n",
            "        ...,\n",
            "        [-2.8406e+00, -5.1223e-01, -2.9522e+00,  ..., -2.7797e+00,\n",
            "         -2.2196e+00, -2.4800e+00],\n",
            "        [-7.7914e-01, -1.9360e+00, -2.8844e+00,  ..., -2.6319e+00,\n",
            "         -1.9574e+00, -2.5465e+00],\n",
            "        [-3.8699e+00, -3.6755e+00, -1.7161e-01,  ..., -3.4520e+00,\n",
            "         -3.7875e+00, -4.3152e+00]], grad_fn=<LogSoftmaxBackward0>)\n",
            "Training: 953\n",
            "Epoch: 0954 loss_train: 0.5670 acc_train: 0.7929 loss_val: 0.9877 acc_val: 0.7033 time: 4.0934s\n",
            "loss_val:0.9877160787582397, val_acc:0.7033333333333334, out_features:tensor([[-1.3224e+01, -1.3404e+01, -3.2782e-05,  ..., -1.3234e+01,\n",
            "         -1.3407e+01, -1.2683e+01],\n",
            "        [-1.9459e+00, -1.9459e+00, -1.9459e+00,  ..., -1.9459e+00,\n",
            "         -1.9459e+00, -1.9459e+00],\n",
            "        [-7.1035e+00, -6.1507e+00, -7.2486e+00,  ..., -7.4351e-03,\n",
            "         -6.0178e+00, -7.2507e+00],\n",
            "        ...,\n",
            "        [-3.7024e+00, -1.7058e-01, -3.7393e+00,  ..., -3.4800e+00,\n",
            "         -3.2974e+00, -3.6654e+00],\n",
            "        [-1.0081e+00, -2.8018e+00, -2.7121e+00,  ..., -2.7219e+00,\n",
            "         -1.3738e+00, -2.8129e+00],\n",
            "        [-1.2353e+01, -1.2034e+01, -3.6239e-05,  ..., -1.1905e+01,\n",
            "         -1.1796e+01, -1.2279e+01]], grad_fn=<LogSoftmaxBackward0>)\n",
            "Training: 954\n",
            "Epoch: 0955 loss_train: 0.5636 acc_train: 0.8214 loss_val: 1.0296 acc_val: 0.6600 time: 4.1639s\n",
            "loss_val:1.0295591354370117, val_acc:0.66, out_features:tensor([[-5.3104e+00, -4.4975e+00, -8.0550e-02,  ..., -4.7988e+00,\n",
            "         -5.1463e+00, -4.8980e+00],\n",
            "        [-2.7569e+00, -4.0806e+00, -3.8697e+00,  ..., -2.8360e+00,\n",
            "         -4.5978e-01, -1.6568e+00],\n",
            "        [-5.1447e+00, -4.8613e+00, -4.6369e+00,  ..., -3.5834e-02,\n",
            "         -5.4696e+00, -5.4619e+00],\n",
            "        ...,\n",
            "        [-2.0152e+00, -1.7238e+00, -1.5578e+00,  ..., -2.4787e+00,\n",
            "         -2.2048e+00, -1.8936e+00],\n",
            "        [-7.0988e-04, -1.0126e+01, -1.0363e+01,  ..., -9.2866e+00,\n",
            "         -7.6800e+00, -1.0337e+01],\n",
            "        [-3.2260e+00, -5.1158e+00, -1.1245e-01,  ..., -3.3237e+00,\n",
            "         -4.3899e+00, -4.9364e+00]], grad_fn=<LogSoftmaxBackward0>)\n",
            "Training: 955\n",
            "Epoch: 0956 loss_train: 0.6990 acc_train: 0.7643 loss_val: 0.9369 acc_val: 0.6900 time: 4.3940s\n",
            "loss_val:0.936905026435852, val_acc:0.69, out_features:tensor([[-6.0762e+00, -6.1243e+00, -1.8339e-02,  ..., -5.9288e+00,\n",
            "         -6.3459e+00, -6.3822e+00],\n",
            "        [-4.4200e+00, -4.4737e+00, -4.0514e+00,  ..., -4.3026e+00,\n",
            "         -5.0229e-01, -3.3753e+00],\n",
            "        [-2.5960e+00, -3.0256e+00, -2.6836e+00,  ..., -4.3871e-01,\n",
            "         -3.0166e+00, -2.8616e+00],\n",
            "        ...,\n",
            "        [-3.0484e+00, -4.8261e-01, -2.8965e+00,  ..., -2.4331e+00,\n",
            "         -2.6661e+00, -2.5387e+00],\n",
            "        [-5.6464e-03, -7.8243e+00, -7.8016e+00,  ..., -5.8085e+00,\n",
            "         -7.1103e+00, -7.3876e+00],\n",
            "        [-3.3861e+00, -2.9797e+00, -6.5100e-01,  ..., -3.0097e+00,\n",
            "         -2.5927e+00, -1.4799e+00]], grad_fn=<LogSoftmaxBackward0>)\n",
            "Training: 956\n",
            "Epoch: 0957 loss_train: 0.5792 acc_train: 0.8357 loss_val: 1.0596 acc_val: 0.6600 time: 4.1859s\n",
            "loss_val:1.059586524963379, val_acc:0.66, out_features:tensor([[-5.4738, -5.5359, -0.0403,  ..., -5.4578, -5.5112, -5.2055],\n",
            "        [-1.9459, -1.9459, -1.9459,  ..., -1.9459, -1.9459, -1.9459],\n",
            "        [-3.7902, -3.5558, -3.6128,  ..., -0.1744, -3.6574, -3.4909],\n",
            "        ...,\n",
            "        [-4.6146, -0.1086, -4.4226,  ..., -3.5408, -3.3665, -4.7086],\n",
            "        [-0.0622, -4.9167, -4.9315,  ..., -4.7792, -4.1318, -4.6194],\n",
            "        [-1.9459, -1.9459, -1.9459,  ..., -1.9459, -1.9459, -1.9459]],\n",
            "       grad_fn=<LogSoftmaxBackward0>)\n",
            "Training: 957\n",
            "Epoch: 0958 loss_train: 0.6658 acc_train: 0.7857 loss_val: 0.9365 acc_val: 0.6967 time: 4.1304s\n",
            "loss_val:0.9364511966705322, val_acc:0.6966666666666667, out_features:tensor([[-3.4023e+00, -2.9215e+00, -4.3631e-01,  ..., -2.3677e+00,\n",
            "         -3.1169e+00, -2.5595e+00],\n",
            "        [-1.9459e+00, -1.9459e+00, -1.9459e+00,  ..., -1.9459e+00,\n",
            "         -1.9459e+00, -1.9459e+00],\n",
            "        [-3.6350e+00, -3.6893e+00, -3.4555e+00,  ..., -2.1777e-01,\n",
            "         -3.8906e+00, -2.6519e+00],\n",
            "        ...,\n",
            "        [-2.2604e+00, -1.8008e+00, -1.6605e+00,  ..., -1.6818e+00,\n",
            "         -1.7561e+00, -2.3304e+00],\n",
            "        [-1.0624e+00, -2.1401e+00, -1.5961e+00,  ..., -2.4111e+00,\n",
            "         -2.1350e+00, -2.8355e+00],\n",
            "        [-6.9036e+00, -6.3738e+00, -6.1507e-03,  ..., -6.7843e+00,\n",
            "         -7.0195e+00, -7.4047e+00]], grad_fn=<LogSoftmaxBackward0>)\n",
            "Training: 958\n",
            "Epoch: 0959 loss_train: 0.5694 acc_train: 0.8357 loss_val: 1.1102 acc_val: 0.6667 time: 4.5673s\n",
            "loss_val:1.1102423667907715, val_acc:0.6666666666666666, out_features:tensor([[-1.2086e+01, -1.1753e+01, -5.1974e-05,  ..., -1.1849e+01,\n",
            "         -1.1790e+01, -1.2079e+01],\n",
            "        [-1.9459e+00, -1.9459e+00, -1.9459e+00,  ..., -1.9459e+00,\n",
            "         -1.9459e+00, -1.9459e+00],\n",
            "        [-9.5473e+00, -7.2359e+00, -1.0227e+01,  ..., -1.0235e-03,\n",
            "         -8.9740e+00, -1.0257e+01],\n",
            "        ...,\n",
            "        [-5.6248e+00, -2.6426e-02, -4.3083e+00,  ..., -5.8517e+00,\n",
            "         -5.9569e+00, -6.2563e+00],\n",
            "        [-4.4613e-01, -2.9242e+00, -2.8133e+00,  ..., -2.3351e+00,\n",
            "         -2.5412e+00, -3.2817e+00],\n",
            "        [-1.6582e+00, -2.1656e+00, -8.8371e-01,  ..., -2.9952e+00,\n",
            "         -2.0377e+00, -2.9605e+00]], grad_fn=<LogSoftmaxBackward0>)\n",
            "Training: 959\n",
            "Epoch: 0960 loss_train: 0.5181 acc_train: 0.8214 loss_val: 1.0129 acc_val: 0.6667 time: 4.0549s\n",
            "loss_val:1.0129380226135254, val_acc:0.6666666666666666, out_features:tensor([[-9.4010e+00, -9.4120e+00, -2.3648e-03,  ..., -8.9851e+00,\n",
            "         -9.1565e+00, -9.2589e+00],\n",
            "        [-1.9459e+00, -1.9459e+00, -1.9459e+00,  ..., -1.9459e+00,\n",
            "         -1.9459e+00, -1.9459e+00],\n",
            "        [-5.9158e+00, -5.6551e+00, -5.7965e+00,  ..., -1.9402e-02,\n",
            "         -5.3667e+00, -5.7977e+00],\n",
            "        ...,\n",
            "        [-1.9585e+00, -1.5483e+00, -2.1526e+00,  ..., -1.9864e+00,\n",
            "         -1.9043e+00, -1.7431e+00],\n",
            "        [-3.3891e-01, -3.4107e+00, -3.5002e+00,  ..., -2.7505e+00,\n",
            "         -2.3810e+00, -3.3650e+00],\n",
            "        [-1.9459e+00, -1.9459e+00, -1.9459e+00,  ..., -1.9459e+00,\n",
            "         -1.9459e+00, -1.9459e+00]], grad_fn=<LogSoftmaxBackward0>)\n",
            "Training: 960\n",
            "Epoch: 0961 loss_train: 0.5829 acc_train: 0.8286 loss_val: 1.0230 acc_val: 0.6767 time: 4.2430s\n",
            "loss_val:1.0230377912521362, val_acc:0.6766666666666666, out_features:tensor([[-9.1029e+00, -8.6828e+00, -9.0153e-04,  ..., -8.7851e+00,\n",
            "         -9.0238e+00, -8.7750e+00],\n",
            "        [-6.2007e+00, -6.9960e+00, -7.8327e+00,  ..., -6.2436e+00,\n",
            "         -1.0831e-02, -5.2839e+00],\n",
            "        [-4.3151e+00, -4.7222e+00, -4.3845e+00,  ..., -8.2535e-02,\n",
            "         -3.7140e+00, -4.3170e+00],\n",
            "        ...,\n",
            "        [-3.4401e+00, -2.3426e-01, -4.4417e+00,  ..., -2.3384e+00,\n",
            "         -3.2760e+00, -3.9415e+00],\n",
            "        [-1.5224e-01, -4.5101e+00, -4.5909e+00,  ..., -3.0817e+00,\n",
            "         -3.0302e+00, -4.4708e+00],\n",
            "        [-3.2890e+00, -2.1433e+00, -3.9062e-01,  ..., -3.3645e+00,\n",
            "         -3.5852e+00, -2.9830e+00]], grad_fn=<LogSoftmaxBackward0>)\n",
            "Training: 961\n",
            "Epoch: 0962 loss_train: 0.6249 acc_train: 0.8286 loss_val: 1.1409 acc_val: 0.6700 time: 4.3494s\n",
            "loss_val:1.1408618688583374, val_acc:0.67, out_features:tensor([[-1.1525e+01, -1.0151e+01, -1.3649e-04,  ..., -1.1436e+01,\n",
            "         -1.1332e+01, -1.1412e+01],\n",
            "        [-1.9529e+00, -2.7510e+00, -2.1955e+00,  ..., -2.4705e+00,\n",
            "         -1.0880e+00, -1.5469e+00],\n",
            "        [-1.9459e+00, -1.9459e+00, -1.9459e+00,  ..., -1.9459e+00,\n",
            "         -1.9459e+00, -1.9459e+00],\n",
            "        ...,\n",
            "        [-3.2585e+00, -4.2057e-01, -2.2480e+00,  ..., -3.4033e+00,\n",
            "         -2.9961e+00, -2.6963e+00],\n",
            "        [-3.6394e-01, -3.3323e+00, -3.5753e+00,  ..., -2.8115e+00,\n",
            "         -2.3760e+00, -2.8191e+00],\n",
            "        [-7.9236e+00, -7.8889e+00, -3.5795e-03,  ..., -6.7989e+00,\n",
            "         -7.9735e+00, -8.0859e+00]], grad_fn=<LogSoftmaxBackward0>)\n",
            "Training: 962\n",
            "Epoch: 0963 loss_train: 0.5794 acc_train: 0.8286 loss_val: 1.1246 acc_val: 0.6467 time: 4.1427s\n",
            "loss_val:1.1245861053466797, val_acc:0.6466666666666666, out_features:tensor([[-1.5147e+01, -1.5087e+01, -4.5299e-06,  ..., -1.3596e+01,\n",
            "         -1.5126e+01, -1.3883e+01],\n",
            "        [-1.9459e+00, -1.9459e+00, -1.9459e+00,  ..., -1.9459e+00,\n",
            "         -1.9459e+00, -1.9459e+00],\n",
            "        [-7.3662e+00, -6.8398e+00, -5.7065e+00,  ..., -6.9107e-03,\n",
            "         -7.4638e+00, -7.2142e+00],\n",
            "        ...,\n",
            "        [-3.9483e+00, -2.2588e-01, -3.0926e+00,  ..., -3.3936e+00,\n",
            "         -2.6837e+00, -3.9646e+00],\n",
            "        [-8.5310e-01, -2.7899e+00, -2.4720e+00,  ..., -1.7223e+00,\n",
            "         -2.0786e+00, -2.6701e+00],\n",
            "        [-3.6892e+00, -6.2890e+00, -3.7963e-02,  ..., -6.4188e+00,\n",
            "         -5.2561e+00, -6.1309e+00]], grad_fn=<LogSoftmaxBackward0>)\n",
            "Training: 963\n",
            "Epoch: 0964 loss_train: 0.6051 acc_train: 0.7857 loss_val: 1.0098 acc_val: 0.6867 time: 4.4957s\n",
            "loss_val:1.009782314300537, val_acc:0.6866666666666666, out_features:tensor([[-7.6752, -7.4249, -0.0078,  ..., -6.5909, -7.6228, -7.3735],\n",
            "        [-1.9459, -1.9459, -1.9459,  ..., -1.9459, -1.9459, -1.9459],\n",
            "        [-6.4240, -6.5414, -5.0833,  ..., -0.0130, -6.5692, -6.6913],\n",
            "        ...,\n",
            "        [-2.5579, -0.5987, -2.9167,  ..., -2.3242, -2.1572, -2.8190],\n",
            "        [-0.2327, -4.2006, -4.7090,  ..., -2.8147, -2.3105, -4.5323],\n",
            "        [-4.7470, -2.4581, -0.1663,  ..., -3.6244, -4.2779, -4.7410]],\n",
            "       grad_fn=<LogSoftmaxBackward0>)\n",
            "Training: 964\n",
            "Epoch: 0965 loss_train: 0.5510 acc_train: 0.8357 loss_val: 1.0493 acc_val: 0.7033 time: 4.2552s\n",
            "loss_val:1.049268126487732, val_acc:0.7033333333333334, out_features:tensor([[-9.5830e+00, -9.8113e+00, -4.4372e-04,  ..., -9.3381e+00,\n",
            "         -9.9494e+00, -9.0944e+00],\n",
            "        [-9.8073e+00, -1.0056e+01, -1.0329e+01,  ..., -7.2751e+00,\n",
            "         -8.8152e-04, -1.0434e+01],\n",
            "        [-2.7647e+00, -3.5940e+00, -3.9775e+00,  ..., -3.2179e-01,\n",
            "         -2.9158e+00, -2.5709e+00],\n",
            "        ...,\n",
            "        [-4.2464e+00, -1.0359e-01, -3.4834e+00,  ..., -4.5893e+00,\n",
            "         -3.6089e+00, -4.8268e+00],\n",
            "        [-2.6357e-03, -8.5928e+00, -9.2504e+00,  ..., -6.3008e+00,\n",
            "         -8.0597e+00, -9.2301e+00],\n",
            "        [-2.7269e+00, -3.2288e+00, -4.6408e-01,  ..., -3.2118e+00,\n",
            "         -2.1702e+00, -2.9116e+00]], grad_fn=<LogSoftmaxBackward0>)\n",
            "Training: 965\n",
            "Epoch: 0966 loss_train: 0.6928 acc_train: 0.7714 loss_val: 1.0548 acc_val: 0.6833 time: 4.1627s\n",
            "loss_val:1.0547796487808228, val_acc:0.6833333333333333, out_features:tensor([[-7.9972e+00, -7.8078e+00, -3.1187e-03,  ..., -7.6853e+00,\n",
            "         -7.9377e+00, -7.9412e+00],\n",
            "        [-1.9459e+00, -1.9459e+00, -1.9459e+00,  ..., -1.9459e+00,\n",
            "         -1.9459e+00, -1.9459e+00],\n",
            "        [-3.2799e+00, -4.0199e+00, -3.5487e+00,  ..., -1.4060e-01,\n",
            "         -3.8909e+00, -4.2130e+00],\n",
            "        ...,\n",
            "        [-5.7255e+00, -3.8201e-02, -5.9241e+00,  ..., -3.7934e+00,\n",
            "         -5.3038e+00, -6.1851e+00],\n",
            "        [-3.8464e-01, -2.3112e+00, -3.2482e+00,  ..., -3.1928e+00,\n",
            "         -2.4746e+00, -3.5840e+00],\n",
            "        [-2.6727e+00, -2.5554e+00, -5.4310e-01,  ..., -3.0879e+00,\n",
            "         -2.2128e+00, -3.1006e+00]], grad_fn=<LogSoftmaxBackward0>)\n",
            "Training: 966\n",
            "Epoch: 0967 loss_train: 0.5874 acc_train: 0.8214 loss_val: 1.0134 acc_val: 0.6733 time: 4.4817s\n",
            "loss_val:1.013421893119812, val_acc:0.6733333333333333, out_features:tensor([[-6.2033, -6.1506, -0.0230,  ..., -4.8969, -6.1402, -4.9484],\n",
            "        [-1.9459, -1.9459, -1.9459,  ..., -1.9459, -1.9459, -1.9459],\n",
            "        [-6.2606, -5.0870, -6.5083,  ..., -0.0219, -5.9422, -4.8047],\n",
            "        ...,\n",
            "        [-1.7480, -1.0981, -1.8965,  ..., -2.3779, -2.1701, -2.7159],\n",
            "        [-1.0727, -2.5682, -2.1980,  ..., -2.0871, -1.7710, -2.4085],\n",
            "        [-3.1337, -3.6807, -0.3159,  ..., -3.7633, -2.9513, -2.8073]],\n",
            "       grad_fn=<LogSoftmaxBackward0>)\n",
            "Training: 967\n",
            "Epoch: 0968 loss_train: 0.6019 acc_train: 0.8143 loss_val: 1.1631 acc_val: 0.6500 time: 4.1039s\n",
            "loss_val:1.1631022691726685, val_acc:0.65, out_features:tensor([[-1.9459, -1.9459, -1.9459,  ..., -1.9459, -1.9459, -1.9459],\n",
            "        [-1.9459, -1.9459, -1.9459,  ..., -1.9459, -1.9459, -1.9459],\n",
            "        [-2.8721, -2.5834, -3.1704,  ..., -0.3833, -3.2169, -3.0426],\n",
            "        ...,\n",
            "        [-2.7187, -0.6357, -2.5971,  ..., -2.5047, -2.6668, -2.4477],\n",
            "        [-0.6026, -2.6203, -3.0940,  ..., -2.4069, -2.0696, -2.7371],\n",
            "        [-2.6971, -3.6394, -0.2556,  ..., -4.2732, -2.5431, -3.6606]],\n",
            "       grad_fn=<LogSoftmaxBackward0>)\n",
            "Training: 968\n",
            "Epoch: 0969 loss_train: 0.5997 acc_train: 0.8571 loss_val: 1.0994 acc_val: 0.6500 time: 4.1658s\n",
            "loss_val:1.0993902683258057, val_acc:0.65, out_features:tensor([[-2.7711, -2.0256, -0.7356,  ..., -2.7905, -2.7481, -2.5177],\n",
            "        [-3.6664, -3.9026, -3.3003,  ..., -3.7380, -0.1919, -2.8457],\n",
            "        [-4.9905, -4.7860, -3.5477,  ..., -0.0714, -4.8714, -4.8450],\n",
            "        ...,\n",
            "        [-6.7629, -0.0078, -6.7363,  ..., -6.1220, -6.8395, -6.8038],\n",
            "        [-0.6923, -3.0868, -2.6954,  ..., -2.5842, -1.8587, -2.5074],\n",
            "        [-1.9459, -1.9459, -1.9459,  ..., -1.9459, -1.9459, -1.9459]],\n",
            "       grad_fn=<LogSoftmaxBackward0>)\n",
            "Training: 969\n",
            "Epoch: 0970 loss_train: 0.4883 acc_train: 0.8857 loss_val: 0.9663 acc_val: 0.6933 time: 4.4022s\n",
            "loss_val:0.9663217067718506, val_acc:0.6933333333333334, out_features:tensor([[-3.4515, -3.9992, -0.2544,  ..., -3.4738, -3.9318, -2.3883],\n",
            "        [-6.5312, -6.9175, -6.7621,  ..., -3.3109, -0.0754, -3.4541],\n",
            "        [-5.4926, -4.5493, -5.6625,  ..., -0.0322, -5.2526, -5.5711],\n",
            "        ...,\n",
            "        [-1.8075, -1.4866, -2.2371,  ..., -2.5258, -1.7433, -2.1167],\n",
            "        [-0.5301, -2.8370, -3.2516,  ..., -2.7160, -1.9726, -2.8049],\n",
            "        [-1.2561, -4.1371, -1.1415,  ..., -4.3522, -1.0778, -4.3586]],\n",
            "       grad_fn=<LogSoftmaxBackward0>)\n",
            "Training: 970\n",
            "Epoch: 0971 loss_train: 0.5571 acc_train: 0.8286 loss_val: 1.0244 acc_val: 0.7067 time: 4.1118s\n",
            "loss_val:1.0244370698928833, val_acc:0.7066666666666667, out_features:tensor([[-1.1704e+01, -1.1204e+01, -7.6768e-05,  ..., -1.1747e+01,\n",
            "         -1.0530e+01, -1.1515e+01],\n",
            "        [-1.9459e+00, -1.9459e+00, -1.9459e+00,  ..., -1.9459e+00,\n",
            "         -1.9459e+00, -1.9459e+00],\n",
            "        [-4.2877e+00, -3.7073e+00, -4.4034e+00,  ..., -9.8960e-02,\n",
            "         -4.1054e+00, -4.1491e+00],\n",
            "        ...,\n",
            "        [-3.1835e+00, -1.5180e-01, -3.3215e+00,  ..., -4.1636e+00,\n",
            "         -4.2308e+00, -3.8372e+00],\n",
            "        [-3.0162e-01, -3.8391e+00, -3.9530e+00,  ..., -3.1712e+00,\n",
            "         -2.2555e+00, -4.0554e+00],\n",
            "        [-9.3788e+00, -7.7334e+00, -1.2714e-03,  ..., -9.3622e+00,\n",
            "         -8.8121e+00, -7.7956e+00]], grad_fn=<LogSoftmaxBackward0>)\n",
            "Training: 971\n",
            "Epoch: 0972 loss_train: 0.6240 acc_train: 0.8357 loss_val: 1.0973 acc_val: 0.6767 time: 4.1308s\n",
            "loss_val:1.0972756147384644, val_acc:0.6766666666666666, out_features:tensor([[-7.8819e+00, -7.8150e+00, -9.2047e-03,  ..., -5.8258e+00,\n",
            "         -7.9104e+00, -7.3284e+00],\n",
            "        [-1.3060e+01, -1.3270e+01, -1.3133e+01,  ..., -1.3264e+01,\n",
            "         -5.7338e-05, -1.0106e+01],\n",
            "        [-2.3306e+00, -2.7590e+00, -1.9270e+00,  ..., -6.8996e-01,\n",
            "         -2.5025e+00, -2.8600e+00],\n",
            "        ...,\n",
            "        [-2.5832e+00, -8.2035e-01, -1.9693e+00,  ..., -2.1720e+00,\n",
            "         -2.1846e+00, -2.8057e+00],\n",
            "        [-5.5198e-01, -3.0419e+00, -3.1816e+00,  ..., -1.8684e+00,\n",
            "         -2.2072e+00, -3.3599e+00],\n",
            "        [-1.3747e+01, -1.3816e+01, -6.3181e-06,  ..., -1.3849e+01,\n",
            "         -1.3833e+01, -1.3620e+01]], grad_fn=<LogSoftmaxBackward0>)\n",
            "Training: 972\n",
            "Epoch: 0973 loss_train: 0.6441 acc_train: 0.8143 loss_val: 0.9688 acc_val: 0.6933 time: 4.4750s\n",
            "loss_val:0.9688042998313904, val_acc:0.6933333333333334, out_features:tensor([[-5.9653e+00, -5.8737e+00, -3.0965e-02,  ..., -5.7785e+00,\n",
            "         -5.7389e+00, -5.9653e+00],\n",
            "        [-1.9459e+00, -1.9459e+00, -1.9459e+00,  ..., -1.9459e+00,\n",
            "         -1.9459e+00, -1.9459e+00],\n",
            "        [-1.9459e+00, -1.9459e+00, -1.9459e+00,  ..., -1.9459e+00,\n",
            "         -1.9459e+00, -1.9459e+00],\n",
            "        ...,\n",
            "        [-2.7296e+00, -3.3293e-01, -3.5787e+00,  ..., -2.9978e+00,\n",
            "         -3.0653e+00, -2.7418e+00],\n",
            "        [-3.3120e-01, -3.5407e+00, -3.9070e+00,  ..., -2.6433e+00,\n",
            "         -2.1419e+00, -3.6561e+00],\n",
            "        [-8.6488e+00, -8.7323e+00, -2.3615e-03,  ..., -7.9942e+00,\n",
            "         -8.2740e+00, -6.8643e+00]], grad_fn=<LogSoftmaxBackward0>)\n",
            "Training: 973\n",
            "Epoch: 0974 loss_train: 0.5750 acc_train: 0.8214 loss_val: 1.0727 acc_val: 0.6500 time: 4.1051s\n",
            "loss_val:1.0726803541183472, val_acc:0.65, out_features:tensor([[-1.4531e+01, -1.4448e+01, -1.0252e-05,  ..., -1.1768e+01,\n",
            "         -1.4479e+01, -1.4555e+01],\n",
            "        [-2.1276e+00, -6.2748e+00, -7.7218e+00,  ..., -7.7683e+00,\n",
            "         -1.3096e-01, -7.6261e+00],\n",
            "        [-3.3980e+00, -3.3626e+00, -4.1727e+00,  ..., -2.2241e-01,\n",
            "         -4.0328e+00, -2.4741e+00],\n",
            "        ...,\n",
            "        [-3.4911e+00, -2.8430e-01, -3.3517e+00,  ..., -3.1126e+00,\n",
            "         -3.6113e+00, -3.2427e+00],\n",
            "        [-2.0506e-01, -4.1153e+00, -4.2096e+00,  ..., -2.9791e+00,\n",
            "         -3.1071e+00, -3.1835e+00],\n",
            "        [-6.5192e+00, -6.0016e+00, -1.9427e-02,  ..., -6.6876e+00,\n",
            "         -5.4112e+00, -6.4170e+00]], grad_fn=<LogSoftmaxBackward0>)\n",
            "Training: 974\n",
            "Epoch: 0975 loss_train: 0.6080 acc_train: 0.8286 loss_val: 1.0209 acc_val: 0.6900 time: 4.1293s\n",
            "loss_val:1.0208839178085327, val_acc:0.69, out_features:tensor([[-3.0893, -4.1191, -0.2303,  ..., -2.9252, -3.4106, -3.2974],\n",
            "        [-1.9459, -1.9459, -1.9459,  ..., -1.9459, -1.9459, -1.9459],\n",
            "        [-6.4466, -6.7386, -5.8881,  ..., -0.0091, -6.5844, -6.8283],\n",
            "        ...,\n",
            "        [-1.9459, -1.9459, -1.9459,  ..., -1.9459, -1.9459, -1.9459],\n",
            "        [-1.0540, -2.1552, -1.9717,  ..., -1.9689, -2.3770, -2.5591],\n",
            "        [-2.6367, -2.6821, -0.6165,  ..., -2.8409, -2.4014, -2.5701]],\n",
            "       grad_fn=<LogSoftmaxBackward0>)\n",
            "Training: 975\n",
            "Epoch: 0976 loss_train: 0.6055 acc_train: 0.8214 loss_val: 1.0087 acc_val: 0.6367 time: 4.3361s\n",
            "loss_val:1.0086597204208374, val_acc:0.6366666666666667, out_features:tensor([[-6.7404, -5.2848, -0.0142,  ..., -6.1370, -6.8205, -6.6517],\n",
            "        [-3.7021, -6.0896, -3.0464,  ..., -5.8949, -0.0882, -5.2726],\n",
            "        [-5.7687, -6.1241, -5.0899,  ..., -0.0254, -4.6792, -6.0803],\n",
            "        ...,\n",
            "        [-6.9031, -0.0091, -7.4450,  ..., -5.3400, -6.5754, -7.2511],\n",
            "        [-1.9459, -1.9459, -1.9459,  ..., -1.9459, -1.9459, -1.9459],\n",
            "        [-4.8626, -5.9735, -0.0345,  ..., -5.2129, -4.8665, -6.2853]],\n",
            "       grad_fn=<LogSoftmaxBackward0>)\n",
            "Training: 976\n",
            "Epoch: 0977 loss_train: 0.5664 acc_train: 0.8357 loss_val: 0.9908 acc_val: 0.6633 time: 4.1761s\n",
            "loss_val:0.9908496141433716, val_acc:0.6633333333333333, out_features:tensor([[-4.9954, -5.1462, -0.0731,  ..., -4.6697, -4.9538, -4.1211],\n",
            "        [-1.9459, -1.9459, -1.9459,  ..., -1.9459, -1.9459, -1.9459],\n",
            "        [-1.9459, -1.9459, -1.9459,  ..., -1.9459, -1.9459, -1.9459],\n",
            "        ...,\n",
            "        [-2.7267, -0.8101, -2.2306,  ..., -2.0069, -1.8299, -2.9527],\n",
            "        [-0.5789, -2.5325, -3.2249,  ..., -2.7922, -2.1061, -2.3814],\n",
            "        [-3.1142, -2.3756, -0.5539,  ..., -1.9488, -3.0204, -2.8089]],\n",
            "       grad_fn=<LogSoftmaxBackward0>)\n",
            "Training: 977\n",
            "Epoch: 0978 loss_train: 0.5734 acc_train: 0.8214 loss_val: 1.0295 acc_val: 0.6933 time: 4.1001s\n",
            "loss_val:1.0294798612594604, val_acc:0.6933333333333334, out_features:tensor([[-2.2363, -2.5999, -0.8440,  ..., -2.4418, -2.6623, -1.8606],\n",
            "        [-1.7248, -3.1676, -3.2177,  ..., -0.8755, -2.4961, -1.5677],\n",
            "        [-3.9201, -2.3688, -3.2486,  ..., -0.2922, -3.6037, -3.0624],\n",
            "        ...,\n",
            "        [-4.2536, -0.1122, -4.3058,  ..., -3.2842, -3.7414, -4.7415],\n",
            "        [-0.2769, -3.0816, -3.7938,  ..., -3.5013, -2.9121, -2.7648],\n",
            "        [-3.3459, -4.7597, -0.1376,  ..., -4.9133, -4.5188, -2.8488]],\n",
            "       grad_fn=<LogSoftmaxBackward0>)\n",
            "Training: 978\n",
            "Epoch: 0979 loss_train: 0.5593 acc_train: 0.8071 loss_val: 1.0680 acc_val: 0.7000 time: 4.3031s\n",
            "loss_val:1.06800377368927, val_acc:0.7, out_features:tensor([[-2.8217, -2.4412, -0.5811,  ..., -2.5357, -2.6502, -2.6312],\n",
            "        [-1.9459, -1.9459, -1.9459,  ..., -1.9459, -1.9459, -1.9459],\n",
            "        [-3.4922, -4.3792, -4.5104,  ..., -0.1532, -2.8079, -4.0611],\n",
            "        ...,\n",
            "        [-5.8207, -0.0217, -5.8730,  ..., -5.5419, -5.3474, -5.6729],\n",
            "        [-0.0132, -7.0294, -7.1404,  ..., -4.9663, -5.9392, -6.9824],\n",
            "        [-7.1258, -5.9063, -0.0075,  ..., -6.8538, -7.0804, -6.7118]],\n",
            "       grad_fn=<LogSoftmaxBackward0>)\n",
            "Training: 979\n",
            "Epoch: 0980 loss_train: 0.5909 acc_train: 0.8571 loss_val: 1.1216 acc_val: 0.6300 time: 4.0700s\n",
            "loss_val:1.1215598583221436, val_acc:0.63, out_features:tensor([[-6.5332, -6.6017, -0.0139,  ..., -6.2353, -6.5332, -6.1536],\n",
            "        [-1.9459, -1.9459, -1.9459,  ..., -1.9459, -1.9459, -1.9459],\n",
            "        [-2.2272, -2.2174, -2.4320,  ..., -0.7840, -2.5985, -2.2399],\n",
            "        ...,\n",
            "        [-1.8471, -1.0589, -2.7621,  ..., -1.7303, -1.8279, -2.9735],\n",
            "        [-0.0562, -5.9357, -5.9727,  ..., -3.4105, -4.5093, -5.8966],\n",
            "        [-5.2886, -4.7090, -0.0418,  ..., -5.3656, -5.0585, -5.4391]],\n",
            "       grad_fn=<LogSoftmaxBackward0>)\n",
            "Training: 980\n",
            "Epoch: 0981 loss_train: 0.6385 acc_train: 0.8000 loss_val: 1.0065 acc_val: 0.6733 time: 4.3439s\n",
            "loss_val:1.0064631700515747, val_acc:0.6733333333333333, out_features:tensor([[-4.5360, -4.1035, -0.1517,  ..., -3.9740, -4.5785, -3.4869],\n",
            "        [-4.1586, -6.7524, -7.3423,  ..., -7.2176, -0.0363, -4.1140],\n",
            "        [-2.4110, -2.4566, -1.6690,  ..., -0.8058, -2.7471, -2.5624],\n",
            "        ...,\n",
            "        [-3.3082, -0.4323, -3.4987,  ..., -2.1086, -2.2990, -3.4262],\n",
            "        [-1.5231, -1.7062, -2.4905,  ..., -2.0263, -1.6515, -2.4362],\n",
            "        [-3.7170, -5.2115, -0.0526,  ..., -5.2427, -4.8798, -5.5678]],\n",
            "       grad_fn=<LogSoftmaxBackward0>)\n",
            "Training: 981\n",
            "Epoch: 0982 loss_train: 0.6717 acc_train: 0.7786 loss_val: 0.9868 acc_val: 0.6867 time: 4.3845s\n",
            "loss_val:0.9868115186691284, val_acc:0.6866666666666666, out_features:tensor([[-1.3246e+01, -1.3188e+01, -4.0530e-05,  ..., -1.2979e+01,\n",
            "         -1.3048e+01, -1.3051e+01],\n",
            "        [-1.9459e+00, -1.9459e+00, -1.9459e+00,  ..., -1.9459e+00,\n",
            "         -1.9459e+00, -1.9459e+00],\n",
            "        [-8.9755e+00, -7.7967e+00, -8.0940e+00,  ..., -1.2835e-03,\n",
            "         -8.6111e+00, -8.8397e+00],\n",
            "        ...,\n",
            "        [-2.5508e+00, -6.7631e-01, -1.9623e+00,  ..., -2.4397e+00,\n",
            "         -2.6838e+00, -2.8659e+00],\n",
            "        [-9.9305e-01, -2.2962e+00, -2.5058e+00,  ..., -1.9399e+00,\n",
            "         -1.9634e+00, -2.4131e+00],\n",
            "        [-1.0675e+01, -1.0608e+01, -1.1896e-04,  ..., -1.1255e+01,\n",
            "         -1.0715e+01, -1.0711e+01]], grad_fn=<LogSoftmaxBackward0>)\n",
            "Training: 982\n",
            "Epoch: 0983 loss_train: 0.4856 acc_train: 0.8643 loss_val: 1.0521 acc_val: 0.6600 time: 4.0292s\n",
            "loss_val:1.0520704984664917, val_acc:0.66, out_features:tensor([[-4.4356, -4.3162, -0.0928,  ..., -3.8902, -4.4391, -4.1624],\n",
            "        [-1.9459, -1.9459, -1.9459,  ..., -1.9459, -1.9459, -1.9459],\n",
            "        [-2.5886, -2.4686, -2.4804,  ..., -0.5422, -2.3882, -3.0007],\n",
            "        ...,\n",
            "        [-2.5790, -0.8905, -2.6521,  ..., -2.7937, -1.3722, -2.5928],\n",
            "        [-0.1596, -4.2071, -4.3300,  ..., -2.7412, -3.6745, -3.9571],\n",
            "        [-1.9459, -1.9459, -1.9459,  ..., -1.9459, -1.9459, -1.9459]],\n",
            "       grad_fn=<LogSoftmaxBackward0>)\n",
            "Training: 983\n",
            "Epoch: 0984 loss_train: 0.6296 acc_train: 0.7857 loss_val: 1.0234 acc_val: 0.7000 time: 4.3428s\n",
            "loss_val:1.0233606100082397, val_acc:0.7, out_features:tensor([[-6.2663e+00, -6.2122e+00, -1.7772e-02,  ..., -5.8336e+00,\n",
            "         -6.3055e+00, -6.0051e+00],\n",
            "        [-1.9540e+00, -2.5194e+00, -1.9580e+00,  ..., -1.5020e+00,\n",
            "         -1.7270e+00, -1.7829e+00],\n",
            "        [-4.2868e+00, -4.6797e+00, -3.9398e+00,  ..., -1.0224e-01,\n",
            "         -4.5163e+00, -3.3580e+00],\n",
            "        ...,\n",
            "        [-2.1919e+00, -1.3420e+00, -2.0268e+00,  ..., -1.7440e+00,\n",
            "         -2.1742e+00, -2.1589e+00],\n",
            "        [-5.6322e-03, -7.4864e+00, -7.6999e+00,  ..., -6.5282e+00,\n",
            "         -6.2262e+00, -7.3142e+00],\n",
            "        [-5.4785e-01, -3.6243e+00, -1.4230e+00,  ..., -3.4801e+00,\n",
            "         -2.5986e+00, -3.7650e+00]], grad_fn=<LogSoftmaxBackward0>)\n",
            "Training: 984\n",
            "Epoch: 0985 loss_train: 0.5408 acc_train: 0.8357 loss_val: 1.0649 acc_val: 0.6500 time: 4.2866s\n",
            "loss_val:1.0648642778396606, val_acc:0.65, out_features:tensor([[-5.7608e+00, -4.7196e+00, -3.3256e-02,  ..., -4.9273e+00,\n",
            "         -5.4914e+00, -5.0815e+00],\n",
            "        [-1.9459e+00, -1.9459e+00, -1.9459e+00,  ..., -1.9459e+00,\n",
            "         -1.9459e+00, -1.9459e+00],\n",
            "        [-6.5447e+00, -8.2354e+00, -8.2913e+00,  ..., -3.8837e-03,\n",
            "         -7.4646e+00, -6.7865e+00],\n",
            "        ...,\n",
            "        [-3.0811e+00, -3.0641e-01, -3.7148e+00,  ..., -3.4154e+00,\n",
            "         -2.6917e+00, -2.7255e+00],\n",
            "        [-5.6516e-01, -2.5128e+00, -3.2410e+00,  ..., -1.8963e+00,\n",
            "         -2.8375e+00, -3.2371e+00],\n",
            "        [-1.6505e+00, -2.7848e+00, -1.1220e+00,  ..., -2.3932e+00,\n",
            "         -1.9054e+00, -2.4123e+00]], grad_fn=<LogSoftmaxBackward0>)\n",
            "Training: 985\n",
            "Epoch: 0986 loss_train: 0.6779 acc_train: 0.7643 loss_val: 1.0973 acc_val: 0.6367 time: 4.1496s\n",
            "loss_val:1.097314715385437, val_acc:0.6366666666666667, out_features:tensor([[-9.0100e+00, -8.9841e+00, -3.9270e-03,  ..., -8.7463e+00,\n",
            "         -9.0377e+00, -7.6059e+00],\n",
            "        [-1.8868e+00, -3.4165e+00, -3.1493e+00,  ..., -1.7778e+00,\n",
            "         -9.5644e-01, -1.6723e+00],\n",
            "        [-2.1958e+00, -2.4412e+00, -2.0994e+00,  ..., -9.6460e-01,\n",
            "         -2.2650e+00, -2.2435e+00],\n",
            "        ...,\n",
            "        [-3.6598e+00, -3.3481e-01, -3.9849e+00,  ..., -2.1290e+00,\n",
            "         -3.5926e+00, -2.5920e+00],\n",
            "        [-2.8729e-01, -3.2074e+00, -3.8931e+00,  ..., -3.5701e+00,\n",
            "         -2.5080e+00, -3.0518e+00],\n",
            "        [-5.5087e+00, -6.8576e+00, -1.3163e-02,  ..., -5.7410e+00,\n",
            "         -5.9573e+00, -6.6872e+00]], grad_fn=<LogSoftmaxBackward0>)\n",
            "Training: 986\n",
            "Epoch: 0987 loss_train: 0.5527 acc_train: 0.8429 loss_val: 1.1508 acc_val: 0.6467 time: 4.5846s\n",
            "loss_val:1.1508463621139526, val_acc:0.6466666666666666, out_features:tensor([[-1.9459, -1.9459, -1.9459,  ..., -1.9459, -1.9459, -1.9459],\n",
            "        [-1.9459, -1.9459, -1.9459,  ..., -1.9459, -1.9459, -1.9459],\n",
            "        [-2.6004, -2.6708, -2.1942,  ..., -0.7564, -2.2787, -2.0757],\n",
            "        ...,\n",
            "        [-2.0658, -0.7984, -2.7335,  ..., -2.2246, -2.2882, -2.5464],\n",
            "        [-0.7129, -2.2107, -2.6755,  ..., -2.1683, -2.4486, -2.7673],\n",
            "        [-2.2132, -2.0709, -0.6816,  ..., -2.8129, -2.7596, -2.8744]],\n",
            "       grad_fn=<LogSoftmaxBackward0>)\n",
            "Training: 987\n",
            "Epoch: 0988 loss_train: 0.5809 acc_train: 0.8429 loss_val: 0.9616 acc_val: 0.6733 time: 4.1653s\n",
            "loss_val:0.961624264717102, val_acc:0.6733333333333333, out_features:tensor([[-2.7640, -2.7758, -0.4838,  ..., -2.7412, -2.7715, -2.5931],\n",
            "        [-2.6452, -7.8829, -8.1726,  ..., -8.1567, -0.0766, -6.7011],\n",
            "        [-2.5623, -2.2794, -2.3127,  ..., -0.8630, -2.7296, -2.0857],\n",
            "        ...,\n",
            "        [-5.4603, -0.0330, -5.5739,  ..., -5.2126, -5.0848, -4.8425],\n",
            "        [-0.0094, -6.8416, -7.4269,  ..., -7.2575, -5.5983, -6.5014],\n",
            "        [-4.1397, -5.7148, -0.0302,  ..., -5.9527, -6.0182, -5.9076]],\n",
            "       grad_fn=<LogSoftmaxBackward0>)\n",
            "Training: 988\n",
            "Epoch: 0989 loss_train: 0.6339 acc_train: 0.8357 loss_val: 1.0080 acc_val: 0.7033 time: 4.1016s\n",
            "loss_val:1.0079596042633057, val_acc:0.7033333333333334, out_features:tensor([[-5.5856, -4.9041, -0.0485,  ..., -5.0149, -5.4764, -4.5715],\n",
            "        [-1.7494, -2.7776, -1.5767,  ..., -2.7556, -1.4752, -1.8284],\n",
            "        [-2.5831, -2.3959, -2.0612,  ..., -0.8609, -2.6638, -2.0038],\n",
            "        ...,\n",
            "        [-2.5806, -0.8934, -1.5600,  ..., -2.5794, -2.3889, -2.9355],\n",
            "        [-1.3472, -2.3761, -2.4060,  ..., -1.8978, -1.7627, -1.8153],\n",
            "        [-1.4691, -2.7716, -1.5389,  ..., -1.8887, -1.8341, -2.6871]],\n",
            "       grad_fn=<LogSoftmaxBackward0>)\n",
            "Training: 989\n",
            "Epoch: 0990 loss_train: 0.6297 acc_train: 0.7929 loss_val: 0.9141 acc_val: 0.7000 time: 4.4608s\n",
            "loss_val:0.9141212105751038, val_acc:0.7, out_features:tensor([[-2.6056, -2.4815, -0.8577,  ..., -2.6031, -2.6471, -2.3608],\n",
            "        [-1.9459, -1.9459, -1.9459,  ..., -1.9459, -1.9459, -1.9459],\n",
            "        [-4.9066, -5.7420, -5.9301,  ..., -0.0250, -5.2039, -5.6747],\n",
            "        ...,\n",
            "        [-2.3723, -1.1804, -1.9072,  ..., -1.9825, -2.2441, -2.3311],\n",
            "        [-0.0086, -6.4965, -6.8518,  ..., -6.5165, -6.4851, -6.3856],\n",
            "        [-4.4961, -4.7007, -0.1373,  ..., -4.0047, -3.1533, -3.2295]],\n",
            "       grad_fn=<LogSoftmaxBackward0>)\n",
            "Training: 990\n",
            "Epoch: 0991 loss_train: 0.5915 acc_train: 0.8000 loss_val: 1.1341 acc_val: 0.6300 time: 4.1525s\n",
            "loss_val:1.1341028213500977, val_acc:0.63, out_features:tensor([[-4.3820e+00, -3.7860e+00, -1.1654e-01,  ..., -3.6202e+00,\n",
            "         -4.3375e+00, -4.0632e+00],\n",
            "        [-1.6883e+00, -2.9197e+00, -2.4456e+00,  ..., -2.1146e+00,\n",
            "         -1.2438e+00, -1.5081e+00],\n",
            "        [-4.3389e+00, -3.7884e+00, -4.1134e+00,  ..., -1.7753e-01,\n",
            "         -2.5976e+00, -4.0787e+00],\n",
            "        ...,\n",
            "        [-5.1019e+00, -8.6085e-02, -4.5301e+00,  ..., -5.2634e+00,\n",
            "         -3.2513e+00, -4.0930e+00],\n",
            "        [-2.2573e-03, -9.2825e+00, -9.2778e+00,  ..., -7.8116e+00,\n",
            "         -6.6110e+00, -8.3824e+00],\n",
            "        [-6.0788e+00, -7.3192e+00, -6.7543e-03,  ..., -7.2729e+00,\n",
            "         -6.6360e+00, -7.3662e+00]], grad_fn=<LogSoftmaxBackward0>)\n",
            "Training: 991\n",
            "Epoch: 0992 loss_train: 0.5848 acc_train: 0.8357 loss_val: 0.9983 acc_val: 0.7100 time: 4.1418s\n",
            "loss_val:0.9983487129211426, val_acc:0.71, out_features:tensor([[-7.8997, -8.2755, -0.0138,  ..., -8.2864, -8.2370, -7.0873],\n",
            "        [-1.9459, -1.9459, -1.9459,  ..., -1.9459, -1.9459, -1.9459],\n",
            "        [-2.4465, -3.0451, -2.7469,  ..., -0.4508, -2.8443, -3.0055],\n",
            "        ...,\n",
            "        [-4.6508, -0.0814, -4.3142,  ..., -3.7513, -4.2048, -4.5299],\n",
            "        [-0.4661, -3.0493, -3.3877,  ..., -2.2055, -2.5559, -2.7995],\n",
            "        [-5.6398, -6.7608, -0.0090,  ..., -6.6158, -7.0086, -7.2149]],\n",
            "       grad_fn=<LogSoftmaxBackward0>)\n",
            "Training: 992\n",
            "Epoch: 0993 loss_train: 0.5834 acc_train: 0.8214 loss_val: 1.0374 acc_val: 0.6567 time: 4.3995s\n",
            "loss_val:1.0373797416687012, val_acc:0.6566666666666666, out_features:tensor([[-6.3188, -5.9747, -0.0215,  ..., -4.4840, -6.1893, -6.4575],\n",
            "        [-1.7770, -2.7367, -2.6033,  ..., -2.3690, -1.2541, -1.3438],\n",
            "        [-4.1255, -4.7741, -4.8798,  ..., -0.0745, -3.8401, -4.4146],\n",
            "        ...,\n",
            "        [-4.2112, -0.1123, -4.2054,  ..., -4.2697, -3.6408, -3.8184],\n",
            "        [-0.1238, -3.9826, -4.4940,  ..., -3.9923, -3.3821, -3.8670],\n",
            "        [-1.6828, -3.7250, -0.3959,  ..., -3.9410, -3.3978, -3.3513]],\n",
            "       grad_fn=<LogSoftmaxBackward0>)\n",
            "Training: 993\n",
            "Epoch: 0994 loss_train: 0.6075 acc_train: 0.8429 loss_val: 1.0264 acc_val: 0.6600 time: 4.1515s\n",
            "loss_val:1.026368498802185, val_acc:0.66, out_features:tensor([[-7.2225e+00, -7.4194e+00, -7.3233e-03,  ..., -7.3939e+00,\n",
            "         -7.3761e+00, -7.3309e+00],\n",
            "        [-2.0163e+00, -2.6090e+00, -2.7056e+00,  ..., -1.9976e+00,\n",
            "         -1.1292e+00, -1.5020e+00],\n",
            "        [-1.2911e+01, -1.2912e+01, -1.3409e+01,  ..., -1.0967e-05,\n",
            "         -1.3179e+01, -1.3417e+01],\n",
            "        ...,\n",
            "        [-3.1537e+00, -5.2766e-01, -3.8941e+00,  ..., -3.0206e+00,\n",
            "         -1.3794e+00, -3.6910e+00],\n",
            "        [-1.5218e-01, -3.9168e+00, -5.0587e+00,  ..., -3.7599e+00,\n",
            "         -2.5667e+00, -4.8877e+00],\n",
            "        [-6.7308e+00, -5.3811e+00, -1.1330e-02,  ..., -6.4791e+00,\n",
            "         -6.7758e+00, -6.8389e+00]], grad_fn=<LogSoftmaxBackward0>)\n",
            "Training: 994\n",
            "Epoch: 0995 loss_train: 0.5800 acc_train: 0.8214 loss_val: 0.9771 acc_val: 0.7033 time: 4.1581s\n",
            "loss_val:0.9771156907081604, val_acc:0.7033333333333334, out_features:tensor([[-8.0775e+00, -7.9425e+00, -2.0092e-03,  ..., -8.1847e+00,\n",
            "         -8.2585e+00, -8.2148e+00],\n",
            "        [-2.8566e+00, -5.7873e+00, -5.4287e+00,  ..., -5.8802e+00,\n",
            "         -8.9462e-02, -5.9239e+00],\n",
            "        [-6.1216e+00, -6.5163e+00, -6.3326e+00,  ..., -1.0623e-02,\n",
            "         -6.5237e+00, -6.2739e+00],\n",
            "        ...,\n",
            "        [-6.2080e+00, -2.8402e-02, -5.7221e+00,  ..., -4.6415e+00,\n",
            "         -4.6577e+00, -6.2436e+00],\n",
            "        [-1.9459e+00, -1.9459e+00, -1.9459e+00,  ..., -1.9459e+00,\n",
            "         -1.9459e+00, -1.9459e+00],\n",
            "        [-7.0110e+00, -7.2548e+00, -4.2904e-03,  ..., -7.3969e+00,\n",
            "         -7.3824e+00, -7.2911e+00]], grad_fn=<LogSoftmaxBackward0>)\n",
            "Training: 995\n",
            "Epoch: 0996 loss_train: 0.5924 acc_train: 0.8143 loss_val: 0.9867 acc_val: 0.7100 time: 4.4456s\n",
            "loss_val:0.9866696000099182, val_acc:0.71, out_features:tensor([[-1.9459e+00, -1.9459e+00, -1.9459e+00,  ..., -1.9459e+00,\n",
            "         -1.9459e+00, -1.9459e+00],\n",
            "        [-2.5205e+00, -3.1442e+00, -2.3751e+00,  ..., -2.0580e+00,\n",
            "         -1.2815e+00, -1.0581e+00],\n",
            "        [-2.4088e+00, -2.7668e+00, -1.7664e+00,  ..., -8.4850e-01,\n",
            "         -2.4335e+00, -2.2796e+00],\n",
            "        ...,\n",
            "        [-9.3872e+00, -6.1338e-04, -9.4071e+00,  ..., -9.2883e+00,\n",
            "         -8.6830e+00, -9.1596e+00],\n",
            "        [-1.2154e+00, -2.1422e+00, -2.2454e+00,  ..., -1.5209e+00,\n",
            "         -2.4570e+00, -2.4478e+00],\n",
            "        [-6.3273e+00, -5.8587e+00, -2.0014e-02,  ..., -6.1940e+00,\n",
            "         -4.8503e+00, -6.2333e+00]], grad_fn=<LogSoftmaxBackward0>)\n",
            "Training: 996\n",
            "Epoch: 0997 loss_train: 0.6701 acc_train: 0.7929 loss_val: 1.0956 acc_val: 0.6800 time: 4.1735s\n",
            "loss_val:1.0956205129623413, val_acc:0.68, out_features:tensor([[-4.9203e+00, -4.2174e+00, -7.5877e-02,  ..., -4.7162e+00,\n",
            "         -4.7426e+00, -3.7172e+00],\n",
            "        [-2.2534e+00, -2.4096e+00, -2.6373e+00,  ..., -1.7886e+00,\n",
            "         -1.1027e+00, -1.7541e+00],\n",
            "        [-9.1889e+00, -9.5266e+00, -1.0308e+01,  ..., -3.1621e-04,\n",
            "         -9.9951e+00, -1.0285e+01],\n",
            "        ...,\n",
            "        [-5.0007e+00, -6.4906e-02, -5.1054e+00,  ..., -4.7511e+00,\n",
            "         -3.8294e+00, -4.2540e+00],\n",
            "        [-1.9459e+00, -1.9459e+00, -1.9459e+00,  ..., -1.9459e+00,\n",
            "         -1.9459e+00, -1.9459e+00],\n",
            "        [-6.6974e+00, -6.3924e+00, -6.7053e-03,  ..., -6.9063e+00,\n",
            "         -6.7660e+00, -7.1883e+00]], grad_fn=<LogSoftmaxBackward0>)\n",
            "Training: 997\n",
            "Epoch: 0998 loss_train: 0.5552 acc_train: 0.8286 loss_val: 0.9797 acc_val: 0.6600 time: 4.2871s\n",
            "loss_val:0.979677140712738, val_acc:0.66, out_features:tensor([[-3.0763, -2.9728, -0.4342,  ..., -2.6839, -2.9304, -2.7182],\n",
            "        [-1.9459, -1.9459, -1.9459,  ..., -1.9459, -1.9459, -1.9459],\n",
            "        [-4.8093, -4.2308, -3.2693,  ..., -0.0944, -4.5817, -4.4691],\n",
            "        ...,\n",
            "        [-1.8166, -1.8849, -2.0397,  ..., -2.0398, -1.8619, -1.8548],\n",
            "        [-1.5782, -2.5931, -2.0970,  ..., -1.5706, -2.0144, -1.7319],\n",
            "        [-5.0877, -3.7587, -0.0521,  ..., -4.8706, -5.2998, -5.4980]],\n",
            "       grad_fn=<LogSoftmaxBackward0>)\n",
            "Training: 998\n",
            "Epoch: 0999 loss_train: 0.5907 acc_train: 0.7929 loss_val: 1.0236 acc_val: 0.6567 time: 4.3454s\n",
            "loss_val:1.0235627889633179, val_acc:0.6566666666666666, out_features:tensor([[-6.7509, -6.8527, -0.0234,  ..., -6.4284, -6.9255, -5.8499],\n",
            "        [-3.0113, -3.2510, -4.0613,  ..., -1.9439, -1.0319, -0.9724],\n",
            "        [-4.6642, -4.4079, -3.4017,  ..., -0.0855, -4.6537, -4.9400],\n",
            "        ...,\n",
            "        [-4.8117, -0.0542, -5.1747,  ..., -4.4772, -4.1828, -4.9512],\n",
            "        [-0.1998, -4.0668, -4.2184,  ..., -3.6808, -2.3323, -4.2995],\n",
            "        [-5.0831, -5.2414, -0.0397,  ..., -4.5739, -4.6142, -5.5708]],\n",
            "       grad_fn=<LogSoftmaxBackward0>)\n",
            "Training: 999\n",
            "Epoch: 1000 loss_train: 0.6713 acc_train: 0.7643 loss_val: 0.9722 acc_val: 0.6667 time: 4.0654s\n",
            "loss_val:0.9721681475639343, val_acc:0.6666666666666666, out_features:tensor([[-7.2771, -7.0770, -0.0097,  ..., -5.1876, -7.1379, -6.9758],\n",
            "        [-4.7656, -6.6918, -4.9422,  ..., -3.7191, -0.0651, -3.8789],\n",
            "        [-5.6637, -6.0138, -4.2241,  ..., -0.0261, -6.4040, -6.2414],\n",
            "        ...,\n",
            "        [-2.1911, -0.8602, -2.1394,  ..., -2.5522, -2.2949, -2.2880],\n",
            "        [-0.8515, -3.0397, -2.3357,  ..., -1.3908, -2.4073, -2.9416],\n",
            "        [-2.4101, -2.1295, -0.9996,  ..., -2.2239, -2.5163, -2.3886]],\n",
            "       grad_fn=<LogSoftmaxBackward0>)\n",
            "Test set results: loss= 0.6499 accuracy= 0.8470\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Visualization"
      ],
      "metadata": {
        "id": "iNod6qKW0b2B"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# visualize learned feature representation\n",
        "def visualize_learnedFeature_tSNE(labels, out_features, dataset):\n",
        "    color_map = {0: \"red\", 1: \"blue\", 2: \"green\",\n",
        "                           3: \"orange\", 4: \"yellow\", 5: \"pink\", 6: \"gray\"}\n",
        "\n",
        "    if dataset =='citeseer':\n",
        "        num_classes = 6\n",
        "    elif dataset == 'cora':\n",
        "        num_classes = 7\n",
        "    elif dataset =='pubmed':\n",
        "        num_classes = 3\n",
        "    node_labels = labels.cpu().numpy()\n",
        "    out_features = out_features.cpu().detach().numpy()\n",
        "    t_sne_X = TSNE(n_components=2, perplexity=30, method='barnes_hut').fit_transform(out_features)\n",
        "\n",
        "    plt.figure()\n",
        "    for class_id in range(num_classes):\n",
        "        plt.scatter(t_sne_X[node_labels == class_id, 0],\n",
        "                    t_sne_X[node_labels == class_id, 1], s=20,\n",
        "                    color=color_map[class_id],\n",
        "                    edgecolors='black', linewidths=0.15)\n",
        "\n",
        "    plt.axis(\"off\")\n",
        "    plt.title(\"t-SNE projection of the learned features for \"+dataset)\n",
        "    plt.show()\n",
        "\n",
        "# visulaize validation loss and accuracy\n",
        "def visualize_validation_performance(val_acc, val_loss):\n",
        "    f, ax = plt.subplots(1, 2, figsize=(13, 5.5))\n",
        "    ax[0].plot(val_loss, linewidth=2, color=\"red\")\n",
        "    ax[0].set_title(\"Validation loss\")\n",
        "    ax[0].set_ylabel(\"Cross Entropy Loss\")\n",
        "    ax[0].set_xlabel(\"Epoch\")\n",
        "    ax[0].grid()\n",
        "    ax[1].plot(val_acc, linewidth=2, color=\"red\")\n",
        "    ax[1].set_title(\"Validation accuracy\")\n",
        "    ax[1].set_ylabel(\"Acc\")\n",
        "    ax[1].set_xlabel(\"Epoch\")\n",
        "    ax[1].grid()\n"
      ],
      "metadata": {
        "id": "FZ8k66T40ddm"
      },
      "execution_count": 58,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "visualize_validation_performance(val_acc_list, val_loss_list)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 526
        },
        "id": "_mY8pJ1irszj",
        "outputId": "f7f29bf1-4968-41aa-cbd4-d5ab4d95f246"
      },
      "execution_count": 59,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 1300x550 with 2 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "dataset = 'cora'\n",
        "\n",
        "visualize_learnedFeature_tSNE(labels, out_features, dataset)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 428
        },
        "id": "aO_DnIuCvO6O",
        "outputId": "4cc31ead-ef18-4525-a2f9-f1a65df5eab1"
      },
      "execution_count": 60,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 640x480 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "PCPQF5i-w3RU"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}