{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyPEPNHuHHdWgPH6I6bn5qGd",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/mlimbuu/pytorch-GAT/blob/main/pytorch_SparseGAT.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Setting Up Environment"
      ],
      "metadata": {
        "id": "D8oT6YND6ykU"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# !pip install torch==2.3.0\n",
        "# !pip install networkx==3.3\n",
        "# !pip install scipy==1.13.0\n",
        "# !pip install numpy==1.26.4\n",
        "# !pip install jupyter==1.0.0"
      ],
      "metadata": {
        "id": "i79XZUAo6zt7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Import Libraries\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "import torch.optim as optim\n",
        "from torch.autograd import Variable\n",
        "\n",
        "\n",
        "import os\n",
        "import glob\n",
        "import time\n",
        "import random\n",
        "import argparse\n",
        "import numpy as np\n",
        "import scipy.sparse as sp\n",
        "\n",
        "import matplotlib.pyplot as plt\n",
        "from sklearn.manifold import TSNE"
      ],
      "metadata": {
        "id": "pQ1BJCYf-Ux2"
      },
      "execution_count": 27,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Data Loading & Data Processing"
      ],
      "metadata": {
        "id": "JVxe6xUO64Vc"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import zipfile\n",
        "with zipfile.ZipFile(\"data.zip\",\"r\") as zip_ref:\n",
        "    zip_ref.extractall(\"data\")"
      ],
      "metadata": {
        "id": "Yw0_Pb3r63tr"
      },
      "execution_count": 28,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def encode_onehot(labels):\n",
        "    # The classes must be sorted before encoding to enable static class encoding.\n",
        "    # In other words, make sure the first class always maps to index 0.\n",
        "    classes = sorted(list(set(labels)))\n",
        "    classes_dict = {c: np.identity(len(classes))[i, :] for i, c in enumerate(classes)}\n",
        "    labels_onehot = np.array(list(map(classes_dict.get, labels)), dtype=np.int32)\n",
        "    return labels_onehot\n",
        "\n",
        "def normalize_adj(mx):\n",
        "    \"\"\"Row-normalize sparse matrix\"\"\"\n",
        "    rowsum = np.array(mx.sum(1))\n",
        "    r_inv_sqrt = np.power(rowsum, -0.5).flatten()\n",
        "    r_inv_sqrt[np.isinf(r_inv_sqrt)] = 0.\n",
        "    r_mat_inv_sqrt = sp.diags(r_inv_sqrt)\n",
        "    return mx.dot(r_mat_inv_sqrt).transpose().dot(r_mat_inv_sqrt)\n",
        "\n",
        "def normalize_features(mx):\n",
        "    \"\"\"Row-normalize sparse matrix\"\"\"\n",
        "    rowsum = np.array(mx.sum(1))\n",
        "    r_inv = np.power(rowsum, -1).flatten()\n",
        "    r_inv[np.isinf(r_inv)] = 0.\n",
        "    r_mat_inv = sp.diags(r_inv)\n",
        "    mx = r_mat_inv.dot(mx)\n",
        "    return mx\n",
        "\n",
        "def load_data(path=\"./data/data/cora/\", dataset=\"cora\"):\n",
        "    \"\"\"Load citation network dataset (cora only for now)\"\"\"\n",
        "    print('Loading {} dataset...'.format(dataset))\n",
        "\n",
        "    idx_features_labels = np.genfromtxt(\"{}{}.content\".format(path, dataset), dtype=np.dtype(str))\n",
        "    features = sp.csr_matrix(idx_features_labels[:, 1:-1], dtype=np.float32)\n",
        "    labels = encode_onehot(idx_features_labels[:, -1])\n",
        "\n",
        "    # build graph\n",
        "    idx = np.array(idx_features_labels[:, 0], dtype=np.int32)\n",
        "    idx_map = {j: i for i, j in enumerate(idx)}\n",
        "    edges_unordered = np.genfromtxt(\"{}{}.cites\".format(path, dataset), dtype=np.int32)\n",
        "    edges = np.array(list(map(idx_map.get, edges_unordered.flatten())), dtype=np.int32).reshape(edges_unordered.shape)\n",
        "    adj = sp.coo_matrix((np.ones(edges.shape[0]), (edges[:, 0], edges[:, 1])), shape=(labels.shape[0], labels.shape[0]), dtype=np.float32)\n",
        "\n",
        "    # build symmetric adjacency matrix\n",
        "    adj = adj + adj.T.multiply(adj.T > adj) - adj.multiply(adj.T > adj)\n",
        "\n",
        "    # normalize features and adjacency matrix\n",
        "    features = normalize_features(features)\n",
        "    adj = normalize_adj(adj + sp.eye(adj.shape[0]))\n",
        "\n",
        "    idx_train = range(140)\n",
        "    idx_val = range(200, 500)\n",
        "    idx_test = range(500, 1500)\n",
        "\n",
        "    adj = torch.FloatTensor(np.array(adj.todense()))\n",
        "    features = torch.FloatTensor(np.array(features.todense()))\n",
        "    labels = torch.LongTensor(np.where(labels)[1])\n",
        "\n",
        "    idx_train = torch.LongTensor(idx_train)\n",
        "    idx_val = torch.LongTensor(idx_val)\n",
        "    idx_test = torch.LongTensor(idx_test)\n",
        "\n",
        "    return adj, features, labels, idx_train, idx_val, idx_test\n"
      ],
      "metadata": {
        "id": "ZMVICxzx-bss"
      },
      "execution_count": 29,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Load data\n",
        "adj, features, labels, idx_train, idx_val, idx_test = load_data()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "EQcDXh2T-h7a",
        "outputId": "d3f4f27c-f1d2-4ab3-a94b-2a2e02903898"
      },
      "execution_count": 30,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Loading cora dataset...\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Data Visualization"
      ],
      "metadata": {
        "id": "QwnbvxUM-AHg"
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "etY88mhO-B5p"
      },
      "execution_count": 30,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Sparse GAT Layer"
      ],
      "metadata": {
        "id": "OgAYfC-J-C-4"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class SpecialSpmmFunction(torch.autograd.Function):\n",
        "    \"\"\"Special function for only sparse region backpropataion layer.\"\"\"\n",
        "    @staticmethod\n",
        "    def forward(ctx, indices, values, shape, b):\n",
        "        assert indices.requires_grad == False\n",
        "        a = torch.sparse_coo_tensor(indices, values, shape)\n",
        "        ctx.save_for_backward(a, b)\n",
        "        ctx.N = shape[0]\n",
        "        return torch.matmul(a, b)\n",
        "\n",
        "    @staticmethod\n",
        "    def backward(ctx, grad_output):\n",
        "        a, b = ctx.saved_tensors\n",
        "        grad_values = grad_b = None\n",
        "        if ctx.needs_input_grad[1]:\n",
        "            grad_a_dense = grad_output.matmul(b.t())\n",
        "            edge_idx = a._indices()[0, :] * ctx.N + a._indices()[1, :]\n",
        "            grad_values = grad_a_dense.view(-1)[edge_idx]\n",
        "        if ctx.needs_input_grad[3]:\n",
        "            grad_b = a.t().matmul(grad_output)\n",
        "        return None, grad_values, None, grad_b\n",
        "\n",
        "class SpecialSpmm(nn.Module):\n",
        "    def forward(self, indices, values, shape, b):\n",
        "        return SpecialSpmmFunction.apply(indices, values, shape, b)"
      ],
      "metadata": {
        "id": "_cXtV0Bg_-J1"
      },
      "execution_count": 31,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class Sparse_GraphAttentionLayer(nn.Module):\n",
        "    \"\"\"\n",
        "    Sparse version GAT layer, similar to https://arxiv.org/abs/1710.10903\n",
        "    \"\"\"\n",
        "\n",
        "    def __init__(self, in_features, out_features, dropout, alpha, concat=True):\n",
        "        super(Sparse_GraphAttentionLayer, self).__init__()\n",
        "        self.in_features = in_features\n",
        "        self.out_features = out_features\n",
        "        self.alpha = alpha\n",
        "        self.concat = concat\n",
        "\n",
        "        self.W = nn.Parameter(torch.zeros(size=(in_features, out_features)))\n",
        "        nn.init.xavier_normal_(self.W.data, gain=1.414)\n",
        "\n",
        "        self.a = nn.Parameter(torch.zeros(size=(1, 2*out_features)))\n",
        "        nn.init.xavier_normal_(self.a.data, gain=1.414)\n",
        "\n",
        "        self.dropout = nn.Dropout(dropout)\n",
        "        self.leakyrelu = nn.LeakyReLU(self.alpha)\n",
        "        self.special_spmm = SpecialSpmm()\n",
        "\n",
        "    def forward(self, input, adj):\n",
        "        dv = 'cuda' if input.is_cuda else 'cpu'\n",
        "\n",
        "        N = input.size()[0]\n",
        "        edge = adj.nonzero().t()\n",
        "\n",
        "        h = torch.mm(input, self.W)\n",
        "        # h: N x out\n",
        "        assert not torch.isnan(h).any()\n",
        "\n",
        "        # Self-attention on the nodes - Shared attention mechanism\n",
        "        edge_h = torch.cat((h[edge[0, :], :], h[edge[1, :], :]), dim=1).t()\n",
        "        # edge: 2*D x E\n",
        "\n",
        "        edge_e = torch.exp(-self.leakyrelu(self.a.mm(edge_h).squeeze()))\n",
        "        assert not torch.isnan(edge_e).any()\n",
        "        # edge_e: E\n",
        "\n",
        "        e_rowsum = self.special_spmm(edge, edge_e, torch.Size([N, N]), torch.ones(size=(N,1), device=dv))\n",
        "        # e_rowsum: N x 1\n",
        "\n",
        "        edge_e = self.dropout(edge_e)\n",
        "        # edge_e: E\n",
        "\n",
        "        h_prime = self.special_spmm(edge, edge_e, torch.Size([N, N]), h)\n",
        "        assert not torch.isnan(h_prime).any()\n",
        "        # h_prime: N x out\n",
        "\n",
        "        h_prime = h_prime.div(e_rowsum)\n",
        "        # h_prime: N x out\n",
        "        assert not torch.isnan(h_prime).any()\n",
        "\n",
        "        if self.concat:\n",
        "            # if this layer is not last layer,\n",
        "            return F.elu(h_prime)\n",
        "        else:\n",
        "            # if this layer is last layer,\n",
        "            return h_prime\n",
        "\n",
        "    def __repr__(self):\n",
        "        return self.__class__.__name__ + ' (' + str(self.in_features) + ' -> ' + str(self.out_features) + ')'\n"
      ],
      "metadata": {
        "id": "MAxuq1YI-FHC"
      },
      "execution_count": 32,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Sparse GAT Model"
      ],
      "metadata": {
        "id": "s90CGeC1-FmN"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class Sparse_GAT(nn.Module):\n",
        "    def __init__(self, nfeat, nhid, nclass, dropout, alpha, nheads):\n",
        "        \"\"\"Sparse version of GAT.\"\"\"\n",
        "        super(Sparse_GAT, self).__init__()\n",
        "        self.dropout = dropout\n",
        "\n",
        "        self.attentions = [Sparse_GraphAttentionLayer(nfeat,\n",
        "                                                 nhid,\n",
        "                                                 dropout=dropout,\n",
        "                                                 alpha=alpha,\n",
        "                                                 concat=True) for _ in range(nheads)]\n",
        "        for i, attention in enumerate(self.attentions):\n",
        "            self.add_module('attention_{}'.format(i), attention)\n",
        "\n",
        "        self.out_att = Sparse_GraphAttentionLayer(nhid * nheads,\n",
        "                                             nclass,\n",
        "                                             dropout=dropout,\n",
        "                                             alpha=alpha,\n",
        "                                             concat=False)\n",
        "\n",
        "    def forward(self, x, adj):\n",
        "        x = F.dropout(x, self.dropout, training=self.training)\n",
        "        x = torch.cat([att(x, adj) for att in self.attentions], dim=1)\n",
        "        x = F.dropout(x, self.dropout, training=self.training)\n",
        "        x = F.elu(self.out_att(x, adj))\n",
        "        return F.log_softmax(x, dim=1)\n",
        "\n"
      ],
      "metadata": {
        "id": "hF_PDjLk-HZd"
      },
      "execution_count": 33,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Model Training"
      ],
      "metadata": {
        "id": "zH9W7ZY_-Jcx"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Training & Test\n",
        "\n",
        "def accuracy(output, labels):\n",
        "    preds = output.max(1)[1].type_as(labels)\n",
        "    correct = preds.eq(labels).double()\n",
        "    correct = correct.sum()\n",
        "    return correct / len(labels)\n",
        "\n",
        "def train(epoch):\n",
        "    t = time.time()\n",
        "    model.train()\n",
        "    optimizer.zero_grad()\n",
        "    output = model(features, adj)\n",
        "    loss_train = F.nll_loss(output[idx_train], labels[idx_train])\n",
        "    acc_train = accuracy(output[idx_train], labels[idx_train])\n",
        "    loss_train.backward()\n",
        "    optimizer.step()\n",
        "\n",
        "    loss_val = F.nll_loss(output[idx_val], labels[idx_val])\n",
        "    acc_val = accuracy(output[idx_val], labels[idx_val])\n",
        "    print('Epoch: {:04d}'.format(epoch+1),\n",
        "          'loss_train: {:.4f}'.format(loss_train.data.item()),\n",
        "          'acc_train: {:.4f}'.format(acc_train.data.item()),\n",
        "          'loss_val: {:.4f}'.format(loss_val.data.item()),\n",
        "          'acc_val: {:.4f}'.format(acc_val.data.item()),\n",
        "          'time: {:.4f}s'.format(time.time() - t))\n",
        "\n",
        "    return loss_val, acc_val, output\n",
        "\n",
        "def test():\n",
        "    model.eval()\n",
        "    output = model(features, adj)\n",
        "    loss_test = F.nll_loss(output[idx_test], labels[idx_test])\n",
        "    acc_test = accuracy(output[idx_test], labels[idx_test])\n",
        "    print(\"Test set results:\",\n",
        "          \"loss= {:.4f}\".format(loss_test.data.item()),\n",
        "          \"accuracy= {:.4f}\".format(acc_test.data.item()))\n"
      ],
      "metadata": {
        "id": "D8N_xeqDArIx"
      },
      "execution_count": 34,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Parameters\n",
        "seed = 72\n",
        "epochs = 1000\n",
        "lr = 0.005\n",
        "weight_decay = 5e-4\n",
        "hidden = 8\n",
        "nb_heads = 8\n",
        "dropout = 0.6\n",
        "alpha = 0.2\n",
        "patience = 100"
      ],
      "metadata": {
        "id": "v8ezqzk3-Ll4"
      },
      "execution_count": 40,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Initialize model\n",
        "model = Sparse_GAT(nfeat=features.shape[1], nhid=hidden, nclass=int(labels.max()) + 1, dropout=dropout, nheads=nb_heads, alpha=alpha)\n",
        "optimizer = optim.Adam(model.parameters(), lr=lr, weight_decay=weight_decay)\n"
      ],
      "metadata": {
        "id": "FTqEUvnd_qiF"
      },
      "execution_count": 41,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "val_acc_list = []\n",
        "val_loss_list = []\n",
        "\n",
        "# Training model\n",
        "for epoch in range(epochs):\n",
        "    print(f\"Training: {epoch}\")\n",
        "    val_loss, val_acc, out_features = train(epoch)\n",
        "    print(f\"loss_val:{val_loss}, val_acc:{val_acc}, out_features:{out_features}\")\n",
        "    # val_acc_list.append(val_acc.item())\n",
        "    # val_loss_list.append(loss_val.item())\n",
        "    val_loss_list.append(val_loss.item())\n",
        "    val_acc_list.append(val_acc.item())\n",
        "\n",
        "# Testing model\n",
        "test()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zg2gYo0pAgOR",
        "outputId": "a264d9f3-12ac-4f9d-8c72-4b8da9049af7"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1;30;43mStreaming output truncated to the last 5000 lines.\u001b[0m\n",
            "        [-1.9459e+00, -1.9459e+00, -1.9459e+00,  ..., -1.9459e+00,\n",
            "         -1.9459e+00, -1.9459e+00],\n",
            "        [-7.5749e+00, -8.2265e+00, -5.0076e-03,  ..., -8.2599e+00,\n",
            "         -7.8295e+00, -8.2482e+00]], grad_fn=<LogSoftmaxBackward0>)\n",
            "Training: 429\n",
            "Epoch: 0430 loss_train: 0.7497 acc_train: 0.7643 loss_val: 1.0279 acc_val: 0.6167 time: 1.7340s\n",
            "loss_val:1.0278730392456055, val_acc:0.6166666666666667, out_features:tensor([[-5.6819e+00, -5.7515e+00, -5.4570e-02,  ..., -5.5676e+00,\n",
            "         -5.5434e+00, -5.1920e+00],\n",
            "        [-2.3693e+00, -3.6388e+00, -3.0708e+00,  ..., -2.5069e+00,\n",
            "         -1.1623e+00, -8.8110e-01],\n",
            "        [-1.7357e+00, -1.7718e+00, -2.4430e+00,  ..., -1.4355e+00,\n",
            "         -2.1238e+00, -2.2585e+00],\n",
            "        ...,\n",
            "        [-3.7013e+00, -1.2011e-01, -4.2276e+00,  ..., -4.0672e+00,\n",
            "         -4.0693e+00, -3.6153e+00],\n",
            "        [-1.4048e-01, -3.2598e+00, -4.8157e+00,  ..., -3.4096e+00,\n",
            "         -3.3874e+00, -4.6031e+00],\n",
            "        [-8.3389e+00, -8.1479e+00, -2.2662e-03,  ..., -6.9947e+00,\n",
            "         -8.0755e+00, -8.2641e+00]], grad_fn=<LogSoftmaxBackward0>)\n",
            "Training: 430\n",
            "Epoch: 0431 loss_train: 0.6396 acc_train: 0.8000 loss_val: 1.0536 acc_val: 0.6833 time: 1.8902s\n",
            "loss_val:1.0535876750946045, val_acc:0.6833333333333333, out_features:tensor([[-1.3116e+01, -1.3045e+01, -1.6808e-05,  ..., -1.2287e+01,\n",
            "         -1.3102e+01, -1.2521e+01],\n",
            "        [-1.4098e+00, -2.5032e+00, -2.4549e+00,  ..., -2.2270e+00,\n",
            "         -1.3569e+00, -1.8629e+00],\n",
            "        [-3.0484e+00, -3.5893e+00, -3.1573e+00,  ..., -1.7812e-01,\n",
            "         -3.9631e+00, -4.3178e+00],\n",
            "        ...,\n",
            "        [-3.8083e+00, -2.5959e-01, -3.5387e+00,  ..., -3.2576e+00,\n",
            "         -2.7586e+00, -2.9206e+00],\n",
            "        [-1.2967e+00, -2.3349e+00, -2.0550e+00,  ..., -2.0846e+00,\n",
            "         -1.8007e+00, -2.4016e+00],\n",
            "        [-6.1938e+00, -6.2600e+00, -1.2920e-02,  ..., -5.8764e+00,\n",
            "         -6.4610e+00, -6.1557e+00]], grad_fn=<LogSoftmaxBackward0>)\n",
            "Training: 431\n",
            "Epoch: 0432 loss_train: 0.6822 acc_train: 0.8143 loss_val: 1.1129 acc_val: 0.6567 time: 1.9478s\n",
            "loss_val:1.1129038333892822, val_acc:0.6566666666666666, out_features:tensor([[-3.5849, -3.4021, -0.4948,  ..., -3.2761, -3.4481, -3.4061],\n",
            "        [-2.5413, -3.3540, -2.6784,  ..., -1.9600, -0.8790, -1.4862],\n",
            "        [-4.0664, -2.5087, -4.0702,  ..., -0.1733, -4.1792, -4.1304],\n",
            "        ...,\n",
            "        [-1.9459, -1.9459, -1.9459,  ..., -1.9459, -1.9459, -1.9459],\n",
            "        [-1.9459, -1.9459, -1.9459,  ..., -1.9459, -1.9459, -1.9459],\n",
            "        [-3.9183, -4.3918, -0.1599,  ..., -4.4599, -4.6165, -4.4955]],\n",
            "       grad_fn=<LogSoftmaxBackward0>)\n",
            "Training: 432\n",
            "Epoch: 0433 loss_train: 0.6298 acc_train: 0.8357 loss_val: 0.9053 acc_val: 0.6967 time: 1.7519s\n",
            "loss_val:0.9052727222442627, val_acc:0.6966666666666667, out_features:tensor([[-2.7725e+00, -3.2364e+00, -5.2845e-01,  ..., -2.5872e+00,\n",
            "         -3.1340e+00, -2.7053e+00],\n",
            "        [-3.1795e+00, -3.4886e+00, -3.0504e+00,  ..., -2.6383e+00,\n",
            "         -4.3986e-01, -1.9610e+00],\n",
            "        [-4.1930e+00, -4.7324e+00, -3.0850e+00,  ..., -1.2186e-01,\n",
            "         -3.9848e+00, -4.1224e+00],\n",
            "        ...,\n",
            "        [-3.1311e+00, -4.8143e-01, -2.7588e+00,  ..., -2.5763e+00,\n",
            "         -2.4111e+00, -2.7986e+00],\n",
            "        [-1.6187e+00, -1.9966e+00, -1.9607e+00,  ..., -1.9115e+00,\n",
            "         -2.1046e+00, -2.0081e+00],\n",
            "        [-1.0352e+01, -8.7657e+00, -1.3501e-03,  ..., -1.0327e+01,\n",
            "         -1.0296e+01, -1.0353e+01]], grad_fn=<LogSoftmaxBackward0>)\n",
            "Training: 433\n",
            "Epoch: 0434 loss_train: 0.5398 acc_train: 0.8500 loss_val: 1.0146 acc_val: 0.6867 time: 1.7439s\n",
            "loss_val:1.014603614807129, val_acc:0.6866666666666666, out_features:tensor([[-4.1812e+00, -4.5982e+00, -9.1388e-02,  ..., -4.1778e+00,\n",
            "         -4.3913e+00, -3.8295e+00],\n",
            "        [-5.9396e+00, -8.6633e+00, -8.8605e+00,  ..., -5.6280e+00,\n",
            "         -9.9880e-03, -5.7283e+00],\n",
            "        [-2.4221e+00, -2.5492e+00, -2.4610e+00,  ..., -7.0818e-01,\n",
            "         -2.2994e+00, -2.3946e+00],\n",
            "        ...,\n",
            "        [-7.7635e+00, -2.7906e-03, -8.2817e+00,  ..., -7.3370e+00,\n",
            "         -7.3816e+00, -7.4901e+00],\n",
            "        [-1.4324e+00, -2.1671e+00, -2.0234e+00,  ..., -1.6556e+00,\n",
            "         -2.2117e+00, -2.2603e+00],\n",
            "        [-2.7328e+00, -3.4759e+00, -2.9312e-01,  ..., -2.8905e+00,\n",
            "         -2.8969e+00, -3.6740e+00]], grad_fn=<LogSoftmaxBackward0>)\n",
            "Training: 434\n",
            "Epoch: 0435 loss_train: 0.7312 acc_train: 0.7571 loss_val: 1.0478 acc_val: 0.6467 time: 1.7640s\n",
            "loss_val:1.0478278398513794, val_acc:0.6466666666666666, out_features:tensor([[-4.8387e+00, -4.5275e+00, -1.2008e-01,  ..., -4.4239e+00,\n",
            "         -4.7157e+00, -3.2362e+00],\n",
            "        [-1.9459e+00, -1.9459e+00, -1.9459e+00,  ..., -1.9459e+00,\n",
            "         -1.9459e+00, -1.9459e+00],\n",
            "        [-4.7861e+00, -6.3614e+00, -6.3078e+00,  ..., -1.7492e-02,\n",
            "         -6.0222e+00, -6.5191e+00],\n",
            "        ...,\n",
            "        [-1.6782e+00, -7.1886e-01, -3.2659e+00,  ..., -2.1590e+00,\n",
            "         -2.8751e+00, -2.5717e+00],\n",
            "        [-1.3764e-03, -8.9819e+00, -9.0191e+00,  ..., -7.7785e+00,\n",
            "         -7.5377e+00, -9.3255e+00],\n",
            "        [-4.1958e+00, -4.8156e+00, -4.5255e-02,  ..., -5.5568e+00,\n",
            "         -4.6061e+00, -5.6393e+00]], grad_fn=<LogSoftmaxBackward0>)\n",
            "Training: 435\n",
            "Epoch: 0436 loss_train: 0.6445 acc_train: 0.8143 loss_val: 1.0645 acc_val: 0.6700 time: 1.7520s\n",
            "loss_val:1.0644901990890503, val_acc:0.67, out_features:tensor([[-7.8222e+00, -7.8209e+00, -4.5468e-03,  ..., -6.9404e+00,\n",
            "         -7.8472e+00, -6.7138e+00],\n",
            "        [-1.9459e+00, -1.9459e+00, -1.9459e+00,  ..., -1.9459e+00,\n",
            "         -1.9459e+00, -1.9459e+00],\n",
            "        [-3.4438e+00, -3.0699e+00, -3.3594e+00,  ..., -2.0552e-01,\n",
            "         -3.7793e+00, -3.5290e+00],\n",
            "        ...,\n",
            "        [-2.1512e+00, -1.3438e+00, -2.1656e+00,  ..., -2.0080e+00,\n",
            "         -2.0608e+00, -1.7484e+00],\n",
            "        [-4.5993e-01, -3.3226e+00, -3.1371e+00,  ..., -2.1163e+00,\n",
            "         -2.4465e+00, -3.1159e+00],\n",
            "        [-1.9459e+00, -1.9459e+00, -1.9459e+00,  ..., -1.9459e+00,\n",
            "         -1.9459e+00, -1.9459e+00]], grad_fn=<LogSoftmaxBackward0>)\n",
            "Training: 436\n",
            "Epoch: 0437 loss_train: 0.6310 acc_train: 0.8071 loss_val: 1.0032 acc_val: 0.6867 time: 1.7408s\n",
            "loss_val:1.0031942129135132, val_acc:0.6866666666666666, out_features:tensor([[-1.3577e+01, -1.3587e+01, -1.1682e-05,  ..., -1.3205e+01,\n",
            "         -1.3590e+01, -1.3606e+01],\n",
            "        [-5.0166e+00, -5.3560e+00, -5.6767e+00,  ..., -5.7635e-01,\n",
            "         -1.1902e+00, -2.1542e+00],\n",
            "        [-4.3155e+00, -4.3325e+00, -4.0873e+00,  ..., -9.2735e-02,\n",
            "         -4.0161e+00, -4.1787e+00],\n",
            "        ...,\n",
            "        [-2.3817e+00, -1.3478e+00, -2.1378e+00,  ..., -2.0820e+00,\n",
            "         -2.0016e+00, -1.8783e+00],\n",
            "        [-7.0038e-02, -3.9022e+00, -5.2830e+00,  ..., -4.7684e+00,\n",
            "         -4.3884e+00, -5.1980e+00],\n",
            "        [-3.9641e+00, -2.8733e+00, -2.2391e-01,  ..., -2.6453e+00,\n",
            "         -3.9057e+00, -4.1190e+00]], grad_fn=<LogSoftmaxBackward0>)\n",
            "Training: 437\n",
            "Epoch: 0438 loss_train: 0.5749 acc_train: 0.8071 loss_val: 1.0498 acc_val: 0.7033 time: 1.9037s\n",
            "loss_val:1.049801230430603, val_acc:0.7033333333333334, out_features:tensor([[-8.9134e+00, -8.7936e+00, -1.1333e-03,  ..., -8.6742e+00,\n",
            "         -8.8496e+00, -8.1222e+00],\n",
            "        [-5.2481e+00, -5.8734e+00, -5.9689e+00,  ..., -3.4246e+00,\n",
            "         -6.8926e-02, -3.8755e+00],\n",
            "        [-4.8359e+00, -6.0886e+00, -5.4511e+00,  ..., -2.8169e-02,\n",
            "         -5.1315e+00, -5.2253e+00],\n",
            "        ...,\n",
            "        [-2.3597e+00, -8.6665e-01, -2.6414e+00,  ..., -2.1193e+00,\n",
            "         -1.9247e+00, -2.4991e+00],\n",
            "        [-7.3746e-01, -2.9181e+00, -3.1628e+00,  ..., -1.9970e+00,\n",
            "         -1.8579e+00, -2.3981e+00],\n",
            "        [-3.4656e+00, -3.3404e+00, -1.5225e-01,  ..., -4.4362e+00,\n",
            "         -3.3228e+00, -4.2416e+00]], grad_fn=<LogSoftmaxBackward0>)\n",
            "Training: 438\n",
            "Epoch: 0439 loss_train: 0.6301 acc_train: 0.8214 loss_val: 1.0220 acc_val: 0.6667 time: 1.9627s\n",
            "loss_val:1.0219885110855103, val_acc:0.6666666666666666, out_features:tensor([[-6.4322e+00, -6.4106e+00, -9.6677e-03,  ..., -6.5391e+00,\n",
            "         -6.1794e+00, -6.5454e+00],\n",
            "        [-3.3304e+00, -5.7837e+00, -6.3427e+00,  ..., -2.9993e+00,\n",
            "         -2.1227e-01, -2.3120e+00],\n",
            "        [-8.2004e+00, -8.4291e+00, -8.4674e+00,  ..., -1.5455e-03,\n",
            "         -8.3907e+00, -7.7242e+00],\n",
            "        ...,\n",
            "        [-3.4904e+00, -2.1700e-01, -4.0522e+00,  ..., -3.0682e+00,\n",
            "         -2.9423e+00, -3.3922e+00],\n",
            "        [-1.9459e+00, -1.9459e+00, -1.9459e+00,  ..., -1.9459e+00,\n",
            "         -1.9459e+00, -1.9459e+00],\n",
            "        [-5.5510e+00, -7.0159e+00, -1.0233e-02,  ..., -6.1074e+00,\n",
            "         -6.7200e+00, -6.8464e+00]], grad_fn=<LogSoftmaxBackward0>)\n",
            "Training: 439\n",
            "Epoch: 0440 loss_train: 0.6643 acc_train: 0.7929 loss_val: 1.0341 acc_val: 0.6967 time: 1.7440s\n",
            "loss_val:1.0340919494628906, val_acc:0.6966666666666667, out_features:tensor([[-4.0522, -3.8401, -0.2155,  ..., -3.8868, -3.6415, -3.9327],\n",
            "        [-3.2768, -3.1794, -2.7157,  ..., -2.6172, -0.5698, -1.6656],\n",
            "        [-4.2584, -3.3914, -4.3379,  ..., -0.1200, -3.7959, -4.4333],\n",
            "        ...,\n",
            "        [-3.3489, -0.5288, -3.1233,  ..., -2.6242, -1.9876, -2.6015],\n",
            "        [-0.0889, -4.5235, -5.1692,  ..., -4.4584, -3.2618, -5.1344],\n",
            "        [-2.5951, -1.8574, -1.1832,  ..., -1.5830, -2.3339, -2.5795]],\n",
            "       grad_fn=<LogSoftmaxBackward0>)\n",
            "Training: 440\n",
            "Epoch: 0441 loss_train: 0.6744 acc_train: 0.7857 loss_val: 1.0320 acc_val: 0.6933 time: 1.7411s\n",
            "loss_val:1.0320196151733398, val_acc:0.6933333333333334, out_features:tensor([[-4.2127, -4.7465, -0.0870,  ..., -4.6663, -4.3711, -4.3746],\n",
            "        [-1.9459, -1.9459, -1.9459,  ..., -1.9459, -1.9459, -1.9459],\n",
            "        [-2.2427, -1.9392, -1.8491,  ..., -1.0448, -2.4895, -2.4720],\n",
            "        ...,\n",
            "        [-1.8643, -1.4449, -2.3691,  ..., -2.3508, -2.0277, -1.7200],\n",
            "        [-0.9026, -2.6202, -2.1984,  ..., -2.0705, -2.2326, -2.4795],\n",
            "        [-2.8564, -3.1873, -0.3668,  ..., -3.2836, -3.2347, -2.3550]],\n",
            "       grad_fn=<LogSoftmaxBackward0>)\n",
            "Training: 441\n",
            "Epoch: 0442 loss_train: 0.6235 acc_train: 0.8643 loss_val: 0.9700 acc_val: 0.6667 time: 1.7286s\n",
            "loss_val:0.9699559807777405, val_acc:0.6666666666666666, out_features:tensor([[-3.1507e+00, -3.3200e+00, -4.9124e-01,  ..., -2.7738e+00,\n",
            "         -3.3100e+00, -2.7921e+00],\n",
            "        [-1.9510e+00, -2.9581e+00, -1.5989e+00,  ..., -2.3338e+00,\n",
            "         -1.0896e+00, -2.0915e+00],\n",
            "        [-2.2585e+00, -2.4508e+00, -3.6570e+00,  ..., -4.0686e-01,\n",
            "         -2.6583e+00, -3.6529e+00],\n",
            "        ...,\n",
            "        [-2.8435e+00, -4.1920e-01, -3.1950e+00,  ..., -2.4769e+00,\n",
            "         -2.4589e+00, -3.1230e+00],\n",
            "        [-3.4818e-01, -3.4508e+00, -3.4978e+00,  ..., -3.2455e+00,\n",
            "         -2.3307e+00, -2.7743e+00],\n",
            "        [-1.0954e+01, -1.0788e+01, -1.3589e-04,  ..., -1.0041e+01,\n",
            "         -1.1052e+01, -1.1088e+01]], grad_fn=<LogSoftmaxBackward0>)\n",
            "Training: 442\n",
            "Epoch: 0443 loss_train: 0.6156 acc_train: 0.8071 loss_val: 1.0363 acc_val: 0.6300 time: 1.7446s\n",
            "loss_val:1.0362892150878906, val_acc:0.63, out_features:tensor([[-6.4828e+00, -6.1803e+00, -1.3248e-02,  ..., -6.4074e+00,\n",
            "         -6.3626e+00, -5.9668e+00],\n",
            "        [-2.7145e+00, -3.6595e+00, -3.2037e+00,  ..., -2.8067e+00,\n",
            "         -5.3288e-01, -1.6159e+00],\n",
            "        [-7.1475e+00, -7.0814e+00, -6.9754e+00,  ..., -5.9080e-03,\n",
            "         -6.1911e+00, -7.2603e+00],\n",
            "        ...,\n",
            "        [-4.0780e+00, -1.1759e-01, -4.2473e+00,  ..., -3.4254e+00,\n",
            "         -3.9052e+00, -4.3811e+00],\n",
            "        [-2.8785e-01, -3.6242e+00, -4.2892e+00,  ..., -2.1990e+00,\n",
            "         -3.6633e+00, -3.0734e+00],\n",
            "        [-2.7666e+00, -3.0090e+00, -4.8978e-01,  ..., -2.5751e+00,\n",
            "         -2.8482e+00, -2.7202e+00]], grad_fn=<LogSoftmaxBackward0>)\n",
            "Training: 443\n",
            "Epoch: 0444 loss_train: 0.5773 acc_train: 0.8643 loss_val: 1.0647 acc_val: 0.6467 time: 1.7499s\n",
            "loss_val:1.0647212266921997, val_acc:0.6466666666666666, out_features:tensor([[-4.9396, -4.7945, -0.0857,  ..., -4.0989, -4.7631, -4.3758],\n",
            "        [-1.7984, -3.0741, -2.1662,  ..., -1.8725, -1.2830, -1.9165],\n",
            "        [-4.6111, -5.0068, -4.4584,  ..., -0.0580, -4.1985, -4.8486],\n",
            "        ...,\n",
            "        [-3.0423, -0.1971, -4.1394,  ..., -4.0373, -3.4602, -2.9812],\n",
            "        [-0.2259, -4.2889, -4.2026,  ..., -3.8672, -2.7672, -4.1620],\n",
            "        [-6.3859, -6.1945, -0.0116,  ..., -6.0757, -6.1329, -6.3882]],\n",
            "       grad_fn=<LogSoftmaxBackward0>)\n",
            "Training: 444\n",
            "Epoch: 0445 loss_train: 0.7056 acc_train: 0.7929 loss_val: 1.0172 acc_val: 0.7000 time: 1.8925s\n",
            "loss_val:1.017244815826416, val_acc:0.7, out_features:tensor([[-9.7117e+00, -9.6726e+00, -1.4638e-03,  ..., -9.2740e+00,\n",
            "         -9.6268e+00, -9.5102e+00],\n",
            "        [-3.6204e+00, -3.8537e+00, -2.4137e+00,  ..., -3.2559e+00,\n",
            "         -5.1595e-01, -1.5829e+00],\n",
            "        [-3.4112e+00, -4.5065e+00, -4.5220e+00,  ..., -9.4317e-02,\n",
            "         -4.2739e+00, -4.4430e+00],\n",
            "        ...,\n",
            "        [-5.5094e+00, -4.5308e-02, -5.9460e+00,  ..., -3.6615e+00,\n",
            "         -5.5619e+00, -5.6973e+00],\n",
            "        [-4.3225e-02, -5.8139e+00, -5.7030e+00,  ..., -4.1599e+00,\n",
            "         -4.4186e+00, -5.2115e+00],\n",
            "        [-1.1995e+01, -1.1986e+01, -5.2212e-05,  ..., -1.2032e+01,\n",
            "         -1.1824e+01, -1.0808e+01]], grad_fn=<LogSoftmaxBackward0>)\n",
            "Training: 445\n",
            "Epoch: 0446 loss_train: 0.5797 acc_train: 0.8786 loss_val: 1.0097 acc_val: 0.6667 time: 1.9470s\n",
            "loss_val:1.0097367763519287, val_acc:0.6666666666666666, out_features:tensor([[-9.4721e+00, -9.4489e+00, -6.0611e-04,  ..., -9.3477e+00,\n",
            "         -9.3399e+00, -8.7725e+00],\n",
            "        [-3.6823e+00, -2.3716e+00, -3.8198e+00,  ..., -9.2749e-01,\n",
            "         -1.0049e+00, -2.5675e+00],\n",
            "        [-5.4326e+00, -5.2068e+00, -3.2946e+00,  ..., -6.1962e-02,\n",
            "         -5.2034e+00, -5.5083e+00],\n",
            "        ...,\n",
            "        [-6.5176e+00, -1.1136e-02, -6.9956e+00,  ..., -6.8653e+00,\n",
            "         -6.4271e+00, -5.3083e+00],\n",
            "        [-3.7616e-01, -3.2159e+00, -3.6748e+00,  ..., -2.9164e+00,\n",
            "         -2.0721e+00, -3.5799e+00],\n",
            "        [-4.1227e+00, -3.5373e+00, -3.4061e-01,  ..., -3.7321e+00,\n",
            "         -3.8862e+00, -3.8612e+00]], grad_fn=<LogSoftmaxBackward0>)\n",
            "Training: 446\n",
            "Epoch: 0447 loss_train: 0.5631 acc_train: 0.8214 loss_val: 0.9652 acc_val: 0.6700 time: 1.7367s\n",
            "loss_val:0.9651901125907898, val_acc:0.67, out_features:tensor([[-2.5673e+00, -2.1479e+00, -6.1364e-01,  ..., -2.7164e+00,\n",
            "         -2.5324e+00, -2.8754e+00],\n",
            "        [-5.8530e+00, -8.9989e+00, -7.2662e+00,  ..., -8.9942e+00,\n",
            "         -4.1819e-03, -8.8796e+00],\n",
            "        [-7.2759e+00, -7.1485e+00, -6.8088e+00,  ..., -6.3860e-03,\n",
            "         -7.1750e+00, -6.8605e+00],\n",
            "        ...,\n",
            "        [-3.5316e+00, -1.5775e-01, -3.6014e+00,  ..., -4.0975e+00,\n",
            "         -3.4421e+00, -3.6687e+00],\n",
            "        [-3.8734e-01, -2.6584e+00, -3.1956e+00,  ..., -3.0860e+00,\n",
            "         -2.5018e+00, -3.0989e+00],\n",
            "        [-9.3346e+00, -9.3135e+00, -1.9294e-03,  ..., -6.5800e+00,\n",
            "         -8.8301e+00, -8.9456e+00]], grad_fn=<LogSoftmaxBackward0>)\n",
            "Training: 447\n",
            "Epoch: 0448 loss_train: 0.6135 acc_train: 0.8500 loss_val: 1.0098 acc_val: 0.7067 time: 1.7419s\n",
            "loss_val:1.0097960233688354, val_acc:0.7066666666666667, out_features:tensor([[-4.9627e+00, -4.7834e+00, -7.2975e-02,  ..., -4.8422e+00,\n",
            "         -5.0338e+00, -4.6414e+00],\n",
            "        [-1.9459e+00, -1.9459e+00, -1.9459e+00,  ..., -1.9459e+00,\n",
            "         -1.9459e+00, -1.9459e+00],\n",
            "        [-7.9396e+00, -8.9692e+00, -9.0182e+00,  ..., -1.3275e-03,\n",
            "         -7.9003e+00, -8.3502e+00],\n",
            "        ...,\n",
            "        [-4.2660e+00, -7.3944e-02, -4.9929e+00,  ..., -4.2525e+00,\n",
            "         -3.7729e+00, -4.9391e+00],\n",
            "        [-2.4359e-01, -4.0982e+00, -3.9536e+00,  ..., -3.0908e+00,\n",
            "         -2.6925e+00, -3.3666e+00],\n",
            "        [-1.9459e+00, -1.9459e+00, -1.9459e+00,  ..., -1.9459e+00,\n",
            "         -1.9459e+00, -1.9459e+00]], grad_fn=<LogSoftmaxBackward0>)\n",
            "Training: 448\n",
            "Epoch: 0449 loss_train: 0.5891 acc_train: 0.7857 loss_val: 0.9728 acc_val: 0.7100 time: 1.7370s\n",
            "loss_val:0.9727864861488342, val_acc:0.71, out_features:tensor([[-1.2940e+01, -1.2709e+01, -1.8596e-05,  ..., -1.2926e+01,\n",
            "         -1.2864e+01, -1.2769e+01],\n",
            "        [-2.0244e+00, -3.0183e+00, -2.6914e+00,  ..., -2.8861e+00,\n",
            "         -9.0598e-01, -1.3651e+00],\n",
            "        [-4.5210e+00, -5.4534e+00, -4.9651e+00,  ..., -3.8142e-02,\n",
            "         -5.1255e+00, -5.0990e+00],\n",
            "        ...,\n",
            "        [-3.8648e+00, -1.6366e-01, -4.5811e+00,  ..., -3.7627e+00,\n",
            "         -3.2532e+00, -3.0312e+00],\n",
            "        [-1.9459e+00, -1.9459e+00, -1.9459e+00,  ..., -1.9459e+00,\n",
            "         -1.9459e+00, -1.9459e+00],\n",
            "        [-6.8600e+00, -6.6461e+00, -6.8828e-03,  ..., -6.4742e+00,\n",
            "         -6.7109e+00, -7.1313e+00]], grad_fn=<LogSoftmaxBackward0>)\n",
            "Training: 449\n",
            "Epoch: 0450 loss_train: 0.6754 acc_train: 0.7929 loss_val: 1.0295 acc_val: 0.6767 time: 1.7668s\n",
            "loss_val:1.0295456647872925, val_acc:0.6766666666666666, out_features:tensor([[-1.2459e+01, -1.2422e+01, -8.5708e-05,  ..., -1.2155e+01,\n",
            "         -1.2461e+01, -1.0470e+01],\n",
            "        [-1.9459e+00, -1.9459e+00, -1.9459e+00,  ..., -1.9459e+00,\n",
            "         -1.9459e+00, -1.9459e+00],\n",
            "        [-4.9357e+00, -4.2432e+00, -4.7631e+00,  ..., -5.4354e-02,\n",
            "         -4.8763e+00, -4.8015e+00],\n",
            "        ...,\n",
            "        [-2.1803e+00, -1.0818e+00, -2.4429e+00,  ..., -2.5466e+00,\n",
            "         -1.7419e+00, -1.9725e+00],\n",
            "        [-2.2975e-01, -3.2278e+00, -3.9829e+00,  ..., -3.4177e+00,\n",
            "         -2.6184e+00, -3.7215e+00],\n",
            "        [-8.1357e+00, -8.8836e+00, -1.1447e-03,  ..., -8.1943e+00,\n",
            "         -8.9211e+00, -8.9019e+00]], grad_fn=<LogSoftmaxBackward0>)\n",
            "Training: 450\n",
            "Epoch: 0451 loss_train: 0.5796 acc_train: 0.8500 loss_val: 1.0521 acc_val: 0.6667 time: 1.7433s\n",
            "loss_val:1.0521457195281982, val_acc:0.6666666666666666, out_features:tensor([[-5.8391, -5.9625, -0.0196,  ..., -5.9676, -6.1595, -5.9134],\n",
            "        [-1.9473, -3.6945, -3.6465,  ..., -1.9136, -1.2088, -1.0803],\n",
            "        [-2.9914, -3.2086, -1.8258,  ..., -0.5034, -2.8752, -3.1903],\n",
            "        ...,\n",
            "        [-4.6280, -0.1208, -4.6139,  ..., -3.6998, -3.2961, -3.6718],\n",
            "        [-0.1983, -3.3296, -4.0647,  ..., -3.0115, -3.1871, -3.8473],\n",
            "        [-3.0733, -1.7707, -0.8387,  ..., -3.0060, -2.4040, -2.8333]],\n",
            "       grad_fn=<LogSoftmaxBackward0>)\n",
            "Training: 451\n",
            "Epoch: 0452 loss_train: 0.6630 acc_train: 0.8214 loss_val: 1.0681 acc_val: 0.6467 time: 1.8867s\n",
            "loss_val:1.0681039094924927, val_acc:0.6466666666666666, out_features:tensor([[-4.5556, -5.0623, -0.0520,  ..., -4.9488, -4.9909, -4.7815],\n",
            "        [-1.9459, -1.9459, -1.9459,  ..., -1.9459, -1.9459, -1.9459],\n",
            "        [-2.8673, -2.1492, -2.5518,  ..., -0.5873, -2.7395, -2.4556],\n",
            "        ...,\n",
            "        [-2.5859, -0.7841, -2.9746,  ..., -1.7983, -2.3798, -2.1373],\n",
            "        [-0.6218, -2.2772, -3.3447,  ..., -3.1527, -1.9693, -2.6789],\n",
            "        [-4.1725, -4.5025, -0.2291,  ..., -2.2279, -4.3829, -3.0915]],\n",
            "       grad_fn=<LogSoftmaxBackward0>)\n",
            "Training: 452\n",
            "Epoch: 0453 loss_train: 0.7098 acc_train: 0.7857 loss_val: 1.0084 acc_val: 0.7100 time: 1.9504s\n",
            "loss_val:1.008386492729187, val_acc:0.71, out_features:tensor([[-1.4698e+01, -1.4327e+01, -6.5565e-06,  ..., -1.4620e+01,\n",
            "         -1.4713e+01, -1.4719e+01],\n",
            "        [-5.9881e+00, -8.8013e+00, -7.4609e+00,  ..., -8.8047e+00,\n",
            "         -3.6950e-03, -8.6532e+00],\n",
            "        [-3.7444e+00, -3.6280e+00, -3.5035e+00,  ..., -1.8632e-01,\n",
            "         -3.7557e+00, -2.9597e+00],\n",
            "        ...,\n",
            "        [-2.7161e+00, -5.9989e-01, -3.0229e+00,  ..., -2.6159e+00,\n",
            "         -2.3056e+00, -2.6803e+00],\n",
            "        [-5.1594e-01, -3.3348e+00, -2.5143e+00,  ..., -2.4983e+00,\n",
            "         -2.4506e+00, -3.0142e+00],\n",
            "        [-6.7030e+00, -6.7972e+00, -1.4830e-02,  ..., -4.6697e+00,\n",
            "         -6.9242e+00, -6.8535e+00]], grad_fn=<LogSoftmaxBackward0>)\n",
            "Training: 453\n",
            "Epoch: 0454 loss_train: 0.6271 acc_train: 0.8071 loss_val: 0.9698 acc_val: 0.6967 time: 1.7448s\n",
            "loss_val:0.9698477983474731, val_acc:0.6966666666666667, out_features:tensor([[-7.0370e+00, -6.9978e+00, -1.1933e-02,  ..., -6.7831e+00,\n",
            "         -7.0435e+00, -6.8363e+00],\n",
            "        [-1.8994e+00, -3.0290e+00, -2.8065e+00,  ..., -1.7465e+00,\n",
            "         -1.1356e+00, -1.5909e+00],\n",
            "        [-3.2587e+00, -2.4365e+00, -3.1889e+00,  ..., -3.6402e-01,\n",
            "         -2.9838e+00, -3.0637e+00],\n",
            "        ...,\n",
            "        [-5.3757e+00, -6.2748e-02, -5.5956e+00,  ..., -4.6809e+00,\n",
            "         -4.0845e+00, -3.7975e+00],\n",
            "        [-4.7675e-01, -2.6913e+00, -3.2780e+00,  ..., -2.3634e+00,\n",
            "         -2.7659e+00, -3.3438e+00],\n",
            "        [-1.0717e+01, -1.0502e+01, -1.8726e-04,  ..., -1.0530e+01,\n",
            "         -9.8680e+00, -1.0173e+01]], grad_fn=<LogSoftmaxBackward0>)\n",
            "Training: 454\n",
            "Epoch: 0455 loss_train: 0.6246 acc_train: 0.8357 loss_val: 1.1517 acc_val: 0.6500 time: 1.7484s\n",
            "loss_val:1.1517431735992432, val_acc:0.65, out_features:tensor([[-4.2818e+00, -4.0734e+00, -1.5857e-01,  ..., -4.0464e+00,\n",
            "         -3.9954e+00, -3.4401e+00],\n",
            "        [-1.9459e+00, -1.9459e+00, -1.9459e+00,  ..., -1.9459e+00,\n",
            "         -1.9459e+00, -1.9459e+00],\n",
            "        [-9.5470e+00, -8.1906e+00, -1.0278e+01,  ..., -5.2367e-04,\n",
            "         -9.9731e+00, -9.6947e+00],\n",
            "        ...,\n",
            "        [-3.8252e+00, -2.7748e-01, -2.3215e+00,  ..., -3.0536e+00,\n",
            "         -3.6353e+00, -3.7616e+00],\n",
            "        [-5.3896e-01, -3.2927e+00, -3.5199e+00,  ..., -3.2805e+00,\n",
            "         -1.6429e+00, -2.5641e+00],\n",
            "        [-1.9459e+00, -1.9459e+00, -1.9459e+00,  ..., -1.9459e+00,\n",
            "         -1.9459e+00, -1.9459e+00]], grad_fn=<LogSoftmaxBackward0>)\n",
            "Training: 455\n",
            "Epoch: 0456 loss_train: 0.6281 acc_train: 0.7929 loss_val: 1.0266 acc_val: 0.6800 time: 1.7356s\n",
            "loss_val:1.026566743850708, val_acc:0.68, out_features:tensor([[-5.2007e+00, -5.2295e+00, -4.4799e-02,  ..., -4.9532e+00,\n",
            "         -5.4303e+00, -5.1010e+00],\n",
            "        [-2.4545e+00, -3.0546e+00, -2.8952e+00,  ..., -3.3929e+00,\n",
            "         -5.2765e-01, -2.9912e+00],\n",
            "        [-4.2932e+00, -3.6881e+00, -2.5101e+00,  ..., -1.7941e-01,\n",
            "         -4.0752e+00, -4.1539e+00],\n",
            "        ...,\n",
            "        [-1.5156e+00, -1.0976e+00, -3.2653e+00,  ..., -1.9022e+00,\n",
            "         -2.1205e+00, -2.2977e+00],\n",
            "        [-1.2048e-01, -4.5089e+00, -3.8971e+00,  ..., -3.7854e+00,\n",
            "         -3.1928e+00, -4.5693e+00],\n",
            "        [-8.9108e+00, -7.8895e+00, -8.8867e-04,  ..., -9.3137e+00,\n",
            "         -9.3145e+00, -9.2355e+00]], grad_fn=<LogSoftmaxBackward0>)\n",
            "Training: 456\n",
            "Epoch: 0457 loss_train: 0.6240 acc_train: 0.8357 loss_val: 1.0580 acc_val: 0.6233 time: 1.7359s\n",
            "loss_val:1.058007001876831, val_acc:0.6233333333333333, out_features:tensor([[-4.2319, -4.1663, -0.2320,  ..., -3.8946, -4.1613, -3.3862],\n",
            "        [-1.9641, -3.0804, -2.7592,  ..., -1.6671, -0.9049, -2.1475],\n",
            "        [-4.0093, -4.0448, -2.4283,  ..., -0.2284, -3.8041, -3.2343],\n",
            "        ...,\n",
            "        [-4.1522, -0.1129, -4.5918,  ..., -3.6415, -4.1836, -3.8600],\n",
            "        [-1.9459, -1.9459, -1.9459,  ..., -1.9459, -1.9459, -1.9459],\n",
            "        [-1.9459, -1.9459, -1.9459,  ..., -1.9459, -1.9459, -1.9459]],\n",
            "       grad_fn=<LogSoftmaxBackward0>)\n",
            "Training: 457\n",
            "Epoch: 0458 loss_train: 0.4850 acc_train: 0.8929 loss_val: 1.0419 acc_val: 0.6667 time: 1.7509s\n",
            "loss_val:1.0418518781661987, val_acc:0.6666666666666666, out_features:tensor([[-9.6555e+00, -9.8082e+00, -4.2179e-04,  ..., -9.6835e+00,\n",
            "         -9.4141e+00, -9.2527e+00],\n",
            "        [-2.2118e+00, -3.5794e+00, -2.8643e+00,  ..., -2.3796e+00,\n",
            "         -5.5140e-01, -2.2099e+00],\n",
            "        [-2.4559e+00, -2.6854e+00, -1.9879e+00,  ..., -6.9540e-01,\n",
            "         -2.6248e+00, -2.5219e+00],\n",
            "        ...,\n",
            "        [-2.2462e+00, -6.0786e-01, -2.6642e+00,  ..., -2.5061e+00,\n",
            "         -2.3745e+00, -2.9754e+00],\n",
            "        [-1.9459e+00, -1.9459e+00, -1.9459e+00,  ..., -1.9459e+00,\n",
            "         -1.9459e+00, -1.9459e+00],\n",
            "        [-9.4582e+00, -9.3155e+00, -1.0779e-03,  ..., -9.4245e+00,\n",
            "         -9.5096e+00, -7.4029e+00]], grad_fn=<LogSoftmaxBackward0>)\n",
            "Training: 458\n",
            "Epoch: 0459 loss_train: 0.6347 acc_train: 0.8214 loss_val: 0.9720 acc_val: 0.7100 time: 1.8783s\n",
            "loss_val:0.9719955325126648, val_acc:0.71, out_features:tensor([[-2.5969, -2.7120, -0.9355,  ..., -2.0126, -2.7620, -2.5625],\n",
            "        [-1.9459, -1.9459, -1.9459,  ..., -1.9459, -1.9459, -1.9459],\n",
            "        [-3.9448, -4.4403, -3.4746,  ..., -0.1065, -4.2901, -4.2534],\n",
            "        ...,\n",
            "        [-4.5346, -0.1024, -3.8027,  ..., -3.3833, -4.3211, -4.6726],\n",
            "        [-0.8171, -2.6841, -2.4976,  ..., -2.1907, -2.1946, -2.4862],\n",
            "        [-2.1492, -2.6418, -0.9512,  ..., -1.8973, -2.3377, -2.2540]],\n",
            "       grad_fn=<LogSoftmaxBackward0>)\n",
            "Training: 459\n",
            "Epoch: 0460 loss_train: 0.5799 acc_train: 0.8571 loss_val: 1.0667 acc_val: 0.6533 time: 1.9444s\n",
            "loss_val:1.0667071342468262, val_acc:0.6533333333333333, out_features:tensor([[-1.9459, -1.9459, -1.9459,  ..., -1.9459, -1.9459, -1.9459],\n",
            "        [-2.8864, -4.7195, -5.7295,  ..., -5.4147, -0.0848, -5.2312],\n",
            "        [-1.9459, -1.9459, -1.9459,  ..., -1.9459, -1.9459, -1.9459],\n",
            "        ...,\n",
            "        [-2.6902, -0.8955, -1.7751,  ..., -2.0148, -2.3979, -2.6922],\n",
            "        [-1.2576, -2.2606, -2.1701,  ..., -1.4309, -2.0413, -2.7281],\n",
            "        [-1.9459, -1.9459, -1.9459,  ..., -1.9459, -1.9459, -1.9459]],\n",
            "       grad_fn=<LogSoftmaxBackward0>)\n",
            "Training: 460\n",
            "Epoch: 0461 loss_train: 0.8197 acc_train: 0.7286 loss_val: 1.1076 acc_val: 0.6533 time: 1.7448s\n",
            "loss_val:1.1075547933578491, val_acc:0.6533333333333333, out_features:tensor([[-4.2424, -4.1701, -0.0994,  ..., -3.5727, -4.2450, -4.5264],\n",
            "        [-3.0964, -5.6011, -5.1575,  ..., -5.1714, -0.2175, -2.0276],\n",
            "        [-1.9667, -3.5136, -3.1208,  ..., -0.5853, -1.8245, -3.1822],\n",
            "        ...,\n",
            "        [-2.1846, -1.8009, -1.7776,  ..., -1.9311, -1.9811, -1.8962],\n",
            "        [-1.9459, -1.9459, -1.9459,  ..., -1.9459, -1.9459, -1.9459],\n",
            "        [-5.6501, -4.7902, -0.0304,  ..., -5.1229, -5.8679, -5.1247]],\n",
            "       grad_fn=<LogSoftmaxBackward0>)\n",
            "Training: 461\n",
            "Epoch: 0462 loss_train: 0.5559 acc_train: 0.8857 loss_val: 1.0507 acc_val: 0.6533 time: 1.7505s\n",
            "loss_val:1.0506819486618042, val_acc:0.6533333333333333, out_features:tensor([[-9.8082e+00, -9.8489e+00, -7.0059e-04,  ..., -9.2681e+00,\n",
            "         -9.8988e+00, -9.8456e+00],\n",
            "        [-1.9459e+00, -1.9459e+00, -1.9459e+00,  ..., -1.9459e+00,\n",
            "         -1.9459e+00, -1.9459e+00],\n",
            "        [-5.9331e+00, -5.9394e+00, -5.4186e+00,  ..., -1.6331e-02,\n",
            "         -6.2758e+00, -6.0987e+00],\n",
            "        ...,\n",
            "        [-6.1959e+00, -1.0291e-02, -7.0117e+00,  ..., -6.2723e+00,\n",
            "         -5.7094e+00, -6.8647e+00],\n",
            "        [-4.0980e-01, -3.2347e+00, -3.9061e+00,  ..., -2.9473e+00,\n",
            "         -2.4810e+00, -2.2853e+00],\n",
            "        [-2.6677e+00, -3.3283e+00, -7.0044e-01,  ..., -3.4268e+00,\n",
            "         -2.5119e+00, -2.8722e+00]], grad_fn=<LogSoftmaxBackward0>)\n",
            "Training: 462\n",
            "Epoch: 0463 loss_train: 0.5857 acc_train: 0.8357 loss_val: 1.1373 acc_val: 0.6467 time: 1.7486s\n",
            "loss_val:1.1372740268707275, val_acc:0.6466666666666666, out_features:tensor([[-7.2862, -7.1603, -0.0092,  ..., -6.8892, -7.1990, -5.5794],\n",
            "        [-1.8632, -2.7842, -3.2632,  ..., -2.4613, -0.6358, -2.2551],\n",
            "        [-2.0011, -2.7955, -2.3327,  ..., -0.7345, -2.7803, -2.3887],\n",
            "        ...,\n",
            "        [-5.6098, -0.0194, -6.6470,  ..., -4.8341, -5.9004, -6.1961],\n",
            "        [-0.0318, -5.3847, -5.7423,  ..., -5.3082, -4.5565, -5.3794],\n",
            "        [-6.8717, -6.9196, -0.0081,  ..., -6.7053, -6.2959, -6.2882]],\n",
            "       grad_fn=<LogSoftmaxBackward0>)\n",
            "Training: 463\n",
            "Epoch: 0464 loss_train: 0.6323 acc_train: 0.8286 loss_val: 1.0476 acc_val: 0.6500 time: 1.7548s\n",
            "loss_val:1.0475798845291138, val_acc:0.65, out_features:tensor([[-2.6737, -3.0657, -0.4678,  ..., -2.7856, -2.4831, -2.7411],\n",
            "        [-1.9459, -1.9459, -1.9459,  ..., -1.9459, -1.9459, -1.9459],\n",
            "        [-3.9368, -4.2699, -3.9437,  ..., -0.1141, -4.4201, -3.5230],\n",
            "        ...,\n",
            "        [-1.9459, -1.9459, -1.9459,  ..., -1.9459, -1.9459, -1.9459],\n",
            "        [-0.1171, -4.4382, -4.3515,  ..., -3.6735, -3.2110, -4.4008],\n",
            "        [-6.1728, -5.9054, -0.0130,  ..., -5.7883, -6.5518, -6.6752]],\n",
            "       grad_fn=<LogSoftmaxBackward0>)\n",
            "Training: 464\n",
            "Epoch: 0465 loss_train: 0.7537 acc_train: 0.7571 loss_val: 1.0776 acc_val: 0.6433 time: 1.7481s\n",
            "loss_val:1.0775964260101318, val_acc:0.6433333333333333, out_features:tensor([[-4.2797, -3.9045, -0.1532,  ..., -3.2773, -4.0737, -3.5162],\n",
            "        [-4.2013, -5.9561, -6.0059,  ..., -5.1696, -0.0711, -3.2023],\n",
            "        [-2.5584, -2.5601, -1.8726,  ..., -0.6402, -2.9391, -2.8553],\n",
            "        ...,\n",
            "        [-3.3096, -0.4683, -2.2759,  ..., -2.8913, -2.1814, -3.3436],\n",
            "        [-0.4200, -3.2701, -3.6972,  ..., -2.0940, -2.4100, -3.8122],\n",
            "        [-3.9431, -2.9915, -0.1548,  ..., -4.1471, -3.7073, -4.1849]],\n",
            "       grad_fn=<LogSoftmaxBackward0>)\n",
            "Training: 465\n",
            "Epoch: 0466 loss_train: 0.6743 acc_train: 0.7857 loss_val: 0.9835 acc_val: 0.6900 time: 1.8710s\n",
            "loss_val:0.9835331439971924, val_acc:0.69, out_features:tensor([[-2.7434, -2.6662, -0.7012,  ..., -1.9677, -2.9233, -2.3023],\n",
            "        [-2.1702, -3.1289, -2.8966,  ..., -1.6806, -0.9991, -1.6288],\n",
            "        [-3.0688, -2.1676, -1.8089,  ..., -0.7757, -2.8160, -2.3973],\n",
            "        ...,\n",
            "        [-2.2035, -1.1402, -2.2949,  ..., -2.2366, -1.6233, -2.3196],\n",
            "        [-0.8031, -2.4713, -3.5756,  ..., -1.3656, -2.3088, -2.9888],\n",
            "        [-3.3956, -3.1866, -0.2044,  ..., -3.8589, -3.7280, -3.4231]],\n",
            "       grad_fn=<LogSoftmaxBackward0>)\n",
            "Training: 466\n",
            "Epoch: 0467 loss_train: 0.6470 acc_train: 0.8214 loss_val: 1.0582 acc_val: 0.6667 time: 1.9865s\n",
            "loss_val:1.0582246780395508, val_acc:0.6666666666666666, out_features:tensor([[-1.5004e+01, -1.5017e+01, -2.8610e-06,  ..., -1.4017e+01,\n",
            "         -1.5014e+01, -1.4968e+01],\n",
            "        [-2.1241e+00, -2.4003e+00, -3.6472e+00,  ..., -2.2535e+00,\n",
            "         -6.5485e-01, -2.1363e+00],\n",
            "        [-3.9539e+00, -4.4051e+00, -4.0505e+00,  ..., -9.8750e-02,\n",
            "         -4.2090e+00, -3.9441e+00],\n",
            "        ...,\n",
            "        [-5.3652e+00, -5.4526e-02, -5.4095e+00,  ..., -4.4718e+00,\n",
            "         -5.4125e+00, -3.8180e+00],\n",
            "        [-1.1736e-01, -4.0163e+00, -4.8984e+00,  ..., -3.7216e+00,\n",
            "         -3.2859e+00, -4.4984e+00],\n",
            "        [-2.1218e+00, -2.9230e+00, -8.2864e-01,  ..., -2.4639e+00,\n",
            "         -1.7100e+00, -2.9211e+00]], grad_fn=<LogSoftmaxBackward0>)\n",
            "Training: 467\n",
            "Epoch: 0468 loss_train: 0.6411 acc_train: 0.8214 loss_val: 1.0750 acc_val: 0.6900 time: 1.7431s\n",
            "loss_val:1.0749906301498413, val_acc:0.69, out_features:tensor([[-3.6950e+00, -3.6076e+00, -1.9401e-01,  ..., -3.1893e+00,\n",
            "         -3.8533e+00, -3.6598e+00],\n",
            "        [-1.9459e+00, -1.9459e+00, -1.9459e+00,  ..., -1.9459e+00,\n",
            "         -1.9459e+00, -1.9459e+00],\n",
            "        [-7.5584e+00, -7.2306e+00, -5.9320e+00,  ..., -6.5118e-03,\n",
            "         -6.5050e+00, -7.2927e+00],\n",
            "        ...,\n",
            "        [-6.4177e+00, -1.9227e-02, -6.3229e+00,  ..., -4.9320e+00,\n",
            "         -5.6007e+00, -5.8237e+00],\n",
            "        [-5.7278e-01, -2.7356e+00, -3.2876e+00,  ..., -2.6629e+00,\n",
            "         -2.4101e+00, -1.9245e+00],\n",
            "        [-4.1800e+00, -3.7694e+00, -1.2999e-01,  ..., -3.9863e+00,\n",
            "         -3.6444e+00, -3.8170e+00]], grad_fn=<LogSoftmaxBackward0>)\n",
            "Training: 468\n",
            "Epoch: 0469 loss_train: 0.5584 acc_train: 0.8429 loss_val: 1.1041 acc_val: 0.6633 time: 1.7641s\n",
            "loss_val:1.1040761470794678, val_acc:0.6633333333333333, out_features:tensor([[-2.7308, -3.0947, -0.5805,  ..., -2.5454, -3.1383, -2.9058],\n",
            "        [-4.0391, -6.0765, -6.7090,  ..., -6.2086, -0.0275, -5.8743],\n",
            "        [-2.1664, -2.7023, -3.2427,  ..., -0.5382, -2.7941, -2.5696],\n",
            "        ...,\n",
            "        [-1.7476, -0.8223, -2.7787,  ..., -2.3022, -2.3677, -2.5460],\n",
            "        [-1.2710, -2.1275, -2.0950,  ..., -1.8952, -1.9258, -2.3885],\n",
            "        [-2.0666, -2.1713, -1.3604,  ..., -1.4488, -2.1586, -2.5662]],\n",
            "       grad_fn=<LogSoftmaxBackward0>)\n",
            "Training: 469\n",
            "Epoch: 0470 loss_train: 0.6303 acc_train: 0.8214 loss_val: 1.1608 acc_val: 0.6667 time: 1.7319s\n",
            "loss_val:1.1607669591903687, val_acc:0.6666666666666666, out_features:tensor([[-5.2264, -5.2208, -0.0446,  ..., -4.8097, -5.0630, -4.8317],\n",
            "        [-2.4336, -3.1927, -1.9839,  ..., -2.4623, -1.1616, -1.1955],\n",
            "        [-4.2519, -4.2390, -4.1767,  ..., -0.0951, -4.5329, -3.8457],\n",
            "        ...,\n",
            "        [-2.0380, -0.3342, -3.5138,  ..., -3.2119, -3.3036, -3.6657],\n",
            "        [-0.1342, -3.1647, -4.6586,  ..., -4.4522, -3.6835, -3.6667],\n",
            "        [-3.7283, -4.3528, -0.5271,  ..., -1.1120, -4.0869, -4.2082]],\n",
            "       grad_fn=<LogSoftmaxBackward0>)\n",
            "Training: 470\n",
            "Epoch: 0471 loss_train: 0.6525 acc_train: 0.8071 loss_val: 0.9868 acc_val: 0.7033 time: 1.7395s\n",
            "loss_val:0.9868142604827881, val_acc:0.7033333333333334, out_features:tensor([[-4.8908, -4.9973, -0.0654,  ..., -4.3998, -4.7916, -4.3795],\n",
            "        [-1.4239, -3.1689, -3.0616,  ..., -3.0233, -0.6660, -2.6513],\n",
            "        [-6.3428, -6.2819, -6.1869,  ..., -0.0115, -6.4320, -5.9670],\n",
            "        ...,\n",
            "        [-2.8898, -0.5250, -2.9402,  ..., -2.0225, -2.7115, -3.0428],\n",
            "        [-0.0307, -5.6307, -5.9092,  ..., -5.6663, -4.2217, -5.8365],\n",
            "        [-3.9598, -4.7806, -0.0952,  ..., -5.2142, -4.6065, -3.4126]],\n",
            "       grad_fn=<LogSoftmaxBackward0>)\n",
            "Training: 471\n",
            "Epoch: 0472 loss_train: 0.6039 acc_train: 0.8571 loss_val: 1.0950 acc_val: 0.6767 time: 1.7517s\n",
            "loss_val:1.0950218439102173, val_acc:0.6766666666666666, out_features:tensor([[-2.6466e+00, -2.3752e+00, -7.3690e-01,  ..., -2.0076e+00,\n",
            "         -2.9514e+00, -2.7925e+00],\n",
            "        [-5.5347e+00, -7.0320e+00, -7.0247e+00,  ..., -2.0509e+00,\n",
            "         -1.6461e-01, -4.0999e+00],\n",
            "        [-2.5534e+00, -1.9778e+00, -1.9615e+00,  ..., -1.0043e+00,\n",
            "         -2.7311e+00, -2.1089e+00],\n",
            "        ...,\n",
            "        [-3.0698e+00, -7.3812e-01, -2.9682e+00,  ..., -2.5457e+00,\n",
            "         -2.0348e+00, -1.8087e+00],\n",
            "        [-1.5111e-01, -4.4498e+00, -4.0659e+00,  ..., -3.9894e+00,\n",
            "         -2.7296e+00, -4.3419e+00],\n",
            "        [-1.0174e+01, -1.0036e+01, -3.3921e-04,  ..., -9.9886e+00,\n",
            "         -1.0123e+01, -1.0143e+01]], grad_fn=<LogSoftmaxBackward0>)\n",
            "Training: 472\n",
            "Epoch: 0473 loss_train: 0.4844 acc_train: 0.8643 loss_val: 1.0590 acc_val: 0.6767 time: 1.8868s\n",
            "loss_val:1.0590041875839233, val_acc:0.6766666666666666, out_features:tensor([[-3.7736, -3.4334, -0.1974,  ..., -3.1826, -3.7841, -3.2976],\n",
            "        [-1.9459, -1.9459, -1.9459,  ..., -1.9459, -1.9459, -1.9459],\n",
            "        [-5.9203, -4.8446, -5.9927,  ..., -0.0194, -6.2319, -5.8943],\n",
            "        ...,\n",
            "        [-2.6837, -0.2490, -4.4925,  ..., -2.4252, -3.6973, -3.9980],\n",
            "        [-0.0610, -4.6204, -4.9496,  ..., -4.4225, -4.0086, -5.2045],\n",
            "        [-4.0201, -3.1164, -0.2430,  ..., -3.4817, -3.9276, -3.0326]],\n",
            "       grad_fn=<LogSoftmaxBackward0>)\n",
            "Training: 473\n",
            "Epoch: 0474 loss_train: 0.5832 acc_train: 0.8500 loss_val: 1.1169 acc_val: 0.6533 time: 1.9597s\n",
            "loss_val:1.1169010400772095, val_acc:0.6533333333333333, out_features:tensor([[-5.2321, -5.4984, -0.0558,  ..., -5.2873, -5.4342, -5.3273],\n",
            "        [-2.1081, -3.1728, -3.5101,  ..., -3.1866, -0.7163, -1.4174],\n",
            "        [-4.5470, -4.0591, -4.5509,  ..., -0.0801, -4.0770, -4.3582],\n",
            "        ...,\n",
            "        [-1.8575, -1.3320, -1.7486,  ..., -2.3627, -2.1314, -2.3926],\n",
            "        [-0.1524, -4.0285, -4.5204,  ..., -3.2133, -3.7804, -3.2672],\n",
            "        [-3.3061, -2.9356, -0.2390,  ..., -3.1501, -3.6084, -3.4081]],\n",
            "       grad_fn=<LogSoftmaxBackward0>)\n",
            "Training: 474\n",
            "Epoch: 0475 loss_train: 0.5930 acc_train: 0.8357 loss_val: 1.0680 acc_val: 0.6667 time: 1.7451s\n",
            "loss_val:1.0680018663406372, val_acc:0.6666666666666666, out_features:tensor([[-6.3842, -6.7537, -0.0215,  ..., -6.3827, -6.8338, -6.7974],\n",
            "        [-1.9459, -1.9459, -1.9459,  ..., -1.9459, -1.9459, -1.9459],\n",
            "        [-3.1323, -2.7533, -1.5067,  ..., -0.7040, -3.3105, -3.0985],\n",
            "        ...,\n",
            "        [-3.2465, -0.1561, -4.6220,  ..., -3.4510, -3.3224, -4.1943],\n",
            "        [-1.2804, -2.4849, -1.7689,  ..., -2.0490, -2.0943, -2.1583],\n",
            "        [-6.6202, -6.6818, -0.0101,  ..., -5.4054, -7.0081, -6.7721]],\n",
            "       grad_fn=<LogSoftmaxBackward0>)\n",
            "Training: 475\n",
            "Epoch: 0476 loss_train: 0.5992 acc_train: 0.8571 loss_val: 1.0768 acc_val: 0.6367 time: 1.7423s\n",
            "loss_val:1.0768440961837769, val_acc:0.6366666666666667, out_features:tensor([[-4.8488, -4.7780, -0.0733,  ..., -4.7113, -4.9007, -4.3674],\n",
            "        [-2.1954, -2.8679, -2.6701,  ..., -2.0418, -0.8779, -1.7403],\n",
            "        [-1.9125, -2.1422, -2.6550,  ..., -0.7153, -2.6276, -3.0202],\n",
            "        ...,\n",
            "        [-1.8727, -1.2808, -2.5426,  ..., -1.9844, -2.2124, -1.9358],\n",
            "        [-0.0590, -5.0979, -4.8374,  ..., -4.0693, -4.3890, -4.8191],\n",
            "        [-3.2769, -3.4762, -0.1971,  ..., -2.9652, -3.7850, -3.9627]],\n",
            "       grad_fn=<LogSoftmaxBackward0>)\n",
            "Training: 476\n",
            "Epoch: 0477 loss_train: 0.6714 acc_train: 0.7643 loss_val: 1.0381 acc_val: 0.6667 time: 1.7497s\n",
            "loss_val:1.0380733013153076, val_acc:0.6666666666666666, out_features:tensor([[-4.1021, -5.2285, -0.0735,  ..., -4.1363, -4.9553, -4.8129],\n",
            "        [-5.3219, -7.3031, -7.2902,  ..., -2.8332, -0.0740, -5.1797],\n",
            "        [-2.6769, -2.4058, -2.2884,  ..., -0.6713, -2.6159, -2.4584],\n",
            "        ...,\n",
            "        [-2.6292, -0.4488, -3.0116,  ..., -2.8559, -2.3491, -3.2087],\n",
            "        [-0.7348, -3.3102, -3.0618,  ..., -1.7368, -2.4352, -2.0252],\n",
            "        [-1.1317, -2.9426, -1.1919,  ..., -3.3800, -1.6201, -3.0310]],\n",
            "       grad_fn=<LogSoftmaxBackward0>)\n",
            "Training: 477\n",
            "Epoch: 0478 loss_train: 0.6501 acc_train: 0.8286 loss_val: 1.0617 acc_val: 0.6967 time: 1.7505s\n",
            "loss_val:1.0616611242294312, val_acc:0.6966666666666667, out_features:tensor([[-1.9459, -1.9459, -1.9459,  ..., -1.9459, -1.9459, -1.9459],\n",
            "        [-6.2626, -6.9185, -7.0058,  ..., -7.0344, -0.0341, -3.5888],\n",
            "        [-5.1158, -4.0329, -4.9690,  ..., -0.0544, -4.7222, -5.0938],\n",
            "        ...,\n",
            "        [-2.6569, -0.8136, -2.7128,  ..., -2.4857, -2.1519, -1.8038],\n",
            "        [-0.4803, -2.3730, -3.2814,  ..., -2.6507, -2.5091, -3.2685],\n",
            "        [-1.0866, -3.1031, -1.1317,  ..., -3.1113, -2.4251, -2.2321]],\n",
            "       grad_fn=<LogSoftmaxBackward0>)\n",
            "Training: 478\n",
            "Epoch: 0479 loss_train: 0.5846 acc_train: 0.8357 loss_val: 1.0442 acc_val: 0.6500 time: 1.7635s\n",
            "loss_val:1.0441821813583374, val_acc:0.65, out_features:tensor([[-3.0704e+00, -4.0399e+00, -1.9095e-01,  ..., -3.9080e+00,\n",
            "         -3.5736e+00, -3.6453e+00],\n",
            "        [-2.0503e+00, -2.2859e+00, -2.7663e+00,  ..., -2.8933e+00,\n",
            "         -8.1777e-01, -1.8412e+00],\n",
            "        [-6.4941e+00, -7.1092e+00, -6.9870e+00,  ..., -6.2232e-03,\n",
            "         -6.7457e+00, -6.9300e+00],\n",
            "        ...,\n",
            "        [-2.2347e+00, -1.1503e+00, -3.3114e+00,  ..., -1.3640e+00,\n",
            "         -1.7966e+00, -2.3834e+00],\n",
            "        [-9.1264e-02, -5.3805e+00, -5.6236e+00,  ..., -3.3012e+00,\n",
            "         -3.4886e+00, -5.3746e+00],\n",
            "        [-5.0140e+00, -4.5700e+00, -9.6949e-02,  ..., -5.3348e+00,\n",
            "         -4.6331e+00, -3.0109e+00]], grad_fn=<LogSoftmaxBackward0>)\n",
            "Training: 479\n",
            "Epoch: 0480 loss_train: 0.5410 acc_train: 0.8643 loss_val: 1.0636 acc_val: 0.6467 time: 1.8817s\n",
            "loss_val:1.0635552406311035, val_acc:0.6466666666666666, out_features:tensor([[-1.9459e+00, -1.9459e+00, -1.9459e+00,  ..., -1.9459e+00,\n",
            "         -1.9459e+00, -1.9459e+00],\n",
            "        [-2.3747e+00, -2.6305e+00, -2.1967e+00,  ..., -1.9948e+00,\n",
            "         -1.1185e+00, -1.6937e+00],\n",
            "        [-7.4062e+00, -8.2604e+00, -8.7763e+00,  ..., -1.5065e-03,\n",
            "         -8.7946e+00, -8.5480e+00],\n",
            "        ...,\n",
            "        [-1.9459e+00, -1.9459e+00, -1.9459e+00,  ..., -1.9459e+00,\n",
            "         -1.9459e+00, -1.9459e+00],\n",
            "        [-1.2604e+00, -2.6429e+00, -2.0851e+00,  ..., -1.7519e+00,\n",
            "         -1.8229e+00, -2.2520e+00],\n",
            "        [-1.5460e+01, -1.3157e+01, -3.2186e-06,  ..., -1.4923e+01,\n",
            "         -1.5479e+01, -1.5466e+01]], grad_fn=<LogSoftmaxBackward0>)\n",
            "Training: 480\n",
            "Epoch: 0481 loss_train: 0.6430 acc_train: 0.8071 loss_val: 1.0219 acc_val: 0.6667 time: 1.9673s\n",
            "loss_val:1.021889567375183, val_acc:0.6666666666666666, out_features:tensor([[-7.9792e+00, -7.9549e+00, -3.6194e-03,  ..., -6.6354e+00,\n",
            "         -7.6539e+00, -7.8810e+00],\n",
            "        [-1.7167e+00, -3.0332e+00, -2.7600e+00,  ..., -2.3573e+00,\n",
            "         -8.7453e-01, -1.8850e+00],\n",
            "        [-3.1955e+00, -2.8492e+00, -1.7880e+00,  ..., -5.0030e-01,\n",
            "         -2.8332e+00, -3.3256e+00],\n",
            "        ...,\n",
            "        [-2.2377e+00, -1.5263e+00, -1.9024e+00,  ..., -1.6724e+00,\n",
            "         -2.1447e+00, -2.2953e+00],\n",
            "        [-3.1890e-01, -3.7691e+00, -4.1710e+00,  ..., -2.6913e+00,\n",
            "         -2.2179e+00, -3.4126e+00],\n",
            "        [-4.7093e+00, -4.2674e+00, -4.6650e-02,  ..., -5.2232e+00,\n",
            "         -5.2941e+00, -5.3362e+00]], grad_fn=<LogSoftmaxBackward0>)\n",
            "Training: 481\n",
            "Epoch: 0482 loss_train: 0.6692 acc_train: 0.8143 loss_val: 1.0551 acc_val: 0.6533 time: 1.7450s\n",
            "loss_val:1.0551422834396362, val_acc:0.6533333333333333, out_features:tensor([[-7.2879, -7.0501, -0.0093,  ..., -7.0810, -7.3023, -6.9694],\n",
            "        [-1.7837, -3.0719, -2.8720,  ..., -2.4308, -0.7169, -2.1555],\n",
            "        [-6.1689, -4.7734, -5.5362,  ..., -0.0225, -6.1429, -5.4780],\n",
            "        ...,\n",
            "        [-3.4667, -0.1927, -4.3309,  ..., -2.9549, -3.1025, -3.8917],\n",
            "        [-0.2669, -3.6304, -4.1983,  ..., -1.8703, -4.3322, -4.1573],\n",
            "        [-5.5660, -5.0663, -0.0597,  ..., -3.5876, -5.3536, -4.6088]],\n",
            "       grad_fn=<LogSoftmaxBackward0>)\n",
            "Training: 482\n",
            "Epoch: 0483 loss_train: 0.6627 acc_train: 0.7929 loss_val: 0.9845 acc_val: 0.6800 time: 1.7424s\n",
            "loss_val:0.9845281839370728, val_acc:0.68, out_features:tensor([[-5.3425, -5.1389, -0.0857,  ..., -4.7370, -5.2677, -4.8225],\n",
            "        [-8.1563, -7.9946, -8.4110,  ..., -7.2975, -0.0085, -5.0079],\n",
            "        [-5.3709, -5.5017, -6.4087,  ..., -0.0193, -5.5357, -5.6449],\n",
            "        ...,\n",
            "        [-1.9459, -1.9459, -1.9459,  ..., -1.9459, -1.9459, -1.9459],\n",
            "        [-0.5078, -2.7793, -3.8592,  ..., -2.1382, -2.4381, -2.4559],\n",
            "        [-2.2900, -2.9673, -0.2991,  ..., -3.2150, -3.5838, -3.9998]],\n",
            "       grad_fn=<LogSoftmaxBackward0>)\n",
            "Training: 483\n",
            "Epoch: 0484 loss_train: 0.5758 acc_train: 0.8500 loss_val: 0.9894 acc_val: 0.7133 time: 1.7396s\n",
            "loss_val:0.9893965721130371, val_acc:0.7133333333333334, out_features:tensor([[-7.0154e+00, -6.9941e+00, -1.2084e-02,  ..., -5.0949e+00,\n",
            "         -7.1024e+00, -6.2558e+00],\n",
            "        [-3.7585e+00, -4.6870e+00, -2.8200e+00,  ..., -3.4329e+00,\n",
            "         -3.4141e-01, -1.8562e+00],\n",
            "        [-7.5567e+00, -8.0159e+00, -7.6931e+00,  ..., -2.3809e-03,\n",
            "         -7.9350e+00, -7.7696e+00],\n",
            "        ...,\n",
            "        [-1.9459e+00, -1.9459e+00, -1.9459e+00,  ..., -1.9459e+00,\n",
            "         -1.9459e+00, -1.9459e+00],\n",
            "        [-8.2158e-02, -4.5737e+00, -5.3783e+00,  ..., -5.1106e+00,\n",
            "         -3.4334e+00, -4.6117e+00],\n",
            "        [-7.5287e+00, -6.9015e+00, -6.7613e-03,  ..., -7.3674e+00,\n",
            "         -7.3835e+00, -7.4835e+00]], grad_fn=<LogSoftmaxBackward0>)\n",
            "Training: 484\n",
            "Epoch: 0485 loss_train: 0.6405 acc_train: 0.8000 loss_val: 1.0163 acc_val: 0.6767 time: 1.7534s\n",
            "loss_val:1.0162944793701172, val_acc:0.6766666666666666, out_features:tensor([[-1.0595e+01, -1.0629e+01, -7.3334e-04,  ..., -1.0278e+01,\n",
            "         -1.0636e+01, -1.0581e+01],\n",
            "        [-1.9459e+00, -1.9459e+00, -1.9459e+00,  ..., -1.9459e+00,\n",
            "         -1.9459e+00, -1.9459e+00],\n",
            "        [-3.2580e+00, -2.5045e+00, -2.4626e+00,  ..., -4.4560e-01,\n",
            "         -3.1613e+00, -2.7001e+00],\n",
            "        ...,\n",
            "        [-2.2625e+00, -4.0711e-01, -3.7621e+00,  ..., -2.9779e+00,\n",
            "         -3.5922e+00, -2.2581e+00],\n",
            "        [-2.5978e-01, -2.7087e+00, -3.7051e+00,  ..., -3.5181e+00,\n",
            "         -2.8389e+00, -3.7104e+00],\n",
            "        [-1.6831e+00, -2.2849e+00, -1.7614e+00,  ..., -2.5521e+00,\n",
            "         -1.9769e+00, -1.5830e+00]], grad_fn=<LogSoftmaxBackward0>)\n",
            "Training: 485\n",
            "Epoch: 0486 loss_train: 0.6620 acc_train: 0.7929 loss_val: 1.0496 acc_val: 0.6100 time: 1.7404s\n",
            "loss_val:1.0495685338974, val_acc:0.61, out_features:tensor([[-6.2873e+00, -6.1125e+00, -1.5341e-02,  ..., -6.1942e+00,\n",
            "         -6.0104e+00, -5.5594e+00],\n",
            "        [-1.9459e+00, -1.9459e+00, -1.9459e+00,  ..., -1.9459e+00,\n",
            "         -1.9459e+00, -1.9459e+00],\n",
            "        [-3.1963e+00, -3.0133e+00, -3.7329e+00,  ..., -2.0480e-01,\n",
            "         -3.4513e+00, -3.9473e+00],\n",
            "        ...,\n",
            "        [-2.5332e+00, -1.7435e-01, -5.1227e+00,  ..., -2.9522e+00,\n",
            "         -4.7012e+00, -4.9163e+00],\n",
            "        [-6.6138e-01, -1.9588e+00, -3.0967e+00,  ..., -2.4220e+00,\n",
            "         -2.4920e+00, -2.8484e+00],\n",
            "        [-1.2224e+01, -1.2392e+01, -2.8133e-05,  ..., -1.1909e+01,\n",
            "         -1.2496e+01, -1.2418e+01]], grad_fn=<LogSoftmaxBackward0>)\n",
            "Training: 486\n",
            "Epoch: 0487 loss_train: 0.7226 acc_train: 0.8214 loss_val: 0.9674 acc_val: 0.6933 time: 1.8913s\n",
            "loss_val:0.9674449563026428, val_acc:0.6933333333333334, out_features:tensor([[-8.4285e+00, -8.2466e+00, -3.6319e-03,  ..., -7.8540e+00,\n",
            "         -8.4227e+00, -8.3405e+00],\n",
            "        [-2.0972e+00, -2.2400e+00, -3.1843e+00,  ..., -1.3522e+00,\n",
            "         -1.2206e+00, -2.0382e+00],\n",
            "        [-2.7041e+00, -3.6004e+00, -3.7198e+00,  ..., -2.4598e-01,\n",
            "         -3.6549e+00, -2.9950e+00],\n",
            "        ...,\n",
            "        [-4.6603e+00, -7.8104e-02, -5.0673e+00,  ..., -3.3345e+00,\n",
            "         -4.6914e+00, -4.6547e+00],\n",
            "        [-1.1283e+00, -2.0107e+00, -2.5259e+00,  ..., -2.0009e+00,\n",
            "         -2.1507e+00, -2.1368e+00],\n",
            "        [-3.6384e+00, -3.2276e+00, -3.4815e-01,  ..., -3.3863e+00,\n",
            "         -3.3073e+00, -2.7885e+00]], grad_fn=<LogSoftmaxBackward0>)\n",
            "Training: 487\n",
            "Epoch: 0488 loss_train: 0.6332 acc_train: 0.8143 loss_val: 1.0546 acc_val: 0.6833 time: 1.9660s\n",
            "loss_val:1.0545775890350342, val_acc:0.6833333333333333, out_features:tensor([[-3.9850, -3.7096, -0.2374,  ..., -3.2435, -3.5672, -3.3366],\n",
            "        [-2.5017, -4.3364, -4.2863,  ..., -4.2767, -0.5451, -1.2651],\n",
            "        [-5.6849, -6.3003, -5.2545,  ..., -0.0189, -6.3305, -5.7873],\n",
            "        ...,\n",
            "        [-3.2093, -0.5867, -2.6852,  ..., -1.8192, -2.5453, -3.0973],\n",
            "        [-0.0257, -5.4572, -6.7035,  ..., -4.3443, -5.6688, -6.2495],\n",
            "        [-2.9261, -2.8772, -0.3930,  ..., -3.1461, -2.4941, -3.1234]],\n",
            "       grad_fn=<LogSoftmaxBackward0>)\n",
            "Training: 488\n",
            "Epoch: 0489 loss_train: 0.6325 acc_train: 0.7857 loss_val: 0.9330 acc_val: 0.6800 time: 1.7480s\n",
            "loss_val:0.9329600930213928, val_acc:0.68, out_features:tensor([[-9.3745e+00, -9.4492e+00, -5.7466e-04,  ..., -9.1234e+00,\n",
            "         -9.2965e+00, -9.2634e+00],\n",
            "        [-1.9459e+00, -1.9459e+00, -1.9459e+00,  ..., -1.9459e+00,\n",
            "         -1.9459e+00, -1.9459e+00],\n",
            "        [-5.5027e+00, -6.8501e+00, -7.3040e+00,  ..., -8.3067e-03,\n",
            "         -6.9749e+00, -6.9817e+00],\n",
            "        ...,\n",
            "        [-4.2875e+00, -5.7246e-02, -4.9311e+00,  ..., -4.6648e+00,\n",
            "         -4.7457e+00, -4.6928e+00],\n",
            "        [-7.2056e-01, -1.9950e+00, -3.2211e+00,  ..., -2.2207e+00,\n",
            "         -2.6578e+00, -2.4100e+00],\n",
            "        [-3.4944e+00, -4.0067e+00, -1.9246e-01,  ..., -2.8665e+00,\n",
            "         -3.6251e+00, -4.0445e+00]], grad_fn=<LogSoftmaxBackward0>)\n",
            "Training: 489\n",
            "Epoch: 0490 loss_train: 0.6610 acc_train: 0.7857 loss_val: 1.0595 acc_val: 0.6333 time: 1.7527s\n",
            "loss_val:1.0594936609268188, val_acc:0.6333333333333333, out_features:tensor([[-5.4352, -5.0942, -0.0338,  ..., -5.2720, -5.2560, -5.0115],\n",
            "        [-1.9078, -4.4969, -4.5303,  ..., -4.7141, -0.2620, -3.4734],\n",
            "        [-3.0993, -3.5602, -3.6114,  ..., -0.1800, -3.7643, -3.7694],\n",
            "        ...,\n",
            "        [-5.2328, -0.0105, -7.1503,  ..., -6.4754, -7.0436, -6.8272],\n",
            "        [-0.1546, -3.4859, -3.7179,  ..., -3.6191, -3.5942, -4.1944],\n",
            "        [-2.6665, -2.0887, -0.6727,  ..., -3.3684, -2.6343, -2.0762]],\n",
            "       grad_fn=<LogSoftmaxBackward0>)\n",
            "Training: 490\n",
            "Epoch: 0491 loss_train: 0.5873 acc_train: 0.8143 loss_val: 1.0057 acc_val: 0.6700 time: 1.7484s\n",
            "loss_val:1.0056613683700562, val_acc:0.67, out_features:tensor([[-6.0925e+00, -4.4411e+00, -2.8001e-02,  ..., -5.5397e+00,\n",
            "         -5.9561e+00, -5.9477e+00],\n",
            "        [-1.9459e+00, -1.9459e+00, -1.9459e+00,  ..., -1.9459e+00,\n",
            "         -1.9459e+00, -1.9459e+00],\n",
            "        [-4.8536e+00, -3.9105e+00, -5.0898e+00,  ..., -6.0710e-02,\n",
            "         -4.4061e+00, -5.2199e+00],\n",
            "        ...,\n",
            "        [-7.1958e+00, -6.2551e-03, -7.5365e+00,  ..., -7.5259e+00,\n",
            "         -7.1222e+00, -6.6988e+00],\n",
            "        [-6.3656e-05, -1.1993e+01, -1.2818e+01,  ..., -1.2364e+01,\n",
            "         -1.0018e+01, -1.2718e+01],\n",
            "        [-7.2901e+00, -7.2286e+00, -3.9245e-03,  ..., -7.2096e+00,\n",
            "         -7.5046e+00, -7.4631e+00]], grad_fn=<LogSoftmaxBackward0>)\n",
            "Training: 491\n",
            "Epoch: 0492 loss_train: 0.5788 acc_train: 0.8286 loss_val: 1.0264 acc_val: 0.6700 time: 1.7574s\n",
            "loss_val:1.02644681930542, val_acc:0.67, out_features:tensor([[-1.9459e+00, -1.9459e+00, -1.9459e+00,  ..., -1.9459e+00,\n",
            "         -1.9459e+00, -1.9459e+00],\n",
            "        [-1.9459e+00, -1.9459e+00, -1.9459e+00,  ..., -1.9459e+00,\n",
            "         -1.9459e+00, -1.9459e+00],\n",
            "        [-1.0476e+01, -1.0075e+01, -8.1534e+00,  ..., -4.3633e-04,\n",
            "         -1.0500e+01, -1.0530e+01],\n",
            "        ...,\n",
            "        [-1.8619e+00, -6.0557e-01, -3.0366e+00,  ..., -2.1850e+00,\n",
            "         -3.3381e+00, -3.1741e+00],\n",
            "        [-9.0535e-02, -4.1096e+00, -5.4081e+00,  ..., -3.5065e+00,\n",
            "         -3.6840e+00, -5.2234e+00],\n",
            "        [-3.9163e+00, -2.9201e+00, -2.7579e-01,  ..., -3.7639e+00,\n",
            "         -3.5220e+00, -3.0546e+00]], grad_fn=<LogSoftmaxBackward0>)\n",
            "Training: 492\n",
            "Epoch: 0493 loss_train: 0.5873 acc_train: 0.8500 loss_val: 1.0713 acc_val: 0.6667 time: 1.7486s\n",
            "loss_val:1.0713400840759277, val_acc:0.6666666666666666, out_features:tensor([[-1.1054e+01, -1.1049e+01, -1.7880e-04,  ..., -1.0441e+01,\n",
            "         -1.1057e+01, -9.4697e+00],\n",
            "        [-8.2624e+00, -7.7116e+00, -8.3459e+00,  ..., -7.9418e+00,\n",
            "         -2.3907e-03, -7.0585e+00],\n",
            "        [-3.4251e+00, -3.8476e+00, -3.2035e+00,  ..., -2.0385e-01,\n",
            "         -3.3652e+00, -3.2959e+00],\n",
            "        ...,\n",
            "        [-4.4015e+00, -1.0783e-01, -5.2397e+00,  ..., -2.9430e+00,\n",
            "         -4.0150e+00, -4.7415e+00],\n",
            "        [-1.9459e+00, -1.9459e+00, -1.9459e+00,  ..., -1.9459e+00,\n",
            "         -1.9459e+00, -1.9459e+00],\n",
            "        [-4.3068e+00, -3.5867e+00, -1.4615e-01,  ..., -3.5588e+00,\n",
            "         -3.7823e+00, -3.8990e+00]], grad_fn=<LogSoftmaxBackward0>)\n",
            "Training: 493\n",
            "Epoch: 0494 loss_train: 0.7097 acc_train: 0.8000 loss_val: 1.0178 acc_val: 0.6700 time: 1.8800s\n",
            "loss_val:1.0178085565567017, val_acc:0.67, out_features:tensor([[-3.1842, -2.9738, -0.3841,  ..., -2.9295, -3.2531, -3.1291],\n",
            "        [-1.9459, -1.9459, -1.9459,  ..., -1.9459, -1.9459, -1.9459],\n",
            "        [-2.5279, -2.3870, -2.6908,  ..., -0.6740, -2.1270, -2.6104],\n",
            "        ...,\n",
            "        [-2.5481, -0.4612, -3.8136,  ..., -1.9388, -2.7156, -3.3442],\n",
            "        [-0.2957, -2.8829, -3.3664,  ..., -2.9800, -3.1536, -3.5281],\n",
            "        [-6.3585, -5.8004, -0.0180,  ..., -6.2632, -4.9504, -6.0625]],\n",
            "       grad_fn=<LogSoftmaxBackward0>)\n",
            "Training: 494\n",
            "Epoch: 0495 loss_train: 0.5682 acc_train: 0.8214 loss_val: 0.9650 acc_val: 0.7067 time: 1.9646s\n",
            "loss_val:0.9650141596794128, val_acc:0.7066666666666667, out_features:tensor([[-8.6327e+00, -8.5609e+00, -5.5912e-03,  ..., -8.6567e+00,\n",
            "         -8.6300e+00, -8.4759e+00],\n",
            "        [-2.3352e+00, -3.0820e+00, -2.3902e+00,  ..., -2.1264e+00,\n",
            "         -9.7637e-01, -1.5107e+00],\n",
            "        [-4.1592e+00, -4.4556e+00, -4.0448e+00,  ..., -1.0592e-01,\n",
            "         -4.4408e+00, -3.9530e+00],\n",
            "        ...,\n",
            "        [-1.7294e+00, -1.1379e+00, -2.7583e+00,  ..., -1.6251e+00,\n",
            "         -2.0914e+00, -2.6633e+00],\n",
            "        [-6.0925e-01, -3.2422e+00, -2.7726e+00,  ..., -2.1977e+00,\n",
            "         -2.2744e+00, -2.5593e+00],\n",
            "        [-3.6372e+00, -3.9875e+00, -1.5377e-01,  ..., -3.8685e+00,\n",
            "         -3.5513e+00, -3.7717e+00]], grad_fn=<LogSoftmaxBackward0>)\n",
            "Training: 495\n",
            "Epoch: 0496 loss_train: 0.6236 acc_train: 0.8071 loss_val: 1.0463 acc_val: 0.6733 time: 1.7422s\n",
            "loss_val:1.0462559461593628, val_acc:0.6733333333333333, out_features:tensor([[-2.6304e+00, -2.7452e+00, -6.1740e-01,  ..., -2.9367e+00,\n",
            "         -2.5143e+00, -2.1844e+00],\n",
            "        [-1.9459e+00, -1.9459e+00, -1.9459e+00,  ..., -1.9459e+00,\n",
            "         -1.9459e+00, -1.9459e+00],\n",
            "        [-3.8270e+00, -4.1009e+00, -4.5429e+00,  ..., -8.3842e-02,\n",
            "         -4.5085e+00, -4.4825e+00],\n",
            "        ...,\n",
            "        [-7.2123e+00, -1.0136e-02, -6.9358e+00,  ..., -5.3695e+00,\n",
            "         -6.0828e+00, -7.1651e+00],\n",
            "        [-1.4591e+00, -2.1810e+00, -2.5664e+00,  ..., -1.8577e+00,\n",
            "         -2.2151e+00, -1.6596e+00],\n",
            "        [-1.1385e+01, -1.1681e+01, -4.8636e-05,  ..., -1.2074e+01,\n",
            "         -1.1875e+01, -1.2062e+01]], grad_fn=<LogSoftmaxBackward0>)\n",
            "Training: 496\n",
            "Epoch: 0497 loss_train: 0.6420 acc_train: 0.7929 loss_val: 1.0035 acc_val: 0.7100 time: 1.7482s\n",
            "loss_val:1.0035027265548706, val_acc:0.71, out_features:tensor([[-1.0315e+01, -1.0318e+01, -4.4241e-04,  ..., -1.0215e+01,\n",
            "         -1.0418e+01, -1.0115e+01],\n",
            "        [-1.9459e+00, -1.9459e+00, -1.9459e+00,  ..., -1.9459e+00,\n",
            "         -1.9459e+00, -1.9459e+00],\n",
            "        [-2.0182e+00, -2.4052e+00, -2.4037e+00,  ..., -8.7810e-01,\n",
            "         -2.4549e+00, -2.2851e+00],\n",
            "        ...,\n",
            "        [-6.9375e+00, -1.2791e-02, -7.1448e+00,  ..., -5.0120e+00,\n",
            "         -5.8834e+00, -7.1176e+00],\n",
            "        [-1.9459e+00, -1.9459e+00, -1.9459e+00,  ..., -1.9459e+00,\n",
            "         -1.9459e+00, -1.9459e+00],\n",
            "        [-1.9459e+00, -1.9459e+00, -1.9459e+00,  ..., -1.9459e+00,\n",
            "         -1.9459e+00, -1.9459e+00]], grad_fn=<LogSoftmaxBackward0>)\n",
            "Training: 497\n",
            "Epoch: 0498 loss_train: 0.5792 acc_train: 0.8429 loss_val: 0.9697 acc_val: 0.7033 time: 1.7279s\n",
            "loss_val:0.9697422385215759, val_acc:0.7033333333333334, out_features:tensor([[-8.1507e+00, -7.7856e+00, -2.6010e-03,  ..., -7.4500e+00,\n",
            "         -8.1547e+00, -7.6708e+00],\n",
            "        [-4.0129e+00, -3.4893e+00, -1.6479e+00,  ..., -3.9815e+00,\n",
            "         -4.4089e-01, -2.7462e+00],\n",
            "        [-2.4975e+00, -2.6972e+00, -2.1752e+00,  ..., -6.6028e-01,\n",
            "         -2.4306e+00, -2.5205e+00],\n",
            "        ...,\n",
            "        [-5.4175e+00, -4.0118e-02, -5.5626e+00,  ..., -5.0792e+00,\n",
            "         -4.2162e+00, -5.2949e+00],\n",
            "        [-4.3043e-01, -2.9011e+00, -3.4924e+00,  ..., -3.1982e+00,\n",
            "         -1.9858e+00, -3.4800e+00],\n",
            "        [-1.9459e+00, -1.9459e+00, -1.9459e+00,  ..., -1.9459e+00,\n",
            "         -1.9459e+00, -1.9459e+00]], grad_fn=<LogSoftmaxBackward0>)\n",
            "Training: 498\n",
            "Epoch: 0499 loss_train: 0.6385 acc_train: 0.7929 loss_val: 1.1129 acc_val: 0.6567 time: 1.7438s\n",
            "loss_val:1.112873911857605, val_acc:0.6566666666666666, out_features:tensor([[-5.4565e+00, -5.2738e+00, -3.8681e-02,  ..., -4.7003e+00,\n",
            "         -5.5863e+00, -5.6884e+00],\n",
            "        [-1.9459e+00, -1.9459e+00, -1.9459e+00,  ..., -1.9459e+00,\n",
            "         -1.9459e+00, -1.9459e+00],\n",
            "        [-1.9459e+00, -1.9459e+00, -1.9459e+00,  ..., -1.9459e+00,\n",
            "         -1.9459e+00, -1.9459e+00],\n",
            "        ...,\n",
            "        [-7.5863e+00, -1.4257e-03, -9.2242e+00,  ..., -8.1724e+00,\n",
            "         -8.1914e+00, -8.7333e+00],\n",
            "        [-2.2625e-01, -3.3715e+00, -4.1317e+00,  ..., -3.4970e+00,\n",
            "         -2.6534e+00, -3.5153e+00],\n",
            "        [-3.4541e+00, -3.7985e+00, -2.9332e-01,  ..., -3.1236e+00,\n",
            "         -2.9998e+00, -3.1958e+00]], grad_fn=<LogSoftmaxBackward0>)\n",
            "Training: 499\n",
            "Epoch: 0500 loss_train: 0.6194 acc_train: 0.8286 loss_val: 1.0999 acc_val: 0.6633 time: 1.7453s\n",
            "loss_val:1.0999090671539307, val_acc:0.6633333333333333, out_features:tensor([[-3.6075, -3.8102, -0.1817,  ..., -3.6056, -3.8216, -3.3706],\n",
            "        [-2.1159, -3.6148, -2.7281,  ..., -3.2609, -0.6341, -1.6294],\n",
            "        [-4.6787, -3.8071, -3.4813,  ..., -0.1073, -4.1183, -4.2776],\n",
            "        ...,\n",
            "        [-2.1919, -1.5848, -1.7657,  ..., -2.0679, -2.0060, -2.0752],\n",
            "        [-0.2280, -3.5547, -4.1364,  ..., -2.6681, -3.5717, -3.1273],\n",
            "        [-5.4961, -4.6372, -0.0378,  ..., -5.6657, -4.9690, -4.8669]],\n",
            "       grad_fn=<LogSoftmaxBackward0>)\n",
            "Training: 500\n",
            "Epoch: 0501 loss_train: 0.6785 acc_train: 0.8214 loss_val: 1.0836 acc_val: 0.6667 time: 1.8797s\n",
            "loss_val:1.083565354347229, val_acc:0.6666666666666666, out_features:tensor([[-2.7618e+00, -2.7207e+00, -7.4266e-01,  ..., -2.2909e+00,\n",
            "         -2.9096e+00, -2.4245e+00],\n",
            "        [-1.9459e+00, -1.9459e+00, -1.9459e+00,  ..., -1.9459e+00,\n",
            "         -1.9459e+00, -1.9459e+00],\n",
            "        [-2.1125e+00, -2.6432e+00, -2.9900e+00,  ..., -7.0172e-01,\n",
            "         -2.1929e+00, -2.2837e+00],\n",
            "        ...,\n",
            "        [-1.9375e+00, -1.0871e+00, -2.4091e+00,  ..., -2.4166e+00,\n",
            "         -1.8869e+00, -2.5528e+00],\n",
            "        [-2.3595e-03, -7.4722e+00, -8.3890e+00,  ..., -7.7138e+00,\n",
            "         -7.7309e+00, -7.8144e+00],\n",
            "        [-3.3774e+00, -2.6960e+00, -3.1858e-01,  ..., -2.7904e+00,\n",
            "         -3.3096e+00, -3.3524e+00]], grad_fn=<LogSoftmaxBackward0>)\n",
            "Training: 501\n",
            "Epoch: 0502 loss_train: 0.7031 acc_train: 0.7786 loss_val: 1.0016 acc_val: 0.6633 time: 1.9522s\n",
            "loss_val:1.0016008615493774, val_acc:0.6633333333333333, out_features:tensor([[-6.1200, -6.3784, -0.0199,  ..., -6.3651, -6.4407, -6.1672],\n",
            "        [-2.5000, -3.6967, -1.3898,  ..., -3.6943, -0.9862, -1.5614],\n",
            "        [-5.4516, -4.8003, -5.3183,  ..., -0.0313, -5.4554, -5.2944],\n",
            "        ...,\n",
            "        [-2.5284, -0.9135, -2.9661,  ..., -1.9773, -1.7423, -2.5750],\n",
            "        [-0.3187, -2.8363, -3.3148,  ..., -2.4599, -3.2300, -3.6647],\n",
            "        [-1.1207, -2.6586, -1.0568,  ..., -3.8711, -2.6405, -1.9339]],\n",
            "       grad_fn=<LogSoftmaxBackward0>)\n",
            "Training: 502\n",
            "Epoch: 0503 loss_train: 0.5528 acc_train: 0.8571 loss_val: 0.9639 acc_val: 0.7000 time: 1.7538s\n",
            "loss_val:0.9638773798942566, val_acc:0.7, out_features:tensor([[-7.1126e+00, -6.8436e+00, -8.2464e-03,  ..., -6.8263e+00,\n",
            "         -7.1371e+00, -6.3610e+00],\n",
            "        [-1.0731e+01, -1.0727e+01, -1.0866e+01,  ..., -1.0844e+01,\n",
            "         -1.2934e-02, -4.3624e+00],\n",
            "        [-2.2610e+00, -1.7501e+00, -3.5758e+00,  ..., -5.2204e-01,\n",
            "         -3.2014e+00, -3.2420e+00],\n",
            "        ...,\n",
            "        [-4.4596e+00, -2.8903e-02, -6.2842e+00,  ..., -6.1231e+00,\n",
            "         -5.8723e+00, -5.1202e+00],\n",
            "        [-1.1359e-01, -4.5431e+00, -4.9439e+00,  ..., -3.2481e+00,\n",
            "         -3.4392e+00, -4.8976e+00],\n",
            "        [-2.0727e+00, -2.8100e+00, -7.3639e-01,  ..., -3.1821e+00,\n",
            "         -2.5189e+00, -3.1532e+00]], grad_fn=<LogSoftmaxBackward0>)\n",
            "Training: 503\n",
            "Epoch: 0504 loss_train: 0.6096 acc_train: 0.8286 loss_val: 1.1473 acc_val: 0.6400 time: 1.7480s\n",
            "loss_val:1.1472713947296143, val_acc:0.64, out_features:tensor([[-7.9559e+00, -7.9919e+00, -5.8175e-03,  ..., -7.3364e+00,\n",
            "         -7.9012e+00, -7.6916e+00],\n",
            "        [-1.9459e+00, -1.9459e+00, -1.9459e+00,  ..., -1.9459e+00,\n",
            "         -1.9459e+00, -1.9459e+00],\n",
            "        [-4.7408e+00, -4.1767e+00, -3.3811e+00,  ..., -9.4672e-02,\n",
            "         -4.4080e+00, -4.3800e+00],\n",
            "        ...,\n",
            "        [-2.3174e+00, -5.8463e-01, -3.2513e+00,  ..., -3.0421e+00,\n",
            "         -2.1935e+00, -2.6807e+00],\n",
            "        [-1.0004e+00, -2.1924e+00, -2.4625e+00,  ..., -1.6737e+00,\n",
            "         -1.9822e+00, -3.0193e+00],\n",
            "        [-1.0359e+01, -9.7850e+00, -2.9309e-04,  ..., -9.6594e+00,\n",
            "         -1.0216e+01, -1.0323e+01]], grad_fn=<LogSoftmaxBackward0>)\n",
            "Training: 504\n",
            "Epoch: 0505 loss_train: 0.6134 acc_train: 0.8429 loss_val: 1.0037 acc_val: 0.6733 time: 1.7524s\n",
            "loss_val:1.003719687461853, val_acc:0.6733333333333333, out_features:tensor([[-1.1898e+01, -1.1688e+01, -5.0067e-05,  ..., -1.1796e+01,\n",
            "         -1.1603e+01, -1.1509e+01],\n",
            "        [-3.8508e+00, -4.1007e+00, -1.6853e+00,  ..., -3.3116e+00,\n",
            "         -3.4964e-01, -4.0196e+00],\n",
            "        [-8.7220e+00, -7.8309e+00, -7.4731e+00,  ..., -1.5246e-03,\n",
            "         -8.8285e+00, -8.9351e+00],\n",
            "        ...,\n",
            "        [-3.8781e+00, -1.7374e-01, -3.3633e+00,  ..., -3.8799e+00,\n",
            "         -3.9134e+00, -3.5389e+00],\n",
            "        [-1.0606e-01, -5.3965e+00, -4.5620e+00,  ..., -4.0176e+00,\n",
            "         -2.8958e+00, -4.8240e+00],\n",
            "        [-3.4389e+00, -5.2998e+00, -1.5247e-01,  ..., -5.4414e+00,\n",
            "         -2.8767e+00, -3.2400e+00]], grad_fn=<LogSoftmaxBackward0>)\n",
            "Training: 505\n",
            "Epoch: 0506 loss_train: 0.6557 acc_train: 0.8071 loss_val: 0.9966 acc_val: 0.6967 time: 1.7358s\n",
            "loss_val:0.9965614080429077, val_acc:0.6966666666666667, out_features:tensor([[-1.3370e+01, -1.3372e+01, -2.1100e-05,  ..., -1.1771e+01,\n",
            "         -1.3224e+01, -1.3377e+01],\n",
            "        [-4.4538e+00, -5.7308e+00, -5.7717e+00,  ..., -5.5927e+00,\n",
            "         -1.0396e-01, -2.6141e+00],\n",
            "        [-1.9459e+00, -1.9459e+00, -1.9459e+00,  ..., -1.9459e+00,\n",
            "         -1.9459e+00, -1.9459e+00],\n",
            "        ...,\n",
            "        [-2.8713e+00, -4.4616e-01, -3.2654e+00,  ..., -2.4574e+00,\n",
            "         -2.4653e+00, -2.9116e+00],\n",
            "        [-4.7838e-01, -2.1133e+00, -3.4027e+00,  ..., -2.2830e+00,\n",
            "         -2.9838e+00, -3.2371e+00],\n",
            "        [-2.1907e+00, -2.9827e+00, -4.9355e-01,  ..., -3.0497e+00,\n",
            "         -2.1080e+00, -3.7702e+00]], grad_fn=<LogSoftmaxBackward0>)\n",
            "Training: 506\n",
            "Epoch: 0507 loss_train: 0.6011 acc_train: 0.8643 loss_val: 1.0795 acc_val: 0.6600 time: 1.7430s\n",
            "loss_val:1.0795245170593262, val_acc:0.66, out_features:tensor([[-5.0561, -5.0747, -0.0648,  ..., -5.1085, -5.1449, -4.7759],\n",
            "        [-2.4381, -3.3887, -3.7036,  ..., -3.2871, -0.5543, -1.5619],\n",
            "        [-5.1659, -5.1892, -5.1092,  ..., -0.0235, -6.2078, -6.2704],\n",
            "        ...,\n",
            "        [-4.8874, -0.0313, -5.3303,  ..., -5.3362, -5.3687, -5.2865],\n",
            "        [-0.0819, -3.8483, -5.3114,  ..., -3.5420, -4.8347, -5.3178],\n",
            "        [-3.4061, -2.6815, -0.3717,  ..., -3.0244, -2.9069, -3.0995]],\n",
            "       grad_fn=<LogSoftmaxBackward0>)\n",
            "Training: 507\n",
            "Epoch: 0508 loss_train: 0.7048 acc_train: 0.7786 loss_val: 1.0539 acc_val: 0.6833 time: 1.8875s\n",
            "loss_val:1.0538727045059204, val_acc:0.6833333333333333, out_features:tensor([[-4.3904, -4.6061, -0.0654,  ..., -4.5874, -4.5191, -4.7836],\n",
            "        [-0.9014, -4.8767, -4.7651,  ..., -4.5441, -0.7859, -2.2796],\n",
            "        [-1.9459, -1.9459, -1.9459,  ..., -1.9459, -1.9459, -1.9459],\n",
            "        ...,\n",
            "        [-2.8407, -0.3581, -3.2889,  ..., -3.0026, -2.6807, -3.0406],\n",
            "        [-0.9043, -1.2747, -2.8388,  ..., -2.3284, -2.6676, -3.2017],\n",
            "        [-2.8902, -2.8800, -0.6841,  ..., -2.2226, -2.7932, -2.2184]],\n",
            "       grad_fn=<LogSoftmaxBackward0>)\n",
            "Training: 508\n",
            "Epoch: 0509 loss_train: 0.5894 acc_train: 0.8143 loss_val: 1.0357 acc_val: 0.6667 time: 1.9622s\n",
            "loss_val:1.03566312789917, val_acc:0.6666666666666666, out_features:tensor([[-7.1018, -7.0565, -0.0146,  ..., -6.8528, -6.9804, -6.5785],\n",
            "        [-2.1813, -2.9055, -2.7831,  ..., -2.3130, -1.1349, -1.3104],\n",
            "        [-1.9459, -1.9459, -1.9459,  ..., -1.9459, -1.9459, -1.9459],\n",
            "        ...,\n",
            "        [-3.2809, -0.3167, -3.6024,  ..., -2.8342, -2.8896, -2.8816],\n",
            "        [-0.4106, -3.3279, -3.3008,  ..., -2.0444, -2.9909, -2.9131],\n",
            "        [-5.0969, -7.3719, -0.0095,  ..., -7.5688, -6.9564, -7.2120]],\n",
            "       grad_fn=<LogSoftmaxBackward0>)\n",
            "Training: 509\n",
            "Epoch: 0510 loss_train: 0.5665 acc_train: 0.8643 loss_val: 1.0292 acc_val: 0.6667 time: 1.7378s\n",
            "loss_val:1.0291823148727417, val_acc:0.6666666666666666, out_features:tensor([[-7.6390e+00, -7.7937e+00, -6.4915e-03,  ..., -7.8425e+00,\n",
            "         -7.8373e+00, -6.3994e+00],\n",
            "        [-1.9459e+00, -1.9459e+00, -1.9459e+00,  ..., -1.9459e+00,\n",
            "         -1.9459e+00, -1.9459e+00],\n",
            "        [-2.4851e+00, -1.4123e+00, -2.7591e+00,  ..., -8.8200e-01,\n",
            "         -2.3056e+00, -2.9630e+00],\n",
            "        ...,\n",
            "        [-4.7385e+00, -7.4177e-02, -4.4471e+00,  ..., -4.0581e+00,\n",
            "         -4.2462e+00, -4.7500e+00],\n",
            "        [-3.4560e-01, -3.0563e+00, -3.2968e+00,  ..., -2.5183e+00,\n",
            "         -2.6497e+00, -3.4717e+00],\n",
            "        [-4.1669e+00, -4.6408e+00, -8.6593e-02,  ..., -4.4494e+00,\n",
            "         -4.5641e+00, -4.8496e+00]], grad_fn=<LogSoftmaxBackward0>)\n",
            "Training: 510\n",
            "Epoch: 0511 loss_train: 0.6349 acc_train: 0.8214 loss_val: 1.0680 acc_val: 0.6767 time: 1.7552s\n",
            "loss_val:1.0679879188537598, val_acc:0.6766666666666666, out_features:tensor([[-7.7270e+00, -7.8050e+00, -2.6724e-03,  ..., -7.7047e+00,\n",
            "         -7.4989e+00, -7.8528e+00],\n",
            "        [-7.0627e+00, -6.4629e+00, -7.5824e+00,  ..., -6.0885e+00,\n",
            "         -1.4819e-02, -4.7145e+00],\n",
            "        [-4.0517e+00, -4.9075e+00, -4.8409e+00,  ..., -6.8194e-02,\n",
            "         -4.2538e+00, -4.4350e+00],\n",
            "        ...,\n",
            "        [-2.6695e+00, -1.1179e+00, -2.4984e+00,  ..., -1.7379e+00,\n",
            "         -1.9347e+00, -1.9592e+00],\n",
            "        [-7.6111e-01, -2.6258e+00, -2.7119e+00,  ..., -2.4143e+00,\n",
            "         -1.7847e+00, -2.5288e+00],\n",
            "        [-3.4705e+00, -3.3489e+00, -2.2297e-01,  ..., -3.6788e+00,\n",
            "         -3.6299e+00, -3.0923e+00]], grad_fn=<LogSoftmaxBackward0>)\n",
            "Training: 511\n",
            "Epoch: 0512 loss_train: 0.5866 acc_train: 0.8571 loss_val: 0.9624 acc_val: 0.6967 time: 1.9892s\n",
            "loss_val:0.9624056220054626, val_acc:0.6966666666666667, out_features:tensor([[-1.0220e+01, -1.0195e+01, -2.9262e-04,  ..., -9.6244e+00,\n",
            "         -1.0210e+01, -1.0223e+01],\n",
            "        [-1.9459e+00, -1.9459e+00, -1.9459e+00,  ..., -1.9459e+00,\n",
            "         -1.9459e+00, -1.9459e+00],\n",
            "        [-5.2484e+00, -3.9835e+00, -4.7499e+00,  ..., -5.7686e-02,\n",
            "         -4.2800e+00, -5.1748e+00],\n",
            "        ...,\n",
            "        [-1.7210e+00, -1.3535e+00, -2.5500e+00,  ..., -1.7547e+00,\n",
            "         -2.5223e+00, -2.2109e+00],\n",
            "        [-1.3813e-01, -4.5262e+00, -4.4454e+00,  ..., -3.1114e+00,\n",
            "         -3.3810e+00, -4.2187e+00],\n",
            "        [-2.1801e+00, -3.2534e+00, -3.7173e-01,  ..., -2.4158e+00,\n",
            "         -3.4270e+00, -4.0355e+00]], grad_fn=<LogSoftmaxBackward0>)\n",
            "Training: 512\n",
            "Epoch: 0513 loss_train: 0.4992 acc_train: 0.8857 loss_val: 1.0289 acc_val: 0.6333 time: 1.7451s\n",
            "loss_val:1.028899073600769, val_acc:0.6333333333333333, out_features:tensor([[-6.6111, -5.7333, -0.0110,  ..., -6.4648, -6.6940, -6.5470],\n",
            "        [-3.1515, -3.9043, -1.7664,  ..., -3.8523, -0.7803, -1.3455],\n",
            "        [-3.5007, -3.0768, -2.9510,  ..., -0.2450, -3.3179, -3.5148],\n",
            "        ...,\n",
            "        [-4.1098, -0.0617, -5.3026,  ..., -3.9370, -4.8476, -5.0020],\n",
            "        [-0.7752, -2.6352, -2.5260,  ..., -1.8827, -2.2834, -2.8122],\n",
            "        [-4.1383, -3.3381, -0.1328,  ..., -4.3734, -4.4374, -4.4087]],\n",
            "       grad_fn=<LogSoftmaxBackward0>)\n",
            "Training: 513\n",
            "Epoch: 0514 loss_train: 0.6587 acc_train: 0.8071 loss_val: 1.0533 acc_val: 0.6467 time: 1.7813s\n",
            "loss_val:1.0533496141433716, val_acc:0.6466666666666666, out_features:tensor([[-8.4834e+00, -8.4575e+00, -5.5630e-03,  ..., -8.2510e+00,\n",
            "         -8.5224e+00, -7.0682e+00],\n",
            "        [-1.9459e+00, -1.9459e+00, -1.9459e+00,  ..., -1.9459e+00,\n",
            "         -1.9459e+00, -1.9459e+00],\n",
            "        [-3.3051e+00, -3.7708e+00, -2.7693e+00,  ..., -2.5044e-01,\n",
            "         -3.4755e+00, -3.1639e+00],\n",
            "        ...,\n",
            "        [-8.0288e+00, -3.9866e-03, -8.1710e+00,  ..., -6.9694e+00,\n",
            "         -6.4529e+00, -7.7161e+00],\n",
            "        [-1.4500e-01, -3.9997e+00, -4.4950e+00,  ..., -3.1031e+00,\n",
            "         -3.3268e+00, -4.3428e+00],\n",
            "        [-4.6927e+00, -4.9807e+00, -7.4093e-02,  ..., -4.9977e+00,\n",
            "         -3.6939e+00, -4.6777e+00]], grad_fn=<LogSoftmaxBackward0>)\n",
            "Training: 514\n",
            "Epoch: 0515 loss_train: 0.4344 acc_train: 0.9071 loss_val: 1.0648 acc_val: 0.6500 time: 1.9195s\n",
            "loss_val:1.0647562742233276, val_acc:0.65, out_features:tensor([[-8.1310e+00, -7.9654e+00, -7.9134e-03,  ..., -7.8435e+00,\n",
            "         -8.0951e+00, -8.0541e+00],\n",
            "        [-3.7018e+00, -3.7556e+00, -3.6007e+00,  ..., -3.7572e+00,\n",
            "         -1.0267e+00, -1.1586e+00],\n",
            "        [-5.5737e+00, -5.4537e+00, -5.6334e+00,  ..., -2.5985e-02,\n",
            "         -5.3002e+00, -5.0845e+00],\n",
            "        ...,\n",
            "        [-2.1050e+00, -1.1405e+00, -2.6826e+00,  ..., -2.4837e+00,\n",
            "         -1.7568e+00, -2.2179e+00],\n",
            "        [-3.2910e-01, -2.5346e+00, -3.4646e+00,  ..., -3.0915e+00,\n",
            "         -2.9230e+00, -3.2713e+00],\n",
            "        [-6.7319e+00, -5.6466e+00, -1.2090e-02,  ..., -6.4371e+00,\n",
            "         -5.9314e+00, -6.6987e+00]], grad_fn=<LogSoftmaxBackward0>)\n",
            "Training: 515\n",
            "Epoch: 0516 loss_train: 0.5589 acc_train: 0.8500 loss_val: 0.9468 acc_val: 0.6833 time: 1.9638s\n",
            "loss_val:0.9467549920082092, val_acc:0.6833333333333333, out_features:tensor([[-3.9388, -4.0586, -0.1081,  ..., -3.9648, -4.4376, -4.3584],\n",
            "        [-2.4359, -2.8160, -2.7198,  ..., -2.3152, -1.0835, -1.2617],\n",
            "        [-5.0595, -4.8610, -5.4748,  ..., -0.0317, -5.1907, -5.3378],\n",
            "        ...,\n",
            "        [-2.6698, -0.5302, -3.4520,  ..., -2.8137, -2.0576, -3.1053],\n",
            "        [-0.3955, -3.5365, -3.1780,  ..., -2.3650, -2.4451, -3.4846],\n",
            "        [-2.7466, -2.0242, -0.9430,  ..., -2.2844, -2.2245, -2.3531]],\n",
            "       grad_fn=<LogSoftmaxBackward0>)\n",
            "Training: 516\n",
            "Epoch: 0517 loss_train: 0.5818 acc_train: 0.8429 loss_val: 1.0436 acc_val: 0.6433 time: 1.7594s\n",
            "loss_val:1.0435861349105835, val_acc:0.6433333333333333, out_features:tensor([[-3.6442, -3.7040, -0.1518,  ..., -3.6600, -4.0227, -3.4218],\n",
            "        [-2.4589, -2.1636, -2.7509,  ..., -1.9528, -1.2943, -1.2665],\n",
            "        [-2.1495, -2.3850, -2.5436,  ..., -0.7053, -2.2764, -2.8667],\n",
            "        ...,\n",
            "        [-2.8342, -0.5106, -3.8434,  ..., -1.7676, -2.5870, -2.8968],\n",
            "        [-0.1963, -3.8966, -3.8143,  ..., -3.0314, -2.8821, -4.0656],\n",
            "        [-5.5647, -4.9908, -0.0473,  ..., -5.4914, -5.5470, -5.7708]],\n",
            "       grad_fn=<LogSoftmaxBackward0>)\n",
            "Training: 517\n",
            "Epoch: 0518 loss_train: 0.6232 acc_train: 0.8071 loss_val: 1.0917 acc_val: 0.6467 time: 1.7520s\n",
            "loss_val:1.0917209386825562, val_acc:0.6466666666666666, out_features:tensor([[-8.1053e+00, -7.8080e+00, -2.9350e-03,  ..., -7.9404e+00,\n",
            "         -8.0770e+00, -7.5326e+00],\n",
            "        [-1.4635e+00, -5.1147e+00, -5.1227e+00,  ..., -4.6905e+00,\n",
            "         -3.4956e-01, -3.3756e+00],\n",
            "        [-2.3677e+00, -3.4314e+00, -2.6962e+00,  ..., -5.2557e-01,\n",
            "         -2.4746e+00, -2.4494e+00],\n",
            "        ...,\n",
            "        [-1.9459e+00, -1.9459e+00, -1.9459e+00,  ..., -1.9459e+00,\n",
            "         -1.9459e+00, -1.9459e+00],\n",
            "        [-1.6872e+00, -2.1300e+00, -1.9912e+00,  ..., -1.8045e+00,\n",
            "         -1.8339e+00, -2.0791e+00],\n",
            "        [-3.0180e+00, -1.9852e+00, -5.8594e-01,  ..., -1.9741e+00,\n",
            "         -3.2444e+00, -3.1124e+00]], grad_fn=<LogSoftmaxBackward0>)\n",
            "Training: 518\n",
            "Epoch: 0519 loss_train: 0.6447 acc_train: 0.8143 loss_val: 0.9664 acc_val: 0.6900 time: 1.7652s\n",
            "loss_val:0.9663694500923157, val_acc:0.69, out_features:tensor([[-2.4322e+00, -2.5373e+00, -9.1625e-01,  ..., -2.3817e+00,\n",
            "         -2.4412e+00, -2.0983e+00],\n",
            "        [-5.7545e+00, -6.0280e+00, -5.4793e+00,  ..., -5.4198e+00,\n",
            "         -6.3319e-02, -3.1099e+00],\n",
            "        [-7.7590e+00, -9.1758e+00, -8.8529e+00,  ..., -1.1410e-03,\n",
            "         -8.4803e+00, -8.6712e+00],\n",
            "        ...,\n",
            "        [-7.1522e+00, -4.4037e-03, -7.9160e+00,  ..., -7.4806e+00,\n",
            "         -6.2974e+00, -7.6711e+00],\n",
            "        [-1.9459e+00, -1.9459e+00, -1.9459e+00,  ..., -1.9459e+00,\n",
            "         -1.9459e+00, -1.9459e+00],\n",
            "        [-7.8083e+00, -6.7024e+00, -3.8216e-03,  ..., -7.6083e+00,\n",
            "         -7.6691e+00, -7.8347e+00]], grad_fn=<LogSoftmaxBackward0>)\n",
            "Training: 519\n",
            "Epoch: 0520 loss_train: 0.6938 acc_train: 0.7714 loss_val: 1.0327 acc_val: 0.6433 time: 1.7465s\n",
            "loss_val:1.0327092409133911, val_acc:0.6433333333333333, out_features:tensor([[-8.4467e+00, -8.4832e+00, -1.7686e-03,  ..., -7.3012e+00,\n",
            "         -8.1806e+00, -8.6206e+00],\n",
            "        [-1.9459e+00, -1.9459e+00, -1.9459e+00,  ..., -1.9459e+00,\n",
            "         -1.9459e+00, -1.9459e+00],\n",
            "        [-2.1570e+00, -2.8117e+00, -2.5824e+00,  ..., -5.6770e-01,\n",
            "         -3.1480e+00, -2.3553e+00],\n",
            "        ...,\n",
            "        [-2.7214e+00, -1.2172e+00, -1.4647e+00,  ..., -2.5743e+00,\n",
            "         -1.6693e+00, -2.6190e+00],\n",
            "        [-2.2795e-02, -5.7278e+00, -6.3497e+00,  ..., -4.9690e+00,\n",
            "         -5.0955e+00, -5.9375e+00],\n",
            "        [-6.2750e+00, -6.2629e+00, -1.0640e-02,  ..., -6.4602e+00,\n",
            "         -6.4883e+00, -6.2555e+00]], grad_fn=<LogSoftmaxBackward0>)\n",
            "Training: 520\n",
            "Epoch: 0521 loss_train: 0.7093 acc_train: 0.7571 loss_val: 1.1267 acc_val: 0.6333 time: 1.7512s\n",
            "loss_val:1.1266926527023315, val_acc:0.6333333333333333, out_features:tensor([[-3.3618e+00, -3.5788e+00, -2.8818e-01,  ..., -2.9736e+00,\n",
            "         -3.5881e+00, -3.3128e+00],\n",
            "        [-1.9459e+00, -1.9459e+00, -1.9459e+00,  ..., -1.9459e+00,\n",
            "         -1.9459e+00, -1.9459e+00],\n",
            "        [-2.8408e+00, -3.2412e+00, -2.9423e+00,  ..., -3.5314e-01,\n",
            "         -3.0484e+00, -2.7939e+00],\n",
            "        ...,\n",
            "        [-4.4128e+00, -1.1659e-01, -4.9507e+00,  ..., -3.1047e+00,\n",
            "         -4.1795e+00, -3.7868e+00],\n",
            "        [-3.7203e-03, -7.9828e+00, -8.3805e+00,  ..., -7.9401e+00,\n",
            "         -6.3266e+00, -7.3058e+00],\n",
            "        [-6.6180e+00, -5.1673e+00, -1.6219e-02,  ..., -5.8103e+00,\n",
            "         -5.8880e+00, -6.4037e+00]], grad_fn=<LogSoftmaxBackward0>)\n",
            "Training: 521\n",
            "Epoch: 0522 loss_train: 0.6846 acc_train: 0.7929 loss_val: 1.0208 acc_val: 0.6933 time: 1.9096s\n",
            "loss_val:1.0208252668380737, val_acc:0.6933333333333334, out_features:tensor([[-2.5954, -2.8659, -0.5857,  ..., -2.1762, -3.0575, -3.0053],\n",
            "        [-3.1541, -5.7265, -5.7336,  ..., -4.8588, -0.0810, -4.0281],\n",
            "        [-6.4251, -5.3711, -4.5139,  ..., -0.0225, -6.5262, -6.2640],\n",
            "        ...,\n",
            "        [-2.3680, -0.4109, -3.3811,  ..., -2.9133, -2.6550, -2.9739],\n",
            "        [-0.3576, -3.1723, -3.5315,  ..., -2.5639, -2.5581, -3.3283],\n",
            "        [-6.4229, -6.2007, -0.0175,  ..., -4.7406, -6.6073, -6.6592]],\n",
            "       grad_fn=<LogSoftmaxBackward0>)\n",
            "Training: 522\n",
            "Epoch: 0523 loss_train: 0.6109 acc_train: 0.8143 loss_val: 1.1652 acc_val: 0.6367 time: 1.9639s\n",
            "loss_val:1.1651567220687866, val_acc:0.6366666666666667, out_features:tensor([[-2.6414, -2.7124, -0.5348,  ..., -2.5964, -3.1185, -2.5013],\n",
            "        [-1.9459, -1.9459, -1.9459,  ..., -1.9459, -1.9459, -1.9459],\n",
            "        [-5.9943, -6.8675, -6.2157,  ..., -0.0097, -6.8186, -6.2568],\n",
            "        ...,\n",
            "        [-0.9916, -1.3902, -2.7411,  ..., -3.1333, -1.9166, -2.4309],\n",
            "        [-0.1664, -3.3723, -4.3874,  ..., -3.5410, -3.2005, -3.8764],\n",
            "        [-2.8869, -3.8192, -0.1674,  ..., -4.0214, -3.4224, -4.2423]],\n",
            "       grad_fn=<LogSoftmaxBackward0>)\n",
            "Training: 523\n",
            "Epoch: 0524 loss_train: 0.6270 acc_train: 0.7929 loss_val: 1.0410 acc_val: 0.6633 time: 1.7393s\n",
            "loss_val:1.041013240814209, val_acc:0.6633333333333333, out_features:tensor([[-7.1994e+00, -7.3994e+00, -7.0569e-03,  ..., -6.8927e+00,\n",
            "         -7.3547e+00, -7.3830e+00],\n",
            "        [-1.9459e+00, -1.9459e+00, -1.9459e+00,  ..., -1.9459e+00,\n",
            "         -1.9459e+00, -1.9459e+00],\n",
            "        [-2.6648e+00, -4.5274e+00, -3.6385e+00,  ..., -1.7852e-01,\n",
            "         -3.3039e+00, -4.4769e+00],\n",
            "        ...,\n",
            "        [-4.6327e+00, -4.6415e-02, -5.5143e+00,  ..., -4.2853e+00,\n",
            "         -4.7147e+00, -5.5671e+00],\n",
            "        [-2.6627e-01, -3.6221e+00, -3.2491e+00,  ..., -2.5573e+00,\n",
            "         -3.3868e+00, -3.8102e+00],\n",
            "        [-7.0156e+00, -6.4961e+00, -6.1565e-03,  ..., -6.9087e+00,\n",
            "         -6.8562e+00, -7.0914e+00]], grad_fn=<LogSoftmaxBackward0>)\n",
            "Training: 524\n",
            "Epoch: 0525 loss_train: 0.5986 acc_train: 0.8357 loss_val: 1.0882 acc_val: 0.6833 time: 1.7471s\n",
            "loss_val:1.0881787538528442, val_acc:0.6833333333333333, out_features:tensor([[-9.2700e+00, -9.3287e+00, -1.4463e-03,  ..., -9.2109e+00,\n",
            "         -9.1807e+00, -7.3830e+00],\n",
            "        [-2.0362e+00, -3.4777e+00, -4.0295e+00,  ..., -4.2079e+00,\n",
            "         -2.6712e-01, -3.9386e+00],\n",
            "        [-9.9475e+00, -1.0909e+01, -1.0946e+01,  ..., -1.4566e-04,\n",
            "         -1.0518e+01, -1.0881e+01],\n",
            "        ...,\n",
            "        [-1.9994e+00, -5.6328e-01, -3.6877e+00,  ..., -3.1505e+00,\n",
            "         -2.8511e+00, -3.1453e+00],\n",
            "        [-3.4679e-01, -3.8308e+00, -3.1421e+00,  ..., -2.3398e+00,\n",
            "         -2.4782e+00, -3.4610e+00],\n",
            "        [-3.0657e+00, -2.3354e+00, -6.0962e-01,  ..., -2.7828e+00,\n",
            "         -2.8159e+00, -2.6084e+00]], grad_fn=<LogSoftmaxBackward0>)\n",
            "Training: 525\n",
            "Epoch: 0526 loss_train: 0.5079 acc_train: 0.8429 loss_val: 0.9353 acc_val: 0.6833 time: 1.7359s\n",
            "loss_val:0.9353091716766357, val_acc:0.6833333333333333, out_features:tensor([[-6.0580, -5.9825, -0.0245,  ..., -4.6277, -5.7793, -5.7067],\n",
            "        [-2.6101, -2.7464, -2.3647,  ..., -2.6886, -0.7606, -1.6347],\n",
            "        [-5.0323, -3.5846, -4.9418,  ..., -0.0638, -4.9279, -4.8594],\n",
            "        ...,\n",
            "        [-1.9459, -1.9459, -1.9459,  ..., -1.9459, -1.9459, -1.9459],\n",
            "        [-0.3280, -2.9114, -3.9846,  ..., -2.3897, -2.8037, -3.4080],\n",
            "        [-4.7493, -4.4214, -0.0887,  ..., -4.8214, -3.5768, -3.9041]],\n",
            "       grad_fn=<LogSoftmaxBackward0>)\n",
            "Training: 526\n",
            "Epoch: 0527 loss_train: 0.7629 acc_train: 0.7571 loss_val: 0.9425 acc_val: 0.7133 time: 1.7404s\n",
            "loss_val:0.9425048828125, val_acc:0.7133333333333334, out_features:tensor([[-1.9459e+00, -1.9459e+00, -1.9459e+00,  ..., -1.9459e+00,\n",
            "         -1.9459e+00, -1.9459e+00],\n",
            "        [-1.9459e+00, -1.9459e+00, -1.9459e+00,  ..., -1.9459e+00,\n",
            "         -1.9459e+00, -1.9459e+00],\n",
            "        [-7.4492e+00, -7.4071e+00, -6.1245e+00,  ..., -5.7616e-03,\n",
            "         -7.4673e+00, -6.6849e+00],\n",
            "        ...,\n",
            "        [-1.9459e+00, -1.9459e+00, -1.9459e+00,  ..., -1.9459e+00,\n",
            "         -1.9459e+00, -1.9459e+00],\n",
            "        [-7.5003e-01, -2.2845e+00, -2.9853e+00,  ..., -2.1445e+00,\n",
            "         -2.2019e+00, -2.6258e+00],\n",
            "        [-1.9459e+00, -1.9459e+00, -1.9459e+00,  ..., -1.9459e+00,\n",
            "         -1.9459e+00, -1.9459e+00]], grad_fn=<LogSoftmaxBackward0>)\n",
            "Training: 527\n",
            "Epoch: 0528 loss_train: 0.6590 acc_train: 0.8214 loss_val: 1.0612 acc_val: 0.6633 time: 1.7405s\n",
            "loss_val:1.0612311363220215, val_acc:0.6633333333333333, out_features:tensor([[-4.5436, -4.6098, -0.0910,  ..., -3.8136, -4.6509, -4.6226],\n",
            "        [-5.9166, -9.1372, -9.1320,  ..., -8.2463, -0.0122, -4.7304],\n",
            "        [-2.0912, -2.0812, -2.8591,  ..., -0.7736, -2.5636, -2.5427],\n",
            "        ...,\n",
            "        [-5.4554, -0.0258, -5.5125,  ..., -5.2996, -5.1844, -5.6043],\n",
            "        [-1.3353, -2.2669, -1.9244,  ..., -2.0791, -2.1026, -2.0907],\n",
            "        [-4.0852, -3.1527, -0.1779,  ..., -3.2457, -4.0468, -3.9814]],\n",
            "       grad_fn=<LogSoftmaxBackward0>)\n",
            "Training: 528\n",
            "Epoch: 0529 loss_train: 0.6176 acc_train: 0.8429 loss_val: 0.9655 acc_val: 0.6833 time: 1.8841s\n",
            "loss_val:0.9654616117477417, val_acc:0.6833333333333333, out_features:tensor([[-4.0445, -4.4454, -0.1985,  ..., -3.0761, -4.2511, -3.9028],\n",
            "        [-1.9459, -1.9459, -1.9459,  ..., -1.9459, -1.9459, -1.9459],\n",
            "        [-1.9459, -1.9459, -1.9459,  ..., -1.9459, -1.9459, -1.9459],\n",
            "        ...,\n",
            "        [-1.9459, -1.9459, -1.9459,  ..., -1.9459, -1.9459, -1.9459],\n",
            "        [-1.5267, -1.9791, -2.1347,  ..., -2.0648, -2.0913, -2.1268],\n",
            "        [-6.0834, -5.2034, -0.0387,  ..., -5.4926, -5.1215, -4.0135]],\n",
            "       grad_fn=<LogSoftmaxBackward0>)\n",
            "Training: 529\n",
            "Epoch: 0530 loss_train: 0.6313 acc_train: 0.8143 loss_val: 0.9779 acc_val: 0.6867 time: 1.9438s\n",
            "loss_val:0.9778621196746826, val_acc:0.6866666666666666, out_features:tensor([[-2.4409, -2.0982, -0.7980,  ..., -2.4449, -2.4564, -2.7278],\n",
            "        [-1.9459, -1.9459, -1.9459,  ..., -1.9459, -1.9459, -1.9459],\n",
            "        [-3.3995, -3.4921, -2.5247,  ..., -0.2852, -3.7614, -2.8666],\n",
            "        ...,\n",
            "        [-4.5660, -0.0638, -5.5977,  ..., -4.2341, -3.9871, -4.5117],\n",
            "        [-0.5400, -3.1586, -3.0943,  ..., -2.5899, -2.0077, -2.6400],\n",
            "        [-1.6146, -2.2914, -1.2934,  ..., -2.4133, -2.0605, -2.7267]],\n",
            "       grad_fn=<LogSoftmaxBackward0>)\n",
            "Training: 530\n",
            "Epoch: 0531 loss_train: 0.6898 acc_train: 0.7929 loss_val: 0.9682 acc_val: 0.6900 time: 1.7310s\n",
            "loss_val:0.9681715965270996, val_acc:0.69, out_features:tensor([[-8.1519e+00, -8.0713e+00, -3.6195e-03,  ..., -6.1826e+00,\n",
            "         -8.1547e+00, -8.1989e+00],\n",
            "        [-1.9459e+00, -1.9459e+00, -1.9459e+00,  ..., -1.9459e+00,\n",
            "         -1.9459e+00, -1.9459e+00],\n",
            "        [-2.8653e+00, -2.2585e+00, -2.1132e+00,  ..., -7.7789e-01,\n",
            "         -2.9001e+00, -2.2188e+00],\n",
            "        ...,\n",
            "        [-1.9459e+00, -1.9459e+00, -1.9459e+00,  ..., -1.9459e+00,\n",
            "         -1.9459e+00, -1.9459e+00],\n",
            "        [-4.6417e-01, -3.0265e+00, -3.8009e+00,  ..., -2.1402e+00,\n",
            "         -2.0167e+00, -3.7031e+00],\n",
            "        [-4.1095e+00, -3.4769e+00, -1.4704e-01,  ..., -4.0584e+00,\n",
            "         -3.4887e+00, -3.6372e+00]], grad_fn=<LogSoftmaxBackward0>)\n",
            "Training: 531\n",
            "Epoch: 0532 loss_train: 0.5876 acc_train: 0.8214 loss_val: 1.0151 acc_val: 0.6400 time: 1.7424s\n",
            "loss_val:1.0151450634002686, val_acc:0.64, out_features:tensor([[-5.4115, -5.1185, -0.1164,  ..., -5.5749, -5.3975, -4.8303],\n",
            "        [-3.3281, -4.2968, -5.2230,  ..., -0.8012, -0.8976, -2.4764],\n",
            "        [-1.9459, -1.9459, -1.9459,  ..., -1.9459, -1.9459, -1.9459],\n",
            "        ...,\n",
            "        [-3.5497, -0.1557, -4.3677,  ..., -3.4243, -3.5412, -3.5601],\n",
            "        [-0.0666, -5.2424, -5.1354,  ..., -5.2607, -4.3612, -3.5513],\n",
            "        [-2.2418, -3.3060, -0.4227,  ..., -2.8573, -2.8811, -3.2473]],\n",
            "       grad_fn=<LogSoftmaxBackward0>)\n",
            "Training: 532\n",
            "Epoch: 0533 loss_train: 0.6184 acc_train: 0.8357 loss_val: 1.0184 acc_val: 0.6967 time: 1.7335s\n",
            "loss_val:1.0183573961257935, val_acc:0.6966666666666667, out_features:tensor([[-4.0764, -4.4096, -0.1808,  ..., -3.6492, -4.4473, -3.9485],\n",
            "        [-2.2081, -3.4058, -2.7169,  ..., -1.5566, -0.8523, -2.0891],\n",
            "        [-3.9725, -3.6112, -2.6482,  ..., -0.2081, -3.6002, -3.5156],\n",
            "        ...,\n",
            "        [-1.9459, -1.9459, -1.9459,  ..., -1.9459, -1.9459, -1.9459],\n",
            "        [-0.5082, -3.5489, -4.1041,  ..., -2.0807, -1.6845, -3.6316],\n",
            "        [-5.2339, -5.3022, -0.0645,  ..., -4.9847, -3.7241, -4.1670]],\n",
            "       grad_fn=<LogSoftmaxBackward0>)\n",
            "Training: 533\n",
            "Epoch: 0534 loss_train: 0.6777 acc_train: 0.8071 loss_val: 1.0841 acc_val: 0.6433 time: 1.7379s\n",
            "loss_val:1.0841056108474731, val_acc:0.6433333333333333, out_features:tensor([[-8.7339e+00, -8.5214e+00, -1.4438e-03,  ..., -8.5461e+00,\n",
            "         -8.5807e+00, -8.2699e+00],\n",
            "        [-1.9459e+00, -1.9459e+00, -1.9459e+00,  ..., -1.9459e+00,\n",
            "         -1.9459e+00, -1.9459e+00],\n",
            "        [-7.0826e+00, -8.0718e+00, -6.6245e+00,  ..., -3.9805e-03,\n",
            "         -8.0969e+00, -7.0591e+00],\n",
            "        ...,\n",
            "        [-1.9459e+00, -1.9459e+00, -1.9459e+00,  ..., -1.9459e+00,\n",
            "         -1.9459e+00, -1.9459e+00],\n",
            "        [-6.0040e-01, -2.9715e+00, -2.0129e+00,  ..., -2.3281e+00,\n",
            "         -2.8649e+00, -2.9575e+00],\n",
            "        [-4.5721e+00, -4.6283e+00, -1.2048e-01,  ..., -3.3878e+00,\n",
            "         -3.6095e+00, -3.9899e+00]], grad_fn=<LogSoftmaxBackward0>)\n",
            "Training: 534\n",
            "Epoch: 0535 loss_train: 0.6967 acc_train: 0.7786 loss_val: 1.0254 acc_val: 0.6733 time: 1.7533s\n",
            "loss_val:1.0254132747650146, val_acc:0.6733333333333333, out_features:tensor([[-7.8632e+00, -7.7502e+00, -5.4481e-03,  ..., -7.2652e+00,\n",
            "         -7.7865e+00, -7.6737e+00],\n",
            "        [-1.9459e+00, -1.9459e+00, -1.9459e+00,  ..., -1.9459e+00,\n",
            "         -1.9459e+00, -1.9459e+00],\n",
            "        [-2.5554e+00, -2.8754e+00, -2.7614e+00,  ..., -4.9547e-01,\n",
            "         -2.7976e+00, -2.3601e+00],\n",
            "        ...,\n",
            "        [-5.4757e+00, -3.0168e-02, -5.8795e+00,  ..., -4.9709e+00,\n",
            "         -4.9023e+00, -5.2028e+00],\n",
            "        [-7.9834e-01, -2.3968e+00, -3.0507e+00,  ..., -1.5396e+00,\n",
            "         -2.5929e+00, -2.5485e+00],\n",
            "        [-1.9459e+00, -1.9459e+00, -1.9459e+00,  ..., -1.9459e+00,\n",
            "         -1.9459e+00, -1.9459e+00]], grad_fn=<LogSoftmaxBackward0>)\n",
            "Training: 535\n",
            "Epoch: 0536 loss_train: 0.7190 acc_train: 0.7857 loss_val: 1.0932 acc_val: 0.6500 time: 1.8868s\n",
            "loss_val:1.0932033061981201, val_acc:0.65, out_features:tensor([[-2.5322e+00, -2.4474e+00, -1.0743e+00,  ..., -2.4306e+00,\n",
            "         -2.3522e+00, -1.6086e+00],\n",
            "        [-7.5592e+00, -1.0123e+01, -1.0118e+01,  ..., -1.0087e+01,\n",
            "         -1.1052e-03, -7.9916e+00],\n",
            "        [-3.8990e+00, -3.0656e+00, -5.2521e+00,  ..., -1.0266e-01,\n",
            "         -5.0409e+00, -4.2504e+00],\n",
            "        ...,\n",
            "        [-3.3248e+00, -3.1305e-01, -3.6151e+00,  ..., -3.5263e+00,\n",
            "         -2.1099e+00, -3.4442e+00],\n",
            "        [-5.9935e-01, -2.7646e+00, -2.9352e+00,  ..., -2.3378e+00,\n",
            "         -2.1596e+00, -2.8882e+00],\n",
            "        [-4.5802e+00, -4.4571e+00, -1.3533e-01,  ..., -4.2245e+00,\n",
            "         -4.5133e+00, -4.1689e+00]], grad_fn=<LogSoftmaxBackward0>)\n",
            "Training: 536\n",
            "Epoch: 0537 loss_train: 0.4841 acc_train: 0.8786 loss_val: 1.0074 acc_val: 0.6800 time: 1.9596s\n",
            "loss_val:1.007384181022644, val_acc:0.68, out_features:tensor([[-8.3127e+00, -8.2556e+00, -2.7055e-03,  ..., -6.7369e+00,\n",
            "         -8.2435e+00, -8.2992e+00],\n",
            "        [-2.7551e+00, -3.8061e+00, -3.8685e+00,  ..., -2.3351e+00,\n",
            "         -6.0054e-01, -1.5078e+00],\n",
            "        [-8.5440e+00, -8.4865e+00, -8.8974e+00,  ..., -9.7787e-04,\n",
            "         -8.7941e+00, -8.7335e+00],\n",
            "        ...,\n",
            "        [-1.9459e+00, -1.9459e+00, -1.9459e+00,  ..., -1.9459e+00,\n",
            "         -1.9459e+00, -1.9459e+00],\n",
            "        [-1.2192e+00, -2.4242e+00, -2.0481e+00,  ..., -1.5841e+00,\n",
            "         -2.1154e+00, -2.4499e+00],\n",
            "        [-1.7098e+00, -2.4538e+00, -8.4568e-01,  ..., -2.7843e+00,\n",
            "         -2.3013e+00, -2.3409e+00]], grad_fn=<LogSoftmaxBackward0>)\n",
            "Training: 537\n",
            "Epoch: 0538 loss_train: 0.6052 acc_train: 0.8071 loss_val: 1.0531 acc_val: 0.6367 time: 1.7389s\n",
            "loss_val:1.0531386137008667, val_acc:0.6366666666666667, out_features:tensor([[-7.4290e+00, -7.4713e+00, -1.0297e-02,  ..., -7.1716e+00,\n",
            "         -7.4246e+00, -7.2656e+00],\n",
            "        [-2.3646e+00, -3.1321e+00, -3.4928e+00,  ..., -2.6226e+00,\n",
            "         -9.5574e-01, -1.0570e+00],\n",
            "        [-9.3637e+00, -1.0189e+01, -1.0143e+01,  ..., -3.1919e-04,\n",
            "         -9.2541e+00, -1.0286e+01],\n",
            "        ...,\n",
            "        [-2.3842e+00, -8.3604e-01, -2.0013e+00,  ..., -2.6629e+00,\n",
            "         -2.2456e+00, -2.3695e+00],\n",
            "        [-1.9459e+00, -1.9459e+00, -1.9459e+00,  ..., -1.9459e+00,\n",
            "         -1.9459e+00, -1.9459e+00],\n",
            "        [-5.9507e+00, -6.0168e+00, -2.6728e-02,  ..., -6.2292e+00,\n",
            "         -4.5516e+00, -5.0989e+00]], grad_fn=<LogSoftmaxBackward0>)\n",
            "Training: 538\n",
            "Epoch: 0539 loss_train: 0.7154 acc_train: 0.8214 loss_val: 1.0037 acc_val: 0.6733 time: 1.7409s\n",
            "loss_val:1.0037380456924438, val_acc:0.6733333333333333, out_features:tensor([[-2.7069, -2.3292, -0.7811,  ..., -1.8985, -2.4772, -2.6043],\n",
            "        [-1.9459, -1.9459, -1.9459,  ..., -1.9459, -1.9459, -1.9459],\n",
            "        [-5.3425, -4.6971, -5.2722,  ..., -0.0288, -5.5894, -5.7433],\n",
            "        ...,\n",
            "        [-6.6646, -0.0076, -6.7115,  ..., -6.5603, -6.6031, -6.6222],\n",
            "        [-0.0695, -4.5371, -5.1035,  ..., -3.6478, -4.6062, -4.9735],\n",
            "        [-2.6631, -2.7588, -0.5363,  ..., -2.4558, -2.8433, -2.6578]],\n",
            "       grad_fn=<LogSoftmaxBackward0>)\n",
            "Training: 539\n",
            "Epoch: 0540 loss_train: 0.5932 acc_train: 0.8500 loss_val: 0.9586 acc_val: 0.7100 time: 1.7311s\n",
            "loss_val:0.9586162567138672, val_acc:0.71, out_features:tensor([[-9.8136e+00, -9.6310e+00, -4.7136e-04,  ..., -9.4757e+00,\n",
            "         -9.6106e+00, -9.5762e+00],\n",
            "        [-1.9459e+00, -1.9459e+00, -1.9459e+00,  ..., -1.9459e+00,\n",
            "         -1.9459e+00, -1.9459e+00],\n",
            "        [-5.5509e+00, -5.3203e+00, -5.4118e+00,  ..., -2.3909e-02,\n",
            "         -5.6120e+00, -5.4626e+00],\n",
            "        ...,\n",
            "        [-6.4535e+00, -3.0476e-02, -6.6306e+00,  ..., -4.7103e+00,\n",
            "         -4.1624e+00, -6.6096e+00],\n",
            "        [-1.0760e+00, -2.2804e+00, -2.3245e+00,  ..., -2.0083e+00,\n",
            "         -1.8978e+00, -2.3269e+00],\n",
            "        [-6.6423e+00, -4.9832e+00, -1.6620e-02,  ..., -5.6437e+00,\n",
            "         -6.5292e+00, -6.4568e+00]], grad_fn=<LogSoftmaxBackward0>)\n",
            "Training: 540\n",
            "Epoch: 0541 loss_train: 0.6292 acc_train: 0.8214 loss_val: 1.0384 acc_val: 0.6567 time: 1.7441s\n",
            "loss_val:1.0383602380752563, val_acc:0.6566666666666666, out_features:tensor([[-5.0372, -5.3919, -0.0567,  ..., -4.8453, -4.2633, -5.1821],\n",
            "        [-1.9459, -1.9459, -1.9459,  ..., -1.9459, -1.9459, -1.9459],\n",
            "        [-2.7349, -2.7774, -2.3357,  ..., -0.4769, -3.0763, -2.9371],\n",
            "        ...,\n",
            "        [-2.7411, -0.6568, -2.1813,  ..., -2.0735, -2.7319, -2.8071],\n",
            "        [-0.0823, -5.0260, -5.1128,  ..., -3.5060, -3.6193, -5.2499],\n",
            "        [-1.9459, -1.9459, -1.9459,  ..., -1.9459, -1.9459, -1.9459]],\n",
            "       grad_fn=<LogSoftmaxBackward0>)\n",
            "Training: 541\n",
            "Epoch: 0542 loss_train: 0.6375 acc_train: 0.8286 loss_val: 1.0034 acc_val: 0.6533 time: 1.7372s\n",
            "loss_val:1.0033650398254395, val_acc:0.6533333333333333, out_features:tensor([[-3.6973, -3.8408, -0.3208,  ..., -2.6179, -3.4185, -2.4609],\n",
            "        [-3.1577, -4.4521, -4.9374,  ..., -3.5622, -0.4353, -1.3632],\n",
            "        [-2.1000, -2.7118, -3.3672,  ..., -0.5913, -2.3520, -2.4039],\n",
            "        ...,\n",
            "        [-4.6837, -0.0922, -5.0708,  ..., -4.9228, -2.9520, -4.8541],\n",
            "        [-0.1052, -3.6003, -4.6325,  ..., -3.7984, -4.0921, -4.3914],\n",
            "        [-2.8348, -2.4881, -0.4896,  ..., -3.0184, -2.3518, -3.0468]],\n",
            "       grad_fn=<LogSoftmaxBackward0>)\n",
            "Training: 542\n",
            "Epoch: 0543 loss_train: 0.5038 acc_train: 0.8714 loss_val: 0.9865 acc_val: 0.6800 time: 1.9023s\n",
            "loss_val:0.9865443110466003, val_acc:0.68, out_features:tensor([[-2.8515, -3.3637, -0.3764,  ..., -2.7349, -3.3950, -2.8493],\n",
            "        [-1.9459, -1.9459, -1.9459,  ..., -1.9459, -1.9459, -1.9459],\n",
            "        [-4.0694, -4.1037, -4.9294,  ..., -0.0637, -4.9312, -4.7503],\n",
            "        ...,\n",
            "        [-3.7699, -0.2321, -3.7408,  ..., -3.4822, -3.0047, -2.9319],\n",
            "        [-0.4474, -2.8605, -3.1805,  ..., -2.4682, -2.5068, -2.8989],\n",
            "        [-1.9459, -1.9459, -1.9459,  ..., -1.9459, -1.9459, -1.9459]],\n",
            "       grad_fn=<LogSoftmaxBackward0>)\n",
            "Training: 543\n",
            "Epoch: 0544 loss_train: 0.6267 acc_train: 0.8071 loss_val: 1.1511 acc_val: 0.6767 time: 1.9405s\n",
            "loss_val:1.1511130332946777, val_acc:0.6766666666666666, out_features:tensor([[-2.6195, -2.6013, -0.7933,  ..., -2.5667, -2.4394, -2.2993],\n",
            "        [-1.9459, -1.9459, -1.9459,  ..., -1.9459, -1.9459, -1.9459],\n",
            "        [-3.3536, -3.5865, -4.4404,  ..., -0.1429, -4.1424, -3.4215],\n",
            "        ...,\n",
            "        [-2.9866, -0.1482, -4.0236,  ..., -4.0792, -3.8228, -4.0711],\n",
            "        [-0.4152, -3.1269, -3.0331,  ..., -2.6268, -2.3908, -3.1322],\n",
            "        [-5.9862, -6.3097, -0.0191,  ..., -5.5041, -6.1251, -5.0505]],\n",
            "       grad_fn=<LogSoftmaxBackward0>)\n",
            "Training: 544\n",
            "Epoch: 0545 loss_train: 0.7077 acc_train: 0.8000 loss_val: 1.0883 acc_val: 0.6500 time: 1.7354s\n",
            "loss_val:1.088341474533081, val_acc:0.65, out_features:tensor([[-8.0174e+00, -7.8163e+00, -3.9336e-03,  ..., -7.0639e+00,\n",
            "         -7.9422e+00, -7.2819e+00],\n",
            "        [-1.9459e+00, -1.9459e+00, -1.9459e+00,  ..., -1.9459e+00,\n",
            "         -1.9459e+00, -1.9459e+00],\n",
            "        [-8.4519e+00, -7.5785e+00, -8.1959e+00,  ..., -1.7695e-03,\n",
            "         -8.4268e+00, -7.8488e+00],\n",
            "        ...,\n",
            "        [-3.7556e+00, -3.2524e-01, -3.6562e+00,  ..., -2.8854e+00,\n",
            "         -2.4763e+00, -2.7753e+00],\n",
            "        [-5.9908e-01, -2.3425e+00, -3.2235e+00,  ..., -2.6522e+00,\n",
            "         -2.8590e+00, -2.6291e+00],\n",
            "        [-2.6120e+00, -3.0428e+00, -4.8847e-01,  ..., -2.4176e+00,\n",
            "         -3.1522e+00, -3.3386e+00]], grad_fn=<LogSoftmaxBackward0>)\n",
            "Training: 545\n",
            "Epoch: 0546 loss_train: 0.6103 acc_train: 0.8357 loss_val: 0.9666 acc_val: 0.6833 time: 1.7508s\n",
            "loss_val:0.9665762186050415, val_acc:0.6833333333333333, out_features:tensor([[-4.8608e+00, -4.5652e+00, -8.5927e-02,  ..., -4.1757e+00,\n",
            "         -4.7823e+00, -4.6074e+00],\n",
            "        [-1.1572e+01, -1.1656e+01, -1.1166e+01,  ..., -1.0099e+01,\n",
            "         -6.5263e-02, -2.7631e+00],\n",
            "        [-8.1371e+00, -7.4302e+00, -8.2941e+00,  ..., -1.8105e-03,\n",
            "         -8.5789e+00, -7.9716e+00],\n",
            "        ...,\n",
            "        [-7.9051e+00, -2.1836e-03, -7.9671e+00,  ..., -8.0671e+00,\n",
            "         -7.3896e+00, -8.2402e+00],\n",
            "        [-7.2330e-03, -7.1626e+00, -7.6003e+00,  ..., -7.4725e+00,\n",
            "         -5.7256e+00, -7.2077e+00],\n",
            "        [-3.7936e+00, -3.5372e+00, -1.9527e-01,  ..., -3.8406e+00,\n",
            "         -2.8778e+00, -3.5177e+00]], grad_fn=<LogSoftmaxBackward0>)\n",
            "Training: 546\n",
            "Epoch: 0547 loss_train: 0.4785 acc_train: 0.8643 loss_val: 1.1164 acc_val: 0.6800 time: 1.7477s\n",
            "loss_val:1.1163642406463623, val_acc:0.68, out_features:tensor([[-7.0493, -7.5066, -0.0089,  ..., -5.1760, -7.4123, -7.4149],\n",
            "        [-5.3665, -5.6426, -4.0006,  ..., -5.6387, -0.2975, -1.9056],\n",
            "        [-2.9197, -3.2681, -3.5182,  ..., -0.2016, -3.6960, -3.9706],\n",
            "        ...,\n",
            "        [-3.2393, -0.3386, -3.2906,  ..., -3.6406, -2.0213, -3.6301],\n",
            "        [-0.3035, -3.7946, -4.2041,  ..., -4.0511, -1.8441, -3.7784],\n",
            "        [-4.1573, -5.6201, -0.0275,  ..., -6.3782, -6.1645, -6.2954]],\n",
            "       grad_fn=<LogSoftmaxBackward0>)\n",
            "Training: 547\n",
            "Epoch: 0548 loss_train: 0.5704 acc_train: 0.8143 loss_val: 0.9801 acc_val: 0.6800 time: 1.7359s\n",
            "loss_val:0.9800669550895691, val_acc:0.68, out_features:tensor([[-1.9459, -1.9459, -1.9459,  ..., -1.9459, -1.9459, -1.9459],\n",
            "        [-4.2867, -4.7704, -3.7363,  ..., -3.5226, -0.1733, -2.5850],\n",
            "        [-5.6649, -6.1137, -5.4036,  ..., -0.0166, -6.3570, -5.6939],\n",
            "        ...,\n",
            "        [-5.7874, -0.0340, -4.6206,  ..., -5.8371, -4.6407, -5.4493],\n",
            "        [-0.0239, -5.6620, -6.3437,  ..., -4.8097, -5.1743, -6.0220],\n",
            "        [-1.9459, -1.9459, -1.9459,  ..., -1.9459, -1.9459, -1.9459]],\n",
            "       grad_fn=<LogSoftmaxBackward0>)\n",
            "Training: 548\n",
            "Epoch: 0549 loss_train: 0.5899 acc_train: 0.8429 loss_val: 1.0246 acc_val: 0.6600 time: 1.7511s\n",
            "loss_val:1.0245628356933594, val_acc:0.66, out_features:tensor([[-6.6232, -6.5957, -0.0141,  ..., -5.6082, -5.9514, -6.3768],\n",
            "        [-2.0123, -4.2198, -3.9217,  ..., -2.9433, -0.5792, -1.5830],\n",
            "        [-2.4401, -2.4564, -2.8683,  ..., -0.5736, -2.9312, -2.7999],\n",
            "        ...,\n",
            "        [-4.6503, -0.0174, -6.3677,  ..., -6.5791, -6.4193, -6.5005],\n",
            "        [-0.9386, -2.2326, -2.5219,  ..., -2.4882, -1.8254, -2.1713],\n",
            "        [-2.4850, -2.9032, -0.6907,  ..., -2.3436, -2.6440, -3.2705]],\n",
            "       grad_fn=<LogSoftmaxBackward0>)\n",
            "Training: 549\n",
            "Epoch: 0550 loss_train: 0.5013 acc_train: 0.8714 loss_val: 1.0520 acc_val: 0.6867 time: 1.8839s\n",
            "loss_val:1.052004337310791, val_acc:0.6866666666666666, out_features:tensor([[-7.3548e+00, -7.4358e+00, -6.9707e-03,  ..., -6.8782e+00,\n",
            "         -7.4222e+00, -5.7526e+00],\n",
            "        [-1.9459e+00, -1.9459e+00, -1.9459e+00,  ..., -1.9459e+00,\n",
            "         -1.9459e+00, -1.9459e+00],\n",
            "        [-6.9083e+00, -5.8411e+00, -7.1971e+00,  ..., -7.4062e-03,\n",
            "         -7.0512e+00, -6.9462e+00],\n",
            "        ...,\n",
            "        [-1.9459e+00, -1.9459e+00, -1.9459e+00,  ..., -1.9459e+00,\n",
            "         -1.9459e+00, -1.9459e+00],\n",
            "        [-1.4325e+00, -2.2567e+00, -2.2254e+00,  ..., -1.6707e+00,\n",
            "         -2.0203e+00, -2.0916e+00],\n",
            "        [-5.4467e+00, -5.5858e+00, -5.5343e-02,  ..., -5.1703e+00,\n",
            "         -5.5508e+00, -5.4492e+00]], grad_fn=<LogSoftmaxBackward0>)\n",
            "Training: 550\n",
            "Epoch: 0551 loss_train: 0.7037 acc_train: 0.7500 loss_val: 1.0085 acc_val: 0.7033 time: 1.9742s\n",
            "loss_val:1.0084655284881592, val_acc:0.7033333333333334, out_features:tensor([[-5.5577, -5.3717, -0.0346,  ..., -5.0414, -5.2418, -5.4076],\n",
            "        [-2.3811, -3.0937, -3.7175,  ..., -4.1862, -0.4047, -1.9685],\n",
            "        [-3.2698, -3.4961, -2.7798,  ..., -0.2631, -3.4824, -3.5220],\n",
            "        ...,\n",
            "        [-4.6201, -0.0766, -4.5030,  ..., -3.8916, -4.6494, -4.2623],\n",
            "        [-0.3900, -3.7569, -3.8049,  ..., -2.5918, -2.0978, -3.5810],\n",
            "        [-1.4839, -3.1048, -0.9401,  ..., -3.3613, -3.2138, -1.6562]],\n",
            "       grad_fn=<LogSoftmaxBackward0>)\n",
            "Training: 551\n",
            "Epoch: 0552 loss_train: 0.7178 acc_train: 0.7786 loss_val: 1.0687 acc_val: 0.6400 time: 1.7531s\n",
            "loss_val:1.0687083005905151, val_acc:0.64, out_features:tensor([[-2.5932e+00, -2.4434e+00, -9.3452e-01,  ..., -2.0271e+00,\n",
            "         -2.7397e+00, -2.5179e+00],\n",
            "        [-2.1352e+00, -2.7166e+00, -2.1645e+00,  ..., -1.9554e+00,\n",
            "         -1.0798e+00, -1.7193e+00],\n",
            "        [-2.5506e+00, -2.8432e+00, -2.3484e+00,  ..., -5.2654e-01,\n",
            "         -3.0442e+00, -2.5592e+00],\n",
            "        ...,\n",
            "        [-1.9459e+00, -1.9459e+00, -1.9459e+00,  ..., -1.9459e+00,\n",
            "         -1.9459e+00, -1.9459e+00],\n",
            "        [-7.3088e-01, -2.6901e+00, -2.8586e+00,  ..., -1.8746e+00,\n",
            "         -2.2720e+00, -2.8589e+00],\n",
            "        [-9.8722e+00, -9.7732e+00, -2.7843e-04,  ..., -1.0001e+01,\n",
            "         -9.9587e+00, -1.0209e+01]], grad_fn=<LogSoftmaxBackward0>)\n",
            "Training: 552\n",
            "Epoch: 0553 loss_train: 0.5801 acc_train: 0.8500 loss_val: 1.0846 acc_val: 0.6767 time: 1.7528s\n",
            "loss_val:1.0846190452575684, val_acc:0.6766666666666666, out_features:tensor([[-8.3573, -8.3646, -0.0119,  ..., -7.6710, -8.3326, -5.6337],\n",
            "        [-3.2437, -3.4410, -2.6171,  ..., -3.0940, -0.4420, -1.9342],\n",
            "        [-2.0525, -2.9755, -2.4991,  ..., -0.6994, -2.7482, -2.2397],\n",
            "        ...,\n",
            "        [-1.9459, -1.9459, -1.9459,  ..., -1.9459, -1.9459, -1.9459],\n",
            "        [-0.0969, -4.8198, -4.7988,  ..., -4.9347, -2.9747, -4.4846],\n",
            "        [-3.9197, -2.9378, -0.1717,  ..., -3.8162, -3.4934, -4.2034]],\n",
            "       grad_fn=<LogSoftmaxBackward0>)\n",
            "Training: 553\n",
            "Epoch: 0554 loss_train: 0.6273 acc_train: 0.8143 loss_val: 1.0006 acc_val: 0.6967 time: 1.7367s\n",
            "loss_val:1.0006399154663086, val_acc:0.6966666666666667, out_features:tensor([[-4.3370, -4.3863, -0.1019,  ..., -4.5027, -4.2459, -3.4132],\n",
            "        [-1.9245, -3.4947, -2.8143,  ..., -1.5567, -0.9971, -1.8660],\n",
            "        [-5.2008, -4.5646, -4.4864,  ..., -0.0424, -5.2583, -5.6041],\n",
            "        ...,\n",
            "        [-4.7468, -0.0570, -4.3348,  ..., -4.0424, -5.1019, -5.4081],\n",
            "        [-0.3476, -3.6118, -4.2488,  ..., -3.5077, -1.9283, -2.8523],\n",
            "        [-3.1081, -3.6709, -0.1499,  ..., -3.6800, -4.2622, -4.3511]],\n",
            "       grad_fn=<LogSoftmaxBackward0>)\n",
            "Training: 554\n",
            "Epoch: 0555 loss_train: 0.7084 acc_train: 0.7571 loss_val: 1.1208 acc_val: 0.6700 time: 1.7253s\n",
            "loss_val:1.120813250541687, val_acc:0.67, out_features:tensor([[-8.2282e+00, -8.4442e+00, -2.6024e-03,  ..., -7.8574e+00,\n",
            "         -8.2893e+00, -8.0176e+00],\n",
            "        [-8.8739e+00, -8.9072e+00, -8.9980e+00,  ..., -7.0565e+00,\n",
            "         -4.5353e-01, -1.0127e+00],\n",
            "        [-1.0544e+01, -9.3044e+00, -8.8290e+00,  ..., -3.3874e-04,\n",
            "         -1.0480e+01, -1.0654e+01],\n",
            "        ...,\n",
            "        [-3.9675e+00, -1.3807e-01, -5.0212e+00,  ..., -2.7915e+00,\n",
            "         -3.5765e+00, -4.8313e+00],\n",
            "        [-9.7629e-02, -4.0889e+00, -4.6724e+00,  ..., -3.8169e+00,\n",
            "         -3.7964e+00, -4.4070e+00],\n",
            "        [-4.3034e+00, -4.3098e+00, -2.5252e-01,  ..., -4.6038e+00,\n",
            "         -4.0792e+00, -4.2243e+00]], grad_fn=<LogSoftmaxBackward0>)\n",
            "Training: 555\n",
            "Epoch: 0556 loss_train: 0.6474 acc_train: 0.8000 loss_val: 1.0517 acc_val: 0.6500 time: 1.7509s\n",
            "loss_val:1.0516678094863892, val_acc:0.65, out_features:tensor([[-5.8236e+00, -5.7755e+00, -1.5267e-02,  ..., -6.0690e+00,\n",
            "         -6.4359e+00, -6.2607e+00],\n",
            "        [-1.9605e+00, -3.6270e+00, -2.6355e+00,  ..., -2.2411e+00,\n",
            "         -1.0136e+00, -1.3102e+00],\n",
            "        [-4.7612e+00, -5.3022e+00, -5.3059e+00,  ..., -4.4076e-02,\n",
            "         -4.9489e+00, -4.3521e+00],\n",
            "        ...,\n",
            "        [-4.1357e+00, -8.7366e-02, -4.6459e+00,  ..., -4.8234e+00,\n",
            "         -3.3917e+00, -4.7021e+00],\n",
            "        [-1.9459e+00, -1.9459e+00, -1.9459e+00,  ..., -1.9459e+00,\n",
            "         -1.9459e+00, -1.9459e+00],\n",
            "        [-1.0081e+01, -1.0365e+01, -1.2802e-04,  ..., -1.1509e+01,\n",
            "         -1.0719e+01, -1.1315e+01]], grad_fn=<LogSoftmaxBackward0>)\n",
            "Training: 556\n",
            "Epoch: 0557 loss_train: 0.6737 acc_train: 0.8000 loss_val: 0.9448 acc_val: 0.7033 time: 1.8767s\n",
            "loss_val:0.9448468089103699, val_acc:0.7033333333333334, out_features:tensor([[-4.8234, -4.9849, -0.0742,  ..., -3.9076, -4.7647, -4.5794],\n",
            "        [-1.9459, -1.9459, -1.9459,  ..., -1.9459, -1.9459, -1.9459],\n",
            "        [-2.4363, -1.8217, -2.2625,  ..., -0.7566, -2.9443, -2.9491],\n",
            "        ...,\n",
            "        [-2.9958, -0.1889, -3.9326,  ..., -3.9501, -2.9745, -4.0487],\n",
            "        [-0.9396, -2.4742, -2.3698,  ..., -2.2781, -1.9796, -2.1081],\n",
            "        [-2.8590, -4.5383, -0.1557,  ..., -4.3460, -3.9304, -3.6824]],\n",
            "       grad_fn=<LogSoftmaxBackward0>)\n",
            "Training: 557\n",
            "Epoch: 0558 loss_train: 0.6652 acc_train: 0.7857 loss_val: 1.0242 acc_val: 0.6933 time: 1.9534s\n",
            "loss_val:1.0242019891738892, val_acc:0.6933333333333334, out_features:tensor([[-3.4765e+00, -3.7077e+00, -3.3498e-01,  ..., -3.2329e+00,\n",
            "         -3.6155e+00, -2.6802e+00],\n",
            "        [-1.9459e+00, -1.9459e+00, -1.9459e+00,  ..., -1.9459e+00,\n",
            "         -1.9459e+00, -1.9459e+00],\n",
            "        [-5.9955e+00, -5.9355e+00, -4.5852e+00,  ..., -2.2877e-02,\n",
            "         -6.0984e+00, -6.1291e+00],\n",
            "        ...,\n",
            "        [-2.4479e+00, -1.1800e+00, -2.5320e+00,  ..., -3.1060e+00,\n",
            "         -1.0781e+00, -2.5035e+00],\n",
            "        [-1.1586e+00, -2.3607e+00, -2.4213e+00,  ..., -2.1139e+00,\n",
            "         -2.2606e+00, -2.2924e+00],\n",
            "        [-9.9078e+00, -8.7960e+00, -1.2113e-03,  ..., -9.3101e+00,\n",
            "         -9.8713e+00, -9.9222e+00]], grad_fn=<LogSoftmaxBackward0>)\n",
            "Training: 558\n",
            "Epoch: 0559 loss_train: 0.6001 acc_train: 0.8500 loss_val: 1.0039 acc_val: 0.6667 time: 1.7492s\n",
            "loss_val:1.0039482116699219, val_acc:0.6666666666666666, out_features:tensor([[-3.2327, -3.0460, -0.4000,  ..., -2.5104, -3.0280, -2.9101],\n",
            "        [-1.9459, -1.9459, -1.9459,  ..., -1.9459, -1.9459, -1.9459],\n",
            "        [-5.5342, -5.8533, -5.3839,  ..., -0.0187, -5.8240, -5.9705],\n",
            "        ...,\n",
            "        [-2.5374, -0.5388, -2.7857,  ..., -2.7925, -2.0750, -3.0345],\n",
            "        [-0.4445, -2.8179, -3.3246,  ..., -2.6438, -2.4340, -2.9911],\n",
            "        [-6.5159, -5.4503, -0.0148,  ..., -6.9262, -5.1120, -6.9476]],\n",
            "       grad_fn=<LogSoftmaxBackward0>)\n",
            "Training: 559\n",
            "Epoch: 0560 loss_train: 0.6680 acc_train: 0.8000 loss_val: 1.0825 acc_val: 0.6033 time: 1.7317s\n",
            "loss_val:1.0825220346450806, val_acc:0.6033333333333334, out_features:tensor([[-4.2974, -4.8339, -0.0596,  ..., -4.2110, -4.8585, -4.9796],\n",
            "        [-2.0889, -3.2943, -3.2693,  ..., -1.3291, -1.0416, -1.9402],\n",
            "        [-5.3861, -5.9496, -6.3074,  ..., -0.0179, -6.1492, -5.2850],\n",
            "        ...,\n",
            "        [-2.9820, -0.4420, -3.1660,  ..., -2.2364, -2.5233, -3.3639],\n",
            "        [-1.2981, -2.7406, -2.1261,  ..., -1.4014, -2.1485, -2.2001],\n",
            "        [-6.9934, -7.0154, -0.0092,  ..., -7.0767, -6.4827, -6.9740]],\n",
            "       grad_fn=<LogSoftmaxBackward0>)\n",
            "Training: 560\n",
            "Epoch: 0561 loss_train: 0.5930 acc_train: 0.8429 loss_val: 0.9320 acc_val: 0.6867 time: 1.7477s\n",
            "loss_val:0.9320111274719238, val_acc:0.6866666666666666, out_features:tensor([[-5.2793e+00, -5.3517e+00, -4.1833e-02,  ..., -5.2994e+00,\n",
            "         -5.1338e+00, -5.3142e+00],\n",
            "        [-2.5022e+00, -2.2677e+00, -2.5556e+00,  ..., -1.4068e+00,\n",
            "         -1.4313e+00, -1.5865e+00],\n",
            "        [-9.5100e+00, -8.2018e+00, -8.5862e+00,  ..., -7.1679e-04,\n",
            "         -9.5628e+00, -9.7011e+00],\n",
            "        ...,\n",
            "        [-2.5170e+00, -7.4568e-01, -3.4493e+00,  ..., -1.3018e+00,\n",
            "         -2.6483e+00, -3.2518e+00],\n",
            "        [-1.1874e-01, -4.9053e+00, -5.1251e+00,  ..., -2.6125e+00,\n",
            "         -4.2062e+00, -5.1777e+00],\n",
            "        [-8.2760e+00, -7.6655e+00, -2.5954e-03,  ..., -8.4157e+00,\n",
            "         -6.8778e+00, -8.3137e+00]], grad_fn=<LogSoftmaxBackward0>)\n",
            "Training: 561\n",
            "Epoch: 0562 loss_train: 0.5265 acc_train: 0.8714 loss_val: 1.0257 acc_val: 0.6733 time: 1.7443s\n",
            "loss_val:1.0256651639938354, val_acc:0.6733333333333333, out_features:tensor([[-9.6977e+00, -9.5242e+00, -5.5774e-04,  ..., -9.6273e+00,\n",
            "         -9.6356e+00, -9.5563e+00],\n",
            "        [-1.9459e+00, -1.9459e+00, -1.9459e+00,  ..., -1.9459e+00,\n",
            "         -1.9459e+00, -1.9459e+00],\n",
            "        [-2.0853e+00, -2.9221e+00, -2.5581e+00,  ..., -6.1428e-01,\n",
            "         -2.7031e+00, -2.4090e+00],\n",
            "        ...,\n",
            "        [-2.8656e+00, -3.1662e-01, -3.8589e+00,  ..., -2.7592e+00,\n",
            "         -3.1429e+00, -2.9382e+00],\n",
            "        [-1.6668e-01, -4.1172e+00, -4.2513e+00,  ..., -3.1841e+00,\n",
            "         -2.8899e+00, -4.4582e+00],\n",
            "        [-7.2469e+00, -6.3910e+00, -1.1908e-02,  ..., -4.9636e+00,\n",
            "         -6.9265e+00, -7.2606e+00]], grad_fn=<LogSoftmaxBackward0>)\n",
            "Training: 562\n",
            "Epoch: 0563 loss_train: 0.6208 acc_train: 0.8000 loss_val: 1.0298 acc_val: 0.6833 time: 1.7380s\n",
            "loss_val:1.029808521270752, val_acc:0.6833333333333333, out_features:tensor([[-4.7636, -4.8818, -0.0747,  ..., -4.0514, -4.3588, -4.2441],\n",
            "        [-1.5490, -2.6295, -2.7312,  ..., -2.2121, -0.8522, -2.5888],\n",
            "        [-6.3110, -5.6758, -6.9791,  ..., -0.0142, -5.0666, -6.9803],\n",
            "        ...,\n",
            "        [-2.7105, -0.5072, -3.1893,  ..., -2.2474, -2.3733, -3.0711],\n",
            "        [-0.6328, -2.3602, -2.9428,  ..., -2.5304, -2.1347, -2.6170],\n",
            "        [-2.1697, -2.0247, -2.0582,  ..., -2.3181, -1.9394, -1.4937]],\n",
            "       grad_fn=<LogSoftmaxBackward0>)\n",
            "Training: 563\n",
            "Epoch: 0564 loss_train: 0.7233 acc_train: 0.7786 loss_val: 1.0039 acc_val: 0.6900 time: 1.8818s\n",
            "loss_val:1.0039153099060059, val_acc:0.69, out_features:tensor([[-7.0537, -7.0950, -0.0116,  ..., -5.9160, -7.0556, -6.3741],\n",
            "        [-1.9459, -1.9459, -1.9459,  ..., -1.9459, -1.9459, -1.9459],\n",
            "        [-5.2090, -5.0438, -6.3685,  ..., -0.0238, -5.1688, -5.9105],\n",
            "        ...,\n",
            "        [-2.4223, -1.7758, -2.0498,  ..., -2.4070, -1.4998, -1.4507],\n",
            "        [-0.2042, -3.3660, -4.3768,  ..., -3.5506, -2.5106, -4.3978],\n",
            "        [-1.9459, -1.9459, -1.9459,  ..., -1.9459, -1.9459, -1.9459]],\n",
            "       grad_fn=<LogSoftmaxBackward0>)\n",
            "Training: 564\n",
            "Epoch: 0565 loss_train: 0.5816 acc_train: 0.8357 loss_val: 1.0699 acc_val: 0.6500 time: 1.9669s\n",
            "loss_val:1.069913387298584, val_acc:0.65, out_features:tensor([[-7.5354e+00, -7.3556e+00, -3.7121e-03,  ..., -7.5496e+00,\n",
            "         -7.6120e+00, -7.7102e+00],\n",
            "        [-2.5598e+00, -2.1904e+00, -3.0442e+00,  ..., -1.3011e+00,\n",
            "         -1.0952e+00, -2.6175e+00],\n",
            "        [-2.7150e+00, -2.9765e+00, -4.4950e+00,  ..., -1.8923e-01,\n",
            "         -3.9456e+00, -4.2344e+00],\n",
            "        ...,\n",
            "        [-3.2835e+00, -2.3100e-01, -3.4802e+00,  ..., -3.3808e+00,\n",
            "         -2.8690e+00, -3.5804e+00],\n",
            "        [-1.1170e+00, -2.0069e+00, -2.2792e+00,  ..., -1.6029e+00,\n",
            "         -2.3651e+00, -2.6619e+00],\n",
            "        [-2.8305e+00, -2.6454e+00, -3.1122e-01,  ..., -3.0756e+00,\n",
            "         -3.6536e+00, -3.7840e+00]], grad_fn=<LogSoftmaxBackward0>)\n",
            "Training: 565\n",
            "Epoch: 0566 loss_train: 0.7010 acc_train: 0.8143 loss_val: 1.0974 acc_val: 0.6600 time: 1.7507s\n",
            "loss_val:1.0974358320236206, val_acc:0.66, out_features:tensor([[-3.4748, -3.7832, -0.2543,  ..., -2.5188, -3.8269, -3.1923],\n",
            "        [-2.2201, -2.7060, -2.5511,  ..., -1.1279, -1.2214, -2.4269],\n",
            "        [-3.9605, -3.0157, -3.6579,  ..., -0.1752, -3.7596, -3.6590],\n",
            "        ...,\n",
            "        [-3.3972, -0.5001, -3.1295,  ..., -2.8369, -2.7050, -1.8796],\n",
            "        [-0.3833, -2.7995, -3.4778,  ..., -2.8693, -2.3899, -3.1731],\n",
            "        [-1.9933, -2.3411, -1.4189,  ..., -2.4021, -1.3732, -2.5184]],\n",
            "       grad_fn=<LogSoftmaxBackward0>)\n",
            "Training: 566\n",
            "Epoch: 0567 loss_train: 0.6638 acc_train: 0.7929 loss_val: 0.9720 acc_val: 0.7033 time: 1.7588s\n",
            "loss_val:0.9720252752304077, val_acc:0.7033333333333334, out_features:tensor([[-4.1323, -3.7080, -0.2095,  ..., -4.2262, -3.6755, -3.9577],\n",
            "        [-1.9459, -1.9459, -1.9459,  ..., -1.9459, -1.9459, -1.9459],\n",
            "        [-2.8154, -3.4044, -3.5413,  ..., -0.2737, -2.8977, -3.5151],\n",
            "        ...,\n",
            "        [-1.8398, -1.2210, -2.5082,  ..., -2.0103, -1.4965, -2.9541],\n",
            "        [-0.9920, -2.3842, -2.7550,  ..., -1.3742, -2.3062, -2.8348],\n",
            "        [-2.2316, -2.5642, -1.2856,  ..., -2.8396, -1.5016, -2.2194]],\n",
            "       grad_fn=<LogSoftmaxBackward0>)\n",
            "Training: 567\n",
            "Epoch: 0568 loss_train: 0.6173 acc_train: 0.8000 loss_val: 0.9957 acc_val: 0.7267 time: 1.7433s\n",
            "loss_val:0.9956660866737366, val_acc:0.7266666666666667, out_features:tensor([[-9.6881e+00, -9.5510e+00, -5.1807e-04,  ..., -9.5636e+00,\n",
            "         -9.5389e+00, -9.0181e+00],\n",
            "        [-1.9459e+00, -1.9459e+00, -1.9459e+00,  ..., -1.9459e+00,\n",
            "         -1.9459e+00, -1.9459e+00],\n",
            "        [-1.9459e+00, -1.9459e+00, -1.9459e+00,  ..., -1.9459e+00,\n",
            "         -1.9459e+00, -1.9459e+00],\n",
            "        ...,\n",
            "        [-2.5514e+00, -6.5040e-01, -2.9394e+00,  ..., -2.4762e+00,\n",
            "         -2.2042e+00, -2.9209e+00],\n",
            "        [-5.5672e-03, -8.5830e+00, -8.7225e+00,  ..., -5.7042e+00,\n",
            "         -6.5002e+00, -8.5428e+00],\n",
            "        [-3.9457e+00, -3.7148e+00, -1.8087e-01,  ..., -2.8971e+00,\n",
            "         -3.7736e+00, -3.5998e+00]], grad_fn=<LogSoftmaxBackward0>)\n",
            "Training: 568\n",
            "Epoch: 0569 loss_train: 0.6222 acc_train: 0.8429 loss_val: 1.0385 acc_val: 0.6833 time: 1.7514s\n",
            "loss_val:1.0385489463806152, val_acc:0.6833333333333333, out_features:tensor([[-5.8814e+00, -5.6670e+00, -2.9990e-02,  ..., -4.2611e+00,\n",
            "         -5.9658e+00, -5.8673e+00],\n",
            "        [-6.7658e+00, -7.8651e+00, -8.2799e+00,  ..., -8.1726e+00,\n",
            "         -3.2908e-03, -6.9596e+00],\n",
            "        [-3.7876e+00, -4.3690e+00, -4.7205e+00,  ..., -8.4876e-02,\n",
            "         -4.1671e+00, -4.2959e+00],\n",
            "        ...,\n",
            "        [-3.5921e+00, -2.6619e-01, -4.0124e+00,  ..., -2.3481e+00,\n",
            "         -3.2494e+00, -3.4584e+00],\n",
            "        [-1.7270e-02, -5.8554e+00, -6.0654e+00,  ..., -5.4124e+00,\n",
            "         -5.8045e+00, -6.1623e+00],\n",
            "        [-5.0969e+00, -4.8828e+00, -3.6045e-02,  ..., -5.4312e+00,\n",
            "         -5.5236e+00, -4.6591e+00]], grad_fn=<LogSoftmaxBackward0>)\n",
            "Training: 569\n",
            "Epoch: 0570 loss_train: 0.5857 acc_train: 0.8643 loss_val: 1.0932 acc_val: 0.6233 time: 1.7543s\n",
            "loss_val:1.0932021141052246, val_acc:0.6233333333333333, out_features:tensor([[-4.9417, -5.4902, -0.0429,  ..., -5.4499, -5.4917, -4.5516],\n",
            "        [-1.6632, -3.3786, -3.2855,  ..., -1.4110, -0.9073, -2.8070],\n",
            "        [-3.3474, -2.8271, -3.8226,  ..., -0.2272, -3.6259, -3.2105],\n",
            "        ...,\n",
            "        [-4.1451, -0.0943, -4.8224,  ..., -4.3405, -3.7625, -3.8172],\n",
            "        [-1.1123, -2.5048, -2.1135,  ..., -1.6479, -2.2522, -2.4911],\n",
            "        [-3.7837, -3.3639, -0.2033,  ..., -3.3372, -3.5108, -3.8902]],\n",
            "       grad_fn=<LogSoftmaxBackward0>)\n",
            "Training: 570\n",
            "Epoch: 0571 loss_train: 0.6498 acc_train: 0.8214 loss_val: 0.9735 acc_val: 0.6600 time: 1.8972s\n",
            "loss_val:0.9735133647918701, val_acc:0.66, out_features:tensor([[-1.9459e+00, -1.9459e+00, -1.9459e+00,  ..., -1.9459e+00,\n",
            "         -1.9459e+00, -1.9459e+00],\n",
            "        [-1.9459e+00, -1.9459e+00, -1.9459e+00,  ..., -1.9459e+00,\n",
            "         -1.9459e+00, -1.9459e+00],\n",
            "        [-8.7497e+00, -7.8011e+00, -8.8257e+00,  ..., -1.2968e-03,\n",
            "         -8.6545e+00, -8.3856e+00],\n",
            "        ...,\n",
            "        [-1.9459e+00, -1.9459e+00, -1.9459e+00,  ..., -1.9459e+00,\n",
            "         -1.9459e+00, -1.9459e+00],\n",
            "        [-1.9459e+00, -1.9459e+00, -1.9459e+00,  ..., -1.9459e+00,\n",
            "         -1.9459e+00, -1.9459e+00],\n",
            "        [-4.2274e+00, -3.2410e+00, -1.3537e-01,  ..., -3.6209e+00,\n",
            "         -3.9243e+00, -4.4062e+00]], grad_fn=<LogSoftmaxBackward0>)\n",
            "Training: 571\n",
            "Epoch: 0572 loss_train: 0.6048 acc_train: 0.8286 loss_val: 1.0478 acc_val: 0.6800 time: 2.0281s\n",
            "loss_val:1.0478054285049438, val_acc:0.68, out_features:tensor([[-1.0555e+01, -1.0501e+01, -1.9834e-04,  ..., -1.0442e+01,\n",
            "         -1.0154e+01, -1.0587e+01],\n",
            "        [-6.8564e+00, -6.8956e+00, -6.7120e+00,  ..., -6.9887e+00,\n",
            "         -1.0746e-02, -5.2006e+00],\n",
            "        [-3.6816e+00, -3.9070e+00, -3.3138e+00,  ..., -2.0560e-01,\n",
            "         -3.9646e+00, -2.9737e+00],\n",
            "        ...,\n",
            "        [-1.9459e+00, -1.9459e+00, -1.9459e+00,  ..., -1.9459e+00,\n",
            "         -1.9459e+00, -1.9459e+00],\n",
            "        [-5.1615e-02, -5.8801e+00, -6.0084e+00,  ..., -4.5670e+00,\n",
            "         -4.0586e+00, -4.2225e+00],\n",
            "        [-1.8450e+00, -3.4593e+00, -5.5212e-01,  ..., -2.6055e+00,\n",
            "         -2.5043e+00, -3.1878e+00]], grad_fn=<LogSoftmaxBackward0>)\n",
            "Training: 572\n",
            "Epoch: 0573 loss_train: 0.7115 acc_train: 0.8071 loss_val: 1.0055 acc_val: 0.6633 time: 1.7510s\n",
            "loss_val:1.005526065826416, val_acc:0.6633333333333333, out_features:tensor([[-2.8523, -2.9129, -0.5212,  ..., -2.7278, -2.9761, -2.2388],\n",
            "        [-1.9459, -1.9459, -1.9459,  ..., -1.9459, -1.9459, -1.9459],\n",
            "        [-1.9459, -1.9459, -1.9459,  ..., -1.9459, -1.9459, -1.9459],\n",
            "        ...,\n",
            "        [-1.9459, -1.9459, -1.9459,  ..., -1.9459, -1.9459, -1.9459],\n",
            "        [-0.5024, -2.8717, -3.6691,  ..., -1.5680, -3.3814, -3.2009],\n",
            "        [-5.8280, -5.6624, -0.0172,  ..., -5.9841, -6.0845, -6.1434]],\n",
            "       grad_fn=<LogSoftmaxBackward0>)\n",
            "Training: 573\n",
            "Epoch: 0574 loss_train: 0.6354 acc_train: 0.8143 loss_val: 1.0631 acc_val: 0.6500 time: 1.7561s\n",
            "loss_val:1.0630927085876465, val_acc:0.65, out_features:tensor([[-6.0165e+00, -6.0501e+00, -2.1812e-02,  ..., -5.2362e+00,\n",
            "         -6.1101e+00, -5.6359e+00],\n",
            "        [-2.9208e+00, -3.5190e+00, -3.6988e+00,  ..., -2.3444e+00,\n",
            "         -7.6659e-01, -1.1726e+00],\n",
            "        [-4.2809e+00, -3.6925e+00, -4.7310e+00,  ..., -8.9102e-02,\n",
            "         -4.0851e+00, -4.4147e+00],\n",
            "        ...,\n",
            "        [-7.8422e+00, -2.6891e-03, -8.4757e+00,  ..., -6.7169e+00,\n",
            "         -7.8442e+00, -8.1853e+00],\n",
            "        [-9.7497e-02, -4.9564e+00, -5.2775e+00,  ..., -2.8741e+00,\n",
            "         -4.4999e+00, -4.9382e+00],\n",
            "        [-4.5713e+00, -5.7846e+00, -4.6380e-02,  ..., -4.5788e+00,\n",
            "         -4.6552e+00, -4.7101e+00]], grad_fn=<LogSoftmaxBackward0>)\n",
            "Training: 574\n",
            "Epoch: 0575 loss_train: 0.5496 acc_train: 0.8429 loss_val: 1.1079 acc_val: 0.6833 time: 1.7526s\n",
            "loss_val:1.107853651046753, val_acc:0.6833333333333333, out_features:tensor([[-7.5984e+00, -7.6112e+00, -6.4256e-03,  ..., -5.7395e+00,\n",
            "         -7.5424e+00, -7.5814e+00],\n",
            "        [-3.4556e+00, -6.5336e+00, -6.8562e+00,  ..., -4.0840e+00,\n",
            "         -6.5880e-02, -4.4393e+00],\n",
            "        [-6.6827e+00, -6.0401e+00, -5.9767e+00,  ..., -1.0720e-02,\n",
            "         -6.3669e+00, -6.3838e+00],\n",
            "        ...,\n",
            "        [-2.9636e+00, -5.6270e-01, -3.1903e+00,  ..., -1.7268e+00,\n",
            "         -2.7875e+00, -3.0988e+00],\n",
            "        [-4.6446e-01, -3.4856e+00, -3.7052e+00,  ..., -2.4642e+00,\n",
            "         -2.2187e+00, -2.7871e+00],\n",
            "        [-4.6639e+00, -5.2223e+00, -3.2107e-02,  ..., -5.7037e+00,\n",
            "         -4.9979e+00, -5.7768e+00]], grad_fn=<LogSoftmaxBackward0>)\n",
            "Training: 575\n",
            "Epoch: 0576 loss_train: 0.5960 acc_train: 0.8286 loss_val: 1.0871 acc_val: 0.6400 time: 1.7524s\n",
            "loss_val:1.0870951414108276, val_acc:0.64, out_features:tensor([[-5.8810, -6.0124, -0.0506,  ..., -4.2308, -6.0302, -5.4126],\n",
            "        [-3.6223, -3.6806, -2.9040,  ..., -3.4145, -0.3604, -1.9952],\n",
            "        [-2.3215, -2.8743, -2.6561,  ..., -0.5971, -2.8174, -2.6028],\n",
            "        ...,\n",
            "        [-6.6138, -0.0152, -7.1119,  ..., -6.2178, -4.7013, -6.8564],\n",
            "        [-0.5028, -3.0969, -3.2504,  ..., -2.1871, -2.2024, -2.8287],\n",
            "        [-6.0086, -6.1573, -0.0169,  ..., -5.0536, -6.2624, -6.3382]],\n",
            "       grad_fn=<LogSoftmaxBackward0>)\n",
            "Training: 576\n",
            "Epoch: 0577 loss_train: 0.5484 acc_train: 0.8500 loss_val: 1.1350 acc_val: 0.6433 time: 1.7509s\n",
            "loss_val:1.1350103616714478, val_acc:0.6433333333333333, out_features:tensor([[-9.4141e+00, -9.3659e+00, -8.1863e-04,  ..., -8.9976e+00,\n",
            "         -9.0072e+00, -8.9070e+00],\n",
            "        [-2.0480e+00, -2.9930e+00, -2.8158e+00,  ..., -2.6123e+00,\n",
            "         -8.9158e-01, -1.4992e+00],\n",
            "        [-6.4054e+00, -6.0863e+00, -5.1562e+00,  ..., -1.6828e-02,\n",
            "         -6.3293e+00, -6.3896e+00],\n",
            "        ...,\n",
            "        [-1.9459e+00, -1.9459e+00, -1.9459e+00,  ..., -1.9459e+00,\n",
            "         -1.9459e+00, -1.9459e+00],\n",
            "        [-1.3480e+00, -2.1420e+00, -2.2558e+00,  ..., -1.9774e+00,\n",
            "         -2.1302e+00, -2.0873e+00],\n",
            "        [-4.1368e+00, -2.1282e+00, -2.3701e-01,  ..., -3.4764e+00,\n",
            "         -4.3221e+00, -4.2902e+00]], grad_fn=<LogSoftmaxBackward0>)\n",
            "Training: 577\n",
            "Epoch: 0578 loss_train: 0.6616 acc_train: 0.8000 loss_val: 1.0850 acc_val: 0.6400 time: 1.8712s\n",
            "loss_val:1.08501398563385, val_acc:0.64, out_features:tensor([[-5.7982e+00, -5.6547e+00, -2.7295e-02,  ..., -5.4203e+00,\n",
            "         -5.7992e+00, -4.7856e+00],\n",
            "        [-6.2921e+00, -6.7657e+00, -6.8249e+00,  ..., -8.6454e-01,\n",
            "         -8.0230e-01, -2.0772e+00],\n",
            "        [-1.0657e+01, -9.1274e+00, -1.0720e+01,  ..., -2.5353e-04,\n",
            "         -1.0815e+01, -1.0811e+01],\n",
            "        ...,\n",
            "        [-5.6453e+00, -2.5942e-02, -6.0618e+00,  ..., -5.6806e+00,\n",
            "         -4.4012e+00, -6.1441e+00],\n",
            "        [-5.7920e-01, -2.7076e+00, -3.3948e+00,  ..., -1.8780e+00,\n",
            "         -2.3303e+00, -3.1628e+00],\n",
            "        [-7.9306e+00, -5.5088e+00, -6.1672e-03,  ..., -7.7353e+00,\n",
            "         -7.3266e+00, -8.0083e+00]], grad_fn=<LogSoftmaxBackward0>)\n",
            "Training: 578\n",
            "Epoch: 0579 loss_train: 0.6867 acc_train: 0.7929 loss_val: 1.0169 acc_val: 0.7200 time: 2.0024s\n",
            "loss_val:1.016912579536438, val_acc:0.72, out_features:tensor([[-6.9429, -6.1735, -0.0080,  ..., -6.6810, -6.7136, -6.4670],\n",
            "        [-2.4794, -6.5193, -6.5352,  ..., -5.0261, -0.1153, -4.2499],\n",
            "        [-1.9459, -1.9459, -1.9459,  ..., -1.9459, -1.9459, -1.9459],\n",
            "        ...,\n",
            "        [-3.6688, -0.1039, -4.8320,  ..., -4.2937, -3.5339, -4.1133],\n",
            "        [-0.0385, -5.7230, -5.9108,  ..., -5.1481, -3.9051, -5.8911],\n",
            "        [-5.5973, -6.2792, -0.0188,  ..., -4.9908, -6.3168, -6.2382]],\n",
            "       grad_fn=<LogSoftmaxBackward0>)\n",
            "Training: 579\n",
            "Epoch: 0580 loss_train: 0.6272 acc_train: 0.7929 loss_val: 1.0671 acc_val: 0.6400 time: 1.7606s\n",
            "loss_val:1.0671335458755493, val_acc:0.64, out_features:tensor([[-5.6740e+00, -5.3621e+00, -7.8412e-02,  ..., -3.6983e+00,\n",
            "         -5.6627e+00, -5.6338e+00],\n",
            "        [-3.0474e+00, -6.9358e+00, -7.0768e+00,  ..., -2.6254e+00,\n",
            "         -1.5711e-01, -3.7797e+00],\n",
            "        [-7.6531e+00, -7.2468e+00, -7.2505e+00,  ..., -3.2473e-03,\n",
            "         -7.6952e+00, -7.5344e+00],\n",
            "        ...,\n",
            "        [-2.9789e+00, -4.0125e-01, -3.3435e+00,  ..., -2.0386e+00,\n",
            "         -2.9622e+00, -3.2804e+00],\n",
            "        [-7.3581e-01, -2.3959e+00, -3.1708e+00,  ..., -1.5746e+00,\n",
            "         -2.3330e+00, -3.0719e+00],\n",
            "        [-1.9459e+00, -1.9459e+00, -1.9459e+00,  ..., -1.9459e+00,\n",
            "         -1.9459e+00, -1.9459e+00]], grad_fn=<LogSoftmaxBackward0>)\n",
            "Training: 580\n",
            "Epoch: 0581 loss_train: 0.6819 acc_train: 0.8000 loss_val: 0.9271 acc_val: 0.6967 time: 1.7578s\n",
            "loss_val:0.9271026849746704, val_acc:0.6966666666666667, out_features:tensor([[-4.3715e+00, -4.1327e+00, -1.4043e-01,  ..., -3.5799e+00,\n",
            "         -4.0950e+00, -3.2737e+00],\n",
            "        [-1.9459e+00, -1.9459e+00, -1.9459e+00,  ..., -1.9459e+00,\n",
            "         -1.9459e+00, -1.9459e+00],\n",
            "        [-7.9879e+00, -8.4139e+00, -8.0875e+00,  ..., -2.3546e-03,\n",
            "         -7.4398e+00, -7.2964e+00],\n",
            "        ...,\n",
            "        [-8.3725e+00, -1.8429e-03, -8.8596e+00,  ..., -8.6234e+00,\n",
            "         -8.5572e+00, -6.9592e+00],\n",
            "        [-3.1305e-02, -4.2709e+00, -6.6297e+00,  ..., -4.6184e+00,\n",
            "         -5.8788e+00, -6.5201e+00],\n",
            "        [-5.1469e+00, -4.2436e+00, -5.0262e-02,  ..., -4.3267e+00,\n",
            "         -5.2584e+00, -5.4031e+00]], grad_fn=<LogSoftmaxBackward0>)\n",
            "Training: 581\n",
            "Epoch: 0582 loss_train: 0.6250 acc_train: 0.8500 loss_val: 1.0573 acc_val: 0.6633 time: 1.7473s\n",
            "loss_val:1.0573471784591675, val_acc:0.6633333333333333, out_features:tensor([[-6.1391, -5.7425, -0.0238,  ..., -5.9483, -6.0132, -5.7293],\n",
            "        [-6.7075, -7.0432, -6.8007,  ..., -7.0411, -0.0148, -5.3153],\n",
            "        [-2.9451, -2.7716, -1.8978,  ..., -0.6488, -2.6615, -2.4806],\n",
            "        ...,\n",
            "        [-1.7366, -0.9224, -2.7068,  ..., -2.4207, -1.9358, -2.5893],\n",
            "        [-0.3840, -3.9434, -4.0285,  ..., -1.8660, -2.7609, -3.4390],\n",
            "        [-2.2865, -2.1700, -1.3693,  ..., -2.2496, -2.3501, -2.1700]],\n",
            "       grad_fn=<LogSoftmaxBackward0>)\n",
            "Training: 582\n",
            "Epoch: 0583 loss_train: 0.4978 acc_train: 0.8786 loss_val: 1.0967 acc_val: 0.6400 time: 1.7671s\n",
            "loss_val:1.0966986417770386, val_acc:0.64, out_features:tensor([[-5.3277, -5.4292, -0.0476,  ..., -4.7260, -5.4172, -5.1478],\n",
            "        [-4.5928, -4.9827, -2.1028,  ..., -4.8982, -0.2337, -2.8891],\n",
            "        [-5.0191, -3.4554, -4.1019,  ..., -0.0783, -4.9677, -4.8306],\n",
            "        ...,\n",
            "        [-3.2304, -0.3694, -3.1467,  ..., -2.7033, -2.8263, -2.9342],\n",
            "        [-0.0085, -6.6433, -7.2327,  ..., -6.1969, -5.9230, -7.0389],\n",
            "        [-4.0098, -4.2633, -0.2136,  ..., -2.3136, -3.7328, -4.0778]],\n",
            "       grad_fn=<LogSoftmaxBackward0>)\n",
            "Training: 583\n",
            "Epoch: 0584 loss_train: 0.6319 acc_train: 0.8286 loss_val: 0.9878 acc_val: 0.7033 time: 1.7545s\n",
            "loss_val:0.987778902053833, val_acc:0.7033333333333334, out_features:tensor([[-3.8384e+00, -3.5077e+00, -3.4553e-01,  ..., -3.2563e+00,\n",
            "         -3.8148e+00, -3.4312e+00],\n",
            "        [-1.1120e+00, -2.6440e+00, -2.7783e+00,  ..., -2.9660e+00,\n",
            "         -1.0397e+00, -3.0596e+00],\n",
            "        [-9.7357e+00, -9.8067e+00, -9.8254e+00,  ..., -4.1274e-04,\n",
            "         -9.3160e+00, -9.2212e+00],\n",
            "        ...,\n",
            "        [-2.5032e+00, -5.4052e-01, -3.2303e+00,  ..., -2.6185e+00,\n",
            "         -2.8327e+00, -2.0329e+00],\n",
            "        [-2.7790e-01, -4.0686e+00, -4.0808e+00,  ..., -3.2986e+00,\n",
            "         -2.6678e+00, -3.1823e+00],\n",
            "        [-5.4934e+00, -5.6737e+00, -3.3060e-02,  ..., -4.2173e+00,\n",
            "         -5.3889e+00, -5.8337e+00]], grad_fn=<LogSoftmaxBackward0>)\n",
            "Training: 584\n",
            "Epoch: 0585 loss_train: 0.4983 acc_train: 0.8929 loss_val: 1.0420 acc_val: 0.6800 time: 1.8975s\n",
            "loss_val:1.0419939756393433, val_acc:0.68, out_features:tensor([[-7.9635e+00, -7.9486e+00, -5.4825e-03,  ..., -7.0662e+00,\n",
            "         -7.9753e+00, -7.7785e+00],\n",
            "        [-3.0441e+00, -3.2667e+00, -3.4465e+00,  ..., -1.4141e+00,\n",
            "         -9.7315e-01, -1.4630e+00],\n",
            "        [-2.9915e+00, -2.2672e+00, -2.4016e+00,  ..., -4.7058e-01,\n",
            "         -3.1651e+00, -2.9489e+00],\n",
            "        ...,\n",
            "        [-2.4377e+00, -6.7260e-01, -3.0884e+00,  ..., -1.8522e+00,\n",
            "         -2.3994e+00, -2.8042e+00],\n",
            "        [-2.0367e-01, -4.0324e+00, -4.2379e+00,  ..., -3.0281e+00,\n",
            "         -2.7008e+00, -3.8011e+00],\n",
            "        [-1.9459e+00, -1.9459e+00, -1.9459e+00,  ..., -1.9459e+00,\n",
            "         -1.9459e+00, -1.9459e+00]], grad_fn=<LogSoftmaxBackward0>)\n",
            "Training: 585\n",
            "Epoch: 0586 loss_train: 0.6291 acc_train: 0.8143 loss_val: 1.0220 acc_val: 0.6833 time: 1.9687s\n",
            "loss_val:1.0220168828964233, val_acc:0.6833333333333333, out_features:tensor([[-1.9459, -1.9459, -1.9459,  ..., -1.9459, -1.9459, -1.9459],\n",
            "        [-1.9459, -1.9459, -1.9459,  ..., -1.9459, -1.9459, -1.9459],\n",
            "        [-2.5805, -2.2768, -2.2870,  ..., -0.6956, -2.8110, -2.2603],\n",
            "        ...,\n",
            "        [-3.0474, -0.5688, -3.2218,  ..., -2.3799, -2.1379, -2.5933],\n",
            "        [-0.0959, -4.2820, -4.4086,  ..., -4.0990, -4.1597, -3.8684],\n",
            "        [-6.5258, -4.4832, -0.0194,  ..., -6.5065, -6.2199, -6.3954]],\n",
            "       grad_fn=<LogSoftmaxBackward0>)\n",
            "Training: 586\n",
            "Epoch: 0587 loss_train: 0.6593 acc_train: 0.8071 loss_val: 1.0316 acc_val: 0.6833 time: 1.7477s\n",
            "loss_val:1.0316276550292969, val_acc:0.6833333333333333, out_features:tensor([[-5.4806, -5.1987, -0.0452,  ..., -4.2718, -5.3730, -5.0959],\n",
            "        [-1.8696, -3.0754, -1.4225,  ..., -2.9579, -1.2153, -1.8147],\n",
            "        [-4.0931, -4.3474, -4.6939,  ..., -0.0713, -4.3901, -4.5349],\n",
            "        ...,\n",
            "        [-2.0992, -0.3830, -3.5813,  ..., -3.0834, -2.9491, -3.0939],\n",
            "        [-1.9459, -1.9459, -1.9459,  ..., -1.9459, -1.9459, -1.9459],\n",
            "        [-4.0887, -5.2426, -0.0495,  ..., -4.7505, -5.1691, -5.2353]],\n",
            "       grad_fn=<LogSoftmaxBackward0>)\n",
            "Training: 587\n",
            "Epoch: 0588 loss_train: 0.6215 acc_train: 0.8357 loss_val: 0.9574 acc_val: 0.7233 time: 1.7519s\n",
            "loss_val:0.9574294090270996, val_acc:0.7233333333333334, out_features:tensor([[-8.6745e+00, -8.7017e+00, -9.9693e-04,  ..., -8.6180e+00,\n",
            "         -8.4854e+00, -8.8598e+00],\n",
            "        [-6.4579e+00, -8.2656e+00, -8.2270e+00,  ..., -7.2647e+00,\n",
            "         -7.2106e-02, -2.7102e+00],\n",
            "        [-3.3512e+00, -3.3185e+00, -3.8967e+00,  ..., -3.8817e-01,\n",
            "         -2.2986e+00, -2.3053e+00],\n",
            "        ...,\n",
            "        [-2.2922e+00, -1.2614e+00, -2.4189e+00,  ..., -1.7678e+00,\n",
            "         -2.0927e+00, -2.2333e+00],\n",
            "        [-9.4449e-02, -4.1632e+00, -5.0347e+00,  ..., -3.7103e+00,\n",
            "         -3.5542e+00, -4.8913e+00],\n",
            "        [-1.9279e+00, -1.9722e+00, -1.0905e+00,  ..., -2.6556e+00,\n",
            "         -1.9288e+00, -2.5496e+00]], grad_fn=<LogSoftmaxBackward0>)\n",
            "Training: 588\n",
            "Epoch: 0589 loss_train: 0.7149 acc_train: 0.7643 loss_val: 1.0724 acc_val: 0.6533 time: 1.7552s\n",
            "loss_val:1.0724247694015503, val_acc:0.6533333333333333, out_features:tensor([[-9.7322e+00, -9.6798e+00, -5.0294e-03,  ..., -9.7231e+00,\n",
            "         -9.7463e+00, -9.1763e+00],\n",
            "        [-1.9459e+00, -1.9459e+00, -1.9459e+00,  ..., -1.9459e+00,\n",
            "         -1.9459e+00, -1.9459e+00],\n",
            "        [-6.2851e+00, -5.2720e+00, -6.7164e+00,  ..., -1.1509e-02,\n",
            "         -6.8940e+00, -6.5197e+00],\n",
            "        ...,\n",
            "        [-8.3862e+00, -2.1238e-03, -8.5138e+00,  ..., -8.1476e+00,\n",
            "         -7.0009e+00, -8.1294e+00],\n",
            "        [-1.5976e-02, -6.6670e+00, -7.1511e+00,  ..., -6.3743e+00,\n",
            "         -4.7438e+00, -7.0669e+00],\n",
            "        [-9.0296e+00, -8.8053e+00, -1.1895e-03,  ..., -7.4411e+00,\n",
            "         -9.1291e+00, -8.9507e+00]], grad_fn=<LogSoftmaxBackward0>)\n",
            "Training: 589\n",
            "Epoch: 0590 loss_train: 0.5899 acc_train: 0.8500 loss_val: 1.1081 acc_val: 0.6300 time: 1.7414s\n",
            "loss_val:1.1080759763717651, val_acc:0.63, out_features:tensor([[-4.6321, -4.5717, -0.0963,  ..., -4.5563, -4.6707, -3.6329],\n",
            "        [-1.9459, -1.9459, -1.9459,  ..., -1.9459, -1.9459, -1.9459],\n",
            "        [-5.7401, -5.0483, -5.3560,  ..., -0.0246, -5.5665, -5.8547],\n",
            "        ...,\n",
            "        [-3.5562, -0.1324, -4.6647,  ..., -4.6864, -3.5426, -3.2568],\n",
            "        [-0.7250, -3.0371, -2.9530,  ..., -2.6512, -1.8937, -2.4145],\n",
            "        [-6.8717, -7.0086, -0.0095,  ..., -5.5330, -6.5439, -6.7440]],\n",
            "       grad_fn=<LogSoftmaxBackward0>)\n",
            "Training: 590\n",
            "Epoch: 0591 loss_train: 0.6917 acc_train: 0.8357 loss_val: 0.9841 acc_val: 0.6867 time: 1.7438s\n",
            "loss_val:0.9841400980949402, val_acc:0.6866666666666666, out_features:tensor([[-5.2641e+00, -5.3459e+00, -7.4319e-02,  ..., -4.4749e+00,\n",
            "         -5.4220e+00, -4.2108e+00],\n",
            "        [-2.2704e+00, -2.2871e+00, -2.0057e+00,  ..., -2.2177e+00,\n",
            "         -9.4691e-01, -2.2045e+00],\n",
            "        [-2.4343e+00, -2.4006e+00, -2.0957e+00,  ..., -8.5128e-01,\n",
            "         -2.4232e+00, -2.3160e+00],\n",
            "        ...,\n",
            "        [-4.8380e+00, -7.2104e-02, -4.5528e+00,  ..., -4.2328e+00,\n",
            "         -4.0937e+00, -4.3743e+00],\n",
            "        [-2.1492e-01, -3.7854e+00, -3.0612e+00,  ..., -2.9385e+00,\n",
            "         -3.2704e+00, -4.0453e+00],\n",
            "        [-7.1168e+00, -6.8472e+00, -5.0111e-03,  ..., -7.2860e+00,\n",
            "         -7.2067e+00, -7.2887e+00]], grad_fn=<LogSoftmaxBackward0>)\n",
            "Training: 591\n",
            "Epoch: 0592 loss_train: 0.6512 acc_train: 0.8000 loss_val: 0.9721 acc_val: 0.6867 time: 1.8966s\n",
            "loss_val:0.9720710515975952, val_acc:0.6866666666666666, out_features:tensor([[-9.2590e+00, -9.2378e+00, -8.7485e-04,  ..., -8.5068e+00,\n",
            "         -9.2394e+00, -9.2006e+00],\n",
            "        [-1.9459e+00, -1.9459e+00, -1.9459e+00,  ..., -1.9459e+00,\n",
            "         -1.9459e+00, -1.9459e+00],\n",
            "        [-3.4521e+00, -3.7625e+00, -4.2090e+00,  ..., -1.8597e-01,\n",
            "         -3.5895e+00, -2.9042e+00],\n",
            "        ...,\n",
            "        [-1.9459e+00, -1.9459e+00, -1.9459e+00,  ..., -1.9459e+00,\n",
            "         -1.9459e+00, -1.9459e+00],\n",
            "        [-3.7047e-02, -5.4428e+00, -5.7349e+00,  ..., -4.6489e+00,\n",
            "         -4.4445e+00, -5.6573e+00],\n",
            "        [-6.3049e+00, -6.1906e+00, -1.6725e-02,  ..., -5.8757e+00,\n",
            "         -6.4844e+00, -5.6713e+00]], grad_fn=<LogSoftmaxBackward0>)\n",
            "Training: 592\n",
            "Epoch: 0593 loss_train: 0.6194 acc_train: 0.8000 loss_val: 0.9928 acc_val: 0.6767 time: 1.9659s\n",
            "loss_val:0.9928067922592163, val_acc:0.6766666666666666, out_features:tensor([[-5.6331e+00, -5.5707e+00, -3.3439e-02,  ..., -4.7850e+00,\n",
            "         -5.3034e+00, -5.6082e+00],\n",
            "        [-5.5021e+00, -1.0625e+01, -8.9257e+00,  ..., -1.0652e+01,\n",
            "         -4.4619e-03, -8.6874e+00],\n",
            "        [-9.8290e+00, -9.3329e+00, -8.8988e+00,  ..., -4.8959e-04,\n",
            "         -9.2403e+00, -9.6669e+00],\n",
            "        ...,\n",
            "        [-2.0652e+00, -1.4564e+00, -2.3916e+00,  ..., -2.2628e+00,\n",
            "         -1.9618e+00, -1.8968e+00],\n",
            "        [-3.7525e-01, -3.1806e+00, -3.3270e+00,  ..., -3.0804e+00,\n",
            "         -2.2835e+00, -3.4585e+00],\n",
            "        [-3.0439e+00, -2.5505e+00, -3.1636e-01,  ..., -3.4815e+00,\n",
            "         -3.0458e+00, -3.3245e+00]], grad_fn=<LogSoftmaxBackward0>)\n",
            "Training: 593\n",
            "Epoch: 0594 loss_train: 0.4839 acc_train: 0.8857 loss_val: 1.0407 acc_val: 0.6867 time: 1.7360s\n",
            "loss_val:1.040677547454834, val_acc:0.6866666666666666, out_features:tensor([[-8.4720e+00, -8.4735e+00, -1.2901e-03,  ..., -8.4695e+00,\n",
            "         -8.3678e+00, -8.3348e+00],\n",
            "        [-1.9459e+00, -1.9459e+00, -1.9459e+00,  ..., -1.9459e+00,\n",
            "         -1.9459e+00, -1.9459e+00],\n",
            "        [-5.2231e+00, -5.0731e+00, -5.0815e+00,  ..., -3.2471e-02,\n",
            "         -4.8256e+00, -5.6845e+00],\n",
            "        ...,\n",
            "        [-3.6032e+00, -2.4614e-01, -3.8884e+00,  ..., -2.5557e+00,\n",
            "         -3.1681e+00, -3.6083e+00],\n",
            "        [-4.6423e-03, -7.4563e+00, -7.9082e+00,  ..., -7.1720e+00,\n",
            "         -6.3174e+00, -7.1645e+00],\n",
            "        [-3.5280e+00, -3.3638e+00, -2.8487e-01,  ..., -2.6636e+00,\n",
            "         -3.5179e+00, -3.2179e+00]], grad_fn=<LogSoftmaxBackward0>)\n",
            "Training: 594\n",
            "Epoch: 0595 loss_train: 0.6316 acc_train: 0.8143 loss_val: 0.9868 acc_val: 0.6600 time: 1.7408s\n",
            "loss_val:0.9867973923683167, val_acc:0.66, out_features:tensor([[-1.0935e+01, -1.0603e+01, -3.7460e-04,  ..., -1.0820e+01,\n",
            "         -1.0937e+01, -1.0707e+01],\n",
            "        [-1.9459e+00, -1.9459e+00, -1.9459e+00,  ..., -1.9459e+00,\n",
            "         -1.9459e+00, -1.9459e+00],\n",
            "        [-8.1960e+00, -6.9439e+00, -7.7025e+00,  ..., -2.3798e-03,\n",
            "         -8.3710e+00, -8.4310e+00],\n",
            "        ...,\n",
            "        [-1.9459e+00, -1.9459e+00, -1.9459e+00,  ..., -1.9459e+00,\n",
            "         -1.9459e+00, -1.9459e+00],\n",
            "        [-8.5856e-01, -2.8277e+00, -2.5652e+00,  ..., -2.4317e+00,\n",
            "         -1.8144e+00, -1.9749e+00],\n",
            "        [-1.9459e+00, -1.9459e+00, -1.9459e+00,  ..., -1.9459e+00,\n",
            "         -1.9459e+00, -1.9459e+00]], grad_fn=<LogSoftmaxBackward0>)\n",
            "Training: 595\n",
            "Epoch: 0596 loss_train: 0.5384 acc_train: 0.8643 loss_val: 1.0279 acc_val: 0.6500 time: 1.7469s\n",
            "loss_val:1.0278921127319336, val_acc:0.65, out_features:tensor([[-1.0189e+01, -1.0325e+01, -2.6151e-04,  ..., -1.0332e+01,\n",
            "         -1.0291e+01, -1.0027e+01],\n",
            "        [-2.3521e+00, -2.6262e+00, -2.5982e+00,  ..., -2.6880e+00,\n",
            "         -1.6749e+00, -1.3890e+00],\n",
            "        [-9.7926e+00, -9.0155e+00, -9.1103e+00,  ..., -4.6838e-04,\n",
            "         -9.7554e+00, -9.6299e+00],\n",
            "        ...,\n",
            "        [-5.5156e+00, -5.4180e-02, -5.1964e+00,  ..., -3.5529e+00,\n",
            "         -5.2123e+00, -5.2527e+00],\n",
            "        [-3.3833e-02, -3.8323e+00, -6.6278e+00,  ..., -6.2408e+00,\n",
            "         -5.2500e+00, -6.5410e+00],\n",
            "        [-1.9459e+00, -1.9459e+00, -1.9459e+00,  ..., -1.9459e+00,\n",
            "         -1.9459e+00, -1.9459e+00]], grad_fn=<LogSoftmaxBackward0>)\n",
            "Training: 596\n",
            "Epoch: 0597 loss_train: 0.5757 acc_train: 0.8214 loss_val: 1.0587 acc_val: 0.6800 time: 1.7537s\n",
            "loss_val:1.0587443113327026, val_acc:0.68, out_features:tensor([[-3.5951, -3.2509, -0.4650,  ..., -2.3983, -3.4919, -2.5240],\n",
            "        [-1.9459, -1.9459, -1.9459,  ..., -1.9459, -1.9459, -1.9459],\n",
            "        [-1.8242, -2.1812, -2.2495,  ..., -0.9919, -2.1568, -2.6284],\n",
            "        ...,\n",
            "        [-4.0531, -0.1815, -3.7946,  ..., -3.3105, -2.7345, -4.3432],\n",
            "        [-0.0502, -5.8866, -5.7290,  ..., -3.2989, -6.0602, -6.1712],\n",
            "        [-3.3463, -4.0997, -0.1301,  ..., -4.1795, -3.8079, -3.8976]],\n",
            "       grad_fn=<LogSoftmaxBackward0>)\n",
            "Training: 597\n",
            "Epoch: 0598 loss_train: 0.5976 acc_train: 0.8143 loss_val: 1.0403 acc_val: 0.6667 time: 1.7298s\n",
            "loss_val:1.040258526802063, val_acc:0.6666666666666666, out_features:tensor([[-7.3855, -7.3412, -0.0089,  ..., -7.3527, -7.1810, -7.0570],\n",
            "        [-3.1153, -8.3138, -8.3264,  ..., -8.3748, -0.0472, -7.1385],\n",
            "        [-5.1801, -3.2402, -5.2726,  ..., -0.0859, -3.7262, -5.2939],\n",
            "        ...,\n",
            "        [-2.1506, -1.9515, -1.9473,  ..., -2.1008, -1.7137, -1.6549],\n",
            "        [-0.1068, -4.3935, -4.5282,  ..., -3.9592, -3.4602, -4.7026],\n",
            "        [-1.9459, -1.9459, -1.9459,  ..., -1.9459, -1.9459, -1.9459]],\n",
            "       grad_fn=<LogSoftmaxBackward0>)\n",
            "Training: 598\n",
            "Epoch: 0599 loss_train: 0.6302 acc_train: 0.8143 loss_val: 0.9873 acc_val: 0.6700 time: 1.8789s\n",
            "loss_val:0.9873489141464233, val_acc:0.67, out_features:tensor([[-7.4557, -7.3398, -0.0748,  ..., -6.9157, -7.4540, -6.3281],\n",
            "        [-1.6738, -3.1028, -3.3700,  ..., -2.6249, -0.9426, -1.4222],\n",
            "        [-3.2344, -3.3923, -3.9102,  ..., -0.1880, -3.5854, -3.4290],\n",
            "        ...,\n",
            "        [-1.9459, -1.9459, -1.9459,  ..., -1.9459, -1.9459, -1.9459],\n",
            "        [-0.2486, -3.8998, -3.6715,  ..., -3.5179, -3.0424, -3.4682],\n",
            "        [-1.9459, -1.9459, -1.9459,  ..., -1.9459, -1.9459, -1.9459]],\n",
            "       grad_fn=<LogSoftmaxBackward0>)\n",
            "Training: 599\n",
            "Epoch: 0600 loss_train: 0.5914 acc_train: 0.8071 loss_val: 1.0078 acc_val: 0.6700 time: 1.9536s\n",
            "loss_val:1.0077515840530396, val_acc:0.67, out_features:tensor([[-4.6587e+00, -4.6535e+00, -7.3543e-02,  ..., -4.4121e+00,\n",
            "         -4.9470e+00, -4.0445e+00],\n",
            "        [-3.4366e+00, -3.7309e+00, -4.5047e+00,  ..., -4.4570e+00,\n",
            "         -2.5250e-01, -3.0889e+00],\n",
            "        [-1.1376e+01, -1.1285e+01, -1.0308e+01,  ..., -8.7973e-05,\n",
            "         -1.1581e+01, -1.1514e+01],\n",
            "        ...,\n",
            "        [-1.9459e+00, -1.9459e+00, -1.9459e+00,  ..., -1.9459e+00,\n",
            "         -1.9459e+00, -1.9459e+00],\n",
            "        [-2.6869e-02, -4.3977e+00, -6.3931e+00,  ..., -6.0422e+00,\n",
            "         -5.4442e+00, -5.9897e+00],\n",
            "        [-6.2114e+00, -5.5475e+00, -1.9637e-02,  ..., -6.0668e+00,\n",
            "         -5.6870e+00, -5.8604e+00]], grad_fn=<LogSoftmaxBackward0>)\n",
            "Training: 600\n",
            "Epoch: 0601 loss_train: 0.6143 acc_train: 0.8286 loss_val: 1.1367 acc_val: 0.6333 time: 1.7394s\n",
            "loss_val:1.1366925239562988, val_acc:0.6333333333333333, out_features:tensor([[-2.7062, -2.6165, -0.6797,  ..., -2.2607, -2.4937, -2.5621],\n",
            "        [-2.7765, -2.4276, -2.0601,  ..., -0.8280, -1.5514, -3.1045],\n",
            "        [-4.5112, -4.6494, -4.0127,  ..., -0.0717, -4.5292, -4.5060],\n",
            "        ...,\n",
            "        [-2.0187, -1.2172, -1.7120,  ..., -1.7271, -2.5239, -2.7229],\n",
            "        [-0.6741, -2.7197, -2.4331,  ..., -2.5743, -2.0374, -2.7753],\n",
            "        [-2.5352, -2.9230, -0.6397,  ..., -2.1286, -3.1554, -3.3138]],\n",
            "       grad_fn=<LogSoftmaxBackward0>)\n",
            "Training: 601\n",
            "Epoch: 0602 loss_train: 0.5875 acc_train: 0.8143 loss_val: 0.9631 acc_val: 0.7067 time: 1.7352s\n",
            "loss_val:0.9631022214889526, val_acc:0.7066666666666667, out_features:tensor([[-3.7742, -3.9733, -0.1695,  ..., -3.4057, -3.6101, -3.3685],\n",
            "        [-1.9459, -1.9459, -1.9459,  ..., -1.9459, -1.9459, -1.9459],\n",
            "        [-2.8849, -3.0168, -2.6721,  ..., -0.4403, -2.6285, -2.4787],\n",
            "        ...,\n",
            "        [-1.5113, -1.4463, -2.5046,  ..., -2.3326, -1.9308, -2.1986],\n",
            "        [-1.1168, -2.3299, -2.5146,  ..., -1.9978, -1.9163, -2.3813],\n",
            "        [-3.9455, -3.8422, -0.1318,  ..., -4.3393, -3.1180, -4.1208]],\n",
            "       grad_fn=<LogSoftmaxBackward0>)\n",
            "Training: 602\n",
            "Epoch: 0603 loss_train: 0.6297 acc_train: 0.8143 loss_val: 1.1246 acc_val: 0.6733 time: 1.7646s\n",
            "loss_val:1.1245802640914917, val_acc:0.6733333333333333, out_features:tensor([[-4.0185, -3.8608, -0.2064,  ..., -2.9548, -3.8126, -3.7639],\n",
            "        [-1.9459, -1.9459, -1.9459,  ..., -1.9459, -1.9459, -1.9459],\n",
            "        [-5.2227, -5.7963, -6.1410,  ..., -0.0248, -6.0656, -4.6353],\n",
            "        ...,\n",
            "        [-5.4053, -0.0554, -5.6404,  ..., -5.1319, -5.0358, -3.5559],\n",
            "        [-0.0139, -5.8578, -5.9706,  ..., -6.0889, -5.9715, -6.4789],\n",
            "        [-4.1010, -5.5579, -0.0403,  ..., -5.7227, -4.9650, -5.4389]],\n",
            "       grad_fn=<LogSoftmaxBackward0>)\n",
            "Training: 603\n",
            "Epoch: 0604 loss_train: 0.6247 acc_train: 0.8143 loss_val: 0.9734 acc_val: 0.6933 time: 1.7517s\n",
            "loss_val:0.973375141620636, val_acc:0.6933333333333334, out_features:tensor([[-6.5407, -6.2225, -0.0153,  ..., -5.3276, -6.3112, -5.8871],\n",
            "        [-2.6100, -4.9935, -5.0533,  ..., -3.2602, -0.2038, -2.9307],\n",
            "        [-5.0512, -5.5524, -5.2300,  ..., -0.0276, -5.7233, -5.2463],\n",
            "        ...,\n",
            "        [-4.8077, -0.0429, -5.1377,  ..., -4.6680, -4.8134, -5.1413],\n",
            "        [-0.1465, -4.5333, -5.0011,  ..., -4.4942, -2.5418, -4.2060],\n",
            "        [-3.8819, -2.4585, -0.3101,  ..., -2.4732, -3.4682, -3.8612]],\n",
            "       grad_fn=<LogSoftmaxBackward0>)\n",
            "Training: 604\n",
            "Epoch: 0605 loss_train: 0.5647 acc_train: 0.8286 loss_val: 1.0095 acc_val: 0.6867 time: 1.7363s\n",
            "loss_val:1.0094525814056396, val_acc:0.6866666666666666, out_features:tensor([[-5.5033, -5.3538, -0.0468,  ..., -4.7605, -5.3506, -4.4877],\n",
            "        [-2.3518, -3.2212, -3.5700,  ..., -4.1158, -0.2785, -3.0055],\n",
            "        [-1.9459, -1.9459, -1.9459,  ..., -1.9459, -1.9459, -1.9459],\n",
            "        ...,\n",
            "        [-5.4984, -0.0111, -7.2895,  ..., -6.0331, -6.1886, -7.1671],\n",
            "        [-0.0268, -5.4324, -6.0849,  ..., -4.9861, -4.8889, -6.0611],\n",
            "        [-2.2481, -2.7587, -0.6159,  ..., -2.6262, -2.6811, -2.5348]],\n",
            "       grad_fn=<LogSoftmaxBackward0>)\n",
            "Training: 605\n",
            "Epoch: 0606 loss_train: 0.6282 acc_train: 0.8143 loss_val: 1.0727 acc_val: 0.6500 time: 1.8889s\n",
            "loss_val:1.0726529359817505, val_acc:0.65, out_features:tensor([[-5.2955e+00, -4.7780e+00, -4.2492e-02,  ..., -4.8642e+00,\n",
            "         -5.2517e+00, -5.2168e+00],\n",
            "        [-8.9805e+00, -9.1924e+00, -9.0907e+00,  ..., -3.5071e+00,\n",
            "         -4.3025e-02, -4.4490e+00],\n",
            "        [-1.0505e+01, -1.0390e+01, -1.0180e+01,  ..., -1.9954e-04,\n",
            "         -1.0123e+01, -1.0197e+01],\n",
            "        ...,\n",
            "        [-4.4796e+00, -8.2669e-02, -4.5214e+00,  ..., -4.6082e+00,\n",
            "         -3.6870e+00, -4.1736e+00],\n",
            "        [-2.0399e-01, -3.7781e+00, -4.1694e+00,  ..., -2.8052e+00,\n",
            "         -3.3861e+00, -3.2548e+00],\n",
            "        [-6.9506e+00, -5.3239e+00, -1.3113e-02,  ..., -7.0369e+00,\n",
            "         -6.2127e+00, -5.7768e+00]], grad_fn=<LogSoftmaxBackward0>)\n",
            "Training: 606\n",
            "Epoch: 0607 loss_train: 0.6006 acc_train: 0.8286 loss_val: 1.0538 acc_val: 0.6500 time: 1.9693s\n",
            "loss_val:1.0537877082824707, val_acc:0.65, out_features:tensor([[-1.9459e+00, -1.9459e+00, -1.9459e+00,  ..., -1.9459e+00,\n",
            "         -1.9459e+00, -1.9459e+00],\n",
            "        [-6.0109e+00, -5.8923e+00, -4.5094e+00,  ..., -5.8204e+00,\n",
            "         -2.6895e-02, -5.1856e+00],\n",
            "        [-4.7705e+00, -5.3649e+00, -5.2429e+00,  ..., -3.5753e-02,\n",
            "         -5.5868e+00, -4.6021e+00],\n",
            "        ...,\n",
            "        [-1.6831e+00, -1.1736e+00, -2.1455e+00,  ..., -2.2325e+00,\n",
            "         -2.1047e+00, -2.4484e+00],\n",
            "        [-3.9632e-03, -8.2569e+00, -8.0725e+00,  ..., -6.2298e+00,\n",
            "         -7.0947e+00, -8.1078e+00],\n",
            "        [-5.1144e+00, -5.7493e+00, -3.1485e-02,  ..., -5.5932e+00,\n",
            "         -4.8622e+00, -5.2754e+00]], grad_fn=<LogSoftmaxBackward0>)\n",
            "Training: 607\n",
            "Epoch: 0608 loss_train: 0.5640 acc_train: 0.8214 loss_val: 1.0082 acc_val: 0.6600 time: 1.7616s\n",
            "loss_val:1.0082347393035889, val_acc:0.66, out_features:tensor([[-2.8409, -2.3494, -0.5401,  ..., -2.1985, -2.8484, -2.9508],\n",
            "        [-3.5669, -4.6568, -3.5883,  ..., -4.3548, -0.3851, -1.4673],\n",
            "        [-2.6270, -2.9074, -1.9428,  ..., -0.5884, -2.8389, -2.6114],\n",
            "        ...,\n",
            "        [-6.5454, -0.0150, -6.5164,  ..., -5.6550, -5.5475, -5.7759],\n",
            "        [-0.0097, -6.5641, -6.8140,  ..., -5.6630, -6.2474, -7.0908],\n",
            "        [-1.9459, -1.9459, -1.9459,  ..., -1.9459, -1.9459, -1.9459]],\n",
            "       grad_fn=<LogSoftmaxBackward0>)\n",
            "Training: 608\n",
            "Epoch: 0609 loss_train: 0.5373 acc_train: 0.8500 loss_val: 0.9323 acc_val: 0.7133 time: 1.7617s\n",
            "loss_val:0.932250440120697, val_acc:0.7133333333333334, out_features:tensor([[-8.4631e+00, -8.3557e+00, -4.1520e-03,  ..., -8.1954e+00,\n",
            "         -8.4373e+00, -8.4905e+00],\n",
            "        [-1.9459e+00, -1.9459e+00, -1.9459e+00,  ..., -1.9459e+00,\n",
            "         -1.9459e+00, -1.9459e+00],\n",
            "        [-2.5945e+00, -2.4967e+00, -2.0356e+00,  ..., -9.2180e-01,\n",
            "         -2.5723e+00, -2.0260e+00],\n",
            "        ...,\n",
            "        [-2.6485e+00, -9.9301e-01, -2.8387e+00,  ..., -2.5811e+00,\n",
            "         -2.5309e+00, -1.9830e+00],\n",
            "        [-1.9969e-01, -3.9979e+00, -4.0818e+00,  ..., -2.8327e+00,\n",
            "         -3.0178e+00, -3.8947e+00],\n",
            "        [-3.0526e+00, -2.9641e+00, -4.5769e-01,  ..., -2.1451e+00,\n",
            "         -3.2011e+00, -2.6154e+00]], grad_fn=<LogSoftmaxBackward0>)\n",
            "Training: 609\n",
            "Epoch: 0610 loss_train: 0.5302 acc_train: 0.8357 loss_val: 0.9974 acc_val: 0.6867 time: 1.7435s\n",
            "loss_val:0.9974231719970703, val_acc:0.6866666666666666, out_features:tensor([[-3.3995e+00, -3.5191e+00, -2.1841e-01,  ..., -3.6780e+00,\n",
            "         -3.6730e+00, -2.9176e+00],\n",
            "        [-1.5401e+00, -2.8069e+00, -2.5015e+00,  ..., -1.7133e+00,\n",
            "         -1.0800e+00, -2.5241e+00],\n",
            "        [-1.0317e+01, -9.8513e+00, -8.5888e+00,  ..., -3.7711e-04,\n",
            "         -1.0372e+01, -1.0073e+01],\n",
            "        ...,\n",
            "        [-4.9658e+00, -6.6594e-02, -5.0503e+00,  ..., -3.4163e+00,\n",
            "         -4.9254e+00, -5.1481e+00],\n",
            "        [-1.3673e-03, -9.9934e+00, -9.9212e+00,  ..., -6.9168e+00,\n",
            "         -8.5298e+00, -1.0110e+01],\n",
            "        [-5.3148e+00, -5.8452e+00, -3.0058e-02,  ..., -5.7509e+00,\n",
            "         -5.6081e+00, -5.6788e+00]], grad_fn=<LogSoftmaxBackward0>)\n",
            "Training: 610\n",
            "Epoch: 0611 loss_train: 0.6155 acc_train: 0.8000 loss_val: 1.0235 acc_val: 0.6233 time: 1.7525s\n",
            "loss_val:1.0235331058502197, val_acc:0.6233333333333333, out_features:tensor([[-7.3348e+00, -6.8362e+00, -4.9260e-03,  ..., -7.2296e+00,\n",
            "         -7.2652e+00, -6.9498e+00],\n",
            "        [-7.8945e+00, -9.2746e+00, -9.2758e+00,  ..., -5.2287e+00,\n",
            "         -3.1999e-02, -3.6700e+00],\n",
            "        [-4.8019e+00, -4.6431e+00, -3.7667e+00,  ..., -7.6047e-02,\n",
            "         -4.8933e+00, -4.5969e+00],\n",
            "        ...,\n",
            "        [-6.1224e+00, -2.0035e-02, -5.8277e+00,  ..., -5.3970e+00,\n",
            "         -5.6925e+00, -5.8241e+00],\n",
            "        [-9.3554e-02, -4.6755e+00, -3.9298e+00,  ..., -3.4267e+00,\n",
            "         -4.3548e+00, -5.0337e+00],\n",
            "        [-4.9940e+00, -4.6850e+00, -5.7691e-02,  ..., -4.7542e+00,\n",
            "         -4.3286e+00, -4.5764e+00]], grad_fn=<LogSoftmaxBackward0>)\n",
            "Training: 611\n",
            "Epoch: 0612 loss_train: 0.6347 acc_train: 0.7786 loss_val: 1.0225 acc_val: 0.6833 time: 1.7612s\n",
            "loss_val:1.0225361585617065, val_acc:0.6833333333333333, out_features:tensor([[-7.7126e+00, -7.7255e+00, -6.8158e-03,  ..., -6.5949e+00,\n",
            "         -7.6343e+00, -7.2023e+00],\n",
            "        [-1.9459e+00, -1.9459e+00, -1.9459e+00,  ..., -1.9459e+00,\n",
            "         -1.9459e+00, -1.9459e+00],\n",
            "        [-4.1586e+00, -4.5501e+00, -5.1403e+00,  ..., -6.5203e-02,\n",
            "         -4.3626e+00, -4.4108e+00],\n",
            "        ...,\n",
            "        [-2.3137e+00, -1.3399e+00, -2.4723e+00,  ..., -1.6015e+00,\n",
            "         -2.5723e+00, -1.4851e+00],\n",
            "        [-5.0315e-02, -5.0945e+00, -5.5485e+00,  ..., -4.8762e+00,\n",
            "         -3.9342e+00, -5.0508e+00],\n",
            "        [-1.9459e+00, -1.9459e+00, -1.9459e+00,  ..., -1.9459e+00,\n",
            "         -1.9459e+00, -1.9459e+00]], grad_fn=<LogSoftmaxBackward0>)\n",
            "Training: 612\n",
            "Epoch: 0613 loss_train: 0.6152 acc_train: 0.8357 loss_val: 0.9796 acc_val: 0.7133 time: 1.8998s\n",
            "loss_val:0.9796240329742432, val_acc:0.7133333333333334, out_features:tensor([[-5.9119, -5.8807, -0.0424,  ..., -5.6181, -5.9191, -4.8281],\n",
            "        [-2.4281, -2.7833, -1.8024,  ..., -3.1638, -0.7730, -1.9641],\n",
            "        [-4.2076, -4.4137, -4.1278,  ..., -0.0882, -4.3835, -4.0338],\n",
            "        ...,\n",
            "        [-1.5118, -1.2889, -2.7142,  ..., -2.6830, -1.6761, -2.2481],\n",
            "        [-0.1013, -2.9911, -5.2498,  ..., -4.0593, -4.4860, -5.1700],\n",
            "        [-3.1205, -3.5097, -0.3092,  ..., -3.6289, -2.5701, -2.7508]],\n",
            "       grad_fn=<LogSoftmaxBackward0>)\n",
            "Training: 613\n",
            "Epoch: 0614 loss_train: 0.6384 acc_train: 0.8000 loss_val: 1.0469 acc_val: 0.6700 time: 1.9774s\n",
            "loss_val:1.0469309091567993, val_acc:0.67, out_features:tensor([[-6.4785e+00, -6.1911e+00, -2.3186e-02,  ..., -5.1429e+00,\n",
            "         -6.3766e+00, -5.2655e+00],\n",
            "        [-1.9459e+00, -1.9459e+00, -1.9459e+00,  ..., -1.9459e+00,\n",
            "         -1.9459e+00, -1.9459e+00],\n",
            "        [-3.3156e+00, -3.3307e+00, -3.4500e+00,  ..., -2.1199e-01,\n",
            "         -3.4911e+00, -3.3163e+00],\n",
            "        ...,\n",
            "        [-2.7912e+00, -6.4243e-01, -2.8337e+00,  ..., -1.9033e+00,\n",
            "         -2.8725e+00, -2.4582e+00],\n",
            "        [-1.3264e+00, -1.8795e+00, -2.0942e+00,  ..., -1.9051e+00,\n",
            "         -2.1365e+00, -2.4835e+00],\n",
            "        [-1.5146e+01, -1.3770e+01, -3.8147e-06,  ..., -1.3222e+01,\n",
            "         -1.5189e+01, -1.5156e+01]], grad_fn=<LogSoftmaxBackward0>)\n",
            "Training: 614\n",
            "Epoch: 0615 loss_train: 0.6576 acc_train: 0.7929 loss_val: 1.0219 acc_val: 0.6567 time: 1.7542s\n",
            "loss_val:1.0218570232391357, val_acc:0.6566666666666666, out_features:tensor([[-1.0097e+01, -1.0091e+01, -1.5476e-02,  ..., -9.7971e+00,\n",
            "         -1.0067e+01, -9.6369e+00],\n",
            "        [-9.8354e+00, -9.8006e+00, -9.9336e+00,  ..., -9.9204e+00,\n",
            "         -2.2561e-03, -7.1495e+00],\n",
            "        [-1.9459e+00, -1.9459e+00, -1.9459e+00,  ..., -1.9459e+00,\n",
            "         -1.9459e+00, -1.9459e+00],\n",
            "        ...,\n",
            "        [-1.9285e+00, -6.3132e-01, -2.5485e+00,  ..., -2.6438e+00,\n",
            "         -2.9046e+00, -2.6807e+00],\n",
            "        [-1.4314e-01, -4.5068e+00, -4.2602e+00,  ..., -3.0238e+00,\n",
            "         -3.8781e+00, -3.6851e+00],\n",
            "        [-7.3626e+00, -7.2270e+00, -4.4638e-03,  ..., -7.0901e+00,\n",
            "         -7.4976e+00, -7.3037e+00]], grad_fn=<LogSoftmaxBackward0>)\n",
            "Training: 615\n",
            "Epoch: 0616 loss_train: 0.7024 acc_train: 0.8214 loss_val: 1.0234 acc_val: 0.6500 time: 1.7652s\n",
            "loss_val:1.0234150886535645, val_acc:0.65, out_features:tensor([[-4.3589, -4.2875, -0.1309,  ..., -3.1809, -4.1551, -4.2868],\n",
            "        [-1.0796, -3.3430, -3.0917,  ..., -1.6654, -1.2745, -2.5393],\n",
            "        [-2.8249, -2.4805, -1.6120,  ..., -0.8736, -2.5924, -2.3218],\n",
            "        ...,\n",
            "        [-2.3071, -1.3890, -2.1028,  ..., -1.9527, -1.8885, -1.9280],\n",
            "        [-0.9779, -2.6219, -3.0528,  ..., -1.5021, -1.7211, -2.8724],\n",
            "        [-4.6399, -3.5357, -0.0842,  ..., -4.7942, -4.2764, -4.5008]],\n",
            "       grad_fn=<LogSoftmaxBackward0>)\n",
            "Training: 616\n",
            "Epoch: 0617 loss_train: 0.5729 acc_train: 0.8071 loss_val: 0.9506 acc_val: 0.7000 time: 1.7367s\n",
            "loss_val:0.9505648612976074, val_acc:0.7, out_features:tensor([[-4.2254e+00, -4.0555e+00, -1.2365e-01,  ..., -3.7725e+00,\n",
            "         -4.0863e+00, -3.6721e+00],\n",
            "        [-2.3837e+00, -3.8820e+00, -3.9236e+00,  ..., -3.2193e+00,\n",
            "         -4.6667e-01, -1.7990e+00],\n",
            "        [-9.9064e+00, -9.0491e+00, -1.0172e+01,  ..., -3.1407e-04,\n",
            "         -1.0143e+01, -1.0140e+01],\n",
            "        ...,\n",
            "        [-2.6908e+00, -1.4395e-01, -4.0435e+00,  ..., -4.3197e+00,\n",
            "         -4.1025e+00, -4.6870e+00],\n",
            "        [-1.9459e+00, -1.9459e+00, -1.9459e+00,  ..., -1.9459e+00,\n",
            "         -1.9459e+00, -1.9459e+00],\n",
            "        [-1.0832e+01, -1.0381e+01, -1.3386e-04,  ..., -1.0900e+01,\n",
            "         -1.0763e+01, -1.0649e+01]], grad_fn=<LogSoftmaxBackward0>)\n",
            "Training: 617\n",
            "Epoch: 0618 loss_train: 0.5829 acc_train: 0.8357 loss_val: 1.1645 acc_val: 0.6433 time: 1.7400s\n",
            "loss_val:1.1645081043243408, val_acc:0.6433333333333333, out_features:tensor([[-7.1472, -7.0815, -0.0084,  ..., -6.0656, -6.6234, -6.8196],\n",
            "        [-2.7745, -2.7076, -2.6687,  ..., -2.2415, -0.7934, -1.6269],\n",
            "        [-5.1987, -5.9214, -6.5258,  ..., -0.0148, -6.3402, -6.1818],\n",
            "        ...,\n",
            "        [-2.4666, -0.7543, -2.7979,  ..., -2.2804, -2.2448, -2.1960],\n",
            "        [-0.2571, -4.0338, -4.0031,  ..., -3.4954, -3.3728, -3.5964],\n",
            "        [-6.8229, -6.7756, -0.0093,  ..., -6.3427, -6.6522, -6.7772]],\n",
            "       grad_fn=<LogSoftmaxBackward0>)\n",
            "Training: 618\n",
            "Epoch: 0619 loss_train: 0.5972 acc_train: 0.8357 loss_val: 1.0617 acc_val: 0.6633 time: 1.7503s\n",
            "loss_val:1.0617121458053589, val_acc:0.6633333333333333, out_features:tensor([[-6.4575, -6.0564, -0.0147,  ..., -5.7926, -6.2654, -5.5735],\n",
            "        [-1.9459, -1.9459, -1.9459,  ..., -1.9459, -1.9459, -1.9459],\n",
            "        [-4.2196, -4.2227, -3.8615,  ..., -0.0928, -4.5331, -4.1178],\n",
            "        ...,\n",
            "        [-4.0870, -0.1091, -4.5525,  ..., -2.9826, -4.7831, -4.7286],\n",
            "        [-1.4606, -1.6323, -1.8422,  ..., -2.1045, -2.2294, -2.2537],\n",
            "        [-4.6320, -4.6240, -0.0700,  ..., -4.7625, -3.7438, -4.7521]],\n",
            "       grad_fn=<LogSoftmaxBackward0>)\n",
            "Training: 619\n",
            "Epoch: 0620 loss_train: 0.6513 acc_train: 0.7786 loss_val: 0.9858 acc_val: 0.6867 time: 1.9037s\n",
            "loss_val:0.9857865571975708, val_acc:0.6866666666666666, out_features:tensor([[-5.5967e+00, -5.4956e+00, -5.1589e-02,  ..., -4.0921e+00,\n",
            "         -5.5132e+00, -5.6300e+00],\n",
            "        [-2.0477e+00, -2.7612e+00, -2.6688e+00,  ..., -2.6462e+00,\n",
            "         -9.5815e-01, -1.4824e+00],\n",
            "        [-1.9459e+00, -1.9459e+00, -1.9459e+00,  ..., -1.9459e+00,\n",
            "         -1.9459e+00, -1.9459e+00],\n",
            "        ...,\n",
            "        [-4.8358e+00, -4.6140e-02, -5.8849e+00,  ..., -5.1473e+00,\n",
            "         -3.7778e+00, -5.7528e+00],\n",
            "        [-2.8225e-04, -1.0729e+01, -1.0904e+01,  ..., -1.0521e+01,\n",
            "         -9.3967e+00, -1.0927e+01],\n",
            "        [-2.5381e+00, -3.3361e+00, -2.1441e-01,  ..., -4.3735e+00,\n",
            "         -3.1989e+00, -4.3609e+00]], grad_fn=<LogSoftmaxBackward0>)\n",
            "Training: 620\n",
            "Epoch: 0621 loss_train: 0.6276 acc_train: 0.8214 loss_val: 1.0538 acc_val: 0.6467 time: 1.9528s\n",
            "loss_val:1.053757667541504, val_acc:0.6466666666666666, out_features:tensor([[-7.2839e+00, -7.1774e+00, -5.2332e-03,  ..., -7.1890e+00,\n",
            "         -7.2956e+00, -6.9799e+00],\n",
            "        [-5.3741e+00, -6.8944e+00, -8.5146e+00,  ..., -8.4186e+00,\n",
            "         -6.6605e-03, -7.8830e+00],\n",
            "        [-3.8498e+00, -3.5330e+00, -4.0606e+00,  ..., -1.6351e-01,\n",
            "         -3.9894e+00, -3.7629e+00],\n",
            "        ...,\n",
            "        [-2.0308e+00, -9.9850e-01, -1.8971e+00,  ..., -2.4410e+00,\n",
            "         -2.7763e+00, -2.9504e+00],\n",
            "        [-1.3176e-01, -4.8137e+00, -4.8650e+00,  ..., -3.4153e+00,\n",
            "         -2.8227e+00, -4.9821e+00],\n",
            "        [-3.2504e+00, -3.1692e+00, -5.0595e-01,  ..., -2.1233e+00,\n",
            "         -2.8444e+00, -2.4315e+00]], grad_fn=<LogSoftmaxBackward0>)\n",
            "Training: 621\n",
            "Epoch: 0622 loss_train: 0.7272 acc_train: 0.7786 loss_val: 1.0453 acc_val: 0.6633 time: 1.7490s\n",
            "loss_val:1.0453481674194336, val_acc:0.6633333333333333, out_features:tensor([[-3.6283, -4.4912, -0.1143,  ..., -3.9321, -4.3251, -4.0752],\n",
            "        [-1.9459, -1.9459, -1.9459,  ..., -1.9459, -1.9459, -1.9459],\n",
            "        [-3.3669, -4.0436, -4.0353,  ..., -0.1385, -3.7979, -3.8994],\n",
            "        ...,\n",
            "        [-5.0360, -0.1042, -4.7575,  ..., -2.7968, -5.0111, -4.5353],\n",
            "        [-1.4454, -2.2280, -2.0954,  ..., -1.8187, -2.1995, -2.0330],\n",
            "        [-2.6191, -2.1430, -0.9305,  ..., -2.4244, -2.4940, -2.3124]],\n",
            "       grad_fn=<LogSoftmaxBackward0>)\n",
            "Training: 622\n",
            "Epoch: 0623 loss_train: 0.6554 acc_train: 0.8214 loss_val: 1.0018 acc_val: 0.6700 time: 1.7436s\n",
            "loss_val:1.0018359422683716, val_acc:0.67, out_features:tensor([[-1.0778e+01, -1.0741e+01, -1.6248e-03,  ..., -1.0711e+01,\n",
            "         -1.0772e+01, -1.0269e+01],\n",
            "        [-2.0225e+00, -3.2081e+00, -2.7985e+00,  ..., -3.2460e+00,\n",
            "         -6.0693e-01, -1.8752e+00],\n",
            "        [-4.0411e+00, -3.5218e+00, -2.7887e+00,  ..., -1.8977e-01,\n",
            "         -3.6326e+00, -3.7642e+00],\n",
            "        ...,\n",
            "        [-4.2014e+00, -1.1516e-01, -4.5477e+00,  ..., -3.2278e+00,\n",
            "         -4.0651e+00, -4.1818e+00],\n",
            "        [-6.8449e-01, -2.9548e+00, -2.9083e+00,  ..., -2.3090e+00,\n",
            "         -2.5794e+00, -2.4117e+00],\n",
            "        [-4.7451e+00, -5.1116e+00, -5.3275e-02,  ..., -4.2651e+00,\n",
            "         -4.7137e+00, -4.9246e+00]], grad_fn=<LogSoftmaxBackward0>)\n",
            "Training: 623\n",
            "Epoch: 0624 loss_train: 0.5705 acc_train: 0.8500 loss_val: 1.0053 acc_val: 0.6900 time: 1.7479s\n",
            "loss_val:1.0053367614746094, val_acc:0.69, out_features:tensor([[-7.9312e+00, -8.0163e+00, -3.1471e-03,  ..., -7.3594e+00,\n",
            "         -8.0035e+00, -7.6136e+00],\n",
            "        [-1.9459e+00, -1.9459e+00, -1.9459e+00,  ..., -1.9459e+00,\n",
            "         -1.9459e+00, -1.9459e+00],\n",
            "        [-3.5198e+00, -3.4174e+00, -2.8783e+00,  ..., -2.5139e-01,\n",
            "         -3.4678e+00, -3.3295e+00],\n",
            "        ...,\n",
            "        [-2.1554e+00, -7.2174e-01, -2.8923e+00,  ..., -2.1279e+00,\n",
            "         -2.2929e+00, -2.8587e+00],\n",
            "        [-4.3735e-01, -2.8233e+00, -3.5143e+00,  ..., -3.0036e+00,\n",
            "         -2.4221e+00, -3.2432e+00],\n",
            "        [-1.2056e+00, -2.1342e+00, -1.6138e+00,  ..., -3.0236e+00,\n",
            "         -2.2732e+00, -1.7369e+00]], grad_fn=<LogSoftmaxBackward0>)\n",
            "Training: 624\n",
            "Epoch: 0625 loss_train: 0.6172 acc_train: 0.8000 loss_val: 1.0403 acc_val: 0.6700 time: 1.7432s\n",
            "loss_val:1.0403203964233398, val_acc:0.67, out_features:tensor([[-8.3454e+00, -8.1773e+00, -2.9178e-03,  ..., -6.7018e+00,\n",
            "         -8.2587e+00, -7.9848e+00],\n",
            "        [-5.2189e+00, -4.9244e+00, -5.2939e+00,  ..., -4.7978e+00,\n",
            "         -3.6587e-02, -4.9834e+00],\n",
            "        [-4.8784e+00, -4.7991e+00, -4.2862e+00,  ..., -4.6354e-02,\n",
            "         -5.2593e+00, -5.0952e+00],\n",
            "        ...,\n",
            "        [-2.9900e+00, -4.4138e-01, -2.8785e+00,  ..., -2.2501e+00,\n",
            "         -2.6024e+00, -3.2215e+00],\n",
            "        [-1.9459e+00, -1.9459e+00, -1.9459e+00,  ..., -1.9459e+00,\n",
            "         -1.9459e+00, -1.9459e+00],\n",
            "        [-4.0351e+00, -3.1973e+00, -2.6422e-01,  ..., -2.4251e+00,\n",
            "         -3.4119e+00, -3.3106e+00]], grad_fn=<LogSoftmaxBackward0>)\n",
            "Training: 625\n",
            "Epoch: 0626 loss_train: 0.6286 acc_train: 0.8000 loss_val: 1.0077 acc_val: 0.6667 time: 1.7456s\n",
            "loss_val:1.0076860189437866, val_acc:0.6666666666666666, out_features:tensor([[-9.6360e+00, -9.8805e+00, -3.7806e-04,  ..., -9.2789e+00,\n",
            "         -9.9929e+00, -9.6006e+00],\n",
            "        [-1.7527e+00, -3.2830e+00, -2.4916e+00,  ..., -3.2191e+00,\n",
            "         -1.0030e+00, -1.3096e+00],\n",
            "        [-5.0701e+00, -5.7859e+00, -6.0563e+00,  ..., -2.2277e-02,\n",
            "         -5.6398e+00, -5.7217e+00],\n",
            "        ...,\n",
            "        [-1.9459e+00, -1.9459e+00, -1.9459e+00,  ..., -1.9459e+00,\n",
            "         -1.9459e+00, -1.9459e+00],\n",
            "        [-4.0498e-01, -3.2777e+00, -3.5815e+00,  ..., -2.1717e+00,\n",
            "         -2.6018e+00, -3.4027e+00],\n",
            "        [-1.9350e+00, -2.6594e+00, -1.3890e+00,  ..., -2.7327e+00,\n",
            "         -2.3456e+00, -2.0333e+00]], grad_fn=<LogSoftmaxBackward0>)\n",
            "Training: 626\n",
            "Epoch: 0627 loss_train: 0.6881 acc_train: 0.7857 loss_val: 1.0503 acc_val: 0.6533 time: 1.8966s\n",
            "loss_val:1.050319790840149, val_acc:0.6533333333333333, out_features:tensor([[-3.5261, -3.6778, -0.2396,  ..., -3.5656, -3.3768, -2.7907],\n",
            "        [-1.9459, -1.9459, -1.9459,  ..., -1.9459, -1.9459, -1.9459],\n",
            "        [-2.8972, -2.8160, -4.2173,  ..., -0.1910, -4.2131, -3.9858],\n",
            "        ...,\n",
            "        [-4.5000, -0.0658, -5.1449,  ..., -4.5877, -3.6734, -5.1847],\n",
            "        [-0.2381, -2.9947, -3.6567,  ..., -2.6656, -3.4290, -4.0598],\n",
            "        [-2.3479, -2.3507, -0.6192,  ..., -3.2182, -2.9612, -2.1684]],\n",
            "       grad_fn=<LogSoftmaxBackward0>)\n",
            "Training: 627\n",
            "Epoch: 0628 loss_train: 0.5143 acc_train: 0.8429 loss_val: 1.0076 acc_val: 0.6933 time: 1.9580s\n",
            "loss_val:1.0075880289077759, val_acc:0.6933333333333334, out_features:tensor([[-3.1246e+00, -2.9739e+00, -6.1029e-01,  ..., -2.7153e+00,\n",
            "         -2.9301e+00, -3.0322e+00],\n",
            "        [-5.8697e+00, -5.6302e+00, -6.9907e+00,  ..., -2.0707e+00,\n",
            "         -1.4812e-01, -5.6751e+00],\n",
            "        [-4.1151e+00, -4.5596e+00, -5.9916e+00,  ..., -4.4172e-02,\n",
            "         -5.1906e+00, -5.1464e+00],\n",
            "        ...,\n",
            "        [-3.1649e+00, -3.7568e-01, -4.3734e+00,  ..., -1.5071e+00,\n",
            "         -4.2583e+00, -4.4217e+00],\n",
            "        [-4.0769e-05, -1.1389e+01, -1.2431e+01,  ..., -1.1985e+01,\n",
            "         -1.1551e+01, -1.2354e+01],\n",
            "        [-3.8396e+00, -4.6815e+00, -7.2616e-02,  ..., -4.6383e+00,\n",
            "         -4.7537e+00, -4.3397e+00]], grad_fn=<LogSoftmaxBackward0>)\n",
            "Training: 628\n",
            "Epoch: 0629 loss_train: 0.5963 acc_train: 0.8214 loss_val: 1.0798 acc_val: 0.6667 time: 1.7487s\n",
            "loss_val:1.0797988176345825, val_acc:0.6666666666666666, out_features:tensor([[-1.0289e+01, -9.7529e+00, -3.3445e-04,  ..., -1.0128e+01,\n",
            "         -1.0060e+01, -9.8776e+00],\n",
            "        [-1.9459e+00, -1.9459e+00, -1.9459e+00,  ..., -1.9459e+00,\n",
            "         -1.9459e+00, -1.9459e+00],\n",
            "        [-5.4209e+00, -4.1288e+00, -5.2234e+00,  ..., -4.7405e-02,\n",
            "         -4.7760e+00, -4.8424e+00],\n",
            "        ...,\n",
            "        [-1.8587e+00, -8.6485e-01, -2.3573e+00,  ..., -2.7117e+00,\n",
            "         -2.1551e+00, -2.4323e+00],\n",
            "        [-1.1749e+00, -1.8854e+00, -1.7910e+00,  ..., -2.5850e+00,\n",
            "         -2.2621e+00, -2.1244e+00],\n",
            "        [-1.9459e+00, -1.9459e+00, -1.9459e+00,  ..., -1.9459e+00,\n",
            "         -1.9459e+00, -1.9459e+00]], grad_fn=<LogSoftmaxBackward0>)\n",
            "Training: 629\n",
            "Epoch: 0630 loss_train: 0.5520 acc_train: 0.8429 loss_val: 1.1164 acc_val: 0.6567 time: 1.7489s\n",
            "loss_val:1.116408348083496, val_acc:0.6566666666666666, out_features:tensor([[-9.9334e+00, -9.8983e+00, -4.3800e-04,  ..., -8.6759e+00,\n",
            "         -9.8716e+00, -9.9253e+00],\n",
            "        [-1.9459e+00, -1.9459e+00, -1.9459e+00,  ..., -1.9459e+00,\n",
            "         -1.9459e+00, -1.9459e+00],\n",
            "        [-4.2954e+00, -5.9481e+00, -5.6279e+00,  ..., -2.8300e-02,\n",
            "         -5.8071e+00, -5.9146e+00],\n",
            "        ...,\n",
            "        [-4.5855e+00, -9.3622e-02, -5.0464e+00,  ..., -2.9773e+00,\n",
            "         -4.6692e+00, -5.1660e+00],\n",
            "        [-4.2269e-01, -3.1502e+00, -2.9282e+00,  ..., -2.4346e+00,\n",
            "         -2.5788e+00, -3.1245e+00],\n",
            "        [-2.0587e+00, -4.2390e+00, -2.4238e-01,  ..., -4.5587e+00,\n",
            "         -3.5543e+00, -4.2458e+00]], grad_fn=<LogSoftmaxBackward0>)\n",
            "Training: 630\n",
            "Epoch: 0631 loss_train: 0.5598 acc_train: 0.8357 loss_val: 0.9911 acc_val: 0.6500 time: 1.7414s\n",
            "loss_val:0.991060197353363, val_acc:0.65, out_features:tensor([[-5.3107, -4.5973, -0.0554,  ..., -4.6879, -5.1763, -5.3947],\n",
            "        [-1.9459, -1.9459, -1.9459,  ..., -1.9459, -1.9459, -1.9459],\n",
            "        [-4.6408, -4.3197, -3.8106,  ..., -0.1019, -4.5818, -3.3835],\n",
            "        ...,\n",
            "        [-2.7290, -0.6744, -3.1977,  ..., -2.1395, -2.3222, -2.0070],\n",
            "        [-0.4269, -3.2149, -2.5183,  ..., -2.6674, -2.7152, -2.8377],\n",
            "        [-5.0573, -4.1400, -0.1939,  ..., -5.1483, -5.2957, -5.2633]],\n",
            "       grad_fn=<LogSoftmaxBackward0>)\n",
            "Training: 631\n",
            "Epoch: 0632 loss_train: 0.6014 acc_train: 0.8357 loss_val: 1.0043 acc_val: 0.6867 time: 1.7305s\n",
            "loss_val:1.0042755603790283, val_acc:0.6866666666666666, out_features:tensor([[-5.6551e+00, -5.9896e+00, -2.1792e-02,  ..., -5.8195e+00,\n",
            "         -5.2416e+00, -5.6793e+00],\n",
            "        [-2.1316e+00, -2.9938e+00, -2.9275e+00,  ..., -1.7458e+00,\n",
            "         -9.3337e-01, -1.7943e+00],\n",
            "        [-7.6401e+00, -8.0040e+00, -7.6435e+00,  ..., -2.1464e-03,\n",
            "         -8.1657e+00, -8.0700e+00],\n",
            "        ...,\n",
            "        [-2.6437e+00, -6.5806e-01, -2.8472e+00,  ..., -2.0824e+00,\n",
            "         -2.4057e+00, -2.6518e+00],\n",
            "        [-3.1464e-02, -4.7109e+00, -5.6810e+00,  ..., -5.5873e+00,\n",
            "         -4.8095e+00, -5.7856e+00],\n",
            "        [-6.0800e+00, -3.2851e+00, -4.8294e-02,  ..., -6.5439e+00,\n",
            "         -5.7609e+00, -6.5344e+00]], grad_fn=<LogSoftmaxBackward0>)\n",
            "Training: 632\n",
            "Epoch: 0633 loss_train: 0.5956 acc_train: 0.8214 loss_val: 1.1305 acc_val: 0.6667 time: 1.7482s\n",
            "loss_val:1.1305434703826904, val_acc:0.6666666666666666, out_features:tensor([[-3.9402e+00, -3.8630e+00, -6.5799e-01,  ..., -3.8403e+00,\n",
            "         -3.3508e+00, -1.5983e+00],\n",
            "        [-2.6521e+00, -2.8103e+00, -3.1063e+00,  ..., -1.8438e+00,\n",
            "         -8.4319e-01, -1.6527e+00],\n",
            "        [-3.5564e+00, -3.9030e+00, -4.3759e+00,  ..., -1.3012e-01,\n",
            "         -4.2395e+00, -3.2966e+00],\n",
            "        ...,\n",
            "        [-2.0295e+00, -9.2700e-01, -2.8356e+00,  ..., -1.9077e+00,\n",
            "         -2.4084e+00, -2.5446e+00],\n",
            "        [-3.6387e-03, -7.1716e+00, -7.8875e+00,  ..., -7.6079e+00,\n",
            "         -7.2628e+00, -7.7805e+00],\n",
            "        [-3.7995e+00, -3.9309e+00, -2.0420e-01,  ..., -3.8649e+00,\n",
            "         -2.9009e+00, -3.2297e+00]], grad_fn=<LogSoftmaxBackward0>)\n",
            "Training: 633\n",
            "Epoch: 0634 loss_train: 0.6546 acc_train: 0.8143 loss_val: 1.0354 acc_val: 0.6667 time: 1.8835s\n",
            "loss_val:1.0354465246200562, val_acc:0.6666666666666666, out_features:tensor([[-1.0011e+01, -9.9804e+00, -2.5019e-03,  ..., -9.1483e+00,\n",
            "         -9.9923e+00, -9.6793e+00],\n",
            "        [-2.0956e+00, -2.9791e+00, -3.1021e+00,  ..., -1.8968e+00,\n",
            "         -1.0392e+00, -1.5201e+00],\n",
            "        [-7.3427e+00, -6.6550e+00, -7.2866e+00,  ..., -3.9841e-03,\n",
            "         -7.7237e+00, -7.7890e+00],\n",
            "        ...,\n",
            "        [-4.4746e+00, -1.2672e-01, -3.4131e+00,  ..., -3.2311e+00,\n",
            "         -4.4245e+00, -4.3042e+00],\n",
            "        [-5.2446e-02, -5.0848e+00, -5.5223e+00,  ..., -4.1515e+00,\n",
            "         -4.4847e+00, -4.8566e+00],\n",
            "        [-4.2069e+00, -4.7663e+00, -6.9535e-02,  ..., -4.8878e+00,\n",
            "         -4.2011e+00, -4.8631e+00]], grad_fn=<LogSoftmaxBackward0>)\n",
            "Training: 634\n",
            "Epoch: 0635 loss_train: 0.6459 acc_train: 0.8000 loss_val: 1.0987 acc_val: 0.6433 time: 1.9330s\n",
            "loss_val:1.0987132787704468, val_acc:0.6433333333333333, out_features:tensor([[-2.9000e+00, -2.9120e+00, -6.2942e-01,  ..., -2.4820e+00,\n",
            "         -2.7261e+00, -2.7458e+00],\n",
            "        [-4.2846e+00, -4.0884e+00, -4.6213e+00,  ..., -4.1428e+00,\n",
            "         -2.0679e-01, -2.1245e+00],\n",
            "        [-3.9581e+00, -3.2048e+00, -3.8874e+00,  ..., -1.6180e-01,\n",
            "         -3.9344e+00, -3.3239e+00],\n",
            "        ...,\n",
            "        [-2.6425e+00, -4.5691e-01, -2.8448e+00,  ..., -2.2644e+00,\n",
            "         -3.1139e+00, -3.0007e+00],\n",
            "        [-3.2015e-03, -7.0303e+00, -8.1886e+00,  ..., -8.1502e+00,\n",
            "         -6.7870e+00, -7.8960e+00],\n",
            "        [-8.8126e+00, -8.6988e+00, -9.7037e-04,  ..., -8.9787e+00,\n",
            "         -8.4444e+00, -8.4192e+00]], grad_fn=<LogSoftmaxBackward0>)\n",
            "Training: 635\n",
            "Epoch: 0636 loss_train: 0.5439 acc_train: 0.8286 loss_val: 0.9446 acc_val: 0.7133 time: 1.7351s\n",
            "loss_val:0.9445979595184326, val_acc:0.7133333333333334, out_features:tensor([[-3.6847e+00, -3.9704e+00, -3.4061e-01,  ..., -3.7080e+00,\n",
            "         -3.7749e+00, -2.4380e+00],\n",
            "        [-4.6296e+00, -6.1244e+00, -6.2397e+00,  ..., -5.0550e+00,\n",
            "         -1.0840e-01, -2.5231e+00],\n",
            "        [-9.4126e+00, -9.5726e+00, -9.9345e+00,  ..., -5.4809e-04,\n",
            "         -8.6462e+00, -8.9823e+00],\n",
            "        ...,\n",
            "        [-2.2463e+00, -8.5463e-01, -2.6756e+00,  ..., -2.1887e+00,\n",
            "         -1.9376e+00, -2.4452e+00],\n",
            "        [-5.4644e-02, -5.0245e+00, -5.4081e+00,  ..., -4.7832e+00,\n",
            "         -4.1811e+00, -5.2769e+00],\n",
            "        [-3.4537e+00, -2.6187e+00, -2.2485e-01,  ..., -3.8430e+00,\n",
            "         -3.8213e+00, -3.7454e+00]], grad_fn=<LogSoftmaxBackward0>)\n",
            "Training: 636\n",
            "Epoch: 0637 loss_train: 0.7003 acc_train: 0.8071 loss_val: 1.0699 acc_val: 0.6433 time: 1.7568s\n",
            "loss_val:1.0698710680007935, val_acc:0.6433333333333333, out_features:tensor([[-1.9459e+00, -1.9459e+00, -1.9459e+00,  ..., -1.9459e+00,\n",
            "         -1.9459e+00, -1.9459e+00],\n",
            "        [-2.5622e+00, -3.1624e+00, -2.4481e+00,  ..., -2.3474e+00,\n",
            "         -8.9696e-01, -1.3567e+00],\n",
            "        [-7.6171e+00, -7.5189e+00, -8.0720e+00,  ..., -2.1945e-03,\n",
            "         -8.1784e+00, -7.9894e+00],\n",
            "        ...,\n",
            "        [-2.1514e+00, -8.9596e-01, -2.8590e+00,  ..., -1.6770e+00,\n",
            "         -2.1470e+00, -2.7562e+00],\n",
            "        [-2.0885e-01, -3.9097e+00, -3.3318e+00,  ..., -3.5246e+00,\n",
            "         -3.3373e+00, -3.1573e+00],\n",
            "        [-3.8192e+00, -3.6190e+00, -5.3646e-01,  ..., -3.9068e+00,\n",
            "         -3.6475e+00, -3.0839e+00]], grad_fn=<LogSoftmaxBackward0>)\n",
            "Training: 637\n",
            "Epoch: 0638 loss_train: 0.6719 acc_train: 0.8286 loss_val: 1.0793 acc_val: 0.6300 time: 1.7411s\n",
            "loss_val:1.0792622566223145, val_acc:0.63, out_features:tensor([[-8.7932e+00, -8.7599e+00, -2.3926e-03,  ..., -8.2010e+00,\n",
            "         -8.7441e+00, -8.4509e+00],\n",
            "        [-5.2472e+00, -5.2010e+00, -3.7929e+00,  ..., -5.3679e+00,\n",
            "         -1.4394e-01, -2.5178e+00],\n",
            "        [-3.4023e+00, -4.2139e+00, -4.6790e+00,  ..., -1.3921e-01,\n",
            "         -4.2057e+00, -3.1750e+00],\n",
            "        ...,\n",
            "        [-6.8384e+00, -1.2937e-02, -6.7696e+00,  ..., -5.5858e+00,\n",
            "         -6.5993e+00, -6.7191e+00],\n",
            "        [-1.2749e-01, -4.2741e+00, -4.8191e+00,  ..., -2.6698e+00,\n",
            "         -4.2084e+00, -4.9600e+00],\n",
            "        [-6.7268e+00, -6.2763e+00, -6.3564e-03,  ..., -7.4993e+00,\n",
            "         -6.5564e+00, -7.3134e+00]], grad_fn=<LogSoftmaxBackward0>)\n",
            "Training: 638\n",
            "Epoch: 0639 loss_train: 0.6800 acc_train: 0.7929 loss_val: 1.0062 acc_val: 0.6567 time: 1.7452s\n",
            "loss_val:1.006152629852295, val_acc:0.6566666666666666, out_features:tensor([[-8.1485e+00, -8.1594e+00, -3.1537e-03,  ..., -7.2575e+00,\n",
            "         -7.7254e+00, -7.3181e+00],\n",
            "        [-1.9459e+00, -1.9459e+00, -1.9459e+00,  ..., -1.9459e+00,\n",
            "         -1.9459e+00, -1.9459e+00],\n",
            "        [-4.5228e+00, -2.9115e+00, -4.7762e+00,  ..., -1.0998e-01,\n",
            "         -4.5733e+00, -4.3795e+00],\n",
            "        ...,\n",
            "        [-4.3626e+00, -1.4311e-01, -4.1915e+00,  ..., -3.7627e+00,\n",
            "         -3.2101e+00, -3.5352e+00],\n",
            "        [-1.0079e+00, -2.5469e+00, -2.3920e+00,  ..., -1.9216e+00,\n",
            "         -2.1433e+00, -2.4475e+00],\n",
            "        [-1.9459e+00, -1.9459e+00, -1.9459e+00,  ..., -1.9459e+00,\n",
            "         -1.9459e+00, -1.9459e+00]], grad_fn=<LogSoftmaxBackward0>)\n",
            "Training: 639\n",
            "Epoch: 0640 loss_train: 0.6520 acc_train: 0.7929 loss_val: 1.0474 acc_val: 0.6867 time: 1.7381s\n",
            "loss_val:1.047389030456543, val_acc:0.6866666666666666, out_features:tensor([[-1.0394e+01, -1.0451e+01, -6.7676e-04,  ..., -9.1912e+00,\n",
            "         -1.0417e+01, -1.0318e+01],\n",
            "        [-1.9459e+00, -1.9459e+00, -1.9459e+00,  ..., -1.9459e+00,\n",
            "         -1.9459e+00, -1.9459e+00],\n",
            "        [-2.4199e+00, -1.9424e+00, -2.2409e+00,  ..., -9.8490e-01,\n",
            "         -2.2816e+00, -2.5263e+00],\n",
            "        ...,\n",
            "        [-3.7551e+00, -1.7072e-01, -4.1254e+00,  ..., -4.2614e+00,\n",
            "         -3.8212e+00, -2.6826e+00],\n",
            "        [-1.4266e-01, -4.4891e+00, -4.8818e+00,  ..., -4.0029e+00,\n",
            "         -2.5608e+00, -4.8204e+00],\n",
            "        [-7.6703e+00, -7.4768e+00, -2.6004e-03,  ..., -7.9598e+00,\n",
            "         -7.7450e+00, -7.6822e+00]], grad_fn=<LogSoftmaxBackward0>)\n",
            "Training: 640\n",
            "Epoch: 0641 loss_train: 0.6061 acc_train: 0.8643 loss_val: 1.1644 acc_val: 0.6433 time: 1.9064s\n",
            "loss_val:1.164365530014038, val_acc:0.6433333333333333, out_features:tensor([[-5.2135e+00, -5.1994e+00, -9.5441e-02,  ..., -5.1886e+00,\n",
            "         -5.0736e+00, -2.8712e+00],\n",
            "        [-1.2369e+00, -4.2190e+00, -4.5464e+00,  ..., -1.7493e+00,\n",
            "         -1.1866e+00, -1.6330e+00],\n",
            "        [-1.2213e+01, -1.1670e+01, -1.2519e+01,  ..., -2.7418e-05,\n",
            "         -1.2509e+01, -1.2634e+01],\n",
            "        ...,\n",
            "        [-3.6506e+00, -2.6866e-01, -4.0421e+00,  ..., -3.3916e+00,\n",
            "         -2.1895e+00, -3.5762e+00],\n",
            "        [-8.7080e-03, -6.6400e+00, -7.2254e+00,  ..., -6.7012e+00,\n",
            "         -5.6723e+00, -6.9459e+00],\n",
            "        [-1.9459e+00, -1.9459e+00, -1.9459e+00,  ..., -1.9459e+00,\n",
            "         -1.9459e+00, -1.9459e+00]], grad_fn=<LogSoftmaxBackward0>)\n",
            "Training: 641\n",
            "Epoch: 0642 loss_train: 0.5811 acc_train: 0.8286 loss_val: 1.0276 acc_val: 0.6733 time: 1.9711s\n",
            "loss_val:1.0275671482086182, val_acc:0.6733333333333333, out_features:tensor([[-8.1212e+00, -8.0468e+00, -3.5739e-03,  ..., -7.5882e+00,\n",
            "         -8.1385e+00, -7.6057e+00],\n",
            "        [-1.9459e+00, -1.9459e+00, -1.9459e+00,  ..., -1.9459e+00,\n",
            "         -1.9459e+00, -1.9459e+00],\n",
            "        [-3.4853e+00, -4.2695e+00, -2.8504e+00,  ..., -2.6564e-01,\n",
            "         -3.0834e+00, -2.6186e+00],\n",
            "        ...,\n",
            "        [-4.3232e+00, -2.0119e-01, -5.4562e+00,  ..., -5.2089e+00,\n",
            "         -4.4205e+00, -1.9505e+00],\n",
            "        [-1.3433e-01, -3.7257e+00, -3.9651e+00,  ..., -3.8029e+00,\n",
            "         -3.6350e+00, -4.2465e+00],\n",
            "        [-3.2241e+00, -2.7545e+00, -2.4983e-01,  ..., -3.0449e+00,\n",
            "         -3.6572e+00, -3.8747e+00]], grad_fn=<LogSoftmaxBackward0>)\n",
            "Training: 642\n",
            "Epoch: 0643 loss_train: 0.5325 acc_train: 0.8714 loss_val: 1.0345 acc_val: 0.6733 time: 1.7355s\n",
            "loss_val:1.0344988107681274, val_acc:0.6733333333333333, out_features:tensor([[-1.1774e+01, -1.1760e+01, -1.4614e-04,  ..., -1.1378e+01,\n",
            "         -1.1694e+01, -1.1556e+01],\n",
            "        [-1.9459e+00, -1.9459e+00, -1.9459e+00,  ..., -1.9459e+00,\n",
            "         -1.9459e+00, -1.9459e+00],\n",
            "        [-2.5575e+00, -2.4421e+00, -2.1529e+00,  ..., -1.0211e+00,\n",
            "         -2.3606e+00, -1.8451e+00],\n",
            "        ...,\n",
            "        [-3.3604e+00, -1.0509e-01, -5.5386e+00,  ..., -3.4336e+00,\n",
            "         -3.9889e+00, -5.0220e+00],\n",
            "        [-4.6476e-01, -3.3083e+00, -2.9046e+00,  ..., -2.8180e+00,\n",
            "         -2.1084e+00, -2.7548e+00],\n",
            "        [-4.2917e+00, -3.2076e+00, -1.2398e-01,  ..., -4.3068e+00,\n",
            "         -4.5283e+00, -4.3174e+00]], grad_fn=<LogSoftmaxBackward0>)\n",
            "Training: 643\n",
            "Epoch: 0644 loss_train: 0.6050 acc_train: 0.8143 loss_val: 0.9939 acc_val: 0.6967 time: 1.7283s\n",
            "loss_val:0.9939215183258057, val_acc:0.6966666666666667, out_features:tensor([[-6.2795e+00, -6.1473e+00, -4.2920e-02,  ..., -5.2090e+00,\n",
            "         -6.2692e+00, -4.2802e+00],\n",
            "        [-8.7603e-01, -5.1811e+00, -5.3137e+00,  ..., -1.1614e+00,\n",
            "         -2.1299e+00, -1.9886e+00],\n",
            "        [-8.7763e+00, -9.0907e+00, -9.1506e+00,  ..., -7.0130e-04,\n",
            "         -9.0283e+00, -9.0622e+00],\n",
            "        ...,\n",
            "        [-2.6846e+00, -2.1167e-01, -3.1832e+00,  ..., -3.8357e+00,\n",
            "         -3.7652e+00, -4.0375e+00],\n",
            "        [-1.2876e+00, -2.1197e+00, -2.5366e+00,  ..., -2.1728e+00,\n",
            "         -1.9165e+00, -1.9106e+00],\n",
            "        [-4.1348e+00, -5.5253e+00, -4.8372e-02,  ..., -5.1776e+00,\n",
            "         -5.1938e+00, -5.0652e+00]], grad_fn=<LogSoftmaxBackward0>)\n",
            "Training: 644\n",
            "Epoch: 0645 loss_train: 0.5394 acc_train: 0.8571 loss_val: 1.0910 acc_val: 0.6367 time: 1.7482s\n",
            "loss_val:1.0909814834594727, val_acc:0.6366666666666667, out_features:tensor([[-1.0902e+01, -1.0866e+01, -8.0613e-04,  ..., -1.0582e+01,\n",
            "         -1.0923e+01, -1.0710e+01],\n",
            "        [-1.8251e+00, -3.2786e+00, -3.2127e+00,  ..., -2.8125e+00,\n",
            "         -8.5315e-01, -1.4209e+00],\n",
            "        [-5.2363e+00, -4.5029e+00, -5.6720e+00,  ..., -3.4059e-02,\n",
            "         -5.4353e+00, -5.5952e+00],\n",
            "        ...,\n",
            "        [-4.4809e+00, -1.0778e-01, -4.9174e+00,  ..., -2.8651e+00,\n",
            "         -4.5184e+00, -4.7534e+00],\n",
            "        [-9.2101e-02, -4.6113e+00, -4.5715e+00,  ..., -3.9246e+00,\n",
            "         -3.8055e+00, -4.2913e+00],\n",
            "        [-3.1390e+00, -3.9893e+00, -1.4507e-01,  ..., -4.3284e+00,\n",
            "         -3.9422e+00, -3.7087e+00]], grad_fn=<LogSoftmaxBackward0>)\n",
            "Training: 645\n",
            "Epoch: 0646 loss_train: 0.7279 acc_train: 0.7786 loss_val: 1.0329 acc_val: 0.6733 time: 1.7475s\n",
            "loss_val:1.0328902006149292, val_acc:0.6733333333333333, out_features:tensor([[-1.9459, -1.9459, -1.9459,  ..., -1.9459, -1.9459, -1.9459],\n",
            "        [-2.8320, -5.1509, -5.1393,  ..., -4.9626, -0.1843, -2.4778],\n",
            "        [-1.9459, -1.9459, -1.9459,  ..., -1.9459, -1.9459, -1.9459],\n",
            "        ...,\n",
            "        [-4.9783, -0.0678, -5.0491,  ..., -3.4389, -4.9446, -5.0533],\n",
            "        [-0.2611, -3.6087, -3.4730,  ..., -2.7378, -3.3033, -3.4203],\n",
            "        [-3.4153, -3.5202, -0.2619,  ..., -2.9375, -3.3391, -3.5278]],\n",
            "       grad_fn=<LogSoftmaxBackward0>)\n",
            "Training: 646\n",
            "Epoch: 0647 loss_train: 0.6544 acc_train: 0.8214 loss_val: 1.0836 acc_val: 0.6767 time: 1.7331s\n",
            "loss_val:1.0836316347122192, val_acc:0.6766666666666666, out_features:tensor([[-5.9719, -6.1071, -0.0466,  ..., -5.9207, -5.8236, -4.4464],\n",
            "        [-1.9459, -1.9459, -1.9459,  ..., -1.9459, -1.9459, -1.9459],\n",
            "        [-2.5303, -3.9793, -3.5461,  ..., -0.2057, -3.6696, -4.0829],\n",
            "        ...,\n",
            "        [-5.8316, -0.0568, -5.6538,  ..., -3.3042, -5.5179, -5.4668],\n",
            "        [-0.7781, -2.8926, -2.9454,  ..., -2.2446, -1.8385, -2.1949],\n",
            "        [-2.3049, -2.2849, -0.9268,  ..., -3.2258, -2.5659, -1.7171]],\n",
            "       grad_fn=<LogSoftmaxBackward0>)\n",
            "Training: 647\n",
            "Epoch: 0648 loss_train: 0.6967 acc_train: 0.8000 loss_val: 1.0737 acc_val: 0.6233 time: 1.8905s\n",
            "loss_val:1.0736572742462158, val_acc:0.6233333333333333, out_features:tensor([[-8.4186e+00, -8.0233e+00, -1.9291e-03,  ..., -8.2046e+00,\n",
            "         -7.9876e+00, -7.7592e+00],\n",
            "        [-1.9459e+00, -1.9459e+00, -1.9459e+00,  ..., -1.9459e+00,\n",
            "         -1.9459e+00, -1.9459e+00],\n",
            "        [-1.1173e+01, -1.1966e+01, -1.1990e+01,  ..., -8.2370e-05,\n",
            "         -1.2001e+01, -1.0031e+01],\n",
            "        ...,\n",
            "        [-2.7919e+00, -6.4522e-01, -2.8158e+00,  ..., -2.8180e+00,\n",
            "         -2.5382e+00, -1.9573e+00],\n",
            "        [-9.2535e-02, -4.6509e+00, -4.8762e+00,  ..., -3.5195e+00,\n",
            "         -4.1886e+00, -4.7475e+00],\n",
            "        [-3.3744e+00, -5.0689e+00, -8.9100e-02,  ..., -5.0334e+00,\n",
            "         -3.9581e+00, -4.8566e+00]], grad_fn=<LogSoftmaxBackward0>)\n",
            "Training: 648\n",
            "Epoch: 0649 loss_train: 0.5893 acc_train: 0.8429 loss_val: 1.0716 acc_val: 0.6433 time: 1.9642s\n",
            "loss_val:1.0715967416763306, val_acc:0.6433333333333333, out_features:tensor([[-7.6003e+00, -7.6059e+00, -4.9142e-03,  ..., -7.0807e+00,\n",
            "         -7.0689e+00, -6.7218e+00],\n",
            "        [-1.9459e+00, -1.9459e+00, -1.9459e+00,  ..., -1.9459e+00,\n",
            "         -1.9459e+00, -1.9459e+00],\n",
            "        [-1.9459e+00, -1.9459e+00, -1.9459e+00,  ..., -1.9459e+00,\n",
            "         -1.9459e+00, -1.9459e+00],\n",
            "        ...,\n",
            "        [-2.7204e+00, -3.5364e-01, -3.4572e+00,  ..., -2.7817e+00,\n",
            "         -3.1309e+00, -3.0666e+00],\n",
            "        [-8.2785e-01, -2.7449e+00, -2.1653e+00,  ..., -2.2239e+00,\n",
            "         -2.1482e+00, -2.2961e+00],\n",
            "        [-6.9236e+00, -6.5044e+00, -1.5447e-02,  ..., -6.8904e+00,\n",
            "         -6.9204e+00, -6.6475e+00]], grad_fn=<LogSoftmaxBackward0>)\n",
            "Training: 649\n",
            "Epoch: 0650 loss_train: 0.7706 acc_train: 0.7571 loss_val: 1.0292 acc_val: 0.6767 time: 1.7515s\n",
            "loss_val:1.0291584730148315, val_acc:0.6766666666666666, out_features:tensor([[-2.6709, -2.8276, -0.8789,  ..., -2.2861, -2.4467, -2.1312],\n",
            "        [-8.0536, -8.2466, -8.8566,  ..., -7.1339, -0.0111, -4.6748],\n",
            "        [-5.9126, -5.5446, -5.7144,  ..., -0.0148, -6.4902, -6.2390],\n",
            "        ...,\n",
            "        [-6.4458, -0.0128, -6.3615,  ..., -5.3545, -6.3141, -6.4450],\n",
            "        [-0.2345, -4.2617, -4.1339,  ..., -2.5022, -2.7223, -3.8946],\n",
            "        [-1.9459, -1.9459, -1.9459,  ..., -1.9459, -1.9459, -1.9459]],\n",
            "       grad_fn=<LogSoftmaxBackward0>)\n",
            "Training: 650\n",
            "Epoch: 0651 loss_train: 0.6175 acc_train: 0.8286 loss_val: 1.0549 acc_val: 0.6667 time: 1.7343s\n",
            "loss_val:1.0548641681671143, val_acc:0.6666666666666666, out_features:tensor([[-1.9459e+00, -1.9459e+00, -1.9459e+00,  ..., -1.9459e+00,\n",
            "         -1.9459e+00, -1.9459e+00],\n",
            "        [-1.9459e+00, -1.9459e+00, -1.9459e+00,  ..., -1.9459e+00,\n",
            "         -1.9459e+00, -1.9459e+00],\n",
            "        [-3.2574e+00, -2.4742e+00, -3.5387e+00,  ..., -2.7386e-01,\n",
            "         -3.3751e+00, -3.4335e+00],\n",
            "        ...,\n",
            "        [-2.2050e+00, -1.5264e+00, -1.6109e+00,  ..., -2.3549e+00,\n",
            "         -2.3677e+00, -1.9746e+00],\n",
            "        [-3.3972e-01, -3.0286e+00, -3.0891e+00,  ..., -3.0058e+00,\n",
            "         -2.9052e+00, -2.8496e+00],\n",
            "        [-1.2152e+01, -1.0616e+01, -7.7602e-05,  ..., -1.0368e+01,\n",
            "         -1.2114e+01, -1.2139e+01]], grad_fn=<LogSoftmaxBackward0>)\n",
            "Training: 651\n",
            "Epoch: 0652 loss_train: 0.6290 acc_train: 0.7857 loss_val: 0.9786 acc_val: 0.6900 time: 1.7363s\n",
            "loss_val:0.9785673022270203, val_acc:0.69, out_features:tensor([[-9.5571e+00, -9.6460e+00, -1.3541e-03,  ..., -8.8942e+00,\n",
            "         -9.6467e+00, -8.1444e+00],\n",
            "        [-1.9459e+00, -1.9459e+00, -1.9459e+00,  ..., -1.9459e+00,\n",
            "         -1.9459e+00, -1.9459e+00],\n",
            "        [-4.5831e+00, -4.5683e+00, -2.1633e+00,  ..., -1.9223e-01,\n",
            "         -4.0473e+00, -4.5451e+00],\n",
            "        ...,\n",
            "        [-7.7003e+00, -9.5984e-03, -7.6164e+00,  ..., -4.9614e+00,\n",
            "         -7.3073e+00, -7.5969e+00],\n",
            "        [-7.4993e-01, -2.3609e+00, -3.2636e+00,  ..., -2.8701e+00,\n",
            "         -2.3439e+00, -1.6602e+00],\n",
            "        [-1.9459e+00, -1.9459e+00, -1.9459e+00,  ..., -1.9459e+00,\n",
            "         -1.9459e+00, -1.9459e+00]], grad_fn=<LogSoftmaxBackward0>)\n",
            "Training: 652\n",
            "Epoch: 0653 loss_train: 0.6924 acc_train: 0.7643 loss_val: 0.9878 acc_val: 0.6633 time: 1.7454s\n",
            "loss_val:0.9878020286560059, val_acc:0.6633333333333333, out_features:tensor([[-2.7041, -2.6498, -0.7418,  ..., -1.7907, -2.6120, -2.9090],\n",
            "        [-4.9901, -6.3166, -3.9285,  ..., -5.4253, -0.0358, -6.6662],\n",
            "        [-1.9459, -1.9459, -1.9459,  ..., -1.9459, -1.9459, -1.9459],\n",
            "        ...,\n",
            "        [-3.0507, -0.3623, -3.7332,  ..., -2.8661, -2.3913, -2.8153],\n",
            "        [-0.0618, -4.4360, -4.9905,  ..., -4.6115, -4.2415, -4.5760],\n",
            "        [-1.9459, -1.9459, -1.9459,  ..., -1.9459, -1.9459, -1.9459]],\n",
            "       grad_fn=<LogSoftmaxBackward0>)\n",
            "Training: 653\n",
            "Epoch: 0654 loss_train: 0.6686 acc_train: 0.8214 loss_val: 0.9704 acc_val: 0.6867 time: 1.7545s\n",
            "loss_val:0.9703797698020935, val_acc:0.6866666666666666, out_features:tensor([[-1.1659e+01, -1.1651e+01, -4.0737e-04,  ..., -1.0830e+01,\n",
            "         -1.1628e+01, -1.1125e+01],\n",
            "        [-4.8718e+00, -7.7888e+00, -5.8572e+00,  ..., -7.1602e+00,\n",
            "         -1.4910e-02, -5.9230e+00],\n",
            "        [-5.1579e+00, -4.8303e+00, -5.5604e+00,  ..., -3.6397e-02,\n",
            "         -5.4208e+00, -5.2508e+00],\n",
            "        ...,\n",
            "        [-3.2088e+00, -2.4982e-01, -3.5678e+00,  ..., -3.2676e+00,\n",
            "         -2.7849e+00, -3.5446e+00],\n",
            "        [-1.2948e-01, -4.5238e+00, -4.9308e+00,  ..., -2.9886e+00,\n",
            "         -3.6918e+00, -4.4550e+00],\n",
            "        [-2.1706e+00, -2.4296e+00, -1.2328e+00,  ..., -2.5457e+00,\n",
            "         -2.3237e+00, -1.7452e+00]], grad_fn=<LogSoftmaxBackward0>)\n",
            "Training: 654\n",
            "Epoch: 0655 loss_train: 0.6564 acc_train: 0.8143 loss_val: 1.1334 acc_val: 0.6633 time: 1.8589s\n",
            "loss_val:1.1333752870559692, val_acc:0.6633333333333333, out_features:tensor([[-1.0389e+01, -1.0299e+01, -3.0179e-04,  ..., -9.8885e+00,\n",
            "         -1.0086e+01, -9.1256e+00],\n",
            "        [-4.5472e+00, -5.7297e+00, -5.2163e+00,  ..., -5.4403e+00,\n",
            "         -2.5128e-01, -1.6514e+00],\n",
            "        [-4.1948e+00, -4.3477e+00, -3.9892e+00,  ..., -1.3277e-01,\n",
            "         -4.2439e+00, -2.9019e+00],\n",
            "        ...,\n",
            "        [-2.3653e+00, -8.9036e-01, -2.1225e+00,  ..., -2.2801e+00,\n",
            "         -2.5471e+00, -2.1805e+00],\n",
            "        [-3.3853e-02, -5.5560e+00, -5.8226e+00,  ..., -4.8350e+00,\n",
            "         -4.3325e+00, -5.8359e+00],\n",
            "        [-4.8295e+00, -3.5842e+00, -1.0911e-01,  ..., -3.3691e+00,\n",
            "         -4.2920e+00, -4.6945e+00]], grad_fn=<LogSoftmaxBackward0>)\n",
            "Training: 655\n",
            "Epoch: 0656 loss_train: 0.6073 acc_train: 0.8429 loss_val: 1.0113 acc_val: 0.6633 time: 1.9838s\n",
            "loss_val:1.0112910270690918, val_acc:0.6633333333333333, out_features:tensor([[-2.2562, -2.3870, -1.1896,  ..., -2.1215, -2.4398, -2.1820],\n",
            "        [-1.9459, -1.9459, -1.9459,  ..., -1.9459, -1.9459, -1.9459],\n",
            "        [-2.4441, -2.9219, -2.8216,  ..., -0.5104, -2.6761, -2.7820],\n",
            "        ...,\n",
            "        [-3.0860, -0.6221, -3.3374,  ..., -1.6867, -2.6705, -3.0685],\n",
            "        [-0.4087, -3.4982, -3.2019,  ..., -2.4389, -2.2371, -3.3344],\n",
            "        [-1.9721, -1.7543, -1.1958,  ..., -2.0284, -2.5395, -2.5106]],\n",
            "       grad_fn=<LogSoftmaxBackward0>)\n",
            "Training: 656\n",
            "Epoch: 0657 loss_train: 0.5935 acc_train: 0.8143 loss_val: 1.0185 acc_val: 0.6433 time: 1.7451s\n",
            "loss_val:1.0185039043426514, val_acc:0.6433333333333333, out_features:tensor([[-9.7527e+00, -9.6455e+00, -5.3439e-04,  ..., -9.6039e+00,\n",
            "         -8.7835e+00, -9.2232e+00],\n",
            "        [-3.7267e+00, -5.9185e+00, -5.9655e+00,  ..., -4.6420e+00,\n",
            "         -7.4589e-01, -7.2842e-01],\n",
            "        [-3.9185e+00, -3.8222e+00, -3.3128e+00,  ..., -1.5656e-01,\n",
            "         -3.6227e+00, -3.9116e+00],\n",
            "        ...,\n",
            "        [-6.3710e+00, -1.0249e-02, -7.0228e+00,  ..., -6.4485e+00,\n",
            "         -5.5490e+00, -6.7453e+00],\n",
            "        [-2.8628e-01, -3.7164e+00, -3.8483e+00,  ..., -2.1700e+00,\n",
            "         -2.9352e+00, -3.9781e+00],\n",
            "        [-2.9290e+00, -2.3864e+00, -4.4977e-01,  ..., -2.5958e+00,\n",
            "         -3.1090e+00, -3.1419e+00]], grad_fn=<LogSoftmaxBackward0>)\n",
            "Training: 657\n",
            "Epoch: 0658 loss_train: 0.5550 acc_train: 0.8214 loss_val: 1.0116 acc_val: 0.6667 time: 1.7575s\n",
            "loss_val:1.011573076248169, val_acc:0.6666666666666666, out_features:tensor([[-3.7518e+00, -3.6909e+00, -3.3378e-01,  ..., -3.2661e+00,\n",
            "         -3.8111e+00, -2.3391e+00],\n",
            "        [-1.9459e+00, -1.9459e+00, -1.9459e+00,  ..., -1.9459e+00,\n",
            "         -1.9459e+00, -1.9459e+00],\n",
            "        [-9.9684e+00, -1.1297e+01, -1.1777e+01,  ..., -9.1668e-05,\n",
            "         -1.1326e+01, -1.1947e+01],\n",
            "        ...,\n",
            "        [-2.6678e+00, -5.1886e-01, -3.0614e+00,  ..., -3.0282e+00,\n",
            "         -2.8669e+00, -2.4299e+00],\n",
            "        [-3.0536e-02, -5.8528e+00, -5.8319e+00,  ..., -6.0307e+00,\n",
            "         -4.3119e+00, -5.0554e+00],\n",
            "        [-3.1210e+00, -2.9011e+00, -6.1954e-01,  ..., -2.7330e+00,\n",
            "         -3.1663e+00, -1.8937e+00]], grad_fn=<LogSoftmaxBackward0>)\n",
            "Training: 658\n",
            "Epoch: 0659 loss_train: 0.5769 acc_train: 0.8429 loss_val: 1.1114 acc_val: 0.6200 time: 1.7498s\n",
            "loss_val:1.1114320755004883, val_acc:0.62, out_features:tensor([[-8.4032e+00, -9.8905e+00, -5.1735e-04,  ..., -9.8298e+00,\n",
            "         -9.4648e+00, -9.7448e+00],\n",
            "        [-1.9808e+00, -2.5773e+00, -2.4651e+00,  ..., -3.0354e+00,\n",
            "         -1.1879e+00, -1.2087e+00],\n",
            "        [-2.6034e+00, -2.5784e+00, -3.0037e+00,  ..., -4.6400e-01,\n",
            "         -2.7361e+00, -2.7569e+00],\n",
            "        ...,\n",
            "        [-2.3321e+00, -7.8792e-01, -2.2318e+00,  ..., -2.6368e+00,\n",
            "         -2.1280e+00, -2.4253e+00],\n",
            "        [-4.3494e-02, -5.0547e+00, -5.5922e+00,  ..., -4.0452e+00,\n",
            "         -4.9946e+00, -5.5001e+00],\n",
            "        [-5.3014e+00, -5.4655e+00, -4.8612e-02,  ..., -4.0457e+00,\n",
            "         -4.9864e+00, -5.2884e+00]], grad_fn=<LogSoftmaxBackward0>)\n",
            "Training: 659\n",
            "Epoch: 0660 loss_train: 0.6388 acc_train: 0.8143 loss_val: 0.9951 acc_val: 0.6667 time: 1.7471s\n",
            "loss_val:0.9951173663139343, val_acc:0.6666666666666666, out_features:tensor([[-3.0432e+00, -3.5965e+00, -2.6594e-01,  ..., -3.4421e+00,\n",
            "         -3.4128e+00, -3.2378e+00],\n",
            "        [-1.6166e+00, -3.4839e+00, -3.1245e+00,  ..., -2.0786e+00,\n",
            "         -9.3344e-01, -1.7127e+00],\n",
            "        [-3.2115e+00, -2.6107e+00, -3.0962e+00,  ..., -3.7308e-01,\n",
            "         -3.3835e+00, -2.5909e+00],\n",
            "        ...,\n",
            "        [-2.7180e+00, -8.1054e-01, -2.4701e+00,  ..., -2.6863e+00,\n",
            "         -2.1810e+00, -2.0525e+00],\n",
            "        [-3.8229e-02, -4.7095e+00, -5.4614e+00,  ..., -4.9914e+00,\n",
            "         -5.0076e+00, -5.5987e+00],\n",
            "        [-1.4881e+01, -1.4529e+01, -2.5034e-06,  ..., -1.4941e+01,\n",
            "         -1.4712e+01, -1.4602e+01]], grad_fn=<LogSoftmaxBackward0>)\n",
            "Training: 660\n",
            "Epoch: 0661 loss_train: 0.6349 acc_train: 0.8214 loss_val: 1.0175 acc_val: 0.7033 time: 1.7432s\n",
            "loss_val:1.0175096988677979, val_acc:0.7033333333333334, out_features:tensor([[-2.6480e+00, -2.4180e+00, -7.5705e-01,  ..., -2.3248e+00,\n",
            "         -2.0359e+00, -2.6255e+00],\n",
            "        [-5.1925e+00, -4.9687e+00, -5.0267e+00,  ..., -1.5359e+00,\n",
            "         -2.8576e-01, -4.6151e+00],\n",
            "        [-9.1588e+00, -9.6645e+00, -9.9974e+00,  ..., -2.7772e-04,\n",
            "         -1.0721e+01, -1.0768e+01],\n",
            "        ...,\n",
            "        [-1.0083e+01, -5.2641e-04, -1.0354e+01,  ..., -8.9728e+00,\n",
            "         -8.3638e+00, -9.7043e+00],\n",
            "        [-8.4690e-01, -2.9093e+00, -2.5123e+00,  ..., -1.8310e+00,\n",
            "         -2.0077e+00, -2.5312e+00],\n",
            "        [-1.9459e+00, -1.9459e+00, -1.9459e+00,  ..., -1.9459e+00,\n",
            "         -1.9459e+00, -1.9459e+00]], grad_fn=<LogSoftmaxBackward0>)\n",
            "Training: 661\n",
            "Epoch: 0662 loss_train: 0.6196 acc_train: 0.8143 loss_val: 1.1738 acc_val: 0.6267 time: 1.8658s\n",
            "loss_val:1.1737874746322632, val_acc:0.6266666666666667, out_features:tensor([[-5.5847, -5.6646, -0.0443,  ..., -5.4394, -5.2737, -4.4991],\n",
            "        [-2.1338, -3.3124, -2.9762,  ..., -2.5297, -1.1031, -1.0447],\n",
            "        [-4.4088, -3.7691, -4.2899,  ..., -0.0848, -4.3153, -4.4744],\n",
            "        ...,\n",
            "        [-1.7682, -1.8760, -1.6685,  ..., -2.2888, -2.0687, -1.9511],\n",
            "        [-0.9068, -2.0419, -2.8755,  ..., -1.9627, -2.2667, -2.5392],\n",
            "        [-3.4610, -3.1557, -0.4992,  ..., -3.4563, -3.0929, -2.9374]],\n",
            "       grad_fn=<LogSoftmaxBackward0>)\n",
            "Training: 662\n",
            "Epoch: 0663 loss_train: 0.5426 acc_train: 0.8571 loss_val: 1.0864 acc_val: 0.6567 time: 1.9818s\n",
            "loss_val:1.0863991975784302, val_acc:0.6566666666666666, out_features:tensor([[-4.7138e+00, -4.8267e+00, -9.4077e-02,  ..., -3.8537e+00,\n",
            "         -4.5416e+00, -3.5190e+00],\n",
            "        [-1.9459e+00, -1.9459e+00, -1.9459e+00,  ..., -1.9459e+00,\n",
            "         -1.9459e+00, -1.9459e+00],\n",
            "        [-2.7979e+00, -2.8113e+00, -2.1174e+00,  ..., -5.2680e-01,\n",
            "         -2.5450e+00, -3.0619e+00],\n",
            "        ...,\n",
            "        [-5.8369e+00, -1.3626e-02, -6.6880e+00,  ..., -5.1606e+00,\n",
            "         -6.5549e+00, -6.7158e+00],\n",
            "        [-1.2903e+00, -2.4816e+00, -2.3205e+00,  ..., -1.5810e+00,\n",
            "         -1.8813e+00, -2.3204e+00],\n",
            "        [-1.1634e+01, -1.1724e+01, -5.4716e-05,  ..., -1.1403e+01,\n",
            "         -1.1390e+01, -1.1749e+01]], grad_fn=<LogSoftmaxBackward0>)\n",
            "Training: 663\n",
            "Epoch: 0664 loss_train: 0.6104 acc_train: 0.8000 loss_val: 1.0207 acc_val: 0.6733 time: 1.7480s\n",
            "loss_val:1.0207339525222778, val_acc:0.6733333333333333, out_features:tensor([[-5.5976, -5.3196, -0.0331,  ..., -5.0831, -5.3644, -5.2499],\n",
            "        [-0.9680, -2.3394, -3.2447,  ..., -3.2636, -1.1284, -2.3177],\n",
            "        [-2.4924, -2.5091, -1.8721,  ..., -0.8695, -2.3078, -2.4833],\n",
            "        ...,\n",
            "        [-1.9459, -1.9459, -1.9459,  ..., -1.9459, -1.9459, -1.9459],\n",
            "        [-0.2545, -3.9356, -3.5160,  ..., -3.2546, -2.6612, -3.2220],\n",
            "        [-7.6629, -7.8045, -0.0085,  ..., -7.8252, -7.4592, -5.1010]],\n",
            "       grad_fn=<LogSoftmaxBackward0>)\n",
            "Training: 664\n",
            "Epoch: 0665 loss_train: 0.5017 acc_train: 0.8714 loss_val: 1.0163 acc_val: 0.6600 time: 1.7461s\n",
            "loss_val:1.0162949562072754, val_acc:0.66, out_features:tensor([[-7.4918e+00, -7.2648e+00, -4.9178e-03,  ..., -6.8756e+00,\n",
            "         -7.5130e+00, -7.5022e+00],\n",
            "        [-4.8528e+00, -4.9064e+00, -5.1785e+00,  ..., -3.7684e+00,\n",
            "         -8.5061e-01, -7.2958e-01],\n",
            "        [-2.7992e+00, -2.3663e+00, -2.1538e+00,  ..., -6.7838e-01,\n",
            "         -2.7032e+00, -2.2730e+00],\n",
            "        ...,\n",
            "        [-4.0886e+00, -1.2186e-01, -4.5812e+00,  ..., -3.4221e+00,\n",
            "         -3.7029e+00, -3.8943e+00],\n",
            "        [-3.1173e-01, -3.2684e+00, -3.8575e+00,  ..., -2.8041e+00,\n",
            "         -2.7892e+00, -2.7502e+00],\n",
            "        [-6.3363e+00, -7.8420e+00, -3.7720e-03,  ..., -8.0220e+00,\n",
            "         -7.3783e+00, -7.9725e+00]], grad_fn=<LogSoftmaxBackward0>)\n",
            "Training: 665\n",
            "Epoch: 0666 loss_train: 0.5906 acc_train: 0.8643 loss_val: 1.1242 acc_val: 0.6300 time: 1.7421s\n",
            "loss_val:1.124192237854004, val_acc:0.63, out_features:tensor([[-9.4874e+00, -9.4216e+00, -1.6003e-03,  ..., -6.9354e+00,\n",
            "         -9.4115e+00, -8.6113e+00],\n",
            "        [-2.1775e+00, -2.5452e+00, -2.9892e+00,  ..., -1.5106e+00,\n",
            "         -1.2366e+00, -2.6074e+00],\n",
            "        [-8.0340e+00, -7.5371e+00, -8.2519e+00,  ..., -2.4256e-03,\n",
            "         -7.6147e+00, -7.4980e+00],\n",
            "        ...,\n",
            "        [-2.7594e+00, -8.1326e-01, -2.8173e+00,  ..., -2.4153e+00,\n",
            "         -2.7161e+00, -1.6709e+00],\n",
            "        [-2.6538e-01, -2.9068e+00, -3.9367e+00,  ..., -2.8203e+00,\n",
            "         -3.1063e+00, -3.3786e+00],\n",
            "        [-2.1837e+00, -2.2354e+00, -8.0019e-01,  ..., -3.0139e+00,\n",
            "         -2.0988e+00, -2.6822e+00]], grad_fn=<LogSoftmaxBackward0>)\n",
            "Training: 666\n",
            "Epoch: 0667 loss_train: 0.6605 acc_train: 0.7929 loss_val: 1.0548 acc_val: 0.6567 time: 1.7541s\n",
            "loss_val:1.0547603368759155, val_acc:0.6566666666666666, out_features:tensor([[-1.0814e+01, -1.0859e+01, -1.7045e-04,  ..., -1.0535e+01,\n",
            "         -1.0765e+01, -1.0376e+01],\n",
            "        [-1.7667e+00, -2.5337e+00, -2.3536e+00,  ..., -2.2741e+00,\n",
            "         -1.2629e+00, -1.5730e+00],\n",
            "        [-6.4988e+00, -6.9903e+00, -6.7978e+00,  ..., -8.0809e-03,\n",
            "         -6.8901e+00, -5.8910e+00],\n",
            "        ...,\n",
            "        [-1.4891e+00, -1.2720e+00, -1.6937e+00,  ..., -2.6785e+00,\n",
            "         -2.5759e+00, -2.1849e+00],\n",
            "        [-1.0222e+00, -1.9301e+00, -2.6784e+00,  ..., -1.8263e+00,\n",
            "         -1.8904e+00, -2.8257e+00],\n",
            "        [-1.9459e+00, -1.9459e+00, -1.9459e+00,  ..., -1.9459e+00,\n",
            "         -1.9459e+00, -1.9459e+00]], grad_fn=<LogSoftmaxBackward0>)\n",
            "Training: 667\n",
            "Epoch: 0668 loss_train: 0.6153 acc_train: 0.8286 loss_val: 1.0526 acc_val: 0.6800 time: 1.7489s\n",
            "loss_val:1.0525959730148315, val_acc:0.68, out_features:tensor([[-1.1877e+01, -1.1904e+01, -1.4769e-04,  ..., -1.1651e+01,\n",
            "         -1.1885e+01, -1.1783e+01],\n",
            "        [-1.9459e+00, -1.9459e+00, -1.9459e+00,  ..., -1.9459e+00,\n",
            "         -1.9459e+00, -1.9459e+00],\n",
            "        [-3.2044e+00, -4.5251e+00, -4.2100e+00,  ..., -1.3626e-01,\n",
            "         -4.2969e+00, -4.1363e+00],\n",
            "        ...,\n",
            "        [-6.5606e+00, -1.4589e-02, -6.8337e+00,  ..., -5.0725e+00,\n",
            "         -6.0093e+00, -6.1317e+00],\n",
            "        [-2.2703e-03, -8.2945e+00, -8.3034e+00,  ..., -7.6472e+00,\n",
            "         -7.2349e+00, -8.0353e+00],\n",
            "        [-5.9870e+00, -5.5496e+00, -2.4125e-02,  ..., -4.8601e+00,\n",
            "         -5.5893e+00, -5.6721e+00]], grad_fn=<LogSoftmaxBackward0>)\n",
            "Training: 668\n",
            "Epoch: 0669 loss_train: 0.4848 acc_train: 0.8500 loss_val: 0.9343 acc_val: 0.7233 time: 1.8660s\n",
            "loss_val:0.9342654347419739, val_acc:0.7233333333333334, out_features:tensor([[-4.8045, -5.1415, -0.0502,  ..., -4.5986, -5.3181, -5.2755],\n",
            "        [-1.9459, -1.9459, -1.9459,  ..., -1.9459, -1.9459, -1.9459],\n",
            "        [-2.0824, -2.1361, -2.5069,  ..., -0.9785, -2.5226, -2.1570],\n",
            "        ...,\n",
            "        [-4.9787, -0.0667, -4.9245,  ..., -4.9241, -4.2145, -3.9589],\n",
            "        [-0.0258, -5.5279, -5.8477,  ..., -5.2110, -4.8670, -5.8587],\n",
            "        [-3.5202, -2.7029, -0.2863,  ..., -3.7190, -2.8854, -3.0374]],\n",
            "       grad_fn=<LogSoftmaxBackward0>)\n",
            "Training: 669\n",
            "Epoch: 0670 loss_train: 0.6400 acc_train: 0.8143 loss_val: 1.0486 acc_val: 0.6700 time: 1.9837s\n",
            "loss_val:1.0486326217651367, val_acc:0.67, out_features:tensor([[-9.1254e+00, -9.1512e+00, -1.6323e-03,  ..., -9.0285e+00,\n",
            "         -9.2064e+00, -9.0722e+00],\n",
            "        [-1.4546e+00, -3.4166e+00, -3.3897e+00,  ..., -2.5675e+00,\n",
            "         -7.8175e-01, -1.9661e+00],\n",
            "        [-1.9459e+00, -1.9459e+00, -1.9459e+00,  ..., -1.9459e+00,\n",
            "         -1.9459e+00, -1.9459e+00],\n",
            "        ...,\n",
            "        [-3.2964e+00, -4.5303e-01, -1.9278e+00,  ..., -3.1833e+00,\n",
            "         -2.7187e+00, -3.4231e+00],\n",
            "        [-1.3594e+00, -2.6218e+00, -1.6733e+00,  ..., -2.0483e+00,\n",
            "         -2.1301e+00, -2.4898e+00],\n",
            "        [-7.9999e+00, -7.9614e+00, -1.9164e-03,  ..., -7.4905e+00,\n",
            "         -8.5230e+00, -8.4731e+00]], grad_fn=<LogSoftmaxBackward0>)\n",
            "Training: 670\n",
            "Epoch: 0671 loss_train: 0.6954 acc_train: 0.7786 loss_val: 1.0545 acc_val: 0.6333 time: 1.7551s\n",
            "loss_val:1.0544766187667847, val_acc:0.6333333333333333, out_features:tensor([[-4.3096, -4.5345, -0.1610,  ..., -4.5002, -3.8320, -2.6039],\n",
            "        [-3.3782, -5.3374, -4.3626,  ..., -4.1088, -0.0910, -4.3077],\n",
            "        [-1.9459, -1.9459, -1.9459,  ..., -1.9459, -1.9459, -1.9459],\n",
            "        ...,\n",
            "        [-2.5297, -0.8935, -1.9351,  ..., -2.2219, -2.7939, -2.1066],\n",
            "        [-0.0372, -4.9323, -5.3447,  ..., -5.2803, -4.4211, -5.5310],\n",
            "        [-1.9459, -1.9459, -1.9459,  ..., -1.9459, -1.9459, -1.9459]],\n",
            "       grad_fn=<LogSoftmaxBackward0>)\n",
            "Training: 671\n",
            "Epoch: 0672 loss_train: 0.6472 acc_train: 0.8571 loss_val: 1.0125 acc_val: 0.6633 time: 1.7490s\n",
            "loss_val:1.0124841928482056, val_acc:0.6633333333333333, out_features:tensor([[-3.5515, -3.2950, -0.3810,  ..., -2.0998, -3.4456, -3.2359],\n",
            "        [-1.6539, -4.3802, -4.3908,  ..., -3.1850, -0.8031, -1.2644],\n",
            "        [-2.5063, -2.8201, -3.2059,  ..., -0.2917, -3.6770, -3.7552],\n",
            "        ...,\n",
            "        [-7.1052, -0.0090, -7.3423,  ..., -6.0136, -5.6265, -7.1760],\n",
            "        [-0.2050, -3.8947, -4.1567,  ..., -3.9059, -2.4147, -3.7729],\n",
            "        [-7.4643, -5.1260, -0.0094,  ..., -6.9928, -7.1981, -7.4897]],\n",
            "       grad_fn=<LogSoftmaxBackward0>)\n",
            "Training: 672\n",
            "Epoch: 0673 loss_train: 0.5358 acc_train: 0.8500 loss_val: 1.0248 acc_val: 0.6867 time: 1.7427s\n",
            "loss_val:1.0248322486877441, val_acc:0.6866666666666666, out_features:tensor([[-2.5657, -2.5982, -0.9637,  ..., -2.2689, -2.5274, -2.6049],\n",
            "        [-1.7268, -2.8317, -3.9619,  ..., -4.4124, -0.3659, -4.2036],\n",
            "        [-5.4339, -5.8946, -6.0454,  ..., -0.0147, -6.2454, -6.3603],\n",
            "        ...,\n",
            "        [-2.5861, -0.7205, -2.6648,  ..., -2.1502, -2.2872, -2.5465],\n",
            "        [-0.4638, -3.0639, -3.1827,  ..., -2.5637, -2.3632, -2.6510],\n",
            "        [-5.2404, -4.6948, -0.0719,  ..., -5.0856, -4.8921, -5.0041]],\n",
            "       grad_fn=<LogSoftmaxBackward0>)\n",
            "Training: 673\n",
            "Epoch: 0674 loss_train: 0.5819 acc_train: 0.8429 loss_val: 1.0693 acc_val: 0.6800 time: 1.7382s\n",
            "loss_val:1.0693203210830688, val_acc:0.68, out_features:tensor([[-1.9459, -1.9459, -1.9459,  ..., -1.9459, -1.9459, -1.9459],\n",
            "        [-2.3514, -2.4563, -2.5519,  ..., -2.4531, -0.9193, -1.5268],\n",
            "        [-5.7828, -4.6153, -5.8916,  ..., -0.0257, -5.3452, -5.9744],\n",
            "        ...,\n",
            "        [-4.1162, -0.1162, -4.2857,  ..., -4.2070, -3.7151, -4.1798],\n",
            "        [-0.0920, -5.1588, -5.2185,  ..., -3.2780, -3.6022, -4.9625],\n",
            "        [-2.0840, -1.7891, -1.6024,  ..., -2.0907, -2.6553, -1.4348]],\n",
            "       grad_fn=<LogSoftmaxBackward0>)\n",
            "Training: 674\n",
            "Epoch: 0675 loss_train: 0.6373 acc_train: 0.8143 loss_val: 0.9694 acc_val: 0.6467 time: 1.7443s\n",
            "loss_val:0.9694364666938782, val_acc:0.6466666666666666, out_features:tensor([[-7.3853, -7.3359, -0.0096,  ..., -5.4928, -7.3318, -7.3658],\n",
            "        [-2.3306, -2.0493, -2.0898,  ..., -2.1508, -1.2793, -1.6363],\n",
            "        [-5.0333, -5.8226, -4.9980,  ..., -0.0256, -5.7361, -5.7494],\n",
            "        ...,\n",
            "        [-2.0474, -0.8875, -2.6803,  ..., -1.5966, -2.6576, -2.7709],\n",
            "        [-1.0675, -1.9843, -2.3888,  ..., -2.3526, -1.8856, -2.2938],\n",
            "        [-4.3227, -4.0997, -0.1385,  ..., -4.4857, -4.1379, -4.1139]],\n",
            "       grad_fn=<LogSoftmaxBackward0>)\n",
            "Training: 675\n",
            "Epoch: 0676 loss_train: 0.6125 acc_train: 0.8000 loss_val: 1.1044 acc_val: 0.6533 time: 1.8742s\n",
            "loss_val:1.1044498682022095, val_acc:0.6533333333333333, out_features:tensor([[-1.0569e+01, -1.0790e+01, -3.6042e-04,  ..., -1.0416e+01,\n",
            "         -1.0844e+01, -1.0680e+01],\n",
            "        [-1.9459e+00, -1.9459e+00, -1.9459e+00,  ..., -1.9459e+00,\n",
            "         -1.9459e+00, -1.9459e+00],\n",
            "        [-6.9376e+00, -6.4524e+00, -6.0255e+00,  ..., -9.7377e-03,\n",
            "         -6.7571e+00, -6.0618e+00],\n",
            "        ...,\n",
            "        [-2.5647e+00, -2.5210e-01, -3.9996e+00,  ..., -3.3327e+00,\n",
            "         -3.1504e+00, -3.8336e+00],\n",
            "        [-6.4775e-01, -2.8358e+00, -2.6665e+00,  ..., -1.7796e+00,\n",
            "         -2.4466e+00, -2.8751e+00],\n",
            "        [-2.3740e+00, -2.3494e+00, -6.9503e-01,  ..., -2.2541e+00,\n",
            "         -2.9023e+00, -2.4471e+00]], grad_fn=<LogSoftmaxBackward0>)\n",
            "Training: 676\n",
            "Epoch: 0677 loss_train: 0.5304 acc_train: 0.8786 loss_val: 0.9896 acc_val: 0.6700 time: 1.9777s\n",
            "loss_val:0.9895655512809753, val_acc:0.67, out_features:tensor([[-2.8779e+00, -3.3715e+00, -4.3232e-01,  ..., -2.4434e+00,\n",
            "         -3.1861e+00, -2.8730e+00],\n",
            "        [-4.1699e+00, -5.3860e+00, -6.6696e+00,  ..., -2.9816e+00,\n",
            "         -1.8389e-01, -2.3568e+00],\n",
            "        [-7.5992e+00, -8.1961e+00, -7.9594e+00,  ..., -2.1579e-03,\n",
            "         -8.1352e+00, -8.1760e+00],\n",
            "        ...,\n",
            "        [-4.1855e+00, -1.0673e-01, -4.7655e+00,  ..., -4.4025e+00,\n",
            "         -3.0838e+00, -4.4832e+00],\n",
            "        [-2.4461e-01, -4.0624e+00, -4.3856e+00,  ..., -2.1703e+00,\n",
            "         -3.0877e+00, -4.1994e+00],\n",
            "        [-1.9459e+00, -1.9459e+00, -1.9459e+00,  ..., -1.9459e+00,\n",
            "         -1.9459e+00, -1.9459e+00]], grad_fn=<LogSoftmaxBackward0>)\n",
            "Training: 677\n",
            "Epoch: 0678 loss_train: 0.5152 acc_train: 0.8357 loss_val: 1.0391 acc_val: 0.6867 time: 1.7360s\n",
            "loss_val:1.0390697717666626, val_acc:0.6866666666666666, out_features:tensor([[-3.0704e+00, -3.3215e+00, -3.3880e-01,  ..., -3.1852e+00,\n",
            "         -3.3242e+00, -2.8576e+00],\n",
            "        [-1.9459e+00, -1.9459e+00, -1.9459e+00,  ..., -1.9459e+00,\n",
            "         -1.9459e+00, -1.9459e+00],\n",
            "        [-1.9459e+00, -1.9459e+00, -1.9459e+00,  ..., -1.9459e+00,\n",
            "         -1.9459e+00, -1.9459e+00],\n",
            "        ...,\n",
            "        [-2.3095e+00, -6.0978e-01, -3.6926e+00,  ..., -1.4182e+00,\n",
            "         -3.1776e+00, -3.7314e+00],\n",
            "        [-4.3240e-03, -6.7743e+00, -8.4472e+00,  ..., -6.8171e+00,\n",
            "         -6.5621e+00, -8.4260e+00],\n",
            "        [-1.9459e+00, -1.9459e+00, -1.9459e+00,  ..., -1.9459e+00,\n",
            "         -1.9459e+00, -1.9459e+00]], grad_fn=<LogSoftmaxBackward0>)\n",
            "Training: 678\n",
            "Epoch: 0679 loss_train: 0.5618 acc_train: 0.8429 loss_val: 1.0362 acc_val: 0.6833 time: 1.7469s\n",
            "loss_val:1.036153793334961, val_acc:0.6833333333333333, out_features:tensor([[-4.8258e+00, -5.0679e+00, -8.5726e-02,  ..., -3.4160e+00,\n",
            "         -5.0455e+00, -4.5328e+00],\n",
            "        [-1.9125e+00, -3.1565e+00, -4.6181e+00,  ..., -4.2392e+00,\n",
            "         -2.7427e-01, -4.1982e+00],\n",
            "        [-5.6097e+00, -5.2321e+00, -4.8149e+00,  ..., -3.1618e-02,\n",
            "         -5.1217e+00, -5.3425e+00],\n",
            "        ...,\n",
            "        [-2.0193e+00, -9.3711e-01, -2.7782e+00,  ..., -2.2726e+00,\n",
            "         -2.5771e+00, -1.9599e+00],\n",
            "        [-1.9459e+00, -1.9459e+00, -1.9459e+00,  ..., -1.9459e+00,\n",
            "         -1.9459e+00, -1.9459e+00],\n",
            "        [-1.2374e+01, -1.2192e+01, -3.7193e-05,  ..., -1.2388e+01,\n",
            "         -1.2219e+01, -1.2404e+01]], grad_fn=<LogSoftmaxBackward0>)\n",
            "Training: 679\n",
            "Epoch: 0680 loss_train: 0.6129 acc_train: 0.8071 loss_val: 1.1526 acc_val: 0.6267 time: 1.7398s\n",
            "loss_val:1.1526368856430054, val_acc:0.6266666666666667, out_features:tensor([[-6.2957e+00, -6.0358e+00, -2.7239e-02,  ..., -4.3206e+00,\n",
            "         -6.2924e+00, -5.4322e+00],\n",
            "        [-1.9459e+00, -1.9459e+00, -1.9459e+00,  ..., -1.9459e+00,\n",
            "         -1.9459e+00, -1.9459e+00],\n",
            "        [-3.3693e+00, -3.4466e+00, -3.0973e+00,  ..., -2.6627e-01,\n",
            "         -3.0390e+00, -3.0015e+00],\n",
            "        ...,\n",
            "        [-1.9459e+00, -1.9459e+00, -1.9459e+00,  ..., -1.9459e+00,\n",
            "         -1.9459e+00, -1.9459e+00],\n",
            "        [-1.6792e-01, -4.1997e+00, -3.8407e+00,  ..., -3.3855e+00,\n",
            "         -3.0274e+00, -4.2530e+00],\n",
            "        [-7.6947e+00, -7.0330e+00, -5.1016e-03,  ..., -7.5698e+00,\n",
            "         -7.4325e+00, -6.1056e+00]], grad_fn=<LogSoftmaxBackward0>)\n",
            "Training: 680\n",
            "Epoch: 0681 loss_train: 0.5618 acc_train: 0.8500 loss_val: 1.0932 acc_val: 0.6500 time: 1.7368s\n",
            "loss_val:1.0931822061538696, val_acc:0.65, out_features:tensor([[-9.0906e+00, -9.1967e+00, -2.2681e-03,  ..., -8.9694e+00,\n",
            "         -9.1786e+00, -8.2142e+00],\n",
            "        [-1.9459e+00, -1.9459e+00, -1.9459e+00,  ..., -1.9459e+00,\n",
            "         -1.9459e+00, -1.9459e+00],\n",
            "        [-2.7904e+00, -3.1635e+00, -3.0936e+00,  ..., -2.9655e-01,\n",
            "         -3.2137e+00, -3.2241e+00],\n",
            "        ...,\n",
            "        [-2.4817e+00, -2.6673e-01, -3.8619e+00,  ..., -3.4546e+00,\n",
            "         -3.2441e+00, -3.3446e+00],\n",
            "        [-3.7067e-01, -2.4467e+00, -3.7999e+00,  ..., -2.7451e+00,\n",
            "         -2.4047e+00, -3.6250e+00],\n",
            "        [-2.7462e+00, -4.2555e+00, -1.3821e-01,  ..., -4.2749e+00,\n",
            "         -4.2335e+00, -4.5231e+00]], grad_fn=<LogSoftmaxBackward0>)\n",
            "Training: 681\n",
            "Epoch: 0682 loss_train: 0.5867 acc_train: 0.8643 loss_val: 1.0564 acc_val: 0.6600 time: 1.7357s\n",
            "loss_val:1.0563914775848389, val_acc:0.66, out_features:tensor([[-4.6719e+00, -4.3829e+00, -1.4239e-01,  ..., -4.1707e+00,\n",
            "         -4.6515e+00, -4.3374e+00],\n",
            "        [-1.7729e+00, -2.9522e+00, -2.2075e+00,  ..., -2.5144e+00,\n",
            "         -9.1670e-01, -1.9528e+00],\n",
            "        [-6.9406e+00, -6.5472e+00, -6.7354e+00,  ..., -5.8016e-03,\n",
            "         -7.1338e+00, -7.0805e+00],\n",
            "        ...,\n",
            "        [-3.0409e+00, -3.4262e-01, -3.5522e+00,  ..., -2.6630e+00,\n",
            "         -2.5208e+00, -3.3604e+00],\n",
            "        [-1.9459e+00, -1.9459e+00, -1.9459e+00,  ..., -1.9459e+00,\n",
            "         -1.9459e+00, -1.9459e+00],\n",
            "        [-6.8321e+00, -6.1507e+00, -8.4733e-03,  ..., -7.0878e+00,\n",
            "         -6.6171e+00, -7.0037e+00]], grad_fn=<LogSoftmaxBackward0>)\n",
            "Training: 682\n",
            "Epoch: 0683 loss_train: 0.6863 acc_train: 0.7786 loss_val: 0.9955 acc_val: 0.6667 time: 1.8888s\n",
            "loss_val:0.9954639673233032, val_acc:0.6666666666666666, out_features:tensor([[-2.8469, -2.6437, -0.5219,  ..., -2.6223, -2.4221, -2.9715],\n",
            "        [-1.9459, -1.9459, -1.9459,  ..., -1.9459, -1.9459, -1.9459],\n",
            "        [-3.0285, -3.3941, -3.2970,  ..., -0.2212, -3.8670, -3.1652],\n",
            "        ...,\n",
            "        [-2.5197, -0.6420, -2.9760,  ..., -2.1576, -2.2948, -2.8391],\n",
            "        [-1.9459, -1.9459, -1.9459,  ..., -1.9459, -1.9459, -1.9459],\n",
            "        [-3.6991, -3.6405, -0.1531,  ..., -4.0288, -3.9949, -4.3475]],\n",
            "       grad_fn=<LogSoftmaxBackward0>)\n",
            "Training: 683\n",
            "Epoch: 0684 loss_train: 0.5898 acc_train: 0.8000 loss_val: 1.0194 acc_val: 0.6600 time: 1.9499s\n",
            "loss_val:1.0193970203399658, val_acc:0.66, out_features:tensor([[-1.9459e+00, -1.9459e+00, -1.9459e+00,  ..., -1.9459e+00,\n",
            "         -1.9459e+00, -1.9459e+00],\n",
            "        [-2.0632e+00, -2.6632e+00, -2.4136e+00,  ..., -2.1266e+00,\n",
            "         -1.1633e+00, -1.5806e+00],\n",
            "        [-9.4947e+00, -9.9138e+00, -1.0108e+01,  ..., -3.1145e-04,\n",
            "         -9.9946e+00, -9.6990e+00],\n",
            "        ...,\n",
            "        [-2.3238e+00, -1.3770e+00, -1.9119e+00,  ..., -2.0528e+00,\n",
            "         -1.9720e+00, -2.6591e+00],\n",
            "        [-9.2381e-01, -2.4761e+00, -2.6782e+00,  ..., -1.6636e+00,\n",
            "         -2.1816e+00, -2.3200e+00],\n",
            "        [-4.3773e+00, -4.1837e+00, -9.0835e-02,  ..., -3.5987e+00,\n",
            "         -4.7908e+00, -4.2026e+00]], grad_fn=<LogSoftmaxBackward0>)\n",
            "Training: 684\n",
            "Epoch: 0685 loss_train: 0.7106 acc_train: 0.7857 loss_val: 1.0852 acc_val: 0.6300 time: 1.7567s\n",
            "loss_val:1.0852158069610596, val_acc:0.63, out_features:tensor([[-4.6144, -4.6171, -0.1029,  ..., -3.6087, -4.6838, -3.5753],\n",
            "        [-1.9459, -1.9459, -1.9459,  ..., -1.9459, -1.9459, -1.9459],\n",
            "        [-5.9631, -5.8039, -5.7381,  ..., -0.0190, -5.2880, -5.8958],\n",
            "        ...,\n",
            "        [-4.3382, -0.0709, -5.6324,  ..., -5.0268, -3.2801, -5.4998],\n",
            "        [-0.4597, -3.1364, -3.3050,  ..., -2.5799, -2.0685, -2.9686],\n",
            "        [-5.0727, -5.4969, -0.0249,  ..., -5.7339, -5.1259, -5.8465]],\n",
            "       grad_fn=<LogSoftmaxBackward0>)\n",
            "Training: 685\n",
            "Epoch: 0686 loss_train: 0.6770 acc_train: 0.7714 loss_val: 1.0543 acc_val: 0.6467 time: 1.7309s\n",
            "loss_val:1.0542570352554321, val_acc:0.6466666666666666, out_features:tensor([[-1.0671e+01, -1.0561e+01, -4.2847e-04,  ..., -1.0035e+01,\n",
            "         -1.0578e+01, -1.0511e+01],\n",
            "        [-1.9459e+00, -1.9459e+00, -1.9459e+00,  ..., -1.9459e+00,\n",
            "         -1.9459e+00, -1.9459e+00],\n",
            "        [-3.9288e+00, -3.7473e+00, -4.1594e+00,  ..., -1.1576e-01,\n",
            "         -4.0549e+00, -3.8744e+00],\n",
            "        ...,\n",
            "        [-3.1500e+00, -5.7421e-01, -1.9502e+00,  ..., -2.6426e+00,\n",
            "         -2.6227e+00, -2.8361e+00],\n",
            "        [-6.1948e-02, -5.5635e+00, -5.9144e+00,  ..., -4.9754e+00,\n",
            "         -5.5395e+00, -5.7371e+00],\n",
            "        [-2.4879e+00, -3.2249e+00, -6.2229e-01,  ..., -3.1774e+00,\n",
            "         -2.3649e+00, -2.4987e+00]], grad_fn=<LogSoftmaxBackward0>)\n",
            "Training: 686\n",
            "Epoch: 0687 loss_train: 0.6423 acc_train: 0.8000 loss_val: 0.9390 acc_val: 0.7167 time: 1.7627s\n",
            "loss_val:0.9389843940734863, val_acc:0.7166666666666667, out_features:tensor([[-9.2675e+00, -9.2373e+00, -1.2477e-03,  ..., -8.4832e+00,\n",
            "         -9.0117e+00, -8.7101e+00],\n",
            "        [-1.9459e+00, -1.9459e+00, -1.9459e+00,  ..., -1.9459e+00,\n",
            "         -1.9459e+00, -1.9459e+00],\n",
            "        [-1.9459e+00, -1.9459e+00, -1.9459e+00,  ..., -1.9459e+00,\n",
            "         -1.9459e+00, -1.9459e+00],\n",
            "        ...,\n",
            "        [-4.0987e+00, -3.8063e-02, -5.9412e+00,  ..., -5.7158e+00,\n",
            "         -4.9101e+00, -5.7997e+00],\n",
            "        [-7.0858e-01, -3.0414e+00, -2.1306e+00,  ..., -1.5111e+00,\n",
            "         -2.8456e+00, -3.4752e+00],\n",
            "        [-3.4058e+00, -4.7478e+00, -1.2512e-01,  ..., -3.7736e+00,\n",
            "         -3.5602e+00, -4.2581e+00]], grad_fn=<LogSoftmaxBackward0>)\n",
            "Training: 687\n",
            "Epoch: 0688 loss_train: 0.5048 acc_train: 0.8786 loss_val: 1.0157 acc_val: 0.6833 time: 1.7341s\n",
            "loss_val:1.0156503915786743, val_acc:0.6833333333333333, out_features:tensor([[-6.5343, -6.4276, -0.0125,  ..., -5.6291, -6.0913, -6.4995],\n",
            "        [-3.5903, -3.7362, -2.7637,  ..., -1.1645, -0.8708, -2.0364],\n",
            "        [-2.9734, -2.9526, -1.7013,  ..., -0.5948, -3.0465, -2.7298],\n",
            "        ...,\n",
            "        [-3.4249, -0.1804, -4.4136,  ..., -2.5784, -3.8644, -4.3075],\n",
            "        [-0.5072, -3.1237, -3.2196,  ..., -2.1084, -2.2073, -3.2954],\n",
            "        [-1.9459, -1.9459, -1.9459,  ..., -1.9459, -1.9459, -1.9459]],\n",
            "       grad_fn=<LogSoftmaxBackward0>)\n",
            "Training: 688\n",
            "Epoch: 0689 loss_train: 0.5127 acc_train: 0.8714 loss_val: 1.0067 acc_val: 0.6633 time: 1.7262s\n",
            "loss_val:1.0066794157028198, val_acc:0.6633333333333333, out_features:tensor([[-7.3715e+00, -7.4241e+00, -4.7951e-03,  ..., -6.6437e+00,\n",
            "         -7.5534e+00, -7.4611e+00],\n",
            "        [-3.0616e+00, -4.0284e+00, -3.8809e+00,  ..., -3.3626e+00,\n",
            "         -3.0786e-01, -2.0664e+00],\n",
            "        [-1.9459e+00, -1.9459e+00, -1.9459e+00,  ..., -1.9459e+00,\n",
            "         -1.9459e+00, -1.9459e+00],\n",
            "        ...,\n",
            "        [-3.0105e+00, -3.7198e-01, -3.4885e+00,  ..., -3.5822e+00,\n",
            "         -2.8508e+00, -2.3890e+00],\n",
            "        [-1.5433e-01, -3.6358e+00, -4.5530e+00,  ..., -3.9071e+00,\n",
            "         -2.7655e+00, -4.6054e+00],\n",
            "        [-4.3171e+00, -4.7279e+00, -9.9102e-02,  ..., -4.8944e+00,\n",
            "         -3.0160e+00, -4.6831e+00]], grad_fn=<LogSoftmaxBackward0>)\n",
            "Training: 689\n",
            "Epoch: 0690 loss_train: 0.5943 acc_train: 0.8571 loss_val: 0.9992 acc_val: 0.6700 time: 1.8861s\n",
            "loss_val:0.9991745948791504, val_acc:0.67, out_features:tensor([[-6.1073e+00, -5.9116e+00, -2.0129e-02,  ..., -5.8382e+00,\n",
            "         -5.8978e+00, -5.9521e+00],\n",
            "        [-7.6939e+00, -8.2946e+00, -7.6152e+00,  ..., -6.1028e+00,\n",
            "         -7.6887e-03, -5.5233e+00],\n",
            "        [-2.3075e+00, -2.7740e+00, -2.6438e+00,  ..., -5.0736e-01,\n",
            "         -3.0029e+00, -2.7267e+00],\n",
            "        ...,\n",
            "        [-3.0076e+00, -6.6358e-01, -2.2609e+00,  ..., -2.6187e+00,\n",
            "         -2.2896e+00, -2.6136e+00],\n",
            "        [-1.8075e+00, -1.9869e+00, -2.1105e+00,  ..., -1.6330e+00,\n",
            "         -2.0812e+00, -1.8459e+00],\n",
            "        [-4.8758e+00, -6.7506e+00, -1.3118e-02,  ..., -6.8418e+00,\n",
            "         -6.6600e+00, -6.9647e+00]], grad_fn=<LogSoftmaxBackward0>)\n",
            "Training: 690\n",
            "Epoch: 0691 loss_train: 0.6053 acc_train: 0.8071 loss_val: 1.0052 acc_val: 0.6633 time: 1.9754s\n",
            "loss_val:1.0052462816238403, val_acc:0.6633333333333333, out_features:tensor([[-7.9061e+00, -7.7299e+00, -2.8090e-03,  ..., -7.7097e+00,\n",
            "         -7.8533e+00, -7.8633e+00],\n",
            "        [-2.4898e+00, -2.7087e+00, -2.4375e+00,  ..., -1.8505e+00,\n",
            "         -1.2474e+00, -1.3278e+00],\n",
            "        [-6.3553e+00, -6.2987e+00, -3.7515e+00,  ..., -3.5443e-02,\n",
            "         -6.2791e+00, -5.5273e+00],\n",
            "        ...,\n",
            "        [-4.5412e+00, -1.0465e-01, -3.8721e+00,  ..., -3.9513e+00,\n",
            "         -3.7643e+00, -4.1696e+00],\n",
            "        [-5.1381e-01, -2.9185e+00, -2.7589e+00,  ..., -3.0881e+00,\n",
            "         -2.2437e+00, -2.5605e+00],\n",
            "        [-2.7318e+00, -2.5990e+00, -6.0741e-01,  ..., -2.3852e+00,\n",
            "         -2.4479e+00, -2.4630e+00]], grad_fn=<LogSoftmaxBackward0>)\n",
            "Training: 691\n",
            "Epoch: 0692 loss_train: 0.5323 acc_train: 0.8571 loss_val: 1.1660 acc_val: 0.6400 time: 1.7509s\n",
            "loss_val:1.1659748554229736, val_acc:0.64, out_features:tensor([[-7.0282e+00, -7.0878e+00, -5.9808e-03,  ..., -6.8539e+00,\n",
            "         -7.1131e+00, -6.8321e+00],\n",
            "        [-1.9459e+00, -1.9459e+00, -1.9459e+00,  ..., -1.9459e+00,\n",
            "         -1.9459e+00, -1.9459e+00],\n",
            "        [-3.6414e+00, -4.1035e+00, -3.2282e+00,  ..., -1.5355e-01,\n",
            "         -4.0729e+00, -3.5288e+00],\n",
            "        ...,\n",
            "        [-4.8269e+00, -6.9311e-02, -5.1024e+00,  ..., -3.7931e+00,\n",
            "         -4.2145e+00, -4.8130e+00],\n",
            "        [-1.9459e+00, -1.9459e+00, -1.9459e+00,  ..., -1.9459e+00,\n",
            "         -1.9459e+00, -1.9459e+00],\n",
            "        [-1.9459e+00, -1.9459e+00, -1.9459e+00,  ..., -1.9459e+00,\n",
            "         -1.9459e+00, -1.9459e+00]], grad_fn=<LogSoftmaxBackward0>)\n",
            "Training: 692\n",
            "Epoch: 0693 loss_train: 0.7411 acc_train: 0.7643 loss_val: 1.0323 acc_val: 0.6500 time: 1.7444s\n",
            "loss_val:1.032271385192871, val_acc:0.65, out_features:tensor([[-5.7917e+00, -5.6970e+00, -3.4829e-02,  ..., -4.8965e+00,\n",
            "         -5.7650e+00, -5.4827e+00],\n",
            "        [-1.9459e+00, -1.9459e+00, -1.9459e+00,  ..., -1.9459e+00,\n",
            "         -1.9459e+00, -1.9459e+00],\n",
            "        [-9.7318e+00, -9.2818e+00, -1.0789e+01,  ..., -2.4506e-04,\n",
            "         -1.0395e+01, -1.0723e+01],\n",
            "        ...,\n",
            "        [-6.1895e+00, -4.4952e-02, -5.6968e+00,  ..., -3.5020e+00,\n",
            "         -5.6220e+00, -5.8785e+00],\n",
            "        [-1.9459e+00, -1.9459e+00, -1.9459e+00,  ..., -1.9459e+00,\n",
            "         -1.9459e+00, -1.9459e+00],\n",
            "        [-1.9459e+00, -1.9459e+00, -1.9459e+00,  ..., -1.9459e+00,\n",
            "         -1.9459e+00, -1.9459e+00]], grad_fn=<LogSoftmaxBackward0>)\n",
            "Training: 693\n",
            "Epoch: 0694 loss_train: 0.5894 acc_train: 0.8071 loss_val: 1.0274 acc_val: 0.6600 time: 1.7431s\n",
            "loss_val:1.0273535251617432, val_acc:0.66, out_features:tensor([[-3.2922e+00, -3.0173e+00, -3.3151e-01,  ..., -3.0101e+00,\n",
            "         -2.9286e+00, -3.0457e+00],\n",
            "        [-3.3036e+00, -5.9720e+00, -5.9746e+00,  ..., -7.5082e-01,\n",
            "         -7.6978e-01, -3.8810e+00],\n",
            "        [-2.2310e+00, -3.2279e+00, -2.6194e+00,  ..., -4.1728e-01,\n",
            "         -3.2235e+00, -2.9847e+00],\n",
            "        ...,\n",
            "        [-3.6965e+00, -2.3808e-01, -3.5054e+00,  ..., -3.6282e+00,\n",
            "         -2.9434e+00, -2.9493e+00],\n",
            "        [-2.0707e-01, -3.9861e+00, -3.8235e+00,  ..., -3.2559e+00,\n",
            "         -2.7699e+00, -3.5869e+00],\n",
            "        [-7.4822e+00, -7.4793e+00, -4.9854e-03,  ..., -7.5177e+00,\n",
            "         -6.2791e+00, -7.3841e+00]], grad_fn=<LogSoftmaxBackward0>)\n",
            "Training: 694\n",
            "Epoch: 0695 loss_train: 0.6152 acc_train: 0.8143 loss_val: 0.9812 acc_val: 0.6800 time: 1.7425s\n",
            "loss_val:0.9811764359474182, val_acc:0.68, out_features:tensor([[-1.9459e+00, -1.9459e+00, -1.9459e+00,  ..., -1.9459e+00,\n",
            "         -1.9459e+00, -1.9459e+00],\n",
            "        [-1.9459e+00, -1.9459e+00, -1.9459e+00,  ..., -1.9459e+00,\n",
            "         -1.9459e+00, -1.9459e+00],\n",
            "        [-1.0412e+01, -8.3415e+00, -1.0487e+01,  ..., -4.0523e-04,\n",
            "         -1.0128e+01, -1.0049e+01],\n",
            "        ...,\n",
            "        [-3.3938e+00, -3.5768e-01, -2.7734e+00,  ..., -3.1960e+00,\n",
            "         -3.2687e+00, -2.3668e+00],\n",
            "        [-2.2762e-02, -6.0194e+00, -6.1549e+00,  ..., -5.1722e+00,\n",
            "         -5.2655e+00, -5.4849e+00],\n",
            "        [-3.5932e+00, -3.2349e+00, -2.9051e-01,  ..., -2.2226e+00,\n",
            "         -3.5713e+00, -3.4822e+00]], grad_fn=<LogSoftmaxBackward0>)\n",
            "Training: 695\n",
            "Epoch: 0696 loss_train: 0.7181 acc_train: 0.7929 loss_val: 1.0276 acc_val: 0.6700 time: 1.7372s\n",
            "loss_val:1.027586817741394, val_acc:0.67, out_features:tensor([[-7.1559e+00, -7.1078e+00, -5.9701e-03,  ..., -6.3258e+00,\n",
            "         -7.1452e+00, -7.2479e+00],\n",
            "        [-3.5066e+00, -4.0977e+00, -4.5935e+00,  ..., -4.3729e+00,\n",
            "         -5.4283e-01, -1.0781e+00],\n",
            "        [-4.9703e+00, -4.4689e+00, -4.4044e+00,  ..., -7.3907e-02,\n",
            "         -5.2304e+00, -3.5128e+00],\n",
            "        ...,\n",
            "        [-2.4404e+00, -8.0799e-01, -2.9636e+00,  ..., -2.1583e+00,\n",
            "         -2.6416e+00, -1.6716e+00],\n",
            "        [-1.6888e-01, -4.1307e+00, -4.5782e+00,  ..., -2.7817e+00,\n",
            "         -3.0528e+00, -4.5814e+00],\n",
            "        [-2.8887e+00, -3.1866e+00, -3.3507e-01,  ..., -2.6348e+00,\n",
            "         -2.9806e+00, -3.3945e+00]], grad_fn=<LogSoftmaxBackward0>)\n",
            "Training: 696\n",
            "Epoch: 0697 loss_train: 0.5698 acc_train: 0.8143 loss_val: 0.9617 acc_val: 0.6833 time: 1.8784s\n",
            "loss_val:0.9616519212722778, val_acc:0.6833333333333333, out_features:tensor([[-1.0024e+01, -1.0020e+01, -6.5603e-04,  ..., -9.7517e+00,\n",
            "         -1.0068e+01, -9.6573e+00],\n",
            "        [-1.9459e+00, -1.9459e+00, -1.9459e+00,  ..., -1.9459e+00,\n",
            "         -1.9459e+00, -1.9459e+00],\n",
            "        [-1.2675e+01, -1.2513e+01, -1.2520e+01,  ..., -2.0504e-05,\n",
            "         -1.2546e+01, -1.2482e+01],\n",
            "        ...,\n",
            "        [-2.1094e+00, -9.4998e-01, -2.2445e+00,  ..., -2.6475e+00,\n",
            "         -2.3667e+00, -2.2166e+00],\n",
            "        [-6.9444e-02, -5.2609e+00, -3.9875e+00,  ..., -4.5753e+00,\n",
            "         -4.0263e+00, -5.1158e+00],\n",
            "        [-8.9486e+00, -9.0756e+00, -1.1815e-03,  ..., -9.1795e+00,\n",
            "         -7.6324e+00, -8.8282e+00]], grad_fn=<LogSoftmaxBackward0>)\n",
            "Training: 697\n",
            "Epoch: 0698 loss_train: 0.5702 acc_train: 0.8143 loss_val: 1.0476 acc_val: 0.6267 time: 1.9853s\n",
            "loss_val:1.0476417541503906, val_acc:0.6266666666666667, out_features:tensor([[-5.6041e+00, -5.6673e+00, -5.6853e-02,  ..., -5.2607e+00,\n",
            "         -5.5347e+00, -4.9727e+00],\n",
            "        [-7.7632e+00, -9.6770e+00, -9.7628e+00,  ..., -3.3881e+00,\n",
            "         -5.1610e-02, -4.1397e+00],\n",
            "        [-3.9492e+00, -3.9460e+00, -4.2484e+00,  ..., -8.5195e-02,\n",
            "         -4.3610e+00, -4.5907e+00],\n",
            "        ...,\n",
            "        [-9.1753e+00, -1.2469e-03, -9.2776e+00,  ..., -9.0067e+00,\n",
            "         -8.1345e+00, -7.5138e+00],\n",
            "        [-8.9577e-02, -5.1839e+00, -5.2018e+00,  ..., -3.0055e+00,\n",
            "         -4.1694e+00, -5.2864e+00],\n",
            "        [-3.0079e+00, -2.0240e+00, -7.4552e-01,  ..., -2.0731e+00,\n",
            "         -3.0016e+00, -2.3156e+00]], grad_fn=<LogSoftmaxBackward0>)\n",
            "Training: 698\n",
            "Epoch: 0699 loss_train: 0.5392 acc_train: 0.8500 loss_val: 1.0008 acc_val: 0.6967 time: 1.7459s\n",
            "loss_val:1.0007556676864624, val_acc:0.6966666666666667, out_features:tensor([[-6.0427, -5.3299, -0.0229,  ..., -5.1920, -5.8289, -5.7678],\n",
            "        [-4.4771, -7.8108, -7.7478,  ..., -7.7075, -0.0148, -7.4512],\n",
            "        [-6.9689, -5.1897, -7.0624,  ..., -0.0119, -5.8886, -6.9992],\n",
            "        ...,\n",
            "        [-3.1871, -0.6096, -2.3302,  ..., -2.9586, -2.4461, -2.0257],\n",
            "        [-0.0183, -4.8120, -7.1521,  ..., -5.2682, -6.0548, -6.9574],\n",
            "        [-5.5868, -4.7640, -0.0495,  ..., -5.2878, -5.5088, -5.5400]],\n",
            "       grad_fn=<LogSoftmaxBackward0>)\n",
            "Training: 699\n",
            "Epoch: 0700 loss_train: 0.6175 acc_train: 0.8357 loss_val: 0.9974 acc_val: 0.6800 time: 1.7541s\n",
            "loss_val:0.99735027551651, val_acc:0.68, out_features:tensor([[-5.4569, -5.0876, -0.0365,  ..., -5.1973, -5.4384, -4.5872],\n",
            "        [-1.7504, -3.2237, -2.9211,  ..., -1.1538, -1.1252, -2.7975],\n",
            "        [-3.5934, -3.6704, -4.1776,  ..., -0.1451, -3.7404, -3.9963],\n",
            "        ...,\n",
            "        [-4.3628, -0.1034, -3.9319,  ..., -4.3707, -3.4214, -4.6833],\n",
            "        [-1.0461, -2.5795, -1.9655,  ..., -2.0003, -1.8897, -2.6521],\n",
            "        [-4.1088, -4.9030, -0.0660,  ..., -4.1681, -4.4841, -5.1462]],\n",
            "       grad_fn=<LogSoftmaxBackward0>)\n",
            "Training: 700\n",
            "Epoch: 0701 loss_train: 0.6901 acc_train: 0.7786 loss_val: 0.9836 acc_val: 0.6833 time: 1.7486s\n",
            "loss_val:0.9835734963417053, val_acc:0.6833333333333333, out_features:tensor([[-6.6256, -6.2853, -0.0217,  ..., -6.5271, -6.4089, -5.9073],\n",
            "        [-8.3493, -8.8184, -2.9331,  ..., -4.1597, -0.0723, -7.9462],\n",
            "        [-5.2021, -4.8547, -5.5326,  ..., -0.0301, -5.6415, -5.1099],\n",
            "        ...,\n",
            "        [-3.8548, -0.0767, -5.3911,  ..., -3.6215, -4.7800, -4.9208],\n",
            "        [-0.5752, -2.3069, -3.2116,  ..., -2.0458, -2.7172, -2.7974],\n",
            "        [-2.7295, -2.5901, -0.7194,  ..., -2.1371, -2.4228, -2.3934]],\n",
            "       grad_fn=<LogSoftmaxBackward0>)\n",
            "Training: 701\n",
            "Epoch: 0702 loss_train: 0.6892 acc_train: 0.7714 loss_val: 1.0312 acc_val: 0.6700 time: 1.7450s\n",
            "loss_val:1.031230092048645, val_acc:0.67, out_features:tensor([[-7.2983e+00, -7.1899e+00, -6.4382e-03,  ..., -6.4825e+00,\n",
            "         -7.1393e+00, -7.0681e+00],\n",
            "        [-3.9638e+00, -4.2536e+00, -4.2232e+00,  ..., -3.6188e+00,\n",
            "         -1.7958e-01, -2.7112e+00],\n",
            "        [-2.8309e+00, -2.7005e+00, -1.8130e+00,  ..., -9.6929e-01,\n",
            "         -2.4761e+00, -1.7892e+00],\n",
            "        ...,\n",
            "        [-1.6924e+00, -1.4783e+00, -2.3312e+00,  ..., -1.9678e+00,\n",
            "         -1.8414e+00, -2.2964e+00],\n",
            "        [-3.2476e-01, -3.8694e+00, -3.1902e+00,  ..., -2.3147e+00,\n",
            "         -2.8204e+00, -3.8220e+00],\n",
            "        [-7.2937e+00, -7.4955e+00, -6.5885e-03,  ..., -7.2391e+00,\n",
            "         -7.2582e+00, -7.5452e+00]], grad_fn=<LogSoftmaxBackward0>)\n",
            "Training: 702\n",
            "Epoch: 0703 loss_train: 0.6417 acc_train: 0.7571 loss_val: 0.9979 acc_val: 0.6833 time: 1.7384s\n",
            "loss_val:0.9979145526885986, val_acc:0.6833333333333333, out_features:tensor([[-4.9450, -5.2635, -0.1029,  ..., -4.7172, -5.0226, -3.3317],\n",
            "        [-1.9459, -1.9459, -1.9459,  ..., -1.9459, -1.9459, -1.9459],\n",
            "        [-4.9526, -5.9814, -5.0449,  ..., -0.0258, -5.7511, -5.5301],\n",
            "        ...,\n",
            "        [-3.0147, -0.3713, -3.5085,  ..., -3.2840, -2.2931, -2.7604],\n",
            "        [-0.1065, -4.1452, -5.2554,  ..., -3.2409, -3.5119, -5.0003],\n",
            "        [-2.2136, -2.8203, -0.6742,  ..., -3.1959, -1.9896, -2.7799]],\n",
            "       grad_fn=<LogSoftmaxBackward0>)\n",
            "Training: 703\n",
            "Epoch: 0704 loss_train: 0.6168 acc_train: 0.8143 loss_val: 1.0644 acc_val: 0.6700 time: 1.8907s\n",
            "loss_val:1.0643894672393799, val_acc:0.67, out_features:tensor([[-1.0623e+01, -1.0484e+01, -2.1038e-04,  ..., -1.0542e+01,\n",
            "         -1.0603e+01, -1.0271e+01],\n",
            "        [-2.7200e+00, -2.7939e+00, -3.0743e+00,  ..., -2.4346e+00,\n",
            "         -1.2183e+00, -9.0632e-01],\n",
            "        [-1.4605e+01, -1.2101e+01, -1.5662e+01,  ..., -6.6757e-06,\n",
            "         -1.5161e+01, -1.5635e+01],\n",
            "        ...,\n",
            "        [-7.8124e+00, -1.7687e-03, -8.5324e+00,  ..., -8.3000e+00,\n",
            "         -7.6409e+00, -8.3609e+00],\n",
            "        [-9.7538e-01, -2.2826e+00, -2.4584e+00,  ..., -1.8123e+00,\n",
            "         -2.4787e+00, -2.4588e+00],\n",
            "        [-2.9246e+00, -3.9766e+00, -2.9129e-01,  ..., -4.0382e+00,\n",
            "         -2.5026e+00, -2.9077e+00]], grad_fn=<LogSoftmaxBackward0>)\n",
            "Training: 704\n",
            "Epoch: 0705 loss_train: 0.5273 acc_train: 0.8643 loss_val: 0.8810 acc_val: 0.7000 time: 1.9738s\n",
            "loss_val:0.8810301423072815, val_acc:0.7, out_features:tensor([[-5.0704, -5.0305, -0.0727,  ..., -3.4165, -4.7095, -4.8070],\n",
            "        [-7.9089, -9.1594, -6.6884,  ..., -8.4316, -0.0211, -3.9731],\n",
            "        [-4.7423, -4.8092, -4.0511,  ..., -0.0839, -4.6770, -3.5668],\n",
            "        ...,\n",
            "        [-3.0444, -0.5664, -2.1188,  ..., -2.1155, -2.9561, -3.1768],\n",
            "        [-0.0795, -4.3720, -4.9347,  ..., -4.4809, -3.7471, -4.4350],\n",
            "        [-1.4694, -3.4905, -0.6564,  ..., -3.2364, -2.1400, -3.4285]],\n",
            "       grad_fn=<LogSoftmaxBackward0>)\n",
            "Training: 705\n",
            "Epoch: 0706 loss_train: 0.5534 acc_train: 0.8571 loss_val: 1.0638 acc_val: 0.6300 time: 1.7471s\n",
            "loss_val:1.0638158321380615, val_acc:0.63, out_features:tensor([[-9.5693e+00, -8.3789e+00, -8.0029e-04,  ..., -8.1723e+00,\n",
            "         -9.5124e+00, -9.5081e+00],\n",
            "        [-1.9459e+00, -1.9459e+00, -1.9459e+00,  ..., -1.9459e+00,\n",
            "         -1.9459e+00, -1.9459e+00],\n",
            "        [-2.8687e+00, -2.7208e+00, -1.8807e+00,  ..., -6.7463e-01,\n",
            "         -2.4959e+00, -2.5364e+00],\n",
            "        ...,\n",
            "        [-3.4959e+00, -2.8982e-01, -3.5306e+00,  ..., -2.1411e+00,\n",
            "         -3.7675e+00, -3.6326e+00],\n",
            "        [-4.7693e-02, -5.2174e+00, -5.8119e+00,  ..., -5.2203e+00,\n",
            "         -4.1541e+00, -4.2834e+00],\n",
            "        [-6.3071e+00, -6.3072e+00, -1.7183e-02,  ..., -6.3619e+00,\n",
            "         -5.2603e+00, -6.2112e+00]], grad_fn=<LogSoftmaxBackward0>)\n",
            "Training: 706\n",
            "Epoch: 0707 loss_train: 0.5216 acc_train: 0.8429 loss_val: 1.0832 acc_val: 0.6200 time: 1.7581s\n",
            "loss_val:1.0832127332687378, val_acc:0.62, out_features:tensor([[-2.5567e+00, -2.3331e+00, -8.3783e-01,  ..., -2.1951e+00,\n",
            "         -2.4549e+00, -2.3401e+00],\n",
            "        [-1.9459e+00, -1.9459e+00, -1.9459e+00,  ..., -1.9459e+00,\n",
            "         -1.9459e+00, -1.9459e+00],\n",
            "        [-4.4242e+00, -4.8870e+00, -3.9175e+00,  ..., -6.5371e-02,\n",
            "         -5.0618e+00, -4.5728e+00],\n",
            "        ...,\n",
            "        [-1.7898e+00, -1.0653e+00, -2.2969e+00,  ..., -2.3167e+00,\n",
            "         -2.2641e+00, -2.5602e+00],\n",
            "        [-6.9618e-01, -2.4630e+00, -3.2784e+00,  ..., -1.4750e+00,\n",
            "         -2.7605e+00, -3.0029e+00],\n",
            "        [-9.6718e+00, -9.6240e+00, -8.1196e-04,  ..., -9.7477e+00,\n",
            "         -9.5919e+00, -7.9220e+00]], grad_fn=<LogSoftmaxBackward0>)\n",
            "Training: 707\n",
            "Epoch: 0708 loss_train: 0.5833 acc_train: 0.8357 loss_val: 1.0259 acc_val: 0.6733 time: 1.7371s\n",
            "loss_val:1.0259000062942505, val_acc:0.6733333333333333, out_features:tensor([[-9.5125e+00, -9.6137e+00, -7.3144e-04,  ..., -9.5570e+00,\n",
            "         -9.4212e+00, -8.0658e+00],\n",
            "        [-2.2429e+00, -3.6736e+00, -3.6679e+00,  ..., -2.6135e+00,\n",
            "         -7.1361e-01, -1.3473e+00],\n",
            "        [-9.2117e+00, -9.3407e+00, -7.5089e+00,  ..., -1.0281e-03,\n",
            "         -9.3574e+00, -8.9982e+00],\n",
            "        ...,\n",
            "        [-4.7851e+00, -5.0323e-02, -5.1712e+00,  ..., -4.7799e+00,\n",
            "         -5.0466e+00, -4.1570e+00],\n",
            "        [-5.0933e-01, -3.1847e+00, -3.3342e+00,  ..., -2.9931e+00,\n",
            "         -2.1081e+00, -2.6868e+00],\n",
            "        [-1.9459e+00, -1.9459e+00, -1.9459e+00,  ..., -1.9459e+00,\n",
            "         -1.9459e+00, -1.9459e+00]], grad_fn=<LogSoftmaxBackward0>)\n",
            "Training: 708\n",
            "Epoch: 0709 loss_train: 0.6134 acc_train: 0.7857 loss_val: 0.9822 acc_val: 0.6967 time: 1.7474s\n",
            "loss_val:0.9821720123291016, val_acc:0.6966666666666667, out_features:tensor([[-7.7340e+00, -8.1678e+00, -2.8643e-03,  ..., -7.6906e+00,\n",
            "         -8.0397e+00, -7.8802e+00],\n",
            "        [-2.3412e+00, -2.8455e+00, -2.9377e+00,  ..., -2.0360e+00,\n",
            "         -1.2732e+00, -1.0639e+00],\n",
            "        [-2.8374e+00, -2.6287e+00, -1.7642e+00,  ..., -5.9524e-01,\n",
            "         -2.7130e+00, -3.0553e+00],\n",
            "        ...,\n",
            "        [-2.2420e+00, -3.1230e-01, -3.6948e+00,  ..., -3.0570e+00,\n",
            "         -3.2868e+00, -3.4327e+00],\n",
            "        [-8.5895e-01, -3.1479e+00, -2.5968e+00,  ..., -1.4095e+00,\n",
            "         -2.2029e+00, -2.8430e+00],\n",
            "        [-5.5859e+00, -4.8480e+00, -7.0363e-02,  ..., -5.6139e+00,\n",
            "         -5.6033e+00, -5.4737e+00]], grad_fn=<LogSoftmaxBackward0>)\n",
            "Training: 709\n",
            "Epoch: 0710 loss_train: 0.5839 acc_train: 0.8357 loss_val: 1.0638 acc_val: 0.6800 time: 1.7548s\n",
            "loss_val:1.0638487339019775, val_acc:0.68, out_features:tensor([[-5.7018e+00, -5.7694e+00, -2.7594e-02,  ..., -4.4415e+00,\n",
            "         -5.7638e+00, -5.7574e+00],\n",
            "        [-1.9459e+00, -1.9459e+00, -1.9459e+00,  ..., -1.9459e+00,\n",
            "         -1.9459e+00, -1.9459e+00],\n",
            "        [-3.9977e+00, -3.4193e+00, -3.1363e+00,  ..., -1.7131e-01,\n",
            "         -3.9104e+00, -3.8592e+00],\n",
            "        ...,\n",
            "        [-8.2086e+00, -1.8514e-03, -9.1594e+00,  ..., -7.9886e+00,\n",
            "         -6.9887e+00, -9.1251e+00],\n",
            "        [-1.1700e+00, -1.5191e+00, -2.5236e+00,  ..., -2.2305e+00,\n",
            "         -2.1419e+00, -2.4492e+00],\n",
            "        [-5.6569e+00, -5.9925e+00, -4.1706e-02,  ..., -5.3972e+00,\n",
            "         -5.6619e+00, -5.7355e+00]], grad_fn=<LogSoftmaxBackward0>)\n",
            "Training: 710\n",
            "Epoch: 0711 loss_train: 0.6928 acc_train: 0.7857 loss_val: 0.9477 acc_val: 0.7033 time: 1.8664s\n",
            "loss_val:0.947715163230896, val_acc:0.7033333333333334, out_features:tensor([[-8.2486e+00, -8.4023e+00, -5.7953e-03,  ..., -7.5924e+00,\n",
            "         -8.2383e+00, -7.9369e+00],\n",
            "        [-4.2021e+00, -3.5411e+00, -4.6894e+00,  ..., -2.2495e+00,\n",
            "         -3.4011e-01, -2.1109e+00],\n",
            "        [-6.9640e+00, -7.3183e+00, -6.5526e+00,  ..., -6.7711e-03,\n",
            "         -6.9024e+00, -6.2244e+00],\n",
            "        ...,\n",
            "        [-2.7929e+00, -6.2251e-01, -2.0474e+00,  ..., -2.3872e+00,\n",
            "         -2.4961e+00, -3.0210e+00],\n",
            "        [-1.9459e+00, -1.9459e+00, -1.9459e+00,  ..., -1.9459e+00,\n",
            "         -1.9459e+00, -1.9459e+00],\n",
            "        [-3.0110e+00, -3.8579e+00, -1.6902e-01,  ..., -3.8839e+00,\n",
            "         -3.5010e+00, -4.0291e+00]], grad_fn=<LogSoftmaxBackward0>)\n",
            "Training: 711\n",
            "Epoch: 0712 loss_train: 0.6037 acc_train: 0.8357 loss_val: 1.0069 acc_val: 0.6700 time: 1.9609s\n",
            "loss_val:1.0069388151168823, val_acc:0.67, out_features:tensor([[-7.1444, -7.1533, -0.0088,  ..., -5.5480, -6.7602, -6.6870],\n",
            "        [-2.1085, -2.8483, -1.8057,  ..., -2.7262, -1.1317, -1.5486],\n",
            "        [-3.5578, -2.6280, -5.0795,  ..., -0.1305, -5.0098, -5.3864],\n",
            "        ...,\n",
            "        [-1.5628, -1.6731, -2.3007,  ..., -2.2120, -1.4697, -2.3254],\n",
            "        [-0.1161, -4.0577, -4.5855,  ..., -3.0726, -4.0224, -4.6944],\n",
            "        [-3.4715, -4.1974, -0.4540,  ..., -4.0249, -2.9387, -1.9989]],\n",
            "       grad_fn=<LogSoftmaxBackward0>)\n",
            "Training: 712\n",
            "Epoch: 0713 loss_train: 0.5407 acc_train: 0.8286 loss_val: 1.0378 acc_val: 0.6633 time: 1.7736s\n",
            "loss_val:1.0378055572509766, val_acc:0.6633333333333333, out_features:tensor([[-3.9633, -4.0955, -0.4093,  ..., -3.5375, -3.7626, -3.9106],\n",
            "        [-4.8062, -7.1098, -7.0144,  ..., -0.6130, -0.8212, -4.8740],\n",
            "        [-2.6939, -2.3404, -2.7026,  ..., -0.4796, -2.7600, -3.0896],\n",
            "        ...,\n",
            "        [-2.3549, -1.1089, -2.4578,  ..., -1.3935, -2.4716, -2.3662],\n",
            "        [-1.6665, -2.2025, -1.8785,  ..., -2.0712, -1.9198, -2.1839],\n",
            "        [-2.2445, -2.5675, -0.7584,  ..., -2.1201, -2.4582, -2.3602]],\n",
            "       grad_fn=<LogSoftmaxBackward0>)\n",
            "Training: 713\n",
            "Epoch: 0714 loss_train: 0.6052 acc_train: 0.8500 loss_val: 0.9584 acc_val: 0.6867 time: 1.7636s\n",
            "loss_val:0.958416759967804, val_acc:0.6866666666666666, out_features:tensor([[-6.8478, -6.5265, -0.0163,  ..., -4.5837, -6.7028, -6.8979],\n",
            "        [-1.8431, -3.2974, -2.7117,  ..., -2.8506, -0.7268, -1.7956],\n",
            "        [-2.9399, -2.9360, -3.2363,  ..., -0.3148, -3.1842, -3.0376],\n",
            "        ...,\n",
            "        [-1.9588, -2.2246, -1.7263,  ..., -2.3812, -1.7715, -1.8472],\n",
            "        [-0.0876, -3.8142, -5.0058,  ..., -3.5996, -4.3446, -4.9128],\n",
            "        [-3.5560, -3.8083, -0.3101,  ..., -4.0439, -3.8701, -3.9849]],\n",
            "       grad_fn=<LogSoftmaxBackward0>)\n",
            "Training: 714\n",
            "Epoch: 0715 loss_train: 0.6404 acc_train: 0.7857 loss_val: 1.1200 acc_val: 0.6800 time: 1.7487s\n",
            "loss_val:1.120003581047058, val_acc:0.68, out_features:tensor([[-6.2199, -5.7394, -0.0213,  ..., -4.7930, -6.2279, -6.0880],\n",
            "        [-2.7816, -5.3944, -5.3330,  ..., -2.5482, -0.3088, -2.1905],\n",
            "        [-3.2619, -2.6339, -2.6557,  ..., -0.3579, -3.0531, -3.2651],\n",
            "        ...,\n",
            "        [-2.1993, -0.9599, -1.5726,  ..., -2.7496, -2.4981, -2.4439],\n",
            "        [-0.0586, -4.7855, -5.1529,  ..., -4.5937, -3.8788, -5.0457],\n",
            "        [-3.2869, -3.4494, -0.1640,  ..., -3.4880, -3.9913, -4.2073]],\n",
            "       grad_fn=<LogSoftmaxBackward0>)\n",
            "Training: 715\n",
            "Epoch: 0716 loss_train: 0.6506 acc_train: 0.8286 loss_val: 1.0124 acc_val: 0.6733 time: 1.7380s\n",
            "loss_val:1.0123565196990967, val_acc:0.6733333333333333, out_features:tensor([[-2.9867e+00, -3.6670e+00, -3.0728e-01,  ..., -2.1691e+00,\n",
            "         -3.6102e+00, -3.6862e+00],\n",
            "        [-1.9459e+00, -1.9459e+00, -1.9459e+00,  ..., -1.9459e+00,\n",
            "         -1.9459e+00, -1.9459e+00],\n",
            "        [-4.0700e+00, -3.7251e+00, -3.3285e+00,  ..., -1.6072e-01,\n",
            "         -3.7913e+00, -3.4825e+00],\n",
            "        ...,\n",
            "        [-5.0269e+00, -6.3102e-02, -5.1308e+00,  ..., -4.5745e+00,\n",
            "         -4.8303e+00, -3.6996e+00],\n",
            "        [-5.3189e-04, -1.0090e+01, -1.0216e+01,  ..., -8.6610e+00,\n",
            "         -8.5247e+00, -1.0122e+01],\n",
            "        [-1.2258e+01, -1.1827e+01, -3.3140e-05,  ..., -1.2101e+01,\n",
            "         -1.1977e+01, -1.2318e+01]], grad_fn=<LogSoftmaxBackward0>)\n",
            "Training: 716\n",
            "Epoch: 0717 loss_train: 0.6993 acc_train: 0.7857 loss_val: 0.9832 acc_val: 0.6967 time: 1.7474s\n",
            "loss_val:0.9831959009170532, val_acc:0.6966666666666667, out_features:tensor([[-6.9057e+00, -6.8947e+00, -1.5373e-02,  ..., -6.5527e+00,\n",
            "         -6.8469e+00, -6.3924e+00],\n",
            "        [-1.6006e+00, -3.3259e+00, -3.1418e+00,  ..., -2.8299e+00,\n",
            "         -1.0113e+00, -1.3193e+00],\n",
            "        [-4.2481e+00, -4.2291e+00, -3.5731e+00,  ..., -9.4694e-02,\n",
            "         -4.4800e+00, -4.3594e+00],\n",
            "        ...,\n",
            "        [-1.3679e+01, -1.2755e-05, -1.3697e+01,  ..., -1.3269e+01,\n",
            "         -1.2002e+01, -1.3386e+01],\n",
            "        [-3.6321e-02, -5.1861e+00, -5.4453e+00,  ..., -4.2324e+00,\n",
            "         -5.0723e+00, -5.9518e+00],\n",
            "        [-5.8916e+00, -5.4801e+00, -1.0965e-02,  ..., -6.8932e+00,\n",
            "         -6.8614e+00, -6.9886e+00]], grad_fn=<LogSoftmaxBackward0>)\n",
            "Training: 717\n",
            "Epoch: 0718 loss_train: 0.5921 acc_train: 0.8286 loss_val: 1.0788 acc_val: 0.6533 time: 1.8832s\n",
            "loss_val:1.078840970993042, val_acc:0.6533333333333333, out_features:tensor([[-7.4915e+00, -7.5002e+00, -1.4626e-02,  ..., -7.0200e+00,\n",
            "         -7.4490e+00, -6.8655e+00],\n",
            "        [-4.3744e+00, -3.0879e+00, -5.8713e+00,  ..., -3.3758e+00,\n",
            "         -1.2674e-01, -3.8627e+00],\n",
            "        [-7.9566e+00, -7.0168e+00, -6.5405e+00,  ..., -3.8263e-03,\n",
            "         -8.0100e+00, -7.6892e+00],\n",
            "        ...,\n",
            "        [-4.4806e+00, -9.5157e-02, -5.1246e+00,  ..., -3.6923e+00,\n",
            "         -3.5079e+00, -4.3884e+00],\n",
            "        [-1.3119e-02, -7.5865e+00, -7.7793e+00,  ..., -6.2541e+00,\n",
            "         -4.6726e+00, -7.8689e+00],\n",
            "        [-5.2855e+00, -4.5041e+00, -4.6270e-02,  ..., -4.4577e+00,\n",
            "         -5.3230e+00, -5.0296e+00]], grad_fn=<LogSoftmaxBackward0>)\n",
            "Training: 718\n",
            "Epoch: 0719 loss_train: 0.6550 acc_train: 0.7929 loss_val: 1.0746 acc_val: 0.6500 time: 1.9705s\n",
            "loss_val:1.0746254920959473, val_acc:0.65, out_features:tensor([[-8.9155e+00, -9.1713e+00, -1.0099e-03,  ..., -8.3335e+00,\n",
            "         -8.5986e+00, -8.3547e+00],\n",
            "        [-1.9459e+00, -1.9459e+00, -1.9459e+00,  ..., -1.9459e+00,\n",
            "         -1.9459e+00, -1.9459e+00],\n",
            "        [-3.2568e+00, -2.8546e+00, -3.0837e+00,  ..., -4.6609e-01,\n",
            "         -2.6695e+00, -2.0631e+00],\n",
            "        ...,\n",
            "        [-3.8134e+00, -1.2361e-01, -3.6377e+00,  ..., -4.4009e+00,\n",
            "         -4.0316e+00, -3.9950e+00],\n",
            "        [-9.2222e-01, -2.2385e+00, -2.6557e+00,  ..., -2.6686e+00,\n",
            "         -1.6971e+00, -2.2826e+00],\n",
            "        [-1.1077e+01, -1.0777e+01, -1.1038e-04,  ..., -1.1027e+01,\n",
            "         -1.0713e+01, -1.0872e+01]], grad_fn=<LogSoftmaxBackward0>)\n",
            "Training: 719\n",
            "Epoch: 0720 loss_train: 0.6153 acc_train: 0.8214 loss_val: 1.0236 acc_val: 0.6667 time: 1.7442s\n",
            "loss_val:1.0235766172409058, val_acc:0.6666666666666666, out_features:tensor([[-3.6127, -3.3679, -0.4905,  ..., -2.6422, -3.6379, -3.5975],\n",
            "        [-2.2055, -2.8760, -2.1142,  ..., -2.1685, -0.9427, -1.8107],\n",
            "        [-2.0286, -2.2113, -2.3857,  ..., -1.0671, -2.6726, -2.2642],\n",
            "        ...,\n",
            "        [-5.8255, -0.0120, -6.9174,  ..., -6.2840, -5.5248, -6.7632],\n",
            "        [-1.1041, -2.4122, -2.2221,  ..., -1.7546, -2.2735, -2.2010],\n",
            "        [-1.9459, -1.9459, -1.9459,  ..., -1.9459, -1.9459, -1.9459]],\n",
            "       grad_fn=<LogSoftmaxBackward0>)\n",
            "Training: 720\n",
            "Epoch: 0721 loss_train: 0.6264 acc_train: 0.8071 loss_val: 1.0174 acc_val: 0.6967 time: 1.7504s\n",
            "loss_val:1.0173850059509277, val_acc:0.6966666666666667, out_features:tensor([[-4.9658e+00, -5.4555e+00, -5.8261e-02,  ..., -4.6936e+00,\n",
            "         -5.3351e+00, -4.7799e+00],\n",
            "        [-4.9934e+00, -9.8497e+00, -9.8570e+00,  ..., -8.5981e+00,\n",
            "         -8.2456e-03, -6.8226e+00],\n",
            "        [-9.5574e+00, -9.3190e+00, -9.7234e+00,  ..., -5.8622e-04,\n",
            "         -9.7783e+00, -8.2399e+00],\n",
            "        ...,\n",
            "        [-2.6889e+00, -7.5039e-01, -2.3627e+00,  ..., -1.9602e+00,\n",
            "         -2.4909e+00, -2.5951e+00],\n",
            "        [-1.8995e-01, -4.6462e+00, -4.5050e+00,  ..., -4.2670e+00,\n",
            "         -2.9074e+00, -2.6254e+00],\n",
            "        [-1.9904e+00, -1.7174e+00, -9.7989e-01,  ..., -2.6748e+00,\n",
            "         -2.3466e+00, -2.6701e+00]], grad_fn=<LogSoftmaxBackward0>)\n",
            "Training: 721\n",
            "Epoch: 0722 loss_train: 0.6133 acc_train: 0.7929 loss_val: 1.0882 acc_val: 0.6467 time: 1.7526s\n",
            "loss_val:1.0882432460784912, val_acc:0.6466666666666666, out_features:tensor([[-4.5665, -4.3798, -0.1362,  ..., -3.9202, -4.3226, -3.3799],\n",
            "        [-1.9459, -1.9459, -1.9459,  ..., -1.9459, -1.9459, -1.9459],\n",
            "        [-2.3577, -2.5270, -2.1461,  ..., -0.6805, -2.6358, -2.5382],\n",
            "        ...,\n",
            "        [-2.8923, -0.3350, -3.4020,  ..., -2.4276, -3.1636, -3.3144],\n",
            "        [-0.1465, -4.2817, -4.7782,  ..., -3.7966, -2.6641, -4.4583],\n",
            "        [-1.7667, -2.7141, -1.0562,  ..., -1.7865, -2.1644, -2.5675]],\n",
            "       grad_fn=<LogSoftmaxBackward0>)\n",
            "Training: 722\n",
            "Epoch: 0723 loss_train: 0.6902 acc_train: 0.7929 loss_val: 1.0206 acc_val: 0.6667 time: 1.7510s\n",
            "loss_val:1.0206066370010376, val_acc:0.6666666666666666, out_features:tensor([[-2.3564, -2.7917, -0.8667,  ..., -2.7317, -2.5850, -1.5790],\n",
            "        [-1.2348, -5.2174, -1.2737,  ..., -4.4842, -0.9146, -5.1129],\n",
            "        [-4.6460, -4.7056, -4.7414,  ..., -0.0491, -4.8745, -4.8327],\n",
            "        ...,\n",
            "        [-2.6879, -0.5600, -3.0439,  ..., -2.9256, -3.0696, -2.3914],\n",
            "        [-1.9459, -1.9459, -1.9459,  ..., -1.9459, -1.9459, -1.9459],\n",
            "        [-1.7391, -2.4697, -0.9754,  ..., -2.4215, -1.9507, -2.6527]],\n",
            "       grad_fn=<LogSoftmaxBackward0>)\n",
            "Training: 723\n",
            "Epoch: 0724 loss_train: 0.6441 acc_train: 0.7929 loss_val: 1.0794 acc_val: 0.6567 time: 1.7402s\n",
            "loss_val:1.0793932676315308, val_acc:0.6566666666666666, out_features:tensor([[-7.4965e+00, -7.4613e+00, -4.7246e-03,  ..., -6.6701e+00,\n",
            "         -7.1264e+00, -7.1999e+00],\n",
            "        [-1.9459e+00, -1.9459e+00, -1.9459e+00,  ..., -1.9459e+00,\n",
            "         -1.9459e+00, -1.9459e+00],\n",
            "        [-2.2295e+00, -3.0105e+00, -2.9087e+00,  ..., -5.8600e-01,\n",
            "         -3.0799e+00, -2.3497e+00],\n",
            "        ...,\n",
            "        [-3.9676e+00, -1.0493e-01, -4.7230e+00,  ..., -3.5757e+00,\n",
            "         -3.8804e+00, -4.3153e+00],\n",
            "        [-1.1042e+00, -2.1513e+00, -2.3596e+00,  ..., -1.8167e+00,\n",
            "         -2.2110e+00, -2.1311e+00],\n",
            "        [-2.3314e+00, -2.8382e+00, -8.1310e-01,  ..., -3.2090e+00,\n",
            "         -2.8488e+00, -1.5004e+00]], grad_fn=<LogSoftmaxBackward0>)\n",
            "Training: 724\n",
            "Epoch: 0725 loss_train: 0.6059 acc_train: 0.8500 loss_val: 1.0748 acc_val: 0.6667 time: 1.8882s\n",
            "loss_val:1.0748294591903687, val_acc:0.6666666666666666, out_features:tensor([[-3.7484, -3.7635, -0.1880,  ..., -3.9467, -3.6063, -3.0378],\n",
            "        [-3.3027, -9.1932, -8.8365,  ..., -9.2818, -0.0381, -9.0545],\n",
            "        [-1.9459, -1.9459, -1.9459,  ..., -1.9459, -1.9459, -1.9459],\n",
            "        ...,\n",
            "        [-4.9469, -0.0401, -6.6597,  ..., -4.8757, -3.8866, -6.5784],\n",
            "        [-0.3389, -3.3626, -3.7265,  ..., -2.1584, -3.1741, -3.4791],\n",
            "        [-6.3015, -6.5960, -0.0112,  ..., -5.4261, -6.8515, -6.6953]],\n",
            "       grad_fn=<LogSoftmaxBackward0>)\n",
            "Training: 725\n",
            "Epoch: 0726 loss_train: 0.6487 acc_train: 0.8071 loss_val: 1.0026 acc_val: 0.6800 time: 1.9617s\n",
            "loss_val:1.0026203393936157, val_acc:0.68, out_features:tensor([[-5.4921, -5.5767, -0.0385,  ..., -4.3153, -5.4774, -4.8454],\n",
            "        [-2.4739, -3.0974, -2.5034,  ..., -3.0884, -0.8029, -1.4341],\n",
            "        [-6.0668, -4.6062, -6.1724,  ..., -0.0213, -5.7408, -6.2513],\n",
            "        ...,\n",
            "        [-2.8581, -0.8849, -2.0174,  ..., -2.2266, -2.2975, -1.9967],\n",
            "        [-0.3915, -2.6850, -2.9925,  ..., -2.5383, -2.9611, -3.1892],\n",
            "        [-3.0487, -2.6529, -0.4263,  ..., -3.0411, -2.6395, -3.0001]],\n",
            "       grad_fn=<LogSoftmaxBackward0>)\n",
            "Training: 726\n",
            "Epoch: 0727 loss_train: 0.6257 acc_train: 0.7857 loss_val: 0.9746 acc_val: 0.6800 time: 1.7415s\n",
            "loss_val:0.9745984673500061, val_acc:0.68, out_features:tensor([[-1.2024e+01, -1.1963e+01, -5.4477e-05,  ..., -1.0795e+01,\n",
            "         -1.1988e+01, -1.1868e+01],\n",
            "        [-7.3578e+00, -6.9300e+00, -8.6079e+00,  ..., -9.3864e+00,\n",
            "         -2.1784e-03, -8.4666e+00],\n",
            "        [-2.9864e+00, -3.0694e+00, -3.1046e+00,  ..., -2.8766e-01,\n",
            "         -3.6154e+00, -2.9858e+00],\n",
            "        ...,\n",
            "        [-2.4508e+00, -8.0754e-01, -2.0992e+00,  ..., -2.2335e+00,\n",
            "         -2.2729e+00, -2.5986e+00],\n",
            "        [-5.9348e-02, -3.9792e+00, -5.5916e+00,  ..., -4.6139e+00,\n",
            "         -4.2677e+00, -5.3646e+00],\n",
            "        [-3.8587e+00, -4.3440e+00, -9.5964e-02,  ..., -4.4501e+00,\n",
            "         -3.5289e+00, -4.6816e+00]], grad_fn=<LogSoftmaxBackward0>)\n",
            "Training: 727\n",
            "Epoch: 0728 loss_train: 0.5976 acc_train: 0.8143 loss_val: 1.0187 acc_val: 0.6967 time: 1.7501s\n",
            "loss_val:1.0187305212020874, val_acc:0.6966666666666667, out_features:tensor([[-5.3455, -5.3562, -0.0530,  ..., -4.1029, -5.4753, -5.1834],\n",
            "        [-1.9459, -1.9459, -1.9459,  ..., -1.9459, -1.9459, -1.9459],\n",
            "        [-1.9459, -1.9459, -1.9459,  ..., -1.9459, -1.9459, -1.9459],\n",
            "        ...,\n",
            "        [-4.3140, -0.1163, -3.0386,  ..., -4.5523, -4.4650, -4.0987],\n",
            "        [-0.6571, -2.3894, -3.3868,  ..., -2.3536, -1.8461, -3.0569],\n",
            "        [-1.9459, -1.9459, -1.9459,  ..., -1.9459, -1.9459, -1.9459]],\n",
            "       grad_fn=<LogSoftmaxBackward0>)\n",
            "Training: 728\n",
            "Epoch: 0729 loss_train: 0.7009 acc_train: 0.7929 loss_val: 0.9615 acc_val: 0.7033 time: 1.7581s\n",
            "loss_val:0.9615482687950134, val_acc:0.7033333333333334, out_features:tensor([[-4.2964e+00, -4.3231e+00, -2.0762e-01,  ..., -4.0896e+00,\n",
            "         -4.6312e+00, -3.7634e+00],\n",
            "        [-1.9459e+00, -1.9459e+00, -1.9459e+00,  ..., -1.9459e+00,\n",
            "         -1.9459e+00, -1.9459e+00],\n",
            "        [-3.7457e+00, -4.0484e+00, -4.3899e+00,  ..., -1.0194e-01,\n",
            "         -3.6930e+00, -4.6002e+00],\n",
            "        ...,\n",
            "        [-2.3368e+00, -7.1668e-01, -2.6327e+00,  ..., -2.4383e+00,\n",
            "         -2.2574e+00, -2.3422e+00],\n",
            "        [-7.8867e-01, -2.3418e+00, -2.6364e+00,  ..., -2.2332e+00,\n",
            "         -1.9800e+00, -2.6643e+00],\n",
            "        [-1.4670e+01, -1.3907e+01, -3.3379e-06,  ..., -1.4647e+01,\n",
            "         -1.4703e+01, -1.4337e+01]], grad_fn=<LogSoftmaxBackward0>)\n",
            "Training: 729\n",
            "Epoch: 0730 loss_train: 0.5806 acc_train: 0.8214 loss_val: 1.0561 acc_val: 0.6400 time: 1.7467s\n",
            "loss_val:1.0560805797576904, val_acc:0.64, out_features:tensor([[-1.0656e+01, -1.0656e+01, -2.5317e-04,  ..., -1.0227e+01,\n",
            "         -1.0611e+01, -9.7102e+00],\n",
            "        [-7.9084e+00, -1.0696e+01, -1.0431e+01,  ..., -9.7834e+00,\n",
            "         -2.1690e-03, -6.3961e+00],\n",
            "        [-3.7523e+00, -3.2755e+00, -3.7431e+00,  ..., -1.9368e-01,\n",
            "         -3.5170e+00, -3.1933e+00],\n",
            "        ...,\n",
            "        [-1.9993e+00, -1.2900e+00, -1.7726e+00,  ..., -2.2890e+00,\n",
            "         -2.0345e+00, -2.4357e+00],\n",
            "        [-1.4020e+00, -2.2378e+00, -1.9715e+00,  ..., -1.7876e+00,\n",
            "         -1.8509e+00, -2.4854e+00],\n",
            "        [-7.5133e+00, -6.3709e+00, -5.0860e-03,  ..., -7.4306e+00,\n",
            "         -7.3545e+00, -7.4534e+00]], grad_fn=<LogSoftmaxBackward0>)\n",
            "Training: 730\n",
            "Epoch: 0731 loss_train: 0.6126 acc_train: 0.8143 loss_val: 1.0165 acc_val: 0.6900 time: 1.7470s\n",
            "loss_val:1.0165461301803589, val_acc:0.69, out_features:tensor([[-8.5902e+00, -8.7493e+00, -1.4566e-03,  ..., -7.5274e+00,\n",
            "         -8.5560e+00, -8.6613e+00],\n",
            "        [-2.9719e+00, -5.9573e+00, -6.0609e+00,  ..., -5.9261e+00,\n",
            "         -1.7665e-01, -2.2973e+00],\n",
            "        [-7.2419e+00, -8.6361e+00, -9.6350e+00,  ..., -1.1977e-03,\n",
            "         -9.2663e+00, -9.4345e+00],\n",
            "        ...,\n",
            "        [-2.8793e+00, -6.5401e-01, -2.6067e+00,  ..., -2.3455e+00,\n",
            "         -2.0235e+00, -2.9354e+00],\n",
            "        [-1.4030e+00, -2.2906e+00, -2.2949e+00,  ..., -1.9005e+00,\n",
            "         -1.8278e+00, -2.1096e+00],\n",
            "        [-3.0236e+00, -3.3553e+00, -4.7133e-01,  ..., -1.7696e+00,\n",
            "         -2.8190e+00, -3.5237e+00]], grad_fn=<LogSoftmaxBackward0>)\n",
            "Training: 731\n",
            "Epoch: 0732 loss_train: 0.6671 acc_train: 0.8429 loss_val: 1.0156 acc_val: 0.7000 time: 1.8969s\n",
            "loss_val:1.015596866607666, val_acc:0.7, out_features:tensor([[-6.7193, -6.6817, -0.0260,  ..., -6.2103, -6.6648, -5.5045],\n",
            "        [-1.7590, -9.8834, -9.8787,  ..., -3.2783, -0.2378, -6.4350],\n",
            "        [-3.1730, -3.8347, -3.1350,  ..., -0.1781, -4.0117, -3.6854],\n",
            "        ...,\n",
            "        [-3.6938, -0.1485, -3.2459,  ..., -3.8055, -3.8389, -4.2269],\n",
            "        [-0.0148, -6.4792, -6.9233,  ..., -5.3082, -5.3807, -6.8322],\n",
            "        [-2.3009, -1.8091, -1.5599,  ..., -2.7033, -1.7335, -1.5604]],\n",
            "       grad_fn=<LogSoftmaxBackward0>)\n",
            "Training: 732\n",
            "Epoch: 0733 loss_train: 0.6171 acc_train: 0.7786 loss_val: 0.9799 acc_val: 0.6633 time: 1.9523s\n",
            "loss_val:0.9798927903175354, val_acc:0.6633333333333333, out_features:tensor([[-1.5297e+01, -1.5423e+01, -3.2186e-06,  ..., -1.5269e+01,\n",
            "         -1.5394e+01, -1.5307e+01],\n",
            "        [-4.6527e+00, -5.0225e+00, -5.9775e+00,  ..., -5.1368e+00,\n",
            "         -4.3805e-02, -4.1439e+00],\n",
            "        [-6.1789e+00, -5.7363e+00, -5.8723e+00,  ..., -1.8101e-02,\n",
            "         -5.9630e+00, -5.1673e+00],\n",
            "        ...,\n",
            "        [-1.8680e+00, -1.2365e+00, -1.9510e+00,  ..., -1.7549e+00,\n",
            "         -2.5052e+00, -2.3558e+00],\n",
            "        [-7.4082e-01, -3.2825e+00, -3.2637e+00,  ..., -1.8655e+00,\n",
            "         -1.4535e+00, -3.3947e+00],\n",
            "        [-1.9459e+00, -1.9459e+00, -1.9459e+00,  ..., -1.9459e+00,\n",
            "         -1.9459e+00, -1.9459e+00]], grad_fn=<LogSoftmaxBackward0>)\n",
            "Training: 733\n",
            "Epoch: 0734 loss_train: 0.5267 acc_train: 0.8571 loss_val: 1.0418 acc_val: 0.6367 time: 1.7463s\n",
            "loss_val:1.041805624961853, val_acc:0.6366666666666667, out_features:tensor([[-7.5739e+00, -7.5538e+00, -4.2565e-03,  ..., -6.7331e+00,\n",
            "         -7.6331e+00, -7.2925e+00],\n",
            "        [-4.4613e+00, -5.2327e+00, -4.7261e+00,  ..., -2.9023e+00,\n",
            "         -1.1233e-01, -3.8939e+00],\n",
            "        [-3.5488e+00, -4.8099e+00, -3.2897e+00,  ..., -9.9571e-02,\n",
            "         -4.8165e+00, -4.8674e+00],\n",
            "        ...,\n",
            "        [-4.2506e+00, -1.4740e-01, -3.5729e+00,  ..., -3.1576e+00,\n",
            "         -4.1273e+00, -3.7536e+00],\n",
            "        [-1.5948e-01, -3.9327e+00, -4.3833e+00,  ..., -3.5097e+00,\n",
            "         -2.8019e+00, -4.2008e+00],\n",
            "        [-3.3766e+00, -1.9470e+00, -3.9028e-01,  ..., -3.0169e+00,\n",
            "         -3.4745e+00, -3.6453e+00]], grad_fn=<LogSoftmaxBackward0>)\n",
            "Training: 734\n",
            "Epoch: 0735 loss_train: 0.5509 acc_train: 0.8500 loss_val: 1.0396 acc_val: 0.6667 time: 1.7505s\n",
            "loss_val:1.039598822593689, val_acc:0.6666666666666666, out_features:tensor([[-3.7255, -3.5595, -0.2040,  ..., -3.2682, -3.5659, -3.7121],\n",
            "        [-1.9459, -1.9459, -1.9459,  ..., -1.9459, -1.9459, -1.9459],\n",
            "        [-2.2891, -1.9813, -2.2462,  ..., -0.9860, -2.1562, -2.2979],\n",
            "        ...,\n",
            "        [-3.4003, -0.2518, -3.6044,  ..., -2.7263, -3.1578, -3.5621],\n",
            "        [-0.0262, -5.2450, -6.1463,  ..., -5.1711, -5.0370, -5.9242],\n",
            "        [-2.8414, -3.3268, -0.7365,  ..., -3.1240, -1.8372, -2.4724]],\n",
            "       grad_fn=<LogSoftmaxBackward0>)\n",
            "Training: 735\n",
            "Epoch: 0736 loss_train: 0.5852 acc_train: 0.8071 loss_val: 1.0657 acc_val: 0.6700 time: 1.7482s\n",
            "loss_val:1.0656802654266357, val_acc:0.67, out_features:tensor([[-1.9459, -1.9459, -1.9459,  ..., -1.9459, -1.9459, -1.9459],\n",
            "        [-1.9459, -1.9459, -1.9459,  ..., -1.9459, -1.9459, -1.9459],\n",
            "        [-6.3717, -5.9726, -6.7649,  ..., -0.0086, -6.6442, -6.8458],\n",
            "        ...,\n",
            "        [-2.7138, -0.9152, -2.4558,  ..., -3.4353, -1.3991, -2.0086],\n",
            "        [-0.7558, -2.9306, -2.5590,  ..., -1.4622, -2.5732, -3.3724],\n",
            "        [-1.9459, -1.9459, -1.9459,  ..., -1.9459, -1.9459, -1.9459]],\n",
            "       grad_fn=<LogSoftmaxBackward0>)\n",
            "Training: 736\n",
            "Epoch: 0737 loss_train: 0.5876 acc_train: 0.8429 loss_val: 1.0028 acc_val: 0.6567 time: 1.7469s\n",
            "loss_val:1.0028153657913208, val_acc:0.6566666666666666, out_features:tensor([[-1.0457e+01, -1.0576e+01, -3.3468e-04,  ..., -1.0130e+01,\n",
            "         -1.0622e+01, -1.0465e+01],\n",
            "        [-3.1779e+00, -4.3685e+00, -3.5758e+00,  ..., -1.9731e+00,\n",
            "         -6.4364e-01, -1.4179e+00],\n",
            "        [-6.8919e+00, -7.4095e+00, -7.8620e+00,  ..., -3.2729e-03,\n",
            "         -7.5884e+00, -7.7664e+00],\n",
            "        ...,\n",
            "        [-5.2365e+00, -1.6925e-02, -6.7192e+00,  ..., -6.6632e+00,\n",
            "         -6.6020e+00, -5.0598e+00],\n",
            "        [-5.3523e-02, -5.3943e+00, -5.6641e+00,  ..., -4.2223e+00,\n",
            "         -4.3505e+00, -4.5139e+00],\n",
            "        [-2.3217e+00, -2.9468e+00, -5.3779e-01,  ..., -2.0419e+00,\n",
            "         -2.9827e+00, -3.0986e+00]], grad_fn=<LogSoftmaxBackward0>)\n",
            "Training: 737\n",
            "Epoch: 0738 loss_train: 0.6080 acc_train: 0.8214 loss_val: 0.9174 acc_val: 0.7167 time: 1.7399s\n",
            "loss_val:0.9174062013626099, val_acc:0.7166666666666667, out_features:tensor([[-7.3607e+00, -7.2904e+00, -6.9234e-03,  ..., -5.7422e+00,\n",
            "         -7.1763e+00, -7.3089e+00],\n",
            "        [-2.6092e+00, -3.5385e+00, -3.1719e+00,  ..., -1.9748e+00,\n",
            "         -1.3050e+00, -8.6437e-01],\n",
            "        [-1.1173e+01, -9.5796e+00, -1.0826e+01,  ..., -1.5210e-04,\n",
            "         -1.0840e+01, -1.1066e+01],\n",
            "        ...,\n",
            "        [-1.8055e+00, -9.8555e-01, -2.5786e+00,  ..., -2.2565e+00,\n",
            "         -2.1318e+00, -2.2406e+00],\n",
            "        [-1.2512e+00, -2.2737e+00, -2.5416e+00,  ..., -1.6436e+00,\n",
            "         -2.2381e+00, -2.5504e+00],\n",
            "        [-4.3507e+00, -2.7571e+00, -2.4534e-01,  ..., -4.2731e+00,\n",
            "         -4.0915e+00, -3.9467e+00]], grad_fn=<LogSoftmaxBackward0>)\n",
            "Training: 738\n",
            "Epoch: 0739 loss_train: 0.4846 acc_train: 0.8357 loss_val: 1.0814 acc_val: 0.6500 time: 1.8961s\n",
            "loss_val:1.08143949508667, val_acc:0.65, out_features:tensor([[-5.1712, -5.2573, -0.0871,  ..., -3.5755, -5.0717, -4.7085],\n",
            "        [-1.9459, -1.9459, -1.9459,  ..., -1.9459, -1.9459, -1.9459],\n",
            "        [-3.0021, -2.7184, -2.7767,  ..., -0.3632, -3.1883, -2.9858],\n",
            "        ...,\n",
            "        [-4.0415, -0.0772, -4.2051,  ..., -4.2760, -4.5881, -4.6025],\n",
            "        [-0.0428, -5.1038, -5.8225,  ..., -5.3045, -4.4351, -4.3750],\n",
            "        [-4.3298, -3.0180, -0.2350,  ..., -4.2850, -4.5780, -4.5916]],\n",
            "       grad_fn=<LogSoftmaxBackward0>)\n",
            "Training: 739\n",
            "Epoch: 0740 loss_train: 0.6439 acc_train: 0.8143 loss_val: 1.0200 acc_val: 0.6867 time: 1.9655s\n",
            "loss_val:1.0199764966964722, val_acc:0.6866666666666666, out_features:tensor([[-7.0748e+00, -6.7937e+00, -7.7646e-03,  ..., -6.3313e+00,\n",
            "         -6.5988e+00, -6.3848e+00],\n",
            "        [-6.4640e+00, -8.4751e+00, -8.7835e+00,  ..., -6.6933e+00,\n",
            "         -5.7848e-01, -8.3025e-01],\n",
            "        [-2.5177e+00, -2.2667e+00, -1.8303e+00,  ..., -1.0665e+00,\n",
            "         -2.4572e+00, -1.9240e+00],\n",
            "        ...,\n",
            "        [-8.5253e+00, -1.2126e-03, -8.7322e+00,  ..., -7.8302e+00,\n",
            "         -8.7241e+00, -8.8862e+00],\n",
            "        [-6.2340e-01, -2.4385e+00, -2.7612e+00,  ..., -1.8331e+00,\n",
            "         -2.5208e+00, -3.2378e+00],\n",
            "        [-7.8841e+00, -8.1628e+00, -1.5447e-03,  ..., -7.7933e+00,\n",
            "         -8.7262e+00, -8.8219e+00]], grad_fn=<LogSoftmaxBackward0>)\n",
            "Training: 740\n",
            "Epoch: 0741 loss_train: 0.6307 acc_train: 0.7786 loss_val: 0.9825 acc_val: 0.7000 time: 1.7538s\n",
            "loss_val:0.9825010895729065, val_acc:0.7, out_features:tensor([[-6.1842, -6.3706, -0.0139,  ..., -6.1555, -6.2692, -5.6423],\n",
            "        [-1.1456, -5.2900, -6.5256,  ..., -3.8605, -0.4784, -3.4036],\n",
            "        [-2.2018, -2.5533, -2.8639,  ..., -0.4825, -2.6342, -3.4545],\n",
            "        ...,\n",
            "        [-3.9464, -0.1774, -4.0745,  ..., -2.6167, -4.0246, -4.2261],\n",
            "        [-0.2226, -3.0959, -3.6718,  ..., -3.6483, -2.9453, -3.8644],\n",
            "        [-4.9206, -4.3130, -0.1008,  ..., -4.8131, -4.7403, -4.1471]],\n",
            "       grad_fn=<LogSoftmaxBackward0>)\n",
            "Training: 741\n",
            "Epoch: 0742 loss_train: 0.6256 acc_train: 0.7857 loss_val: 1.0547 acc_val: 0.6500 time: 1.7376s\n",
            "loss_val:1.0546880960464478, val_acc:0.65, out_features:tensor([[-1.0619e+01, -1.0620e+01, -5.2593e-04,  ..., -9.9134e+00,\n",
            "         -1.0636e+01, -1.0358e+01],\n",
            "        [-2.5548e+00, -3.1511e+00, -2.4993e+00,  ..., -3.3617e+00,\n",
            "         -8.6015e-01, -1.2385e+00],\n",
            "        [-1.9459e+00, -1.9459e+00, -1.9459e+00,  ..., -1.9459e+00,\n",
            "         -1.9459e+00, -1.9459e+00],\n",
            "        ...,\n",
            "        [-4.3106e+00, -1.1214e-01, -3.7983e+00,  ..., -3.4117e+00,\n",
            "         -4.0395e+00, -4.6716e+00],\n",
            "        [-2.1675e-01, -3.7502e+00, -3.8553e+00,  ..., -3.3583e+00,\n",
            "         -3.5507e+00, -2.9475e+00],\n",
            "        [-1.2568e+00, -2.6954e+00, -1.7383e+00,  ..., -2.5679e+00,\n",
            "         -2.4936e+00, -1.8304e+00]], grad_fn=<LogSoftmaxBackward0>)\n",
            "Training: 742\n",
            "Epoch: 0743 loss_train: 0.6807 acc_train: 0.8071 loss_val: 1.0545 acc_val: 0.6500 time: 1.7555s\n",
            "loss_val:1.054479718208313, val_acc:0.65, out_features:tensor([[-1.5022e+01, -1.4957e+01, -3.4571e-06,  ..., -1.4815e+01,\n",
            "         -1.5015e+01, -1.4963e+01],\n",
            "        [-1.9459e+00, -1.9459e+00, -1.9459e+00,  ..., -1.9459e+00,\n",
            "         -1.9459e+00, -1.9459e+00],\n",
            "        [-2.1757e+00, -2.3898e+00, -2.2685e+00,  ..., -9.5820e-01,\n",
            "         -2.2183e+00, -2.1224e+00],\n",
            "        ...,\n",
            "        [-2.1917e+00, -1.1862e+00, -2.3290e+00,  ..., -2.1734e+00,\n",
            "         -1.9401e+00, -2.1315e+00],\n",
            "        [-3.7209e-01, -3.4073e+00, -3.9294e+00,  ..., -2.3544e+00,\n",
            "         -2.1871e+00, -3.5017e+00],\n",
            "        [-5.5652e+00, -5.9222e+00, -4.1480e-02,  ..., -3.7535e+00,\n",
            "         -5.0430e+00, -6.2006e+00]], grad_fn=<LogSoftmaxBackward0>)\n",
            "Training: 743\n",
            "Epoch: 0744 loss_train: 0.5777 acc_train: 0.7857 loss_val: 1.0783 acc_val: 0.6867 time: 1.7581s\n",
            "loss_val:1.0782771110534668, val_acc:0.6866666666666666, out_features:tensor([[-5.6248e+00, -5.5707e+00, -1.1158e-01,  ..., -4.7018e+00,\n",
            "         -5.5270e+00, -4.1117e+00],\n",
            "        [-3.6061e+00, -4.6208e+00, -3.7137e+00,  ..., -3.0621e+00,\n",
            "         -1.4374e-01, -4.4903e+00],\n",
            "        [-4.4643e+00, -4.4032e+00, -3.0183e+00,  ..., -1.2823e-01,\n",
            "         -4.6327e+00, -4.1534e+00],\n",
            "        ...,\n",
            "        [-8.3382e+00, -7.2068e-03, -8.3499e+00,  ..., -5.1701e+00,\n",
            "         -7.5896e+00, -8.3256e+00],\n",
            "        [-1.9459e+00, -1.9459e+00, -1.9459e+00,  ..., -1.9459e+00,\n",
            "         -1.9459e+00, -1.9459e+00],\n",
            "        [-8.2449e+00, -6.1090e+00, -1.5056e-02,  ..., -4.4592e+00,\n",
            "         -7.9850e+00, -8.1530e+00]], grad_fn=<LogSoftmaxBackward0>)\n",
            "Training: 744\n",
            "Epoch: 0745 loss_train: 0.5464 acc_train: 0.8500 loss_val: 1.0551 acc_val: 0.6767 time: 1.7355s\n",
            "loss_val:1.0551447868347168, val_acc:0.6766666666666666, out_features:tensor([[-4.0512, -4.1235, -0.2440,  ..., -3.6193, -3.9432, -3.0903],\n",
            "        [-1.9105, -5.9261, -5.9491,  ..., -3.3401, -0.2686, -3.1156],\n",
            "        [-4.7305, -4.7513, -5.1798,  ..., -0.0501, -4.9171, -4.9160],\n",
            "        ...,\n",
            "        [-6.1771, -0.0159, -6.3928,  ..., -5.8643, -5.3359, -6.2114],\n",
            "        [-0.3664, -2.9782, -3.0139,  ..., -3.2885, -2.6458, -2.8477],\n",
            "        [-3.6945, -3.6818, -0.2663,  ..., -3.6783, -2.3957, -3.1150]],\n",
            "       grad_fn=<LogSoftmaxBackward0>)\n",
            "Training: 745\n",
            "Epoch: 0746 loss_train: 0.6056 acc_train: 0.8071 loss_val: 1.0806 acc_val: 0.6800 time: 1.8732s\n",
            "loss_val:1.080571174621582, val_acc:0.68, out_features:tensor([[-4.1171, -4.2447, -0.3332,  ..., -4.3554, -4.2432, -2.3844],\n",
            "        [-1.7921, -3.5391, -3.1700,  ..., -2.6138, -0.6344, -2.0242],\n",
            "        [-4.2467, -4.0007, -2.6017,  ..., -0.1890, -4.3153, -3.3056],\n",
            "        ...,\n",
            "        [-1.9459, -1.9459, -1.9459,  ..., -1.9459, -1.9459, -1.9459],\n",
            "        [-1.2142, -2.3534, -2.3339,  ..., -1.9351, -1.8386, -2.0328],\n",
            "        [-3.0368, -3.0564, -0.3532,  ..., -3.8282, -3.0681, -3.5476]],\n",
            "       grad_fn=<LogSoftmaxBackward0>)\n",
            "Training: 746\n",
            "Epoch: 0747 loss_train: 0.5768 acc_train: 0.8429 loss_val: 0.9137 acc_val: 0.7100 time: 1.9726s\n",
            "loss_val:0.9136689305305481, val_acc:0.71, out_features:tensor([[-1.0451e+01, -1.0407e+01, -1.2758e-03,  ..., -1.0094e+01,\n",
            "         -1.0449e+01, -1.0143e+01],\n",
            "        [-1.9459e+00, -1.9459e+00, -1.9459e+00,  ..., -1.9459e+00,\n",
            "         -1.9459e+00, -1.9459e+00],\n",
            "        [-1.9459e+00, -1.9459e+00, -1.9459e+00,  ..., -1.9459e+00,\n",
            "         -1.9459e+00, -1.9459e+00],\n",
            "        ...,\n",
            "        [-3.2844e+00, -4.8475e-01, -2.4682e+00,  ..., -2.0498e+00,\n",
            "         -2.8308e+00, -3.1454e+00],\n",
            "        [-1.5106e+00, -2.0507e+00, -2.0369e+00,  ..., -1.7834e+00,\n",
            "         -2.2498e+00, -1.9229e+00],\n",
            "        [-1.9459e+00, -1.9459e+00, -1.9459e+00,  ..., -1.9459e+00,\n",
            "         -1.9459e+00, -1.9459e+00]], grad_fn=<LogSoftmaxBackward0>)\n",
            "Training: 747\n",
            "Epoch: 0748 loss_train: 0.5997 acc_train: 0.8571 loss_val: 0.9272 acc_val: 0.7133 time: 1.7369s\n",
            "loss_val:0.9272257685661316, val_acc:0.7133333333333334, out_features:tensor([[-8.3267e+00, -8.3620e+00, -2.1401e-03,  ..., -7.8813e+00,\n",
            "         -8.4618e+00, -7.7931e+00],\n",
            "        [-6.9032e+00, -5.3690e+00, -6.6992e+00,  ..., -6.9150e+00,\n",
            "         -2.1098e-02, -4.4131e+00],\n",
            "        [-9.3611e+00, -9.6341e+00, -1.0216e+01,  ..., -2.9679e-04,\n",
            "         -1.0027e+01, -1.0293e+01],\n",
            "        ...,\n",
            "        [-2.9704e+00, -5.2963e-01, -3.0202e+00,  ..., -2.4481e+00,\n",
            "         -2.3926e+00, -2.7076e+00],\n",
            "        [-4.6247e-02, -5.2642e+00, -5.9013e+00,  ..., -4.1476e+00,\n",
            "         -4.1640e+00, -5.9159e+00],\n",
            "        [-4.7057e+00, -2.8465e+00, -1.2543e-01,  ..., -4.2982e+00,\n",
            "         -4.4138e+00, -4.4537e+00]], grad_fn=<LogSoftmaxBackward0>)\n",
            "Training: 748\n",
            "Epoch: 0749 loss_train: 0.6239 acc_train: 0.8143 loss_val: 1.0693 acc_val: 0.6633 time: 1.7286s\n",
            "loss_val:1.0692752599716187, val_acc:0.6633333333333333, out_features:tensor([[-6.4632, -6.0923, -0.0137,  ..., -6.1524, -6.1412, -5.8602],\n",
            "        [-3.3208, -3.8337, -2.8837,  ..., -3.4644, -0.4433, -1.7337],\n",
            "        [-2.6194, -2.4855, -2.1713,  ..., -0.7518, -2.5566, -2.7148],\n",
            "        ...,\n",
            "        [-3.7537, -0.1522, -4.5227,  ..., -3.0720, -3.3492, -4.2868],\n",
            "        [-1.2257, -2.1347, -2.5450,  ..., -1.6691, -1.9334, -2.2816],\n",
            "        [-4.1972, -6.5186, -0.0239,  ..., -6.2229, -6.0891, -6.6786]],\n",
            "       grad_fn=<LogSoftmaxBackward0>)\n",
            "Training: 749\n",
            "Epoch: 0750 loss_train: 0.5286 acc_train: 0.8214 loss_val: 1.0175 acc_val: 0.6800 time: 1.7417s\n",
            "loss_val:1.0175042152404785, val_acc:0.68, out_features:tensor([[-5.1107e+00, -4.8858e+00, -5.0745e-02,  ..., -4.8774e+00,\n",
            "         -4.9697e+00, -5.0263e+00],\n",
            "        [-4.9345e+00, -5.2435e+00, -4.7983e+00,  ..., -5.1685e+00,\n",
            "         -8.5013e-02, -3.0121e+00],\n",
            "        [-8.7801e+00, -8.7946e+00, -8.1261e+00,  ..., -8.9677e-04,\n",
            "         -9.1127e+00, -9.1547e+00],\n",
            "        ...,\n",
            "        [-2.6848e+00, -8.2331e-01, -2.7503e+00,  ..., -1.7608e+00,\n",
            "         -2.0631e+00, -2.6762e+00],\n",
            "        [-5.3735e-01, -2.7824e+00, -2.9571e+00,  ..., -2.9414e+00,\n",
            "         -2.1184e+00, -2.5228e+00],\n",
            "        [-5.0645e+00, -4.6605e+00, -4.9393e-02,  ..., -4.2940e+00,\n",
            "         -4.9606e+00, -5.3657e+00]], grad_fn=<LogSoftmaxBackward0>)\n",
            "Training: 750\n",
            "Epoch: 0751 loss_train: 0.4875 acc_train: 0.8786 loss_val: 0.9642 acc_val: 0.7067 time: 1.7462s\n",
            "loss_val:0.9642392992973328, val_acc:0.7066666666666667, out_features:tensor([[-4.5061e+00, -4.4933e+00, -1.1076e-01,  ..., -3.9894e+00,\n",
            "         -4.3958e+00, -3.9952e+00],\n",
            "        [-1.5258e+00, -3.6483e+00, -3.7543e+00,  ..., -3.1619e+00,\n",
            "         -9.2836e-01, -1.2926e+00],\n",
            "        [-4.0883e+00, -4.9622e+00, -5.3833e+00,  ..., -5.7048e-02,\n",
            "         -4.4336e+00, -4.6732e+00],\n",
            "        ...,\n",
            "        [-6.9431e+00, -3.1474e-03, -8.7226e+00,  ..., -6.6602e+00,\n",
            "         -8.0015e+00, -8.3565e+00],\n",
            "        [-3.7821e-01, -2.6467e+00, -3.9921e+00,  ..., -2.3218e+00,\n",
            "         -3.0652e+00, -2.7520e+00],\n",
            "        [-4.0494e+00, -3.7395e+00, -3.6118e-01,  ..., -3.8587e+00,\n",
            "         -3.4842e+00, -1.6788e+00]], grad_fn=<LogSoftmaxBackward0>)\n",
            "Training: 751\n",
            "Epoch: 0752 loss_train: 0.5358 acc_train: 0.8429 loss_val: 1.0236 acc_val: 0.6667 time: 1.7297s\n",
            "loss_val:1.0236265659332275, val_acc:0.6666666666666666, out_features:tensor([[-3.6563, -3.4333, -0.2201,  ..., -3.3696, -3.3235, -3.6421],\n",
            "        [-1.8028, -4.8775, -5.5472,  ..., -5.1511, -0.2446, -3.4615],\n",
            "        [-2.4704, -2.3078, -2.2037,  ..., -0.9101, -2.4921, -1.9467],\n",
            "        ...,\n",
            "        [-2.8640, -0.3762, -3.0015,  ..., -2.5394, -2.8670, -3.2089],\n",
            "        [-1.1989, -1.8713, -2.4323,  ..., -2.0223, -2.2066, -2.1348],\n",
            "        [-7.1549, -6.0281, -0.0089,  ..., -5.7519, -7.3108, -7.2999]],\n",
            "       grad_fn=<LogSoftmaxBackward0>)\n",
            "Training: 752\n",
            "Epoch: 0753 loss_train: 0.5904 acc_train: 0.8500 loss_val: 0.9799 acc_val: 0.6633 time: 1.8739s\n",
            "loss_val:0.9798542261123657, val_acc:0.6633333333333333, out_features:tensor([[-1.0315e+01, -1.0473e+01, -2.0502e-04,  ..., -1.0371e+01,\n",
            "         -1.0379e+01, -1.0171e+01],\n",
            "        [-1.9459e+00, -1.9459e+00, -1.9459e+00,  ..., -1.9459e+00,\n",
            "         -1.9459e+00, -1.9459e+00],\n",
            "        [-2.2340e+00, -2.5495e+00, -4.2521e+00,  ..., -2.9967e-01,\n",
            "         -4.0135e+00, -3.6677e+00],\n",
            "        ...,\n",
            "        [-4.9767e+00, -7.1134e-02, -5.0351e+00,  ..., -4.0190e+00,\n",
            "         -3.6729e+00, -4.9874e+00],\n",
            "        [-6.7747e-01, -2.6782e+00, -3.2293e+00,  ..., -1.7737e+00,\n",
            "         -2.5197e+00, -2.6974e+00],\n",
            "        [-2.7886e+00, -2.7962e+00, -6.2092e-01,  ..., -3.0858e+00,\n",
            "         -2.6875e+00, -1.8261e+00]], grad_fn=<LogSoftmaxBackward0>)\n",
            "Training: 753\n",
            "Epoch: 0754 loss_train: 0.5979 acc_train: 0.8071 loss_val: 0.9732 acc_val: 0.6833 time: 1.9722s\n",
            "loss_val:0.9731738567352295, val_acc:0.6833333333333333, out_features:tensor([[-5.7593, -5.7970, -0.0290,  ..., -4.4765, -5.6231, -5.6849],\n",
            "        [-5.4243, -5.2746, -1.1078,  ..., -5.5518, -0.4330, -5.5060],\n",
            "        [-5.5702, -4.8289, -7.4038,  ..., -0.0146, -7.1892, -7.2078],\n",
            "        ...,\n",
            "        [-2.1340, -1.0799, -2.2144,  ..., -2.0348, -2.0281, -2.3740],\n",
            "        [-0.5420, -2.6799, -3.4681,  ..., -1.7664, -2.8810, -3.1427],\n",
            "        [-6.2725, -4.4866, -0.0215,  ..., -6.2323, -5.9408, -6.3323]],\n",
            "       grad_fn=<LogSoftmaxBackward0>)\n",
            "Training: 754\n",
            "Epoch: 0755 loss_train: 0.5147 acc_train: 0.8643 loss_val: 0.9993 acc_val: 0.6667 time: 1.7443s\n",
            "loss_val:0.9992792010307312, val_acc:0.6666666666666666, out_features:tensor([[-6.0863, -6.1465, -0.0420,  ..., -5.6820, -6.0526, -5.5563],\n",
            "        [-2.0332, -3.9271, -2.7476,  ..., -3.9219, -0.3598, -2.9524],\n",
            "        [-3.3805, -4.2847, -4.3450,  ..., -0.1042, -4.2796, -4.3821],\n",
            "        ...,\n",
            "        [-2.2606, -1.6496, -2.4500,  ..., -2.1687, -2.1266, -2.0153],\n",
            "        [-1.2541, -2.7191, -2.3082,  ..., -2.1822, -2.1383, -2.5052],\n",
            "        [-4.9187, -4.7321, -0.0950,  ..., -4.9821, -4.2536, -3.8620]],\n",
            "       grad_fn=<LogSoftmaxBackward0>)\n",
            "Training: 755\n",
            "Epoch: 0756 loss_train: 0.6522 acc_train: 0.7786 loss_val: 1.0533 acc_val: 0.6867 time: 1.7479s\n",
            "loss_val:1.053300380706787, val_acc:0.6866666666666666, out_features:tensor([[-4.0028e+00, -4.3717e+00, -1.4775e-01,  ..., -4.1143e+00,\n",
            "         -4.4447e+00, -3.7043e+00],\n",
            "        [-2.4864e+00, -2.3527e+00, -1.7391e+00,  ..., -2.2658e+00,\n",
            "         -1.1429e+00, -1.7475e+00],\n",
            "        [-8.8390e+00, -9.6795e+00, -9.0810e+00,  ..., -5.7836e-04,\n",
            "         -9.1245e+00, -9.5583e+00],\n",
            "        ...,\n",
            "        [-6.7663e+00, -4.4338e-03, -7.8657e+00,  ..., -7.7749e+00,\n",
            "         -6.4426e+00, -7.6102e+00],\n",
            "        [-1.1012e+00, -2.5725e+00, -2.3739e+00,  ..., -1.6564e+00,\n",
            "         -2.1958e+00, -2.3427e+00],\n",
            "        [-1.2568e+01, -1.2683e+01, -3.0994e-05,  ..., -1.2363e+01,\n",
            "         -1.1279e+01, -1.2474e+01]], grad_fn=<LogSoftmaxBackward0>)\n",
            "Training: 756\n",
            "Epoch: 0757 loss_train: 0.5201 acc_train: 0.8500 loss_val: 0.9820 acc_val: 0.6767 time: 1.7284s\n",
            "loss_val:0.9819933176040649, val_acc:0.6766666666666666, out_features:tensor([[-3.1077e+00, -2.7739e+00, -4.4670e-01,  ..., -2.4031e+00,\n",
            "         -2.9893e+00, -2.9497e+00],\n",
            "        [-2.2639e+00, -2.3374e+00, -2.8806e+00,  ..., -1.9669e+00,\n",
            "         -9.7997e-01, -1.7745e+00],\n",
            "        [-8.0496e+00, -6.8591e+00, -7.3423e+00,  ..., -2.9517e-03,\n",
            "         -7.6890e+00, -8.3247e+00],\n",
            "        ...,\n",
            "        [-6.0045e+00, -1.6861e-02, -6.6421e+00,  ..., -5.8340e+00,\n",
            "         -4.9382e+00, -6.4449e+00],\n",
            "        [-9.5576e-01, -2.8032e+00, -2.6550e+00,  ..., -1.6970e+00,\n",
            "         -2.0406e+00, -2.3048e+00],\n",
            "        [-3.6849e+00, -3.3714e+00, -1.8719e-01,  ..., -2.9592e+00,\n",
            "         -3.8091e+00, -3.9244e+00]], grad_fn=<LogSoftmaxBackward0>)\n",
            "Training: 757\n",
            "Epoch: 0758 loss_train: 0.6139 acc_train: 0.7857 loss_val: 1.0430 acc_val: 0.6200 time: 1.7422s\n",
            "loss_val:1.0429881811141968, val_acc:0.62, out_features:tensor([[-1.6234e+01, -1.6292e+01, -7.1526e-07,  ..., -1.6282e+01,\n",
            "         -1.6184e+01, -1.5861e+01],\n",
            "        [-1.8841e+00, -5.0117e+00, -4.8392e+00,  ..., -2.0201e+00,\n",
            "         -4.1164e-01, -3.4221e+00],\n",
            "        [-7.1638e+00, -5.9826e+00, -7.3281e+00,  ..., -5.3787e-03,\n",
            "         -7.4318e+00, -7.7218e+00],\n",
            "        ...,\n",
            "        [-3.0324e+00, -8.0762e-01, -2.7203e+00,  ..., -1.6576e+00,\n",
            "         -2.3774e+00, -2.8948e+00],\n",
            "        [-2.8055e-03, -8.5001e+00, -8.7634e+00,  ..., -7.8458e+00,\n",
            "         -6.6165e+00, -8.7126e+00],\n",
            "        [-3.3390e+00, -3.3394e+00, -3.2550e-01,  ..., -3.0240e+00,\n",
            "         -2.9638e+00, -2.8551e+00]], grad_fn=<LogSoftmaxBackward0>)\n",
            "Training: 758\n",
            "Epoch: 0759 loss_train: 0.6544 acc_train: 0.8143 loss_val: 1.0566 acc_val: 0.6767 time: 1.7469s\n",
            "loss_val:1.0565834045410156, val_acc:0.6766666666666666, out_features:tensor([[-2.9907e+00, -2.4136e+00, -5.8916e-01,  ..., -2.4140e+00,\n",
            "         -2.6003e+00, -2.8241e+00],\n",
            "        [-2.8137e+00, -3.4806e+00, -3.2437e+00,  ..., -2.9493e+00,\n",
            "         -4.0502e-01, -3.4188e+00],\n",
            "        [-8.2645e+00, -7.8043e+00, -7.0401e+00,  ..., -2.3299e-03,\n",
            "         -8.3778e+00, -8.0473e+00],\n",
            "        ...,\n",
            "        [-5.3324e+00, -1.8548e-02, -6.2430e+00,  ..., -6.0439e+00,\n",
            "         -5.7075e+00, -5.4755e+00],\n",
            "        [-2.8221e-02, -5.6815e+00, -5.9605e+00,  ..., -5.1579e+00,\n",
            "         -4.5356e+00, -5.9570e+00],\n",
            "        [-5.4179e+00, -2.7649e+00, -9.8530e-02,  ..., -4.7401e+00,\n",
            "         -5.4238e+00, -5.2802e+00]], grad_fn=<LogSoftmaxBackward0>)\n",
            "Training: 759\n",
            "Epoch: 0760 loss_train: 0.5734 acc_train: 0.8214 loss_val: 1.0206 acc_val: 0.6667 time: 1.8687s\n",
            "loss_val:1.0205821990966797, val_acc:0.6666666666666666, out_features:tensor([[-9.2600e+00, -9.0877e+00, -9.1648e-03,  ..., -8.9774e+00,\n",
            "         -9.2321e+00, -8.7500e+00],\n",
            "        [-1.9459e+00, -1.9459e+00, -1.9459e+00,  ..., -1.9459e+00,\n",
            "         -1.9459e+00, -1.9459e+00],\n",
            "        [-3.5023e+00, -3.7413e+00, -3.4892e+00,  ..., -2.3977e-01,\n",
            "         -3.8340e+00, -2.7768e+00],\n",
            "        ...,\n",
            "        [-3.7165e+00, -2.1021e-01, -3.2641e+00,  ..., -3.6134e+00,\n",
            "         -3.0324e+00, -3.8000e+00],\n",
            "        [-7.3708e-01, -2.6716e+00, -2.4063e+00,  ..., -1.8064e+00,\n",
            "         -2.7499e+00, -2.3728e+00],\n",
            "        [-2.4601e+00, -1.8029e+00, -1.4618e+00,  ..., -2.6985e+00,\n",
            "         -1.7714e+00, -1.7258e+00]], grad_fn=<LogSoftmaxBackward0>)\n",
            "Training: 760\n",
            "Epoch: 0761 loss_train: 0.6407 acc_train: 0.8071 loss_val: 0.9703 acc_val: 0.6800 time: 1.9436s\n",
            "loss_val:0.9702782034873962, val_acc:0.68, out_features:tensor([[-5.5481, -5.5426, -0.0617,  ..., -5.0321, -5.5491, -5.1872],\n",
            "        [-1.9459, -1.9459, -1.9459,  ..., -1.9459, -1.9459, -1.9459],\n",
            "        [-4.0509, -3.4118, -3.0940,  ..., -0.2021, -4.1638, -3.1719],\n",
            "        ...,\n",
            "        [-2.5691, -1.1319, -2.9045,  ..., -2.6175, -2.1930, -1.6837],\n",
            "        [-0.2145, -3.8518, -4.2579,  ..., -2.8961, -2.6591, -4.0532],\n",
            "        [-6.4059, -4.6795, -0.0230,  ..., -5.3817, -6.3766, -5.9703]],\n",
            "       grad_fn=<LogSoftmaxBackward0>)\n",
            "Training: 761\n",
            "Epoch: 0762 loss_train: 0.6345 acc_train: 0.8214 loss_val: 0.9979 acc_val: 0.6767 time: 1.7434s\n",
            "loss_val:0.9978833198547363, val_acc:0.6766666666666666, out_features:tensor([[-5.4938e+00, -5.3890e+00, -4.8972e-02,  ..., -3.8506e+00,\n",
            "         -5.0187e+00, -4.9778e+00],\n",
            "        [-2.7429e+00, -3.7558e+00, -4.3472e+00,  ..., -3.9092e+00,\n",
            "         -1.9343e-01, -3.2986e+00],\n",
            "        [-7.9986e+00, -8.5168e+00, -7.8778e+00,  ..., -1.5635e-03,\n",
            "         -8.3778e+00, -8.3692e+00],\n",
            "        ...,\n",
            "        [-6.6758e+00, -6.2340e-03, -7.2393e+00,  ..., -6.5136e+00,\n",
            "         -6.9810e+00, -6.7883e+00],\n",
            "        [-9.9050e-04, -9.5435e+00, -9.6702e+00,  ..., -9.7807e+00,\n",
            "         -7.3045e+00, -9.6031e+00],\n",
            "        [-3.3308e+00, -3.0805e+00, -4.5288e-01,  ..., -3.0725e+00,\n",
            "         -3.3839e+00, -2.1748e+00]], grad_fn=<LogSoftmaxBackward0>)\n",
            "Training: 762\n",
            "Epoch: 0763 loss_train: 0.6725 acc_train: 0.8071 loss_val: 0.9814 acc_val: 0.6967 time: 1.7454s\n",
            "loss_val:0.9814026951789856, val_acc:0.6966666666666667, out_features:tensor([[-5.7570, -5.6599, -0.0350,  ..., -4.7703, -5.4523, -5.2779],\n",
            "        [-2.3672, -3.5526, -1.6430,  ..., -2.0987, -0.8226, -2.3659],\n",
            "        [-3.6880, -3.6800, -5.2741,  ..., -0.0944, -3.7249, -5.1588],\n",
            "        ...,\n",
            "        [-3.5899, -0.1565, -4.4097,  ..., -2.8183, -3.7605, -4.4706],\n",
            "        [-0.0203, -6.2359, -6.7700,  ..., -5.7930, -4.7015, -5.6530],\n",
            "        [-5.5103, -5.8789, -0.0268,  ..., -5.5021, -5.4721, -5.9598]],\n",
            "       grad_fn=<LogSoftmaxBackward0>)\n",
            "Training: 763\n",
            "Epoch: 0764 loss_train: 0.5769 acc_train: 0.8214 loss_val: 1.0975 acc_val: 0.6433 time: 1.7296s\n",
            "loss_val:1.097501516342163, val_acc:0.6433333333333333, out_features:tensor([[-4.3376, -4.4141, -0.0974,  ..., -4.0264, -3.9498, -4.1681],\n",
            "        [-1.9459, -1.9459, -1.9459,  ..., -1.9459, -1.9459, -1.9459],\n",
            "        [-2.5073, -3.0675, -2.6613,  ..., -0.4762, -2.9865, -2.4116],\n",
            "        ...,\n",
            "        [-4.6261, -0.0725, -5.0189,  ..., -3.9952, -3.8315, -5.0081],\n",
            "        [-0.1993, -4.4372, -4.5474,  ..., -2.8006, -3.0661, -3.2065],\n",
            "        [-1.9459, -1.9459, -1.9459,  ..., -1.9459, -1.9459, -1.9459]],\n",
            "       grad_fn=<LogSoftmaxBackward0>)\n",
            "Training: 764\n",
            "Epoch: 0765 loss_train: 0.6234 acc_train: 0.8429 loss_val: 1.1010 acc_val: 0.6600 time: 1.7474s\n",
            "loss_val:1.1009894609451294, val_acc:0.66, out_features:tensor([[-4.5024, -4.1201, -0.1259,  ..., -4.2783, -4.5203, -4.5398],\n",
            "        [-3.9645, -6.6003, -5.7850,  ..., -6.1695, -0.1026, -2.6487],\n",
            "        [-1.9459, -1.9459, -1.9459,  ..., -1.9459, -1.9459, -1.9459],\n",
            "        ...,\n",
            "        [-2.6249, -0.8022, -2.7856,  ..., -1.5260, -2.6745, -2.7730],\n",
            "        [-0.0316, -4.7786, -6.0703,  ..., -5.1641, -5.8628, -4.7500],\n",
            "        [-5.5497, -6.7270, -0.0090,  ..., -7.8501, -5.9604, -7.6473]],\n",
            "       grad_fn=<LogSoftmaxBackward0>)\n",
            "Training: 765\n",
            "Epoch: 0766 loss_train: 0.5429 acc_train: 0.8500 loss_val: 1.0226 acc_val: 0.6700 time: 1.7399s\n",
            "loss_val:1.0226280689239502, val_acc:0.67, out_features:tensor([[-3.2345, -3.1990, -0.3904,  ..., -3.3370, -3.0198, -3.0605],\n",
            "        [-2.4925, -2.3690, -1.6517,  ..., -3.0211, -0.7314, -3.0901],\n",
            "        [-4.7032, -5.1822, -3.9564,  ..., -0.0488, -5.3246, -5.2083],\n",
            "        ...,\n",
            "        [-2.3816, -0.8990, -2.7446,  ..., -2.0503, -1.6625, -2.8906],\n",
            "        [-0.0241, -6.2126, -6.4393,  ..., -5.0023, -4.7382, -5.9279],\n",
            "        [-1.3301, -2.5403, -1.1438,  ..., -3.0670, -2.5963, -1.7912]],\n",
            "       grad_fn=<LogSoftmaxBackward0>)\n",
            "Training: 766\n",
            "Epoch: 0767 loss_train: 0.6004 acc_train: 0.8071 loss_val: 0.9856 acc_val: 0.7167 time: 1.8615s\n",
            "loss_val:0.9856235980987549, val_acc:0.7166666666666667, out_features:tensor([[-1.4547e+01, -1.4047e+01, -4.2915e-06,  ..., -1.4415e+01,\n",
            "         -1.3422e+01, -1.4508e+01],\n",
            "        [-4.0359e+00, -6.4077e+00, -6.1732e+00,  ..., -6.0429e+00,\n",
            "         -4.0705e-02, -4.2465e+00],\n",
            "        [-2.6184e+00, -2.7651e+00, -1.7382e+00,  ..., -7.2796e-01,\n",
            "         -2.4356e+00, -2.6069e+00],\n",
            "        ...,\n",
            "        [-4.7354e+00, -8.2615e-02, -4.7413e+00,  ..., -3.7234e+00,\n",
            "         -4.3890e+00, -4.0694e+00],\n",
            "        [-1.6177e-01, -3.5812e+00, -4.0885e+00,  ..., -3.1206e+00,\n",
            "         -3.6077e+00, -4.1264e+00],\n",
            "        [-3.3298e+00, -3.3283e+00, -3.4305e-01,  ..., -1.9923e+00,\n",
            "         -3.6715e+00, -3.4997e+00]], grad_fn=<LogSoftmaxBackward0>)\n",
            "Training: 767\n",
            "Epoch: 0768 loss_train: 0.5725 acc_train: 0.8714 loss_val: 0.9706 acc_val: 0.6933 time: 1.9714s\n",
            "loss_val:0.9706288576126099, val_acc:0.6933333333333334, out_features:tensor([[-1.0287e+01, -1.0164e+01, -2.2075e-04,  ..., -1.0127e+01,\n",
            "         -1.0228e+01, -1.0416e+01],\n",
            "        [-1.9683e+00, -1.5660e+00, -3.2655e+00,  ..., -1.2705e+00,\n",
            "         -2.0203e+00, -1.7873e+00],\n",
            "        [-6.0332e+00, -6.0410e+00, -4.9882e+00,  ..., -1.9532e-02,\n",
            "         -5.7904e+00, -5.8375e+00],\n",
            "        ...,\n",
            "        [-4.2604e+00, -8.8633e-02, -4.7605e+00,  ..., -3.6605e+00,\n",
            "         -4.4518e+00, -4.2069e+00],\n",
            "        [-1.4108e+00, -2.4676e+00, -1.8706e+00,  ..., -2.4287e+00,\n",
            "         -2.4183e+00, -1.6405e+00],\n",
            "        [-1.9459e+00, -1.9459e+00, -1.9459e+00,  ..., -1.9459e+00,\n",
            "         -1.9459e+00, -1.9459e+00]], grad_fn=<LogSoftmaxBackward0>)\n",
            "Training: 768\n",
            "Epoch: 0769 loss_train: 0.6574 acc_train: 0.7643 loss_val: 1.0743 acc_val: 0.6600 time: 1.7459s\n",
            "loss_val:1.0742714405059814, val_acc:0.66, out_features:tensor([[-1.0744e+01, -1.0630e+01, -2.2111e-04,  ..., -9.6923e+00,\n",
            "         -1.0617e+01, -1.0677e+01],\n",
            "        [-1.9459e+00, -1.9459e+00, -1.9459e+00,  ..., -1.9459e+00,\n",
            "         -1.9459e+00, -1.9459e+00],\n",
            "        [-5.3942e+00, -5.5478e+00, -4.6157e+00,  ..., -3.1911e-02,\n",
            "         -5.4365e+00, -5.5686e+00],\n",
            "        ...,\n",
            "        [-4.9699e+00, -3.3918e-02, -5.8180e+00,  ..., -5.6760e+00,\n",
            "         -4.3542e+00, -5.4446e+00],\n",
            "        [-1.9459e+00, -1.9459e+00, -1.9459e+00,  ..., -1.9459e+00,\n",
            "         -1.9459e+00, -1.9459e+00],\n",
            "        [-2.0062e+00, -3.9601e+00, -5.7892e-01,  ..., -1.5537e+00,\n",
            "         -3.3229e+00, -3.9518e+00]], grad_fn=<LogSoftmaxBackward0>)\n",
            "Training: 769\n",
            "Epoch: 0770 loss_train: 0.6153 acc_train: 0.8286 loss_val: 1.0353 acc_val: 0.6800 time: 1.7416s\n",
            "loss_val:1.0352885723114014, val_acc:0.68, out_features:tensor([[-4.8356e+00, -5.0168e+00, -8.4369e-02,  ..., -4.7994e+00,\n",
            "         -4.8155e+00, -3.8987e+00],\n",
            "        [-2.2385e+00, -3.5730e+00, -2.9285e+00,  ..., -3.8821e+00,\n",
            "         -8.2883e-01, -1.0928e+00],\n",
            "        [-8.8460e+00, -9.3798e+00, -6.8685e+00,  ..., -1.5404e-03,\n",
            "         -9.1917e+00, -9.2984e+00],\n",
            "        ...,\n",
            "        [-1.9459e+00, -1.9459e+00, -1.9459e+00,  ..., -1.9459e+00,\n",
            "         -1.9459e+00, -1.9459e+00],\n",
            "        [-7.1413e-02, -5.3702e+00, -5.1536e+00,  ..., -3.1341e+00,\n",
            "         -5.1354e+00, -5.3881e+00],\n",
            "        [-7.4282e+00, -6.9782e+00, -4.7251e-03,  ..., -6.7038e+00,\n",
            "         -7.3396e+00, -7.0873e+00]], grad_fn=<LogSoftmaxBackward0>)\n",
            "Training: 770\n",
            "Epoch: 0771 loss_train: 0.6241 acc_train: 0.8143 loss_val: 0.9744 acc_val: 0.6800 time: 1.7422s\n",
            "loss_val:0.9744256734848022, val_acc:0.68, out_features:tensor([[-4.9957, -5.1133, -0.0830,  ..., -3.5811, -4.5707, -4.9693],\n",
            "        [-2.1440, -2.9999, -2.1291,  ..., -3.0362, -1.0820, -1.2150],\n",
            "        [-6.1503, -5.0286, -3.4932,  ..., -0.0474, -6.1550, -5.8041],\n",
            "        ...,\n",
            "        [-2.5609, -1.3930, -3.2157,  ..., -1.2229, -1.4739, -2.6338],\n",
            "        [-0.0760, -3.9557, -5.2346,  ..., -3.8610, -4.0834, -5.2395],\n",
            "        [-5.0178, -5.3724, -0.0422,  ..., -5.4183, -4.6119, -5.1166]],\n",
            "       grad_fn=<LogSoftmaxBackward0>)\n",
            "Training: 771\n",
            "Epoch: 0772 loss_train: 0.6030 acc_train: 0.8357 loss_val: 1.0784 acc_val: 0.6600 time: 1.7373s\n",
            "loss_val:1.0784003734588623, val_acc:0.66, out_features:tensor([[-4.9027, -4.7314, -0.0712,  ..., -4.4876, -4.8426, -4.1459],\n",
            "        [-1.9459, -1.9459, -1.9459,  ..., -1.9459, -1.9459, -1.9459],\n",
            "        [-5.1053, -4.6901, -3.5579,  ..., -0.0683, -4.9445, -4.5956],\n",
            "        ...,\n",
            "        [-3.6037, -0.1588, -4.4059,  ..., -3.5226, -3.6434, -3.3083],\n",
            "        [-0.8037, -2.4250, -2.7618,  ..., -2.0111, -2.4939, -2.1795],\n",
            "        [-1.6653, -2.5975, -1.4008,  ..., -1.4737, -1.9762, -2.7111]],\n",
            "       grad_fn=<LogSoftmaxBackward0>)\n",
            "Training: 772\n",
            "Epoch: 0773 loss_train: 0.6169 acc_train: 0.8000 loss_val: 0.9795 acc_val: 0.6933 time: 1.7578s\n",
            "loss_val:0.9795107841491699, val_acc:0.6933333333333334, out_features:tensor([[-3.3779e+00, -3.6257e+00, -4.3645e-01,  ..., -3.6341e+00,\n",
            "         -3.7623e+00, -2.5270e+00],\n",
            "        [-5.5413e+00, -7.8263e+00, -7.8800e+00,  ..., -5.6629e+00,\n",
            "         -1.0546e-02, -6.2518e+00],\n",
            "        [-6.3671e+00, -6.4486e+00, -7.2828e+00,  ..., -7.0560e-03,\n",
            "         -6.7239e+00, -6.8070e+00],\n",
            "        ...,\n",
            "        [-1.9459e+00, -1.9459e+00, -1.9459e+00,  ..., -1.9459e+00,\n",
            "         -1.9459e+00, -1.9459e+00],\n",
            "        [-6.5075e-02, -5.3982e+00, -5.6264e+00,  ..., -3.3893e+00,\n",
            "         -4.4756e+00, -5.5402e+00],\n",
            "        [-3.5288e+00, -2.9985e+00, -3.3752e-01,  ..., -2.6467e+00,\n",
            "         -2.4986e+00, -3.4959e+00]], grad_fn=<LogSoftmaxBackward0>)\n",
            "Training: 773\n",
            "Epoch: 0774 loss_train: 0.5727 acc_train: 0.8214 loss_val: 1.1000 acc_val: 0.6367 time: 1.8782s\n",
            "loss_val:1.0999884605407715, val_acc:0.6366666666666667, out_features:tensor([[-4.2096e+00, -4.4037e+00, -9.9675e-02,  ..., -4.2528e+00,\n",
            "         -4.2528e+00, -3.6885e+00],\n",
            "        [-2.2292e+00, -3.0877e+00, -2.9699e+00,  ..., -2.8103e+00,\n",
            "         -8.1849e-01, -1.3597e+00],\n",
            "        [-9.9820e+00, -1.0285e+01, -1.0860e+01,  ..., -1.6259e-04,\n",
            "         -1.0967e+01, -1.0446e+01],\n",
            "        ...,\n",
            "        [-6.2962e+00, -1.1233e-02, -6.7364e+00,  ..., -5.4601e+00,\n",
            "         -6.5457e+00, -6.6105e+00],\n",
            "        [-2.0414e-01, -3.1383e+00, -4.3503e+00,  ..., -3.2543e+00,\n",
            "         -3.1439e+00, -3.9965e+00],\n",
            "        [-2.5202e+00, -2.1370e+00, -6.3301e-01,  ..., -2.9149e+00,\n",
            "         -2.2933e+00, -2.5702e+00]], grad_fn=<LogSoftmaxBackward0>)\n",
            "Training: 774\n",
            "Epoch: 0775 loss_train: 0.5507 acc_train: 0.8071 loss_val: 1.0957 acc_val: 0.6400 time: 1.9554s\n",
            "loss_val:1.0956758260726929, val_acc:0.64, out_features:tensor([[-4.0906, -4.1676, -0.1654,  ..., -3.4349, -3.7850, -3.5699],\n",
            "        [-1.9459, -1.9459, -1.9459,  ..., -1.9459, -1.9459, -1.9459],\n",
            "        [-3.2177, -3.1252, -2.6762,  ..., -0.3276, -3.3211, -3.1003],\n",
            "        ...,\n",
            "        [-1.9459, -1.9459, -1.9459,  ..., -1.9459, -1.9459, -1.9459],\n",
            "        [-0.3507, -3.4793, -3.9372,  ..., -2.1955, -2.4203, -3.8330],\n",
            "        [-3.1720, -3.9967, -0.3950,  ..., -3.9664, -3.6425, -2.9483]],\n",
            "       grad_fn=<LogSoftmaxBackward0>)\n",
            "Training: 775\n",
            "Epoch: 0776 loss_train: 0.5524 acc_train: 0.8429 loss_val: 1.0813 acc_val: 0.6733 time: 1.7374s\n",
            "loss_val:1.0813432931900024, val_acc:0.6733333333333333, out_features:tensor([[-9.1385e+00, -9.0154e+00, -1.4782e-03,  ..., -8.0105e+00,\n",
            "         -8.9740e+00, -8.9082e+00],\n",
            "        [-2.7410e+00, -3.6998e+00, -3.4300e+00,  ..., -1.9329e+00,\n",
            "         -5.8540e-01, -1.8697e+00],\n",
            "        [-3.6733e+00, -4.1720e+00, -5.3279e+00,  ..., -6.0014e-02,\n",
            "         -5.5355e+00, -5.3655e+00],\n",
            "        ...,\n",
            "        [-4.0815e+00, -1.4589e-01, -4.3377e+00,  ..., -2.9461e+00,\n",
            "         -4.1551e+00, -3.6958e+00],\n",
            "        [-1.5234e-01, -3.8636e+00, -4.5973e+00,  ..., -2.7767e+00,\n",
            "         -3.6073e+00, -4.5578e+00],\n",
            "        [-2.1178e+00, -3.1831e+00, -1.4063e+00,  ..., -3.2077e+00,\n",
            "         -1.9510e+00, -1.2763e+00]], grad_fn=<LogSoftmaxBackward0>)\n",
            "Training: 776\n",
            "Epoch: 0777 loss_train: 0.6444 acc_train: 0.8071 loss_val: 1.0456 acc_val: 0.6733 time: 1.7375s\n",
            "loss_val:1.0456428527832031, val_acc:0.6733333333333333, out_features:tensor([[-8.6520e+00, -8.7339e+00, -1.8028e-03,  ..., -8.6227e+00,\n",
            "         -8.7789e+00, -7.5764e+00],\n",
            "        [-1.9459e+00, -1.9459e+00, -1.9459e+00,  ..., -1.9459e+00,\n",
            "         -1.9459e+00, -1.9459e+00],\n",
            "        [-5.9189e+00, -6.0084e+00, -3.9285e+00,  ..., -3.1347e-02,\n",
            "         -6.2591e+00, -6.2207e+00],\n",
            "        ...,\n",
            "        [-4.2240e+00, -1.7231e-01, -4.1942e+00,  ..., -2.6141e+00,\n",
            "         -3.6023e+00, -4.0535e+00],\n",
            "        [-5.5255e-01, -3.1680e+00, -3.5394e+00,  ..., -2.1895e+00,\n",
            "         -2.1777e+00, -2.3561e+00],\n",
            "        [-7.7263e+00, -6.9747e+00, -3.6209e-03,  ..., -6.8786e+00,\n",
            "         -7.6397e+00, -7.9584e+00]], grad_fn=<LogSoftmaxBackward0>)\n",
            "Training: 777\n",
            "Epoch: 0778 loss_train: 0.7076 acc_train: 0.7929 loss_val: 1.0104 acc_val: 0.6700 time: 1.7438s\n",
            "loss_val:1.0103775262832642, val_acc:0.67, out_features:tensor([[-5.2757e+00, -4.2267e+00, -4.2965e-02,  ..., -5.2666e+00,\n",
            "         -5.1711e+00, -5.3649e+00],\n",
            "        [-1.1142e+01, -1.1180e+01, -1.1566e+01,  ..., -1.0975e+01,\n",
            "         -6.2084e-03, -5.0954e+00],\n",
            "        [-2.5068e+00, -3.1606e+00, -2.7618e+00,  ..., -4.9830e-01,\n",
            "         -2.9099e+00, -2.7091e+00],\n",
            "        ...,\n",
            "        [-3.5273e+00, -1.3219e-01, -3.9947e+00,  ..., -3.5699e+00,\n",
            "         -4.0630e+00, -3.8927e+00],\n",
            "        [-2.7163e-01, -3.9210e+00, -4.2045e+00,  ..., -2.4215e+00,\n",
            "         -2.5624e+00, -3.9791e+00],\n",
            "        [-2.6559e+00, -3.5245e+00, -2.4631e+00,  ..., -3.9176e+00,\n",
            "         -1.5411e+00, -8.1797e-01]], grad_fn=<LogSoftmaxBackward0>)\n",
            "Training: 778\n",
            "Epoch: 0779 loss_train: 0.6143 acc_train: 0.8071 loss_val: 1.0022 acc_val: 0.6767 time: 1.7509s\n",
            "loss_val:1.0022292137145996, val_acc:0.6766666666666666, out_features:tensor([[-4.7968e+00, -4.6027e+00, -1.3431e-01,  ..., -4.6082e+00,\n",
            "         -4.6854e+00, -4.4427e+00],\n",
            "        [-2.1165e+00, -3.7807e+00, -3.4661e+00,  ..., -3.2073e+00,\n",
            "         -5.4158e-01, -1.6904e+00],\n",
            "        [-8.0132e+00, -7.2920e+00, -8.8336e+00,  ..., -2.0362e-03,\n",
            "         -7.4592e+00, -8.7339e+00],\n",
            "        ...,\n",
            "        [-3.0390e+00, -5.9759e-01, -2.3424e+00,  ..., -2.8244e+00,\n",
            "         -2.7517e+00, -2.7337e+00],\n",
            "        [-6.7124e-01, -2.6862e+00, -2.7433e+00,  ..., -2.0177e+00,\n",
            "         -2.2617e+00, -2.6488e+00],\n",
            "        [-3.2472e+00, -3.3371e+00, -2.0332e-01,  ..., -3.1582e+00,\n",
            "         -3.6993e+00, -3.9578e+00]], grad_fn=<LogSoftmaxBackward0>)\n",
            "Training: 779\n",
            "Epoch: 0780 loss_train: 0.5209 acc_train: 0.8786 loss_val: 0.9594 acc_val: 0.7233 time: 1.7538s\n",
            "loss_val:0.9593520164489746, val_acc:0.7233333333333334, out_features:tensor([[-1.6089e+01, -1.6080e+01, -1.2218e-04,  ..., -1.5948e+01,\n",
            "         -1.6087e+01, -1.4513e+01],\n",
            "        [-2.3180e+00, -3.3881e+00, -2.8253e+00,  ..., -1.2427e+00,\n",
            "         -9.1552e-01, -2.4080e+00],\n",
            "        [-5.4958e+00, -5.5623e+00, -6.1955e+00,  ..., -1.3496e-02,\n",
            "         -6.7769e+00, -6.5924e+00],\n",
            "        ...,\n",
            "        [-2.6157e+00, -7.3925e-01, -2.5954e+00,  ..., -2.5878e+00,\n",
            "         -2.4282e+00, -1.7818e+00],\n",
            "        [-7.0573e-02, -4.0663e+00, -4.8494e+00,  ..., -4.2109e+00,\n",
            "         -4.3820e+00, -4.7074e+00],\n",
            "        [-3.3077e+00, -4.2158e+00, -1.2908e-01,  ..., -3.5280e+00,\n",
            "         -4.1529e+00, -4.1839e+00]], grad_fn=<LogSoftmaxBackward0>)\n",
            "Training: 780\n",
            "Epoch: 0781 loss_train: 0.6050 acc_train: 0.8000 loss_val: 1.0488 acc_val: 0.6600 time: 1.8691s\n",
            "loss_val:1.048790454864502, val_acc:0.66, out_features:tensor([[-9.8400e+00, -9.7172e+00, -3.6841e-04,  ..., -9.6092e+00,\n",
            "         -9.9302e+00, -9.5687e+00],\n",
            "        [-1.9459e+00, -1.9459e+00, -1.9459e+00,  ..., -1.9459e+00,\n",
            "         -1.9459e+00, -1.9459e+00],\n",
            "        [-1.1079e+01, -1.0857e+01, -1.0922e+01,  ..., -7.4265e-05,\n",
            "         -1.1680e+01, -1.1920e+01],\n",
            "        ...,\n",
            "        [-5.2446e+00, -4.0337e-02, -5.3787e+00,  ..., -4.3971e+00,\n",
            "         -5.2555e+00, -4.9515e+00],\n",
            "        [-1.8430e-01, -4.0562e+00, -4.4953e+00,  ..., -4.0653e+00,\n",
            "         -2.7040e+00, -4.4387e+00],\n",
            "        [-2.7674e+00, -3.7718e+00, -3.2637e-01,  ..., -2.5731e+00,\n",
            "         -2.8191e+00, -3.6145e+00]], grad_fn=<LogSoftmaxBackward0>)\n",
            "Training: 781\n",
            "Epoch: 0782 loss_train: 0.5984 acc_train: 0.8286 loss_val: 1.0017 acc_val: 0.6500 time: 1.9585s\n",
            "loss_val:1.001709222793579, val_acc:0.65, out_features:tensor([[-1.0277e+01, -1.0257e+01, -4.8554e-04,  ..., -9.9759e+00,\n",
            "         -1.0165e+01, -9.9765e+00],\n",
            "        [-1.4223e+00, -3.8859e+00, -3.7778e+00,  ..., -3.9786e+00,\n",
            "         -5.9334e-01, -2.1018e+00],\n",
            "        [-3.2383e+00, -3.8565e+00, -4.2575e+00,  ..., -1.2277e-01,\n",
            "         -4.4863e+00, -4.3085e+00],\n",
            "        ...,\n",
            "        [-1.8969e+00, -1.5649e+00, -1.5664e+00,  ..., -1.9137e+00,\n",
            "         -2.2348e+00, -2.4360e+00],\n",
            "        [-3.1683e-01, -3.2286e+00, -3.0004e+00,  ..., -2.6663e+00,\n",
            "         -3.2666e+00, -3.2119e+00],\n",
            "        [-9.0598e+00, -9.2224e+00, -1.7112e-03,  ..., -9.3497e+00,\n",
            "         -7.5138e+00, -8.3283e+00]], grad_fn=<LogSoftmaxBackward0>)\n",
            "Training: 782\n",
            "Epoch: 0783 loss_train: 0.6022 acc_train: 0.7929 loss_val: 0.9859 acc_val: 0.6533 time: 1.7575s\n",
            "loss_val:0.9858688116073608, val_acc:0.6533333333333333, out_features:tensor([[-5.7200e+00, -5.6899e+00, -1.1153e-01,  ..., -4.1566e+00,\n",
            "         -5.7593e+00, -4.1964e+00],\n",
            "        [-2.5281e+00, -2.6982e+00, -3.1325e+00,  ..., -1.6665e+00,\n",
            "         -1.3812e+00, -1.0938e+00],\n",
            "        [-6.8281e+00, -7.2642e+00, -6.5920e+00,  ..., -6.0621e-03,\n",
            "         -7.0276e+00, -6.5447e+00],\n",
            "        ...,\n",
            "        [-2.4942e+00, -6.8288e-01, -2.6237e+00,  ..., -2.8718e+00,\n",
            "         -2.1815e+00, -2.0207e+00],\n",
            "        [-1.8729e-01, -3.2572e+00, -4.2221e+00,  ..., -3.3182e+00,\n",
            "         -3.5921e+00, -3.6296e+00],\n",
            "        [-1.9823e+00, -2.6908e+00, -1.1360e+00,  ..., -2.4620e+00,\n",
            "         -1.7442e+00, -1.9462e+00]], grad_fn=<LogSoftmaxBackward0>)\n",
            "Training: 783\n",
            "Epoch: 0784 loss_train: 0.7053 acc_train: 0.7929 loss_val: 1.0845 acc_val: 0.6533 time: 1.7465s\n",
            "loss_val:1.0844759941101074, val_acc:0.6533333333333333, out_features:tensor([[-2.4632, -2.6775, -1.2925,  ..., -2.0931, -2.3423, -2.1100],\n",
            "        [-2.4974, -2.5473, -2.6628,  ..., -1.4385, -0.9585, -2.4628],\n",
            "        [-4.9687, -4.0570, -4.2861,  ..., -0.0558, -5.3389, -4.8981],\n",
            "        ...,\n",
            "        [-4.9992, -0.0541, -5.4343,  ..., -4.8501, -4.2130, -4.2318],\n",
            "        [-0.2863, -3.6134, -4.2911,  ..., -2.2859, -2.6699, -4.1265],\n",
            "        [-3.6462, -4.5242, -0.1674,  ..., -4.6721, -2.6421, -3.5121]],\n",
            "       grad_fn=<LogSoftmaxBackward0>)\n",
            "Training: 784\n",
            "Epoch: 0785 loss_train: 0.5670 acc_train: 0.8571 loss_val: 0.9509 acc_val: 0.6767 time: 1.7473s\n",
            "loss_val:0.9508537650108337, val_acc:0.6766666666666666, out_features:tensor([[-6.3485, -5.9888, -0.0237,  ..., -6.2503, -6.4761, -5.2383],\n",
            "        [-2.4315, -3.6071, -3.5065,  ..., -3.0500, -0.3781, -2.3569],\n",
            "        [-6.6024, -5.5966, -6.0109,  ..., -0.0111, -6.6777, -6.6941],\n",
            "        ...,\n",
            "        [-3.4482, -0.1963, -4.1637,  ..., -3.9639, -2.7715, -3.3409],\n",
            "        [-1.4165, -2.1635, -2.2429,  ..., -2.0329, -1.8484, -2.0516],\n",
            "        [-2.7294, -2.3180, -0.6763,  ..., -3.2199, -2.2377, -2.0539]],\n",
            "       grad_fn=<LogSoftmaxBackward0>)\n",
            "Training: 785\n",
            "Epoch: 0786 loss_train: 0.5706 acc_train: 0.8357 loss_val: 1.1760 acc_val: 0.6300 time: 1.7363s\n",
            "loss_val:1.1760116815567017, val_acc:0.63, out_features:tensor([[-4.1406, -4.3656, -0.1079,  ..., -4.4466, -4.2171, -4.4330],\n",
            "        [-3.0735, -3.6617, -3.9446,  ..., -1.1505, -0.8406, -1.9818],\n",
            "        [-2.5089, -2.2949, -2.3785,  ..., -0.9142, -1.9560, -2.2424],\n",
            "        ...,\n",
            "        [-1.9459, -1.9459, -1.9459,  ..., -1.9459, -1.9459, -1.9459],\n",
            "        [-0.6720, -2.7733, -3.3414,  ..., -1.4070, -3.0394, -2.8146],\n",
            "        [-3.4795, -2.8150, -0.3421,  ..., -2.8989, -3.6160, -2.9058]],\n",
            "       grad_fn=<LogSoftmaxBackward0>)\n",
            "Training: 786\n",
            "Epoch: 0787 loss_train: 0.5878 acc_train: 0.8429 loss_val: 0.9734 acc_val: 0.6800 time: 1.7613s\n",
            "loss_val:0.9733695387840271, val_acc:0.68, out_features:tensor([[-1.9459, -1.9459, -1.9459,  ..., -1.9459, -1.9459, -1.9459],\n",
            "        [-1.9588, -3.6904, -3.4126,  ..., -2.7535, -0.5204, -2.1179],\n",
            "        [-2.3499, -2.5390, -3.0495,  ..., -0.5713, -2.6697, -2.3105],\n",
            "        ...,\n",
            "        [-4.6893, -0.0926, -5.4151,  ..., -3.0048, -4.3710, -4.7698],\n",
            "        [-0.0134, -5.6638, -6.8322,  ..., -6.5317, -5.4154, -6.3748],\n",
            "        [-4.4678, -3.6628, -0.1255,  ..., -3.2712, -4.4059, -4.6169]],\n",
            "       grad_fn=<LogSoftmaxBackward0>)\n",
            "Training: 787\n",
            "Epoch: 0788 loss_train: 0.6421 acc_train: 0.8214 loss_val: 1.1058 acc_val: 0.6333 time: 1.8883s\n",
            "loss_val:1.1058319807052612, val_acc:0.6333333333333333, out_features:tensor([[-2.9810, -2.9621, -0.5562,  ..., -2.2698, -3.1756, -2.5395],\n",
            "        [-1.9459, -1.9459, -1.9459,  ..., -1.9459, -1.9459, -1.9459],\n",
            "        [-4.8045, -4.3784, -3.4070,  ..., -0.0876, -4.7818, -4.6243],\n",
            "        ...,\n",
            "        [-2.4249, -0.6947, -2.8249,  ..., -2.8299, -2.5513, -2.7940],\n",
            "        [-0.1918, -3.6531, -4.5962,  ..., -4.0527, -2.4924, -3.8191],\n",
            "        [-1.9459, -1.9459, -1.9459,  ..., -1.9459, -1.9459, -1.9459]],\n",
            "       grad_fn=<LogSoftmaxBackward0>)\n",
            "Training: 788\n",
            "Epoch: 0789 loss_train: 0.7019 acc_train: 0.7643 loss_val: 1.0095 acc_val: 0.7000 time: 1.9803s\n",
            "loss_val:1.0095020532608032, val_acc:0.7, out_features:tensor([[-2.7662, -3.0079, -0.4079,  ..., -2.5686, -2.8179, -3.1567],\n",
            "        [-3.9450, -4.0995, -1.2743,  ..., -1.5469, -0.9599, -2.6101],\n",
            "        [-3.6307, -3.3496, -3.3592,  ..., -0.1946, -3.6417, -3.4535],\n",
            "        ...,\n",
            "        [-2.9309, -0.3137, -3.3904,  ..., -2.7701, -2.8213, -3.2609],\n",
            "        [-1.1284, -1.8616, -2.2530,  ..., -1.7505, -2.5525, -2.6814],\n",
            "        [-5.0858, -4.2570, -0.0434,  ..., -5.7090, -4.3446, -5.7656]],\n",
            "       grad_fn=<LogSoftmaxBackward0>)\n",
            "Training: 789\n",
            "Epoch: 0790 loss_train: 0.6475 acc_train: 0.7929 loss_val: 1.0335 acc_val: 0.6967 time: 1.7437s\n",
            "loss_val:1.0335363149642944, val_acc:0.6966666666666667, out_features:tensor([[-2.9618e+00, -2.6834e+00, -4.9048e-01,  ..., -2.1001e+00,\n",
            "         -3.1569e+00, -3.2509e+00],\n",
            "        [-5.9593e+00, -6.6899e+00, -7.8692e+00,  ..., -7.9692e+00,\n",
            "         -5.2275e-03, -8.0021e+00],\n",
            "        [-4.3851e+00, -4.1227e+00, -2.7910e+00,  ..., -1.3883e-01,\n",
            "         -4.2510e+00, -4.5415e+00],\n",
            "        ...,\n",
            "        [-2.8461e+00, -5.0299e-01, -4.1521e+00,  ..., -1.3984e+00,\n",
            "         -3.6227e+00, -3.5040e+00],\n",
            "        [-8.1696e-01, -1.9037e+00, -2.2026e+00,  ..., -2.1350e+00,\n",
            "         -2.6339e+00, -2.9467e+00],\n",
            "        [-5.4443e+00, -5.1926e+00, -5.3446e-02,  ..., -3.6265e+00,\n",
            "         -4.9719e+00, -5.6338e+00]], grad_fn=<LogSoftmaxBackward0>)\n",
            "Training: 790\n",
            "Epoch: 0791 loss_train: 0.6160 acc_train: 0.8714 loss_val: 0.9993 acc_val: 0.6833 time: 1.7397s\n",
            "loss_val:0.999298095703125, val_acc:0.6833333333333333, out_features:tensor([[-5.1806, -4.7888, -0.0522,  ..., -4.4158, -4.9849, -5.1323],\n",
            "        [-1.7765, -2.2107, -2.7755,  ..., -2.0602, -1.1836, -1.8774],\n",
            "        [-3.8254, -2.7761, -3.0521,  ..., -0.2230, -3.6984, -3.5537],\n",
            "        ...,\n",
            "        [-2.4491, -0.7928, -2.7482,  ..., -1.9395, -2.1865, -2.3955],\n",
            "        [-0.7050, -2.8826, -3.0296,  ..., -2.3199, -1.5398, -3.0694],\n",
            "        [-4.7259, -3.7266, -0.0644,  ..., -4.5581, -5.0962, -5.1613]],\n",
            "       grad_fn=<LogSoftmaxBackward0>)\n",
            "Training: 791\n",
            "Epoch: 0792 loss_train: 0.5183 acc_train: 0.8786 loss_val: 1.0027 acc_val: 0.6733 time: 1.7421s\n",
            "loss_val:1.0026696920394897, val_acc:0.6733333333333333, out_features:tensor([[-4.3725, -4.1255, -0.1787,  ..., -3.9312, -4.4780, -4.3672],\n",
            "        [-3.9906, -3.3990, -4.0914,  ..., -3.9098, -0.5505, -1.1619],\n",
            "        [-2.8617, -4.0570, -4.8519,  ..., -0.1320, -3.5718, -4.9395],\n",
            "        ...,\n",
            "        [-5.8928, -0.0155, -6.1426,  ..., -6.1029, -5.5864, -5.9143],\n",
            "        [-0.0100, -8.0150, -8.2260,  ..., -7.2438, -4.8324, -7.9420],\n",
            "        [-2.1773, -3.4031, -1.6074,  ..., -3.0527, -3.1209, -1.3947]],\n",
            "       grad_fn=<LogSoftmaxBackward0>)\n",
            "Training: 792\n",
            "Epoch: 0793 loss_train: 0.5792 acc_train: 0.8429 loss_val: 1.0456 acc_val: 0.6500 time: 1.7455s\n",
            "loss_val:1.045568823814392, val_acc:0.65, out_features:tensor([[-7.4223e+00, -7.3162e+00, -5.0694e-03,  ..., -6.9759e+00,\n",
            "         -7.3126e+00, -7.3692e+00],\n",
            "        [-3.1480e+00, -5.0400e+00, -5.3435e+00,  ..., -4.6529e+00,\n",
            "         -2.5037e-01, -1.8862e+00],\n",
            "        [-5.7684e+00, -7.3631e+00, -7.6516e+00,  ..., -5.5813e-03,\n",
            "         -7.4825e+00, -7.7949e+00],\n",
            "        ...,\n",
            "        [-2.3731e+00, -8.2122e-01, -2.6057e+00,  ..., -2.4861e+00,\n",
            "         -2.5904e+00, -2.1096e+00],\n",
            "        [-2.7779e-01, -3.2601e+00, -3.7059e+00,  ..., -2.8308e+00,\n",
            "         -3.2069e+00, -3.3462e+00],\n",
            "        [-5.9635e+00, -5.2340e+00, -5.0128e-02,  ..., -6.0621e+00,\n",
            "         -5.3734e+00, -5.7828e+00]], grad_fn=<LogSoftmaxBackward0>)\n",
            "Training: 793\n",
            "Epoch: 0794 loss_train: 0.5531 acc_train: 0.8286 loss_val: 0.9138 acc_val: 0.6767 time: 1.7339s\n",
            "loss_val:0.9137732982635498, val_acc:0.6766666666666666, out_features:tensor([[-8.2877e+00, -8.0335e+00, -2.4550e-03,  ..., -6.7881e+00,\n",
            "         -8.4263e+00, -8.3832e+00],\n",
            "        [-1.9459e+00, -1.9459e+00, -1.9459e+00,  ..., -1.9459e+00,\n",
            "         -1.9459e+00, -1.9459e+00],\n",
            "        [-2.5051e+00, -3.2439e+00, -2.7370e+00,  ..., -3.4540e-01,\n",
            "         -3.5693e+00, -2.9793e+00],\n",
            "        ...,\n",
            "        [-1.6147e+00, -1.5808e+00, -2.2369e+00,  ..., -2.5246e+00,\n",
            "         -2.2582e+00, -1.6556e+00],\n",
            "        [-1.4853e-01, -3.3781e+00, -4.0354e+00,  ..., -4.2911e+00,\n",
            "         -3.2417e+00, -4.0585e+00],\n",
            "        [-1.9459e+00, -1.9459e+00, -1.9459e+00,  ..., -1.9459e+00,\n",
            "         -1.9459e+00, -1.9459e+00]], grad_fn=<LogSoftmaxBackward0>)\n",
            "Training: 794\n",
            "Epoch: 0795 loss_train: 0.6447 acc_train: 0.7929 loss_val: 1.0717 acc_val: 0.6600 time: 1.8668s\n",
            "loss_val:1.0716737508773804, val_acc:0.66, out_features:tensor([[-6.2203, -5.9981, -0.0244,  ..., -4.8358, -5.9722, -6.1357],\n",
            "        [-3.6563, -2.6736, -3.0998,  ..., -1.6122, -0.5818, -2.5903],\n",
            "        [-1.9459, -1.9459, -1.9459,  ..., -1.9459, -1.9459, -1.9459],\n",
            "        ...,\n",
            "        [-2.4447, -1.1559, -2.5837,  ..., -2.2739, -1.8841, -1.7191],\n",
            "        [-0.1571, -4.3524, -4.7181,  ..., -2.4487, -3.8755, -4.8021],\n",
            "        [-3.6411, -2.8018, -0.2848,  ..., -2.9747, -3.4540, -3.5271]],\n",
            "       grad_fn=<LogSoftmaxBackward0>)\n",
            "Training: 795\n",
            "Epoch: 0796 loss_train: 0.5581 acc_train: 0.8429 loss_val: 1.0163 acc_val: 0.6633 time: 1.9852s\n",
            "loss_val:1.0162835121154785, val_acc:0.6633333333333333, out_features:tensor([[-5.7837, -5.7081, -0.0258,  ..., -5.1820, -5.7646, -5.3510],\n",
            "        [-1.7698, -2.5523, -2.8857,  ..., -2.1149, -0.8347, -2.3586],\n",
            "        [-3.1670, -2.8323, -3.3356,  ..., -0.2720, -3.3464, -3.0592],\n",
            "        ...,\n",
            "        [-3.1228, -0.7301, -1.8138,  ..., -2.7517, -2.5704, -2.1321],\n",
            "        [-0.0201, -6.8853, -7.1053,  ..., -6.9805, -4.6980, -6.9911],\n",
            "        [-3.3709, -2.2301, -0.6030,  ..., -2.0282, -3.3347, -3.0952]],\n",
            "       grad_fn=<LogSoftmaxBackward0>)\n",
            "Training: 796\n",
            "Epoch: 0797 loss_train: 0.6190 acc_train: 0.8286 loss_val: 1.0698 acc_val: 0.6233 time: 1.7421s\n",
            "loss_val:1.0697996616363525, val_acc:0.6233333333333333, out_features:tensor([[-4.6548e+00, -4.7111e+00, -1.0228e-01,  ..., -4.0157e+00,\n",
            "         -4.3528e+00, -4.7196e+00],\n",
            "        [-1.9459e+00, -1.9459e+00, -1.9459e+00,  ..., -1.9459e+00,\n",
            "         -1.9459e+00, -1.9459e+00],\n",
            "        [-5.5927e+00, -4.8163e+00, -5.4086e+00,  ..., -3.3049e-02,\n",
            "         -5.7944e+00, -4.5432e+00],\n",
            "        ...,\n",
            "        [-1.9459e+00, -1.9459e+00, -1.9459e+00,  ..., -1.9459e+00,\n",
            "         -1.9459e+00, -1.9459e+00],\n",
            "        [-1.4141e-01, -4.2798e+00, -4.9626e+00,  ..., -3.5840e+00,\n",
            "         -2.8491e+00, -4.8915e+00],\n",
            "        [-1.1768e+01, -1.0283e+01, -8.9999e-05,  ..., -1.1830e+01,\n",
            "         -1.1376e+01, -1.0700e+01]], grad_fn=<LogSoftmaxBackward0>)\n",
            "Training: 797\n",
            "Epoch: 0798 loss_train: 0.6246 acc_train: 0.8429 loss_val: 1.0405 acc_val: 0.6700 time: 1.7420s\n",
            "loss_val:1.0405049324035645, val_acc:0.67, out_features:tensor([[-9.0945e+00, -7.8565e+00, -1.1304e-03,  ..., -8.6392e+00,\n",
            "         -8.9610e+00, -9.0960e+00],\n",
            "        [-1.1035e+01, -1.1129e+01, -1.1490e+01,  ..., -1.1449e+01,\n",
            "         -2.9493e-03, -5.8493e+00],\n",
            "        [-3.0311e+00, -3.0649e+00, -3.0543e+00,  ..., -4.3736e-01,\n",
            "         -3.1728e+00, -2.1008e+00],\n",
            "        ...,\n",
            "        [-1.9459e+00, -1.9459e+00, -1.9459e+00,  ..., -1.9459e+00,\n",
            "         -1.9459e+00, -1.9459e+00],\n",
            "        [-6.3342e-01, -2.4492e+00, -2.8094e+00,  ..., -1.9994e+00,\n",
            "         -2.3273e+00, -3.0934e+00],\n",
            "        [-7.4277e+00, -6.4160e+00, -5.1834e-03,  ..., -7.1637e+00,\n",
            "         -7.3537e+00, -7.0697e+00]], grad_fn=<LogSoftmaxBackward0>)\n",
            "Training: 798\n",
            "Epoch: 0799 loss_train: 0.6135 acc_train: 0.8000 loss_val: 1.0555 acc_val: 0.6600 time: 1.7540s\n",
            "loss_val:1.0554733276367188, val_acc:0.66, out_features:tensor([[-7.2594, -7.1860, -0.0120,  ..., -6.4226, -7.3955, -6.5313],\n",
            "        [-4.8461, -7.1187, -6.9837,  ..., -6.8633, -0.0266, -4.2478],\n",
            "        [-4.0474, -3.8762, -2.8363,  ..., -0.1814, -4.0633, -3.6209],\n",
            "        ...,\n",
            "        [-2.9246, -0.8275, -2.3346,  ..., -2.7894, -2.6106, -1.7312],\n",
            "        [-0.0162, -5.2945, -7.4897,  ..., -4.9425, -6.3145, -7.0441],\n",
            "        [-1.9459, -1.9459, -1.9459,  ..., -1.9459, -1.9459, -1.9459]],\n",
            "       grad_fn=<LogSoftmaxBackward0>)\n",
            "Training: 799\n",
            "Epoch: 0800 loss_train: 0.6476 acc_train: 0.8214 loss_val: 1.1186 acc_val: 0.6667 time: 1.7445s\n",
            "loss_val:1.1186362504959106, val_acc:0.6666666666666666, out_features:tensor([[-5.0313e+00, -5.7408e+00, -3.7679e-02,  ..., -4.9592e+00,\n",
            "         -5.4655e+00, -4.4393e+00],\n",
            "        [-1.9459e+00, -1.9459e+00, -1.9459e+00,  ..., -1.9459e+00,\n",
            "         -1.9459e+00, -1.9459e+00],\n",
            "        [-2.2551e+00, -2.9131e+00, -2.6992e+00,  ..., -5.8205e-01,\n",
            "         -2.5616e+00, -2.4033e+00],\n",
            "        ...,\n",
            "        [-2.5520e+00, -7.3207e-01, -3.6747e+00,  ..., -1.1613e+00,\n",
            "         -2.9911e+00, -3.4077e+00],\n",
            "        [-2.4824e-01, -3.7545e+00, -4.0841e+00,  ..., -2.3179e+00,\n",
            "         -3.1010e+00, -3.8384e+00],\n",
            "        [-9.5396e+00, -9.7246e+00, -2.8713e-04,  ..., -1.0468e+01,\n",
            "         -1.0104e+01, -1.0502e+01]], grad_fn=<LogSoftmaxBackward0>)\n",
            "Training: 800\n",
            "Epoch: 0801 loss_train: 0.5963 acc_train: 0.8143 loss_val: 1.0114 acc_val: 0.6733 time: 1.7415s\n",
            "loss_val:1.011435866355896, val_acc:0.6733333333333333, out_features:tensor([[-1.4575e+01, -1.4703e+01, -6.9141e-06,  ..., -1.4263e+01,\n",
            "         -1.4752e+01, -1.4755e+01],\n",
            "        [-6.1775e+00, -6.1565e+00, -6.0604e+00,  ..., -6.1216e+00,\n",
            "         -3.7551e-02, -3.7067e+00],\n",
            "        [-2.4782e+00, -2.3483e+00, -2.3730e+00,  ..., -8.1110e-01,\n",
            "         -2.5625e+00, -2.4616e+00],\n",
            "        ...,\n",
            "        [-4.3883e+00, -1.1962e-01, -4.1163e+00,  ..., -3.3213e+00,\n",
            "         -3.8992e+00, -4.1242e+00],\n",
            "        [-8.7667e-01, -2.7003e+00, -2.6174e+00,  ..., -2.6083e+00,\n",
            "         -1.5526e+00, -2.7716e+00],\n",
            "        [-7.8510e+00, -6.0725e+00, -5.9620e-03,  ..., -6.2919e+00,\n",
            "         -7.4745e+00, -7.8553e+00]], grad_fn=<LogSoftmaxBackward0>)\n",
            "Training: 801\n",
            "Epoch: 0802 loss_train: 0.6152 acc_train: 0.8071 loss_val: 1.0772 acc_val: 0.6233 time: 1.8775s\n",
            "loss_val:1.0772024393081665, val_acc:0.6233333333333333, out_features:tensor([[-1.1213e+01, -1.1060e+01, -1.3088e-04,  ..., -9.9321e+00,\n",
            "         -1.1026e+01, -1.0959e+01],\n",
            "        [-1.9459e+00, -1.9459e+00, -1.9459e+00,  ..., -1.9459e+00,\n",
            "         -1.9459e+00, -1.9459e+00],\n",
            "        [-2.7901e+00, -2.7186e+00, -3.3144e+00,  ..., -5.7180e-01,\n",
            "         -1.7818e+00, -2.8641e+00],\n",
            "        ...,\n",
            "        [-2.9676e+00, -2.3134e-01, -3.5477e+00,  ..., -3.5678e+00,\n",
            "         -3.1600e+00, -3.4082e+00],\n",
            "        [-2.6473e-01, -2.6458e+00, -3.5998e+00,  ..., -3.2395e+00,\n",
            "         -3.0871e+00, -3.5318e+00],\n",
            "        [-8.0976e+00, -6.6500e+00, -3.9078e-03,  ..., -7.3056e+00,\n",
            "         -7.9992e+00, -7.9066e+00]], grad_fn=<LogSoftmaxBackward0>)\n",
            "Training: 802\n",
            "Epoch: 0803 loss_train: 0.5805 acc_train: 0.8571 loss_val: 1.0836 acc_val: 0.6700 time: 1.9860s\n",
            "loss_val:1.0836073160171509, val_acc:0.67, out_features:tensor([[-7.6450e+00, -7.7049e+00, -9.0706e-03,  ..., -7.0618e+00,\n",
            "         -7.6295e+00, -6.7536e+00],\n",
            "        [-2.8982e+00, -4.2412e+00, -3.7061e+00,  ..., -3.2365e+00,\n",
            "         -3.3616e-01, -1.9631e+00],\n",
            "        [-3.5777e+00, -3.3794e+00, -2.9523e+00,  ..., -2.3894e-01,\n",
            "         -3.4965e+00, -3.3692e+00],\n",
            "        ...,\n",
            "        [-3.2032e+00, -4.3028e-01, -2.5760e+00,  ..., -2.8240e+00,\n",
            "         -2.5007e+00, -2.7432e+00],\n",
            "        [-1.1824e-01, -3.6843e+00, -4.2019e+00,  ..., -3.6574e+00,\n",
            "         -4.0027e+00, -4.3218e+00],\n",
            "        [-8.8012e+00, -8.6561e+00, -1.3272e-03,  ..., -8.6538e+00,\n",
            "         -7.9638e+00, -8.4111e+00]], grad_fn=<LogSoftmaxBackward0>)\n",
            "Training: 803\n",
            "Epoch: 0804 loss_train: 0.5030 acc_train: 0.8786 loss_val: 1.0215 acc_val: 0.6567 time: 1.7613s\n",
            "loss_val:1.0214886665344238, val_acc:0.6566666666666666, out_features:tensor([[-6.8490, -7.0723, -0.0092,  ..., -6.6869, -6.9125, -6.8128],\n",
            "        [-2.7682, -2.5219, -2.4479,  ..., -2.0297, -1.2796, -1.2729],\n",
            "        [-3.8684, -3.4364, -3.1508,  ..., -0.2001, -3.6772, -3.2258],\n",
            "        ...,\n",
            "        [-3.6451, -0.1456, -4.0726,  ..., -3.8373, -3.3572, -4.1822],\n",
            "        [-1.9459, -1.9459, -1.9459,  ..., -1.9459, -1.9459, -1.9459],\n",
            "        [-3.6985, -3.8163, -0.1680,  ..., -2.8850, -3.7843, -4.2968]],\n",
            "       grad_fn=<LogSoftmaxBackward0>)\n",
            "Training: 804\n",
            "Epoch: 0805 loss_train: 0.5584 acc_train: 0.8214 loss_val: 1.0184 acc_val: 0.6933 time: 1.7439s\n",
            "loss_val:1.0184131860733032, val_acc:0.6933333333333334, out_features:tensor([[-6.5261e+00, -5.7133e+00, -1.2825e-02,  ..., -6.4600e+00,\n",
            "         -6.3814e+00, -5.8852e+00],\n",
            "        [-1.9459e+00, -1.9459e+00, -1.9459e+00,  ..., -1.9459e+00,\n",
            "         -1.9459e+00, -1.9459e+00],\n",
            "        [-6.8754e+00, -5.0624e+00, -6.4190e+00,  ..., -1.3741e-02,\n",
            "         -6.4397e+00, -6.1936e+00],\n",
            "        ...,\n",
            "        [-3.7446e+00, -2.4322e-01, -2.9555e+00,  ..., -3.6796e+00,\n",
            "         -2.5854e+00, -3.7897e+00],\n",
            "        [-1.3994e-01, -4.0965e+00, -4.8079e+00,  ..., -2.7864e+00,\n",
            "         -3.7645e+00, -4.7127e+00],\n",
            "        [-1.0018e+01, -9.5923e+00, -3.3468e-04,  ..., -1.0114e+01,\n",
            "         -9.5370e+00, -9.5104e+00]], grad_fn=<LogSoftmaxBackward0>)\n",
            "Training: 805\n",
            "Epoch: 0806 loss_train: 0.6562 acc_train: 0.7786 loss_val: 0.9737 acc_val: 0.6900 time: 1.7373s\n",
            "loss_val:0.9737325310707092, val_acc:0.69, out_features:tensor([[-1.2226e+01, -1.2343e+01, -3.8742e-05,  ..., -1.2321e+01,\n",
            "         -1.1811e+01, -1.1338e+01],\n",
            "        [-1.9412e+00, -2.2478e+00, -2.2790e+00,  ..., -1.8232e+00,\n",
            "         -1.6870e+00, -1.4980e+00],\n",
            "        [-5.2896e+00, -5.8294e+00, -6.4827e+00,  ..., -1.7409e-02,\n",
            "         -6.0967e+00, -5.4617e+00],\n",
            "        ...,\n",
            "        [-6.0427e+00, -1.6372e-02, -6.5002e+00,  ..., -5.1309e+00,\n",
            "         -5.6427e+00, -6.3243e+00],\n",
            "        [-6.1818e-02, -3.7908e+00, -5.1796e+00,  ..., -4.8472e+00,\n",
            "         -4.3442e+00, -5.1961e+00],\n",
            "        [-3.4699e+00, -3.0321e+00, -2.7710e-01,  ..., -3.6991e+00,\n",
            "         -3.9325e+00, -3.9638e+00]], grad_fn=<LogSoftmaxBackward0>)\n",
            "Training: 806\n",
            "Epoch: 0807 loss_train: 0.6518 acc_train: 0.8071 loss_val: 1.1184 acc_val: 0.6200 time: 1.7355s\n",
            "loss_val:1.1184368133544922, val_acc:0.62, out_features:tensor([[-1.9459e+00, -1.9459e+00, -1.9459e+00,  ..., -1.9459e+00,\n",
            "         -1.9459e+00, -1.9459e+00],\n",
            "        [-1.2135e+01, -1.2165e+01, -1.2083e+01,  ..., -1.1622e+01,\n",
            "         -8.7342e-04, -7.0796e+00],\n",
            "        [-2.5243e+00, -2.0987e+00, -3.5519e+00,  ..., -4.5012e-01,\n",
            "         -2.5149e+00, -3.6185e+00],\n",
            "        ...,\n",
            "        [-4.4055e+00, -8.8031e-02, -4.6904e+00,  ..., -3.7460e+00,\n",
            "         -4.0406e+00, -4.2912e+00],\n",
            "        [-2.6210e-01, -2.9825e+00, -3.8925e+00,  ..., -2.6575e+00,\n",
            "         -3.1067e+00, -3.7264e+00],\n",
            "        [-5.0152e+00, -5.2950e+00, -4.1389e-02,  ..., -5.0606e+00,\n",
            "         -5.2364e+00, -5.1024e+00]], grad_fn=<LogSoftmaxBackward0>)\n",
            "Training: 807\n",
            "Epoch: 0808 loss_train: 0.5432 acc_train: 0.8143 loss_val: 0.9945 acc_val: 0.6567 time: 1.7585s\n",
            "loss_val:0.9944695234298706, val_acc:0.6566666666666666, out_features:tensor([[-8.2159e+00, -8.3419e+00, -3.9153e-02,  ..., -7.1605e+00,\n",
            "         -8.3081e+00, -8.2271e+00],\n",
            "        [-1.9459e+00, -1.9459e+00, -1.9459e+00,  ..., -1.9459e+00,\n",
            "         -1.9459e+00, -1.9459e+00],\n",
            "        [-9.1218e+00, -9.1603e+00, -8.2989e+00,  ..., -1.0323e-03,\n",
            "         -9.2179e+00, -7.8747e+00],\n",
            "        ...,\n",
            "        [-2.6669e+00, -9.8690e-01, -2.1170e+00,  ..., -2.1183e+00,\n",
            "         -2.4889e+00, -2.2660e+00],\n",
            "        [-1.2287e-01, -3.7457e+00, -5.0508e+00,  ..., -2.8802e+00,\n",
            "         -4.2131e+00, -4.9767e+00],\n",
            "        [-1.0341e+01, -1.0414e+01, -3.4934e-04,  ..., -1.0413e+01,\n",
            "         -1.0397e+01, -1.0440e+01]], grad_fn=<LogSoftmaxBackward0>)\n",
            "Training: 808\n",
            "Epoch: 0809 loss_train: 0.6124 acc_train: 0.8143 loss_val: 1.0075 acc_val: 0.6867 time: 1.8606s\n",
            "loss_val:1.0074553489685059, val_acc:0.6866666666666666, out_features:tensor([[-3.6790e+00, -3.2828e+00, -3.3354e-01,  ..., -2.9806e+00,\n",
            "         -3.0848e+00, -3.5122e+00],\n",
            "        [-1.9459e+00, -1.9459e+00, -1.9459e+00,  ..., -1.9459e+00,\n",
            "         -1.9459e+00, -1.9459e+00],\n",
            "        [-5.8977e+00, -5.6704e+00, -5.8982e+00,  ..., -1.7084e-02,\n",
            "         -5.9982e+00, -5.5836e+00],\n",
            "        ...,\n",
            "        [-1.9459e+00, -1.9459e+00, -1.9459e+00,  ..., -1.9459e+00,\n",
            "         -1.9459e+00, -1.9459e+00],\n",
            "        [-1.9052e-03, -9.0400e+00, -9.2437e+00,  ..., -7.6887e+00,\n",
            "         -6.9276e+00, -9.0224e+00],\n",
            "        [-7.1169e+00, -6.8092e+00, -9.7739e-03,  ..., -5.5151e+00,\n",
            "         -7.1857e+00, -6.9636e+00]], grad_fn=<LogSoftmaxBackward0>)\n",
            "Training: 809\n",
            "Epoch: 0810 loss_train: 0.6195 acc_train: 0.8500 loss_val: 0.9950 acc_val: 0.6833 time: 1.9865s\n",
            "loss_val:0.9950207471847534, val_acc:0.6833333333333333, out_features:tensor([[-6.2130e+00, -6.3944e+00, -6.0615e-02,  ..., -5.0235e+00,\n",
            "         -6.3280e+00, -6.2945e+00],\n",
            "        [-2.6720e+00, -2.1638e+00, -2.8076e+00,  ..., -1.8379e+00,\n",
            "         -1.3204e+00, -1.3436e+00],\n",
            "        [-5.3511e+00, -4.6228e+00, -5.8156e+00,  ..., -2.4252e-02,\n",
            "         -5.9919e+00, -6.2542e+00],\n",
            "        ...,\n",
            "        [-2.2651e+00, -2.8677e-01, -4.1139e+00,  ..., -3.8740e+00,\n",
            "         -2.8069e+00, -3.5114e+00],\n",
            "        [-2.5546e-03, -7.7362e+00, -8.7607e+00,  ..., -7.0385e+00,\n",
            "         -7.2613e+00, -8.5930e+00],\n",
            "        [-2.4089e+00, -2.8590e+00, -3.4887e-01,  ..., -3.6993e+00,\n",
            "         -2.6207e+00, -3.5492e+00]], grad_fn=<LogSoftmaxBackward0>)\n",
            "Training: 810\n",
            "Epoch: 0811 loss_train: 0.5723 acc_train: 0.8714 loss_val: 1.0046 acc_val: 0.6833 time: 1.7455s\n",
            "loss_val:1.0045896768569946, val_acc:0.6833333333333333, out_features:tensor([[-9.0874e+00, -9.1242e+00, -7.9183e-04,  ..., -8.8725e+00,\n",
            "         -9.0605e+00, -8.9111e+00],\n",
            "        [-2.4232e+00, -3.4921e+00, -3.5324e+00,  ..., -3.2269e+00,\n",
            "         -5.2867e-01, -1.7691e+00],\n",
            "        [-1.9459e+00, -1.9459e+00, -1.9459e+00,  ..., -1.9459e+00,\n",
            "         -1.9459e+00, -1.9459e+00],\n",
            "        ...,\n",
            "        [-2.2398e+00, -9.6403e-01, -1.8561e+00,  ..., -2.4893e+00,\n",
            "         -2.2105e+00, -2.3078e+00],\n",
            "        [-1.6142e-01, -3.7157e+00, -4.7214e+00,  ..., -3.4332e+00,\n",
            "         -2.8955e+00, -4.2823e+00],\n",
            "        [-3.5383e+00, -3.4724e+00, -1.7619e-01,  ..., -3.5233e+00,\n",
            "         -3.5166e+00, -3.6475e+00]], grad_fn=<LogSoftmaxBackward0>)\n",
            "Training: 811\n",
            "Epoch: 0812 loss_train: 0.6063 acc_train: 0.8000 loss_val: 1.0309 acc_val: 0.6667 time: 1.7435s\n",
            "loss_val:1.03091299533844, val_acc:0.6666666666666666, out_features:tensor([[-4.2446, -4.4422, -0.0985,  ..., -4.5919, -4.7790, -3.9497],\n",
            "        [-1.9459, -1.9459, -1.9459,  ..., -1.9459, -1.9459, -1.9459],\n",
            "        [-5.3453, -6.2324, -6.1324,  ..., -0.0155, -5.6866, -6.3819],\n",
            "        ...,\n",
            "        [-2.3498, -0.4210, -3.2720,  ..., -2.5520, -2.9801, -2.9307],\n",
            "        [-0.0654, -4.1819, -5.5192,  ..., -4.8674, -3.6192, -5.4536],\n",
            "        [-2.7339, -3.2783, -0.3325,  ..., -2.6015, -3.1406, -3.1676]],\n",
            "       grad_fn=<LogSoftmaxBackward0>)\n",
            "Training: 812\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Result Visualization"
      ],
      "metadata": {
        "id": "8ZTp2_-N-MYw"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 1. Visualize earned feature representation"
      ],
      "metadata": {
        "id": "3UEI30CvA4Ee"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# visualize learned feature representation\n",
        "def visualize_learnedFeature_tSNE(labels, out_features, dataset):\n",
        "    color_map = {0: \"red\", 1: \"blue\", 2: \"green\",\n",
        "                           3: \"orange\", 4: \"yellow\", 5: \"pink\", 6: \"gray\"}\n",
        "\n",
        "    if dataset =='citeseer':\n",
        "        num_classes = 6\n",
        "    elif dataset == 'cora':\n",
        "        num_classes = 7\n",
        "    elif dataset =='pubmed':\n",
        "        num_classes = 3\n",
        "    node_labels = labels.cpu().numpy()\n",
        "    out_features = out_features.cpu().detach().numpy()\n",
        "    t_sne_X = TSNE(n_components=2, perplexity=30, method='barnes_hut').fit_transform(out_features)\n",
        "\n",
        "    plt.figure()\n",
        "    for class_id in range(num_classes):\n",
        "        plt.scatter(t_sne_X[node_labels == class_id, 0],\n",
        "                    t_sne_X[node_labels == class_id, 1], s=20,\n",
        "                    color=color_map[class_id],\n",
        "                    edgecolors='black', linewidths=0.15)\n",
        "\n",
        "    plt.axis(\"off\")\n",
        "    plt.title(\"t-SNE projection of the learned features for \"+dataset)\n",
        "    plt.show()\n"
      ],
      "metadata": {
        "id": "WWKstE5n-Oo9"
      },
      "execution_count": 45,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "dataset = 'cora'\n",
        "visualize_learnedFeature_tSNE(labels, out_features, dataset)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 428
        },
        "id": "CU7eWQUME17s",
        "outputId": "7d1d44b4-24ea-4341-949b-31b93f8a4e24"
      },
      "execution_count": 46,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 640x480 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 2. Visulaize validation loss and accuracy"
      ],
      "metadata": {
        "id": "0j40yo9ZBDd6"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# visulaize validation loss and accuracy\n",
        "def visualize_validation_performance(val_acc, val_loss):\n",
        "    f, ax = plt.subplots(1, 2, figsize=(13, 5.5))\n",
        "    ax[0].plot(val_loss, linewidth=2, color=\"red\")\n",
        "    ax[0].set_title(\"Validation loss\")\n",
        "    ax[0].set_ylabel(\"Cross Entropy Loss\")\n",
        "    ax[0].set_xlabel(\"Epoch\")\n",
        "    ax[0].grid()\n",
        "    ax[1].plot(val_acc, linewidth=2, color=\"red\")\n",
        "    ax[1].set_title(\"Validation accuracy\")\n",
        "    ax[1].set_ylabel(\"Acc\")\n",
        "    ax[1].set_xlabel(\"Epoch\")\n",
        "    ax[1].grid()"
      ],
      "metadata": {
        "id": "xYrWJ6EsBC2v"
      },
      "execution_count": 47,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "visualize_validation_performance(val_acc_list, val_loss_list)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 486
        },
        "id": "HIxgL7ANBGU8",
        "outputId": "429359f3-9eea-44a5-b80d-c936a8316da8"
      },
      "execution_count": 48,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 1300x550 with 2 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "OLYjLBilFHpa"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}